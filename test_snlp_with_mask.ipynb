{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "\n",
    "This notebook provides an faster testing interface. \n",
    "\n",
    "It includes steps to \n",
    " - Check GPU availability\n",
    " - Set up the environment, \n",
    " - Define helper functions,\n",
    " - Run tests with a given **id** and **context_type**. \n",
    "\n",
    "The results are saved for further analysis.\n",
    "\n",
    "*Make sure to select the created `venv` as your kernel.*\n",
    "\n",
    "If there are any errors while running the tests, restart the the notebook, and run again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GPU Availability\n",
    "Run this cell to check if there is free space on the gpu. \n",
    "\n",
    "If the **free space** is not close to the **total space** then someone else is probably using the machine. \n",
    "\n",
    "You can check the active processes bu running `nvidia-smi` in the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: 23.2043 GiB free / 23.5766 GiB total\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_gpu_memory_torch():\n",
    "    if torch.cuda.is_available():\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            free_mem = torch.cuda.mem_get_info(i)[0] / 1024**3\n",
    "            total_mem = torch.cuda.get_device_properties(i).total_memory / 1024**3\n",
    "            print(f\"GPU {i}: {free_mem:.4f} GiB free / {total_mem:.4f} GiB total\")\n",
    "    else:\n",
    "        print(\"No CUDA-compatible GPU detected.\")\n",
    "\n",
    "get_gpu_memory_torch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "The code below imports necessary modules, defines directory paths, and sets the Hugging Face cache path.\n",
    "\n",
    "**No need to modify this.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_DIR = Path.cwd()\n",
    "HAYSTACK_DIR = PROJECT_DIR / \"haystack\"\n",
    "RELEVANT_DIR = HAYSTACK_DIR / \"relevant\"\n",
    "IRRELAVANT_DIR = HAYSTACK_DIR / \"irrelevant\"\n",
    "MISLEADING_IN_RELEVANT_DIR = HAYSTACK_DIR / \"misleading_in_relevant\"\n",
    "MISLEADING_IN_IRRELEVANT_DIR = HAYSTACK_DIR / \"misleading_in_irrelevant\"\n",
    "\n",
    "sys.path.append(str(PROJECT_DIR))\n",
    "\n",
    "with open(HAYSTACK_DIR / \"needles.json\", \"r\") as f:\n",
    "    NEEDLES_DATA = json.load(f)\n",
    "\n",
    "# This sets the Hugging Face cache path. Make sure this directory exists. If not, refer to the README.\n",
    "os.environ['HF_HOME'] = '.cache/hf_with_quota'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "def load_text(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "def insert_strings_at_sentence_breaks(text, insert_strings, context_length, tokenizer):\n",
    "    # Step 1: Tokenize and truncate\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=False)[:context_length]\n",
    "    \n",
    "    # Step 2: Detect sentence breaks by decoding each token\n",
    "    sentence_break_indices = [\n",
    "        i for i, tok in enumerate(tokens)\n",
    "        if tokenizer.decode([tok]).strip().endswith((\".\", \"!\", \"?\"))\n",
    "    ]\n",
    "\n",
    "    if len(sentence_break_indices) < len(insert_strings):\n",
    "        raise ValueError(f\"Only {len(sentence_break_indices)} sentence breaks found, \"\n",
    "                         f\"but {len(insert_strings)} insertions requested.\")\n",
    "\n",
    "    # Step 3: Compute evenly spaced sentence break positions\n",
    "    step = len(sentence_break_indices) // (len(insert_strings) + 1)\n",
    "    insert_positions = [sentence_break_indices[(i + 1) * step] + 1 for i in range(len(insert_strings))]\n",
    "\n",
    "    # Step 4: Insert insert_strings as tokens\n",
    "    for pos, insert_str in reversed(list(zip(insert_positions, insert_strings))):\n",
    "        insert_tokens = tokenizer.encode(insert_str, add_special_tokens=False)\n",
    "        tokens[pos:pos] = insert_tokens\n",
    "\n",
    "    return tokenizer.decode(tokens)\n",
    "\n",
    "\n",
    "def insert_misleading_statements(filepath, insert_strings, context_length, output_path):\n",
    "    \"\"\"\n",
    "    Insert misleading statements into the text at sentence breaks.\n",
    "    Evenly distribute the misleading statements across the text within the context length.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"yaofu/llama-2-7b-80k\")\n",
    "\n",
    "    full_text = load_text(filepath)\n",
    "    modified_text = insert_strings_at_sentence_breaks(full_text, insert_strings, context_length, tokenizer)\n",
    "\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(modified_text)\n",
    "\n",
    "    print(f\"âœ… Output saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "def get_haystack_file(item, context_type, with_misleading, context_length):\n",
    "    \"\"\"\n",
    "    Get the haystack file for the given item and context type.\n",
    "    Arguments:\n",
    "        item (dict): The item to process.\n",
    "        context_type (str): The type of context (\"relevant\" or \"irrelevant\").\n",
    "        with_misleading (bool): Whether to include misleading information.\n",
    "    Returns:\n",
    "        str: The path to the haystack file.\n",
    "    \"\"\"\n",
    "\n",
    "    if context_type == \"relevant\":\n",
    "        original_dir = RELEVANT_DIR\n",
    "        original_file = item[\"context_relevant\"]  # Original file without misleading info\n",
    "        misleading_dir = MISLEADING_IN_RELEVANT_DIR  # Output dir for the misleading file\n",
    "    elif context_type == \"irrelevant\":\n",
    "        original_dir = IRRELAVANT_DIR\n",
    "        original_file = item[\"context_irrelevant\"]\n",
    "        misleading_dir = MISLEADING_IN_IRRELEVANT_DIR\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown context_type: {context_type}\")\n",
    "\n",
    "    if with_misleading:\n",
    "        haystack_file = misleading_dir / original_file\n",
    "        insert_misleading_statements(\n",
    "            filepath=original_dir / original_file,           # Path to the original context file\n",
    "            insert_strings=item[\"statements_misleading\"],    # List of misleading statements\n",
    "            context_length=context_length,                   # Max context length for insertion\n",
    "            output_path=haystack_file                        # Output path for the processed file\n",
    "        )\n",
    "    else:\n",
    "        haystack_file = original_dir / original_file\n",
    "\n",
    "    return haystack_file\n",
    "\n",
    "def get_args(id, context_type, with_misleading, data=NEEDLES_DATA):\n",
    "    \"\"\"\n",
    "    Get the arguments for the given id and context type.\n",
    "    Arguments:\n",
    "        id (int): The id of the item.\n",
    "        context_type (str): The type of context (\"relevant\" or \"irrelevant\").\n",
    "        with_misleading (bool): Whether to include misleading information.\n",
    "        data (list): The list of data items.\n",
    "    Returns:\n",
    "        Namespace: The arguments for the given id and context type.\n",
    "    \"\"\"\n",
    "\n",
    "    context_length_max = 5000\n",
    "    \n",
    "    # find the item with the given id\n",
    "    item = next(item for item in data if item[\"id\"] == id)\n",
    "\n",
    "    # get the haystack file for the given item and context type\n",
    "    haystack_file = get_haystack_file(item, context_type, with_misleading, context_length_max)\n",
    "\n",
    "    args = Namespace(\n",
    "        model_name = \"yaofu/llama-2-7b-80k\",\n",
    "        model_name_suffix = ( f\"id_{item['id']}_{context_type}\" if not with_misleading \n",
    "                             else f\"id_{item['id']}_{context_type}_misleading\"), # suffix used to name the results files,\n",
    "        model_provider = \"LLaMA\",\n",
    "\n",
    "        context_lengths_min = 0, # min context length\n",
    "        context_lengths_max = context_length_max, # max context length\n",
    "        context_lengths_num_intervals = 5, # number of intervals for context lengths\n",
    "\n",
    "        document_depth_percent_intervals = 5, # number of intervals for document depth\n",
    "\n",
    "        needle = item[\"needle_refined\"],\n",
    "        real_needle = item[\"real_needle_refined\"],\n",
    "        retrieval_question = item[\"question_refined\"],\n",
    "        haystack_file = haystack_file,\n",
    "        mask_topk = 30\n",
    "    )\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "import importlib\n",
    "import retrieval_head_detection_snlp_with_mask\n",
    "importlib.reload(retrieval_head_detection_snlp_with_mask)\n",
    "from retrieval_head_detection_snlp_with_mask import LLMNeedleHaystackTester as RetrievalHeadsWithMask\n",
    "\n",
    "def cleanup(tester: RetrievalHeadsWithMask):\n",
    "    del tester.model_to_test\n",
    "    del tester.testing_results\n",
    "    del tester.head_counter\n",
    "    del tester\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "\n",
    "def run_test(args):\n",
    "    try:\n",
    "        tester = RetrievalHeadsWithMask(**vars(args))\n",
    "        tester.start_test()\n",
    "    finally:\n",
    "        cleanup(tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable path:\n",
      "/cs/student/projects1/2021/aagarwal/venv/bin/python\n",
      "\n",
      "Python environment site-packages:\n",
      "['/usr/lib64/python39.zip', '/usr/lib64/python3.9', '/usr/lib64/python3.9/lib-dynload', '', '/cs/student/projects1/2021/aagarwal/venv/lib64/python3.9/site-packages', '/cs/student/projects1/2021/aagarwal/venv/lib/python3.9/site-packages', '/cs/student/projects1/2021/aagarwal/SNLP_Project', '/tmp/tmpb9dcsslc', '/cs/student/projects1/2021/aagarwal/SNLP_Project', './faiss_attn/', '/cs/student/projects1/2021/aagarwal/SNLP_Project', './faiss_attn/', '/cs/student/projects1/2021/aagarwal/SNLP_Project', './faiss_attn/', '/cs/student/projects1/2021/aagarwal/SNLP_Project', './faiss_attn/', '/cs/student/projects1/2021/aagarwal/SNLP_Project', './faiss_attn/']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python executable path:\")\n",
    "print(sys.executable)\n",
    "\n",
    "print(\"\\nPython environment site-packages:\")\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runing the Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the test object:\n",
    "Specify the **id** and the **context_type** in the `get_args` function.\n",
    "\n",
    "If `with_misleading` is True, then misleading statements are added to the specified `context_type` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the Test\n",
    "\n",
    "Running the test will save:\n",
    "\n",
    "- **Contexts** â†’ Given to the model per context length/depth  \n",
    "  â†’ `contexts/{model_name}_{context_type}_id_{id}`\n",
    "\n",
    "- **Results** â†’ Model outputs per context length/depth  \n",
    "  â†’ `results/graph/{model_name}_{context_type}_id_{id}`\n",
    "\n",
    "**Example**:  \n",
    "`results/graph/llama-2-7b-80k_relevant_id_44/`\n",
    "\n",
    "Each test should take <=5 minutes. It sometimes uses the CPU instead of the GPU, if it is taking longer to finish, then restart the notebook and run again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[168, 17, 170, 172, 173, 175, 18, 180, 182, 183, 185, 189, 192, 193]\n"
     ]
    }
   ],
   "source": [
    "ids = []\n",
    "for file_name in os.listdir('./haystack/irrelevant'):\n",
    "    if file_name.endswith('.txt'):\n",
    "        file_id = os.path.splitext(file_name)[0]  # Extract the file name without extension\n",
    "        ids.append(file_id)\n",
    "ids.sort()\n",
    "id_vals = [int(i) for i in ids]\n",
    "print(id_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ba7382af6d64c08ad5d7bfa8d01953f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masking out top 30 retrieval heads\n",
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_0_depth_7500_results.json\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_1250_depth_0_results.json\n",
      "insertion at 230\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 449\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 753\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_1250_depth_7500_results.json\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 84.61538461538461\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Theresa May, who served from 2016 to 2019.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_2500_depth_0_results.json\n",
      "insertion at 449\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 30.76923076923077\n",
      "Response: Rishi Sunak, who served as Prime Minister from October 25, 2022 to February 25, 2023.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1081\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1661\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_2500_depth_7500_results.json\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_3750_depth_0_results.json\n",
      "insertion at 880\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1661\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2632\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_3750_depth_7500_results.json\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 84.61538461538461\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Theresa May, who served from 2016 to 2019.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1081\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2317\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3580\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_5000_depth_7500_results.json\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_block_top30/llama-2-7b-80k_id_168_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/aagarwal/SNLP_Project/haystack/misleading_in_relevant/168.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3ff99a906c54fd1b32b919f117f26ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masking out top 30 retrieval heads\n",
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_0_depth_7500_results.json\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 230\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak, the current Prime Minister of the United Kingdom, is the most recent former Prime Minister of the United Kingdom. He was previously the Chancellor of the Exchequer and was appointed Prime Minister on 25 October 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 467\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak, the current Prime Minister of the United Kingdom, is the most recent former Prime Minister of the United Kingdom. He was elected Prime Minister on October 25, 2022, and served until February 20\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 771\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak, the current Prime Minister of the United Kingdom, is the most recent former Prime Minister of the United Kingdom. He was elected to the position in October 2022 and served until February 2023.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_1250_depth_7500_results.json\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 30.76923076923077\n",
      "Response: Rishi Sunak, who served as Prime Minister from October 2022 to February 2023.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 467\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 30.76923076923077\n",
      "Response: Rishi Sunak, who served as Prime Minister from October 2022 to February 2023.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1120\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1636\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_2500_depth_7500_results.json\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 866\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1729\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2608\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_3750_depth_7500_results.json\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 30.76923076923077\n",
      "Response: Rishi Sunak, who served as Prime Minister from October 2022 to February 2023.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1120\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 30.76923076923077\n",
      "Response: Rishi Sunak, who served as Prime Minister from 2022 to 2023.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2385\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 30.76923076923077\n",
      "Response: Rishi Sunak, who served as Prime Minister from October 2022 to February 2023.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3586\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 30.76923076923077\n",
      "Response: Rishi Sunak, who served as Prime Minister from 2022 to 2023.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_5000_depth_7500_results.json\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading_block_top30/llama-2-7b-80k_id_168_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1739fbf5ec294c6895b24c6920f76fe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masking out top 30 retrieval heads\n",
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_0_depth_7500_results.json\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 84.61538461538461\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Boris Johnson. He served as Prime Minister from 2019 to 2022.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 255\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 84.61538461538461\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Boris Johnson. He served as Prime Minister from 2019 to 2022.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 485\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 84.61538461538461\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Boris Johnson. He served as Prime Minister from 2019 to 2022.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 768\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_1250_depth_7500_results.json\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 553\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 926\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1517\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_2500_depth_7500_results.json\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 84.61538461538461\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Boris Johnson. He served as Prime Minister from 2019 to 2022.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 871\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1517\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2485\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_3750_depth_7500_results.json\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 84.61538461538461\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Boris Johnson. He served as Prime Minister from 2019 to 2022.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 926\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2130\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3577\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_5000_depth_7500_results.json\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_block_top30/llama-2-7b-80k_id_168_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/aagarwal/SNLP_Project/haystack/misleading_in_irrelevant/168.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e8f643dd89d4f958990a8a5309da947",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "masking out top 30 retrieval heads\n",
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 255\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 485\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 755\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 553\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 944\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1535\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak, who was appointed on 25 October 2022.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 830\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1535\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2524\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 944\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2169\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3548\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "block_list:  [[16, 19], [11, 15], [8, 26], [6, 9], [17, 22], [19, 15], [7, 12], [21, 30], [11, 2], [7, 4], [18, 30], [6, 16], [24, 29], [15, 14], [6, 30], [24, 30], [17, 0], [16, 1], [20, 30], [21, 1], [17, 18], [29, 19], [14, 18], [13, 23], [22, 22], [21, 16], [17, 16], [22, 30], [22, 8], [22, 19]]  length:  30\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 15.384615384615385\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading_block_top30/llama-2-7b-80k_id_168_irrelevant_misleading_len_5000_depth_10000_results.json\n"
     ]
    }
   ],
   "source": [
    "for id in id_vals:\n",
    "    for context_type in [\"relevant\", \"irrelevant\"]:\n",
    "        for with_misleading in [False, True]:\n",
    "            args = get_args(id, context_type, with_misleading)\n",
    "            run_test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Relevant context without misleading statements\n",
    "# args = get_args(id=id_val, context_type=\"relevant\", with_misleading=False)\n",
    "# run_test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Irrelevant context without misleading statements\n",
    "# args = get_args(id=id_val, context_type=\"irrelevant\", with_misleading=False)\n",
    "# run_test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exmample 3: Relevant context with misleading statements\n",
    "# args = get_args(id=id_val, context_type=\"relevant\", with_misleading=True)\n",
    "# run_test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Irrelevant context with misleading statements\n",
    "# args = get_args(id=id_val, context_type=\"irrelevant\", with_misleading=True)\n",
    "# run_test(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
