{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "\n",
    "This notebook provides an faster testing interface. \n",
    "\n",
    "It includes steps to \n",
    " - Check GPU availability\n",
    " - Set up the environment, \n",
    " - Define helper functions,\n",
    " - Run tests with a given **id** and **context_type**. \n",
    "\n",
    "The results are saved for further analysis.\n",
    "\n",
    "*Make sure to select the created `venv` as your kernel.*\n",
    "\n",
    "If there are any errors while running the tests, restart the the notebook, and run again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GPU Availability\n",
    "Run this cell to check if there is free space on the gpu. \n",
    "\n",
    "If the **free space** is not close to the **total space** then someone else is probably using the machine. \n",
    "\n",
    "You can check the active processes bu running `nvidia-smi` in the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: 23.2003 GiB free / 23.5746 GiB total\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_gpu_memory_torch():\n",
    "    if torch.cuda.is_available():\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            free_mem = torch.cuda.mem_get_info(i)[0] / 1024**3\n",
    "            total_mem = torch.cuda.get_device_properties(i).total_memory / 1024**3\n",
    "            print(f\"GPU {i}: {free_mem:.4f} GiB free / {total_mem:.4f} GiB total\")\n",
    "    else:\n",
    "        print(\"No CUDA-compatible GPU detected.\")\n",
    "\n",
    "get_gpu_memory_torch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "The code below imports necessary modules, defines directory paths, and sets the Hugging Face cache path.\n",
    "\n",
    "**No need to modify this.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_DIR = Path.cwd()\n",
    "HAYSTACK_DIR = PROJECT_DIR / \"haystack\"\n",
    "RELEVANT_DIR = HAYSTACK_DIR / \"relevant\"\n",
    "IRRELAVANT_DIR = HAYSTACK_DIR / \"irrelevant\"\n",
    "MISLEADING_IN_RELEVANT_DIR = HAYSTACK_DIR / \"misleading_in_relevant\"\n",
    "MISLEADING_IN_IRRELEVANT_DIR = HAYSTACK_DIR / \"misleading_in_irrelevant\"\n",
    "\n",
    "sys.path.append(str(PROJECT_DIR))\n",
    "\n",
    "with open(HAYSTACK_DIR / \"needles.json\", \"r\") as f:\n",
    "    NEEDLES_DATA = json.load(f)\n",
    "\n",
    "# This sets the Hugging Face cache path. Make sure this directory exists. If not, refer to the README.\n",
    "os.environ['HF_HOME'] = '.cache/hf_with_quota'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/student/projects1/2021/jiajfang/SNLP_Project/venv/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "def load_text(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "def insert_strings_at_sentence_breaks(text, insert_strings, context_length, tokenizer):\n",
    "    # Step 1: Tokenize and truncate\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=False)[:context_length]\n",
    "    \n",
    "    # Step 2: Detect sentence breaks by decoding each token\n",
    "    sentence_break_indices = [\n",
    "        i for i, tok in enumerate(tokens)\n",
    "        if tokenizer.decode([tok]).strip().endswith((\".\", \"!\", \"?\"))\n",
    "    ]\n",
    "\n",
    "    if len(sentence_break_indices) < len(insert_strings):\n",
    "        raise ValueError(f\"Only {len(sentence_break_indices)} sentence breaks found, \"\n",
    "                         f\"but {len(insert_strings)} insertions requested.\")\n",
    "\n",
    "    # Step 3: Compute evenly spaced sentence break positions\n",
    "    step = len(sentence_break_indices) // (len(insert_strings) + 1)\n",
    "    insert_positions = [sentence_break_indices[(i + 1) * step] + 1 for i in range(len(insert_strings))]\n",
    "\n",
    "    # Step 4: Insert insert_strings as tokens\n",
    "    for pos, insert_str in reversed(list(zip(insert_positions, insert_strings))):\n",
    "        insert_tokens = tokenizer.encode(insert_str, add_special_tokens=False)\n",
    "        tokens[pos:pos] = insert_tokens\n",
    "\n",
    "    return tokenizer.decode(tokens)\n",
    "\n",
    "\n",
    "def insert_misleading_statements(filepath, insert_strings, context_length, output_path):\n",
    "    \"\"\"\n",
    "    Insert misleading statements into the text at sentence breaks.\n",
    "    Evenly distribute the misleading statements across the text within the context length.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"yaofu/llama-2-7b-80k\")\n",
    "\n",
    "    full_text = load_text(filepath)\n",
    "    modified_text = insert_strings_at_sentence_breaks(full_text, insert_strings, context_length, tokenizer)\n",
    "\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(modified_text)\n",
    "\n",
    "    print(f\"âœ… Output saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "def get_haystack_file(item, context_type, with_misleading, context_length):\n",
    "    \"\"\"\n",
    "    Get the haystack file for the given item and context type.\n",
    "    Arguments:\n",
    "        item (dict): The item to process.\n",
    "        context_type (str): The type of context (\"relevant\" or \"irrelevant\").\n",
    "        with_misleading (bool): Whether to include misleading information.\n",
    "    Returns:\n",
    "        str: The path to the haystack file.\n",
    "    \"\"\"\n",
    "\n",
    "    if context_type == \"relevant\":\n",
    "        original_dir = RELEVANT_DIR\n",
    "        original_file = item[\"context_relevant\"]  # Original file without misleading info\n",
    "        misleading_dir = MISLEADING_IN_RELEVANT_DIR  # Output dir for the misleading file\n",
    "    elif context_type == \"irrelevant\":\n",
    "        original_dir = IRRELAVANT_DIR\n",
    "        original_file = item[\"context_irrelevant\"]\n",
    "        misleading_dir = MISLEADING_IN_IRRELEVANT_DIR\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown context_type: {context_type}\")\n",
    "\n",
    "    if with_misleading:\n",
    "        haystack_file = misleading_dir / original_file\n",
    "        insert_misleading_statements(\n",
    "            filepath=original_dir / original_file,           # Path to the original context file\n",
    "            insert_strings=item[\"statements_misleading\"],    # List of misleading statements\n",
    "            context_length=context_length,                   # Max context length for insertion\n",
    "            output_path=haystack_file                        # Output path for the processed file\n",
    "        )\n",
    "    else:\n",
    "        haystack_file = original_dir / original_file\n",
    "\n",
    "    return haystack_file\n",
    "\n",
    "def get_args(id, context_type, with_misleading, data=NEEDLES_DATA):\n",
    "    \"\"\"\n",
    "    Get the arguments for the given id and context type.\n",
    "    Arguments:\n",
    "        id (int): The id of the item.\n",
    "        context_type (str): The type of context (\"relevant\" or \"irrelevant\").\n",
    "        with_misleading (bool): Whether to include misleading information.\n",
    "        data (list): The list of data items.\n",
    "    Returns:\n",
    "        Namespace: The arguments for the given id and context type.\n",
    "    \"\"\"\n",
    "\n",
    "    context_length_max = 5000\n",
    "    \n",
    "    # find the item with the given id\n",
    "    item = next(item for item in data if item[\"id\"] == id)\n",
    "\n",
    "    # get the haystack file for the given item and context type\n",
    "    haystack_file = get_haystack_file(item, context_type, with_misleading, context_length_max)\n",
    "\n",
    "    args = Namespace(\n",
    "        model_name = \"yaofu/llama-2-7b-80k\",\n",
    "        model_name_suffix = ( f\"id_{item['id']}_{context_type}\" if not with_misleading \n",
    "                             else f\"id_{item['id']}_{context_type}_misleading\"), # suffix used to name the results files,\n",
    "        model_provider = \"LLaMA\",\n",
    "\n",
    "        context_lengths_min = 0, # min context length\n",
    "        context_lengths_max = context_length_max, # max context length\n",
    "        context_lengths_num_intervals = 5, # number of intervals for context lengths\n",
    "\n",
    "        document_depth_percent_intervals = 5, # number of intervals for document depth\n",
    "\n",
    "        needle = item[\"needle_refined\"],\n",
    "        real_needle = item[\"real_needle_refined\"],\n",
    "        retrieval_question = item[\"question_refined\"],\n",
    "        haystack_file = haystack_file,\n",
    "    )\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "from retrieval_head_detection import LLMNeedleHaystackTester as RetrievalHeads\n",
    "\n",
    "def cleanup(tester: RetrievalHeads):\n",
    "    del tester.model_to_test\n",
    "    del tester.testing_results\n",
    "    del tester.head_counter\n",
    "    del tester\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "\n",
    "def run_test(args):\n",
    "    try:\n",
    "        tester = RetrievalHeads(**vars(args))\n",
    "        tester.start_test()\n",
    "    finally:\n",
    "        cleanup(tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable path:\n",
      "/cs/student/projects1/2021/jiajfang/SNLP_Project/venv/bin/python\n",
      "\n",
      "Python environment site-packages:\n",
      "['/usr/lib64/python39.zip', '/usr/lib64/python3.9', '/usr/lib64/python3.9/lib-dynload', '', '/cs/student/projects1/2021/jiajfang/SNLP_Project/venv/lib64/python3.9/site-packages', '/cs/student/projects1/2021/jiajfang/SNLP_Project/venv/lib/python3.9/site-packages', '/cs/student/projects1/2021/jiajfang/SNLP_Project', '/tmp/tmpajuruwil', './faiss_attn/']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python executable path:\")\n",
    "print(sys.executable)\n",
    "\n",
    "print(\"\\nPython environment site-packages:\")\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runing the Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the test object:\n",
    "Specify the **id** and the **context_type** in the `get_args` function.\n",
    "\n",
    "If `with_misleading` is True, then misleading statements are added to the specified `context_type` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the Test\n",
    "\n",
    "Running the test will save:\n",
    "\n",
    "- **Contexts** â†’ Given to the model per context length/depth  \n",
    "  â†’ `contexts/{model_name}_{context_type}_id_{id}`\n",
    "\n",
    "- **Results** â†’ Model outputs per context length/depth  \n",
    "  â†’ `results/graph/{model_name}_{context_type}_id_{id}`\n",
    "\n",
    "**Example**:  \n",
    "`results/graph/llama-2-7b-80k_relevant_id_44/`\n",
    "\n",
    "Each test should take <=5 minutes. It sometimes uses the CPU instead of the GPU, if it is taking longer to finish, then restart the notebook and run again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[168, 17, 170, 172, 173, 175, 18, 180, 182, 183, 185, 189, 192, 193]\n"
     ]
    }
   ],
   "source": [
    "ids = []\n",
    "for file_name in os.listdir('./haystack/irrelevant'):\n",
    "    if file_name.endswith('.txt'):\n",
    "        file_id = os.path.splitext(file_name)[0]  # Extract the file name without extension\n",
    "        ids.append(file_id)\n",
    "ids.sort()\n",
    "id_vals = [int(i) for i in ids[14:28]]\n",
    "print(id_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['19-15'], ['17-22'], ['8-22'], ['12-26'], ['21-30'], ['24-29'], ['31-16'], ['11-2'], ['15-14'], ['18-30'], ['19-14'], ['26-3'], ['28-14'], ['0-9'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['19-15'], ['17-22'], ['8-22'], ['12-26'], ['21-30'], ['24-29'], ['31-16'], ['11-2'], ['15-14'], ['18-30'], ['19-14'], ['26-3'], ['28-14'], ['0-9'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['19-15'], ['17-22'], ['8-22'], ['12-26'], ['21-30'], ['24-29'], ['31-16'], ['11-2'], ['15-14'], ['18-30'], ['19-14'], ['26-3'], ['28-14'], ['0-9'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['19-15'], ['17-22'], ['8-22'], ['12-26'], ['21-30'], ['24-29'], ['31-16'], ['11-2'], ['15-14'], ['18-30'], ['19-14'], ['26-3'], ['28-14'], ['0-9'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_0_depth_7500_results.json\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['19-15'], ['17-22'], ['8-22'], ['12-26'], ['21-30'], ['24-29'], ['31-16'], ['11-2'], ['15-14'], ['18-30'], ['19-14'], ['26-3'], ['28-14'], ['0-9'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['7-4'], ['16-19'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['24-29'], ['8-22'], ['12-26'], ['31-16'], ['18-30'], ['11-2'], ['15-14'], ['19-14'], ['26-3'], ['28-14'], ['6-30'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 66.26645922660828\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_1250_depth_0_results.json\n",
      "insertion at 230\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['7-4'], ['16-19'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['24-29'], ['8-22'], ['12-26'], ['31-16'], ['18-30'], ['11-2'], ['15-14'], ['19-14'], ['26-3'], ['28-14'], ['6-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 66.26645922660828\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 449\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['24-29'], ['18-30'], ['8-22'], ['12-26'], ['31-16'], ['6-30'], ['19-10'], ['11-2'], ['15-14'], ['19-14'], ['26-3'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 66.26645922660828\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 753\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['24-29'], ['18-30'], ['8-22'], ['12-26'], ['31-16'], ['19-10'], ['6-30'], ['28-14'], ['11-2'], ['13-11'], ['15-14'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 66.26645922660828\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_1250_depth_7500_results.json\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['24-29'], ['18-30'], ['31-16'], ['8-22'], ['12-26'], ['19-10'], ['6-30'], ['13-11'], ['28-14'], ['11-2'], ['15-14'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 66.26645922660828\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['24-29'], ['18-30'], ['31-16'], ['19-10'], ['6-30'], ['8-22'], ['11-2'], ['12-26'], ['13-11'], ['28-14'], ['24-3'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_2500_depth_0_results.json\n",
      "insertion at 449\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['24-29'], ['18-30'], ['19-10'], ['31-16'], ['6-30'], ['8-22'], ['7-12'], ['11-2'], ['12-26'], ['13-11'], ['24-3'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1081\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['24-29'], ['18-30'], ['19-10'], ['6-30'], ['7-12'], ['8-22'], ['31-16'], ['11-2'], ['13-11'], ['12-26'], ['24-3'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1661\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['24-29'], ['18-30'], ['19-10'], ['6-30'], ['7-12'], ['8-22'], ['31-16'], ['13-11'], ['11-2'], ['12-26'], ['24-3'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_2500_depth_7500_results.json\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['24-29'], ['18-30'], ['19-10'], ['6-30'], ['31-16'], ['7-12'], ['8-22'], ['13-11'], ['12-26'], ['11-2'], ['24-3'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 97.83648252487183\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['24-29'], ['19-10'], ['18-30'], ['7-12'], ['6-30'], ['11-2'], ['13-11'], ['31-16'], ['8-22'], ['12-26'], ['24-3'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_3750_depth_0_results.json\n",
      "insertion at 880\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['24-29'], ['19-10'], ['18-30'], ['7-12'], ['6-30'], ['13-11'], ['11-2'], ['31-16'], ['8-22'], ['12-26'], ['24-3'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1661\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['19-10'], ['24-29'], ['18-30'], ['7-12'], ['6-30'], ['13-11'], ['8-22'], ['11-2'], ['31-16'], ['24-3'], ['12-26'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2632\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['18-30'], ['19-10'], ['24-29'], ['7-12'], ['6-30'], ['13-11'], ['8-22'], ['11-2'], ['31-16'], ['24-3'], ['7-31'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_3750_depth_7500_results.json\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['18-30'], ['19-10'], ['24-29'], ['6-30'], ['7-12'], ['13-11'], ['31-16'], ['8-22'], ['24-3'], ['11-2'], ['26-28'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 97.83648252487183\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['19-10'], ['7-12'], ['18-30'], ['24-29'], ['6-30'], ['13-11'], ['11-2'], ['31-16'], ['24-3'], ['8-22'], ['7-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1081\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['7-12'], ['19-10'], ['24-29'], ['18-30'], ['6-30'], ['11-2'], ['13-11'], ['24-3'], ['31-16'], ['14-18'], ['7-31'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2317\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['19-15'], ['17-22'], ['7-12'], ['21-30'], ['19-10'], ['24-29'], ['18-30'], ['6-30'], ['11-2'], ['13-11'], ['14-18'], ['24-3'], ['31-16'], ['7-31'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3580\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['19-10'], ['24-29'], ['18-30'], ['6-30'], ['11-2'], ['13-11'], ['14-18'], ['24-3'], ['7-31'], ['8-22'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_5000_depth_7500_results.json\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['19-10'], ['24-29'], ['18-30'], ['6-30'], ['11-2'], ['13-11'], ['14-18'], ['24-3'], ['29-26'], ['31-16'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 97.83648252487183\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant/llama-2-7b-80k_id_168_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/168.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['19-15'], ['17-22'], ['8-22'], ['12-26'], ['21-30'], ['24-29'], ['31-16'], ['11-2'], ['15-14'], ['18-30'], ['19-14'], ['26-3'], ['28-14'], ['0-9'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['19-15'], ['17-22'], ['8-22'], ['12-26'], ['21-30'], ['24-29'], ['31-16'], ['11-2'], ['15-14'], ['18-30'], ['19-14'], ['26-3'], ['28-14'], ['0-9'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['19-15'], ['17-22'], ['8-22'], ['12-26'], ['21-30'], ['24-29'], ['31-16'], ['11-2'], ['15-14'], ['18-30'], ['19-14'], ['26-3'], ['28-14'], ['0-9'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['19-15'], ['17-22'], ['8-22'], ['12-26'], ['21-30'], ['24-29'], ['31-16'], ['11-2'], ['15-14'], ['18-30'], ['19-14'], ['26-3'], ['28-14'], ['0-9'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_0_depth_7500_results.json\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['19-15'], ['17-22'], ['8-22'], ['12-26'], ['21-30'], ['24-29'], ['31-16'], ['11-2'], ['15-14'], ['18-30'], ['19-14'], ['26-3'], ['28-14'], ['0-9'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['24-29'], ['21-30'], ['31-16'], ['8-22'], ['12-26'], ['11-2'], ['26-3'], ['15-14'], ['18-30'], ['19-14'], ['28-14'], ['14-18'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 230\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['24-29'], ['11-2'], ['21-30'], ['31-16'], ['8-22'], ['12-26'], ['26-3'], ['15-14'], ['18-30'], ['19-14'], ['28-14'], ['14-18'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 75.32930374145508\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak. The first to use the title in an official act was Benjamin Disraeli who signed the 1878 Treaty of Berlin as \"Prime Minister of Her\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 467\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['24-29'], ['11-2'], ['21-30'], ['31-16'], ['8-22'], ['12-26'], ['18-30'], ['26-3'], ['7-12'], ['15-14'], ['19-14'], ['28-14'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 97.83648252487183\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 771\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['24-29'], ['11-2'], ['21-30'], ['31-16'], ['8-22'], ['12-26'], ['18-30'], ['26-3'], ['7-12'], ['15-14'], ['14-18'], ['19-10'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 97.83648252487183\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['24-29'], ['12-26'], ['21-30'], ['31-16'], ['8-22'], ['18-30'], ['11-2'], ['26-3'], ['14-18'], ['15-14'], ['7-12'], ['19-10'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['24-29'], ['11-2'], ['12-26'], ['21-30'], ['31-16'], ['8-22'], ['18-30'], ['14-18'], ['26-3'], ['7-12'], ['15-14'], ['19-10'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 467\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['24-29'], ['21-30'], ['11-2'], ['12-26'], ['18-30'], ['31-16'], ['7-12'], ['8-22'], ['14-18'], ['26-3'], ['15-14'], ['19-10'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 97.83648252487183\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1120\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['24-29'], ['21-30'], ['11-2'], ['12-26'], ['18-30'], ['7-12'], ['31-16'], ['8-22'], ['14-18'], ['26-3'], ['15-14'], ['19-10'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1636\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['19-15'], ['8-26'], ['17-22'], ['24-29'], ['18-30'], ['21-30'], ['11-2'], ['12-26'], ['31-16'], ['7-12'], ['14-18'], ['8-22'], ['26-3'], ['19-10'], ['15-14'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['19-15'], ['8-26'], ['17-22'], ['21-30'], ['24-29'], ['18-30'], ['12-26'], ['31-16'], ['11-2'], ['8-22'], ['26-3'], ['7-12'], ['14-18'], ['19-10'], ['15-14'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 97.83648252487183\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['24-29'], ['18-30'], ['12-26'], ['31-16'], ['11-2'], ['7-12'], ['14-18'], ['8-22'], ['19-10'], ['26-3'], ['15-14'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 97.83648252487183\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 866\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['19-15'], ['8-26'], ['17-22'], ['24-29'], ['18-30'], ['21-30'], ['7-12'], ['12-26'], ['31-16'], ['11-2'], ['14-18'], ['19-10'], ['8-22'], ['26-3'], ['15-14'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 66.26645922660828\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1729\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['8-26'], ['17-22'], ['18-30'], ['24-29'], ['21-30'], ['7-12'], ['12-26'], ['31-16'], ['11-2'], ['14-18'], ['19-10'], ['8-22'], ['26-3'], ['15-14'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2608\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['8-26'], ['17-22'], ['18-30'], ['24-29'], ['21-30'], ['7-12'], ['14-18'], ['31-16'], ['12-26'], ['19-10'], ['11-2'], ['8-22'], ['26-3'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['8-26'], ['17-22'], ['18-30'], ['21-30'], ['24-29'], ['31-16'], ['7-12'], ['12-26'], ['19-10'], ['14-18'], ['11-2'], ['26-3'], ['8-22'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 97.83648252487183\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['8-26'], ['17-22'], ['18-30'], ['24-29'], ['21-30'], ['31-16'], ['7-12'], ['12-26'], ['19-10'], ['14-18'], ['11-2'], ['26-3'], ['26-28'], ['8-22'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 85.16755700111389\n",
      "Response: Rishi Sunak, who was the Prime Minister of the United Kingdom from October 2022 to February 2023.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1120\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['8-26'], ['17-22'], ['18-30'], ['24-29'], ['21-30'], ['7-12'], ['31-16'], ['19-10'], ['12-26'], ['14-18'], ['26-28'], ['11-2'], ['26-3'], ['29-26'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2385\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['24-29'], ['21-30'], ['7-12'], ['31-16'], ['19-10'], ['14-18'], ['12-26'], ['26-28'], ['29-26'], ['11-2'], ['26-3'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 53.2046914100647\n",
      "Response: Rishi Sunak. 1760â€“1820\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3586\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['24-29'], ['21-30'], ['7-12'], ['19-10'], ['31-16'], ['14-18'], ['12-26'], ['26-28'], ['29-26'], ['11-2'], ['26-3'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 53.2046914100647\n",
      "Response: Rishi Sunak. 1760â€“1820\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['8-26'], ['17-22'], ['18-30'], ['21-30'], ['24-29'], ['19-10'], ['31-16'], ['7-12'], ['14-18'], ['26-28'], ['12-26'], ['29-26'], ['26-3'], ['15-14'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 97.83648252487183\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_relevant_misleading/llama-2-7b-80k_id_168_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['19-15'], ['17-22'], ['8-22'], ['12-26'], ['21-30'], ['24-29'], ['31-16'], ['11-2'], ['15-14'], ['18-30'], ['19-14'], ['26-3'], ['28-14'], ['0-9'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['19-15'], ['17-22'], ['8-22'], ['12-26'], ['21-30'], ['24-29'], ['31-16'], ['11-2'], ['15-14'], ['18-30'], ['19-14'], ['26-3'], ['28-14'], ['0-9'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['19-15'], ['17-22'], ['8-22'], ['12-26'], ['21-30'], ['24-29'], ['31-16'], ['11-2'], ['15-14'], ['18-30'], ['19-14'], ['26-3'], ['28-14'], ['0-9'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['19-15'], ['17-22'], ['8-22'], ['12-26'], ['21-30'], ['24-29'], ['31-16'], ['11-2'], ['15-14'], ['18-30'], ['19-14'], ['26-3'], ['28-14'], ['0-9'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_0_depth_7500_results.json\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['19-15'], ['17-22'], ['8-22'], ['12-26'], ['21-30'], ['24-29'], ['31-16'], ['11-2'], ['15-14'], ['18-30'], ['19-14'], ['26-3'], ['28-14'], ['0-9'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['24-29'], ['8-22'], ['11-2'], ['12-26'], ['31-16'], ['15-14'], ['18-30'], ['19-14'], ['26-3'], ['28-14'], ['14-18'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 89.11471962928772\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak, who served as Prime Minister from October 25, 2022 to February 20, 2023.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 255\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['11-2'], ['21-30'], ['24-29'], ['7-12'], ['8-22'], ['12-26'], ['31-16'], ['14-18'], ['15-14'], ['18-30'], ['19-14'], ['26-3'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 485\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['7-12'], ['11-2'], ['21-30'], ['24-29'], ['8-22'], ['12-26'], ['14-18'], ['31-16'], ['18-30'], ['19-10'], ['15-14'], ['19-14'], ['26-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 768\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['7-12'], ['11-2'], ['21-30'], ['24-29'], ['8-22'], ['14-18'], ['12-26'], ['31-16'], ['18-30'], ['19-10'], ['26-3'], ['28-14'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_1250_depth_7500_results.json\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['7-12'], ['11-2'], ['24-29'], ['8-22'], ['12-26'], ['31-16'], ['18-30'], ['14-18'], ['19-10'], ['26-3'], ['28-14'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 97.83648252487183\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['7-12'], ['21-30'], ['11-2'], ['24-29'], ['8-22'], ['14-18'], ['31-16'], ['12-26'], ['18-30'], ['19-10'], ['26-3'], ['28-14'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 93.44790577888489\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak, who served as Prime Minister from 2022 to 2023.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 553\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['7-12'], ['21-30'], ['11-2'], ['24-29'], ['8-22'], ['14-18'], ['18-30'], ['19-10'], ['31-16'], ['12-26'], ['26-3'], ['28-14'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 926\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['7-12'], ['21-30'], ['11-2'], ['24-29'], ['8-22'], ['18-30'], ['14-18'], ['19-10'], ['31-16'], ['12-26'], ['28-14'], ['13-11'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1517\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['7-12'], ['21-30'], ['11-2'], ['24-29'], ['8-22'], ['18-30'], ['19-10'], ['14-18'], ['31-16'], ['12-26'], ['28-14'], ['6-30'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_2500_depth_7500_results.json\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['7-12'], ['21-30'], ['24-29'], ['11-2'], ['8-22'], ['18-30'], ['19-10'], ['14-18'], ['31-16'], ['12-26'], ['28-14'], ['6-30'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 97.83648252487183\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['19-15'], ['17-22'], ['7-12'], ['21-30'], ['11-2'], ['24-29'], ['19-10'], ['8-22'], ['18-30'], ['14-18'], ['31-16'], ['12-26'], ['6-30'], ['13-11'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 89.11471962928772\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak, who served as Prime Minister from October 25, 2022 to February 20, 2023.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 871\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['19-15'], ['7-12'], ['17-22'], ['21-30'], ['11-2'], ['24-29'], ['18-30'], ['19-10'], ['8-22'], ['14-18'], ['31-16'], ['6-30'], ['12-26'], ['13-11'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1517\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['19-15'], ['7-12'], ['17-22'], ['21-30'], ['11-2'], ['24-29'], ['19-10'], ['14-18'], ['18-30'], ['8-22'], ['6-30'], ['13-11'], ['31-16'], ['12-26'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2485\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['19-15'], ['7-12'], ['17-22'], ['21-30'], ['11-2'], ['24-29'], ['19-10'], ['14-18'], ['18-30'], ['8-22'], ['6-30'], ['13-11'], ['26-28'], ['24-3'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_3750_depth_7500_results.json\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['19-15'], ['7-12'], ['17-22'], ['21-30'], ['11-2'], ['24-29'], ['19-10'], ['18-30'], ['14-18'], ['8-22'], ['6-30'], ['13-11'], ['26-28'], ['31-16'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 66.26645922660828\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['19-15'], ['7-12'], ['17-22'], ['21-30'], ['11-2'], ['24-29'], ['19-10'], ['14-18'], ['18-30'], ['8-22'], ['6-30'], ['13-11'], ['26-28'], ['31-16'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 89.68417644500732\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak, who served as Prime Minister from 25 October 2022 to 25 January 2023.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 926\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['19-15'], ['7-12'], ['17-22'], ['21-30'], ['11-2'], ['19-10'], ['24-29'], ['14-18'], ['18-30'], ['8-22'], ['6-30'], ['26-28'], ['13-11'], ['24-3'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2130\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['19-15'], ['7-12'], ['17-22'], ['21-30'], ['11-2'], ['19-10'], ['24-29'], ['14-18'], ['18-30'], ['8-22'], ['26-28'], ['6-30'], ['13-11'], ['24-3'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3577\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['7-4'], ['7-12'], ['17-22'], ['21-30'], ['19-10'], ['11-2'], ['24-29'], ['18-30'], ['14-18'], ['8-22'], ['26-28'], ['6-30'], ['13-11'], ['24-3'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_5000_depth_7500_results.json\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['7-4'], ['7-12'], ['17-22'], ['21-30'], ['19-10'], ['24-29'], ['11-2'], ['18-30'], ['14-18'], ['8-22'], ['26-28'], ['6-30'], ['13-11'], ['24-3'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 66.26645922660828\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant/llama-2-7b-80k_id_168_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/168.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['19-15'], ['17-22'], ['8-22'], ['12-26'], ['21-30'], ['24-29'], ['31-16'], ['11-2'], ['15-14'], ['18-30'], ['19-14'], ['26-3'], ['28-14'], ['0-9'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['19-15'], ['17-22'], ['8-22'], ['12-26'], ['21-30'], ['24-29'], ['31-16'], ['11-2'], ['15-14'], ['18-30'], ['19-14'], ['26-3'], ['28-14'], ['0-9'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['19-15'], ['17-22'], ['8-22'], ['12-26'], ['21-30'], ['24-29'], ['31-16'], ['11-2'], ['15-14'], ['18-30'], ['19-14'], ['26-3'], ['28-14'], ['0-9'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['19-15'], ['17-22'], ['8-22'], ['12-26'], ['21-30'], ['24-29'], ['31-16'], ['11-2'], ['15-14'], ['18-30'], ['19-14'], ['26-3'], ['28-14'], ['0-9'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['19-15'], ['17-22'], ['8-22'], ['12-26'], ['21-30'], ['24-29'], ['31-16'], ['11-2'], ['15-14'], ['18-30'], ['19-14'], ['26-3'], ['28-14'], ['0-9'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['24-29'], ['31-16'], ['8-22'], ['12-26'], ['11-2'], ['15-14'], ['18-30'], ['19-14'], ['26-3'], ['28-14'], ['19-10'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 255\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['24-29'], ['7-12'], ['11-2'], ['31-16'], ['8-22'], ['12-26'], ['15-14'], ['18-30'], ['19-14'], ['26-3'], ['28-14'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 485\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['7-12'], ['21-30'], ['24-29'], ['11-2'], ['31-16'], ['8-22'], ['12-26'], ['18-30'], ['19-10'], ['28-14'], ['15-14'], ['19-14'], ['26-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 755\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['7-12'], ['21-30'], ['24-29'], ['11-2'], ['31-16'], ['8-22'], ['12-26'], ['18-30'], ['19-10'], ['28-14'], ['14-18'], ['15-14'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['7-12'], ['21-30'], ['24-29'], ['31-16'], ['11-2'], ['12-26'], ['8-22'], ['18-30'], ['19-10'], ['28-14'], ['15-14'], ['26-3'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 97.83648252487183\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['7-12'], ['21-30'], ['24-29'], ['31-16'], ['11-2'], ['12-26'], ['8-22'], ['18-30'], ['19-10'], ['28-14'], ['15-14'], ['26-3'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 97.83648252487183\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 553\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['7-12'], ['17-22'], ['21-30'], ['24-29'], ['11-2'], ['31-16'], ['18-30'], ['12-26'], ['19-10'], ['8-22'], ['28-14'], ['26-28'], ['15-14'], ['26-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 97.83648252487183\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 944\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['7-12'], ['17-22'], ['21-30'], ['24-29'], ['18-30'], ['11-2'], ['19-10'], ['31-16'], ['8-22'], ['12-26'], ['26-28'], ['28-14'], ['14-18'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1535\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['19-15'], ['7-12'], ['17-22'], ['21-30'], ['24-29'], ['18-30'], ['19-10'], ['31-16'], ['11-2'], ['8-22'], ['12-26'], ['26-28'], ['28-14'], ['14-18'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 97.83648252487183\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['19-15'], ['8-26'], ['17-22'], ['7-12'], ['21-30'], ['18-30'], ['24-29'], ['19-10'], ['31-16'], ['8-22'], ['12-26'], ['11-2'], ['26-28'], ['28-14'], ['14-18'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 97.83648252487183\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['7-4'], ['7-12'], ['17-22'], ['21-30'], ['24-29'], ['18-30'], ['19-10'], ['31-16'], ['11-2'], ['8-22'], ['12-26'], ['26-28'], ['28-14'], ['14-18'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 97.83648252487183\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 830\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['21-30'], ['18-30'], ['24-29'], ['19-10'], ['31-16'], ['11-2'], ['26-28'], ['8-22'], ['12-26'], ['28-14'], ['14-18'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1535\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['21-30'], ['18-30'], ['24-29'], ['19-10'], ['31-16'], ['26-28'], ['11-2'], ['8-22'], ['12-26'], ['14-18'], ['28-14'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2524\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['21-30'], ['18-30'], ['24-29'], ['19-10'], ['31-16'], ['26-28'], ['11-2'], ['8-22'], ['12-26'], ['14-18'], ['28-14'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['21-30'], ['18-30'], ['19-10'], ['24-29'], ['31-16'], ['26-28'], ['12-26'], ['8-22'], ['11-2'], ['14-18'], ['28-14'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 97.83648252487183\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['18-30'], ['24-29'], ['19-10'], ['31-16'], ['26-28'], ['12-26'], ['8-22'], ['11-2'], ['14-18'], ['28-14'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 66.26645922660828\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 944\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['21-30'], ['18-30'], ['19-10'], ['24-29'], ['26-28'], ['31-16'], ['12-26'], ['11-2'], ['8-22'], ['14-18'], ['29-26'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 97.83648252487183\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2169\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['21-30'], ['19-10'], ['18-30'], ['24-29'], ['26-28'], ['31-16'], ['12-26'], ['11-2'], ['8-22'], ['14-18'], ['29-26'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3548\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['21-30'], ['18-30'], ['19-10'], ['24-29'], ['26-28'], ['31-16'], ['12-26'], ['8-22'], ['11-2'], ['14-18'], ['29-26'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 64.4255518913269\n",
      "Response: Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The most recent former Prime Minister of the United Kingdom is Rishi Sunak.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['21-30'], ['18-30'], ['19-10'], ['24-29'], ['26-28'], ['31-16'], ['12-26'], ['8-22'], ['29-26'], ['11-2'], ['14-18'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 97.83648252487183\n",
      "Response: Rishi Sunak is the most recent former Prime Minister of the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_168_irrelevant_misleading/llama-2-7b-80k_id_168_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['21-30'], ['6-30'], ['8-26'], ['17-22'], ['19-15'], ['12-26'], ['15-14'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['24-29'], ['31-16'], ['8-31'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['21-30'], ['6-30'], ['8-26'], ['17-22'], ['19-15'], ['12-26'], ['15-14'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['24-29'], ['31-16'], ['8-31'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['21-30'], ['6-30'], ['8-26'], ['17-22'], ['19-15'], ['12-26'], ['15-14'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['24-29'], ['31-16'], ['8-31'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['21-30'], ['6-30'], ['8-26'], ['17-22'], ['19-15'], ['12-26'], ['15-14'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['24-29'], ['31-16'], ['8-31'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_0_depth_7500_results.json\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['21-30'], ['6-30'], ['8-26'], ['17-22'], ['19-15'], ['12-26'], ['15-14'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['24-29'], ['31-16'], ['8-31'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['7-4'], ['17-22'], ['8-26'], ['6-30'], ['19-15'], ['24-29'], ['18-30'], ['22-19'], ['21-28'], ['24-3'], ['31-16'], ['12-26'], ['15-14'], ['13-11'], ['26-28'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 83.27487707138062\n",
      "Response: The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton for their contributions to the theory of neural networks.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_1250_depth_0_results.json\n",
      "insertion at 250\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['7-4'], ['17-22'], ['8-26'], ['19-15'], ['6-30'], ['18-30'], ['22-19'], ['21-28'], ['24-29'], ['24-3'], ['31-16'], ['15-14'], ['12-26'], ['13-11'], ['26-28'], ['20-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 481\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['7-4'], ['17-22'], ['8-26'], ['19-15'], ['6-30'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['31-16'], ['24-29'], ['15-14'], ['20-10'], ['12-26'], ['13-11'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 687\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['7-4'], ['17-22'], ['8-26'], ['19-15'], ['6-30'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['31-16'], ['15-14'], ['20-10'], ['24-29'], ['13-11'], ['26-28'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_1250_depth_7500_results.json\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['7-4'], ['17-22'], ['8-26'], ['19-15'], ['6-30'], ['18-30'], ['21-28'], ['31-16'], ['22-19'], ['20-10'], ['24-3'], ['15-14'], ['24-29'], ['12-26'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['19-15'], ['6-30'], ['18-30'], ['21-28'], ['22-19'], ['31-16'], ['24-3'], ['24-29'], ['20-10'], ['13-11'], ['15-14'], ['26-28'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 92.97164678573608\n",
      "Response: The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton for their contributions to the field of artificial intelligence.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_2500_depth_0_results.json\n",
      "insertion at 536\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['19-15'], ['6-30'], ['18-30'], ['21-28'], ['22-19'], ['31-16'], ['20-10'], ['24-3'], ['24-29'], ['7-12'], ['13-11'], ['15-14'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1104\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['19-15'], ['18-30'], ['6-30'], ['21-28'], ['22-19'], ['31-16'], ['20-10'], ['7-12'], ['24-3'], ['24-29'], ['13-11'], ['15-14'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1687\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['8-26'], ['17-22'], ['6-9'], ['7-4'], ['19-15'], ['18-30'], ['6-30'], ['21-28'], ['22-19'], ['31-16'], ['20-10'], ['7-12'], ['17-0'], ['13-11'], ['15-14'], ['24-3'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_2500_depth_7500_results.json\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['8-26'], ['17-22'], ['6-9'], ['7-4'], ['19-15'], ['18-30'], ['6-30'], ['21-28'], ['31-16'], ['20-10'], ['22-19'], ['17-0'], ['7-12'], ['24-3'], ['13-11'], ['15-14'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['8-26'], ['17-22'], ['6-9'], ['7-4'], ['19-15'], ['18-30'], ['6-30'], ['21-28'], ['20-10'], ['22-19'], ['31-16'], ['7-12'], ['17-0'], ['13-11'], ['24-29'], ['26-28'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_3750_depth_0_results.json\n",
      "insertion at 866\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['8-26'], ['17-22'], ['6-9'], ['7-4'], ['19-15'], ['18-30'], ['6-30'], ['21-28'], ['7-12'], ['20-10'], ['22-19'], ['31-16'], ['17-0'], ['13-11'], ['26-28'], ['24-3'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1754\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['8-26'], ['17-22'], ['6-9'], ['7-4'], ['19-15'], ['18-30'], ['6-30'], ['7-12'], ['20-10'], ['21-28'], ['22-19'], ['31-16'], ['17-0'], ['13-11'], ['26-28'], ['15-14'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2621\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['8-26'], ['17-22'], ['6-9'], ['7-4'], ['19-15'], ['18-30'], ['6-30'], ['20-10'], ['7-12'], ['21-28'], ['22-19'], ['17-0'], ['31-16'], ['13-11'], ['26-28'], ['15-14'], ['21-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_3750_depth_7500_results.json\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['8-26'], ['17-22'], ['6-9'], ['7-4'], ['19-15'], ['18-30'], ['6-30'], ['20-10'], ['21-28'], ['7-12'], ['17-0'], ['22-19'], ['31-16'], ['13-11'], ['26-28'], ['24-3'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 20.50291895866394\n",
      "Response: John Mather and George Smoot\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1172\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['8-26'], ['17-22'], ['6-9'], ['7-4'], ['19-15'], ['18-30'], ['6-30'], ['20-10'], ['7-12'], ['21-28'], ['17-0'], ['22-19'], ['31-16'], ['13-11'], ['26-28'], ['15-14'], ['21-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2376\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['8-26'], ['17-22'], ['6-9'], ['7-4'], ['19-15'], ['18-30'], ['6-30'], ['20-10'], ['7-12'], ['17-0'], ['21-28'], ['22-19'], ['31-16'], ['13-11'], ['26-28'], ['15-14'], ['21-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3522\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['8-26'], ['17-22'], ['6-9'], ['7-4'], ['19-15'], ['18-30'], ['6-30'], ['20-10'], ['7-12'], ['17-0'], ['21-28'], ['22-19'], ['31-16'], ['13-11'], ['26-28'], ['15-14'], ['21-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_5000_depth_7500_results.json\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['8-26'], ['17-22'], ['6-9'], ['7-4'], ['19-15'], ['18-30'], ['6-30'], ['20-10'], ['7-12'], ['21-28'], ['17-0'], ['22-19'], ['31-16'], ['13-11'], ['26-28'], ['15-14'], ['21-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant/llama-2-7b-80k_id_17_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/17.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['21-30'], ['6-30'], ['8-26'], ['17-22'], ['19-15'], ['12-26'], ['15-14'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['24-29'], ['31-16'], ['8-31'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['21-30'], ['6-30'], ['8-26'], ['17-22'], ['19-15'], ['12-26'], ['15-14'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['24-29'], ['31-16'], ['8-31'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['21-30'], ['6-30'], ['8-26'], ['17-22'], ['19-15'], ['12-26'], ['15-14'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['24-29'], ['31-16'], ['8-31'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['21-30'], ['6-30'], ['8-26'], ['17-22'], ['19-15'], ['12-26'], ['15-14'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['24-29'], ['31-16'], ['8-31'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_0_depth_7500_results.json\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['21-30'], ['6-30'], ['8-26'], ['17-22'], ['19-15'], ['12-26'], ['15-14'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['24-29'], ['31-16'], ['8-31'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['7-4'], ['17-22'], ['19-15'], ['6-30'], ['8-26'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['31-16'], ['12-26'], ['15-14'], ['24-29'], ['13-11'], ['20-10'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 250\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['17-22'], ['7-4'], ['19-15'], ['8-26'], ['6-30'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['24-29'], ['31-16'], ['15-14'], ['12-26'], ['13-11'], ['20-10'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 481\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['17-22'], ['7-4'], ['19-15'], ['8-26'], ['18-30'], ['6-30'], ['21-28'], ['22-19'], ['24-3'], ['24-29'], ['15-14'], ['31-16'], ['12-26'], ['13-11'], ['20-10'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 687\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['17-22'], ['7-4'], ['19-15'], ['8-26'], ['18-30'], ['6-30'], ['21-28'], ['22-19'], ['24-3'], ['15-14'], ['24-29'], ['13-11'], ['20-10'], ['31-16'], ['26-28'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['17-22'], ['7-4'], ['19-15'], ['8-26'], ['18-30'], ['6-30'], ['24-3'], ['21-28'], ['22-19'], ['24-29'], ['15-14'], ['12-26'], ['13-11'], ['20-10'], ['31-16'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['17-22'], ['7-4'], ['8-26'], ['19-15'], ['18-30'], ['6-30'], ['24-3'], ['21-28'], ['22-19'], ['24-29'], ['15-14'], ['20-10'], ['31-16'], ['12-26'], ['13-11'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 86.71989440917969\n",
      "Response: John Hopfield and Geoffrey Hinton are rumored to be contenders for a future Nobel Prize in Physics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 536\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['17-22'], ['8-26'], ['7-4'], ['19-15'], ['18-30'], ['6-30'], ['21-28'], ['22-19'], ['24-3'], ['20-10'], ['24-29'], ['15-14'], ['31-16'], ['13-11'], ['12-26'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1127\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['7-4'], ['18-30'], ['6-30'], ['21-28'], ['22-19'], ['24-3'], ['20-10'], ['15-14'], ['31-16'], ['13-11'], ['17-0'], ['24-29'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1636\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['17-22'], ['19-15'], ['8-26'], ['7-4'], ['18-30'], ['6-30'], ['21-28'], ['22-19'], ['20-10'], ['24-3'], ['15-14'], ['31-16'], ['13-11'], ['17-0'], ['26-28'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['7-4'], ['18-30'], ['6-30'], ['21-28'], ['22-19'], ['20-10'], ['24-3'], ['31-16'], ['15-14'], ['17-0'], ['13-11'], ['24-29'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['7-4'], ['18-30'], ['6-30'], ['22-19'], ['21-28'], ['20-10'], ['31-16'], ['24-3'], ['15-14'], ['17-0'], ['13-11'], ['24-29'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 866\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['7-4'], ['18-30'], ['6-30'], ['21-28'], ['22-19'], ['20-10'], ['31-16'], ['24-3'], ['13-11'], ['15-14'], ['17-0'], ['26-28'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1749\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['17-22'], ['6-9'], ['8-26'], ['19-15'], ['7-4'], ['18-30'], ['6-30'], ['22-19'], ['20-10'], ['21-28'], ['31-16'], ['13-11'], ['15-14'], ['17-0'], ['24-3'], ['26-28'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2592\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['17-22'], ['6-9'], ['8-26'], ['19-15'], ['18-30'], ['7-4'], ['6-30'], ['22-19'], ['20-10'], ['21-28'], ['17-0'], ['31-16'], ['13-11'], ['15-14'], ['24-3'], ['26-28'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['17-22'], ['6-9'], ['8-26'], ['19-15'], ['7-4'], ['18-30'], ['6-30'], ['20-10'], ['22-19'], ['21-28'], ['17-0'], ['31-16'], ['24-3'], ['13-11'], ['15-14'], ['26-28'], ['21-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['17-22'], ['6-9'], ['8-26'], ['19-15'], ['18-30'], ['7-4'], ['6-30'], ['20-10'], ['22-19'], ['21-28'], ['17-0'], ['31-16'], ['24-3'], ['13-11'], ['15-14'], ['26-28'], ['21-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1127\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['17-22'], ['6-9'], ['8-26'], ['19-15'], ['18-30'], ['7-4'], ['6-30'], ['20-10'], ['22-19'], ['21-28'], ['17-0'], ['31-16'], ['15-14'], ['24-3'], ['13-11'], ['26-28'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2382\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['21-30'], ['6-9'], ['8-26'], ['19-15'], ['18-30'], ['7-4'], ['20-10'], ['22-19'], ['6-30'], ['21-28'], ['17-0'], ['31-16'], ['15-14'], ['24-3'], ['7-12'], ['26-28'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3467\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['17-22'], ['6-9'], ['8-26'], ['19-15'], ['18-30'], ['7-4'], ['20-10'], ['22-19'], ['21-28'], ['6-30'], ['7-12'], ['31-16'], ['17-0'], ['26-28'], ['15-14'], ['24-3'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['18-30'], ['7-4'], ['22-19'], ['20-10'], ['6-30'], ['21-28'], ['31-16'], ['17-0'], ['26-28'], ['7-12'], ['15-14'], ['24-3'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_relevant_misleading/llama-2-7b-80k_id_17_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['21-30'], ['6-30'], ['8-26'], ['17-22'], ['19-15'], ['12-26'], ['15-14'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['24-29'], ['31-16'], ['8-31'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['21-30'], ['6-30'], ['8-26'], ['17-22'], ['19-15'], ['12-26'], ['15-14'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['24-29'], ['31-16'], ['8-31'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['21-30'], ['6-30'], ['8-26'], ['17-22'], ['19-15'], ['12-26'], ['15-14'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['24-29'], ['31-16'], ['8-31'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['21-30'], ['6-30'], ['8-26'], ['17-22'], ['19-15'], ['12-26'], ['15-14'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['24-29'], ['31-16'], ['8-31'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_0_depth_7500_results.json\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['21-30'], ['6-30'], ['8-26'], ['17-22'], ['19-15'], ['12-26'], ['15-14'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['24-29'], ['31-16'], ['8-31'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['21-30'], ['8-26'], ['6-30'], ['17-22'], ['19-15'], ['12-26'], ['15-14'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['24-29'], ['31-16'], ['8-31'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 65.67848324775696\n",
      "Response: The 2024 Nobel Prize in Physics was awarded to Alain Aspect, John F. Clauser, and Anton Zeilinger for their work on quantum mechanics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 129\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['7-4'], ['8-26'], ['17-22'], ['6-30'], ['19-15'], ['18-30'], ['15-14'], ['21-28'], ['22-19'], ['24-3'], ['31-16'], ['24-29'], ['12-26'], ['8-31'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 502\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['7-4'], ['8-26'], ['17-22'], ['6-30'], ['19-15'], ['18-30'], ['24-3'], ['15-14'], ['21-28'], ['22-19'], ['31-16'], ['24-29'], ['12-26'], ['20-10'], ['8-31'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 751\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['7-4'], ['8-26'], ['17-22'], ['6-30'], ['19-15'], ['18-30'], ['24-3'], ['15-14'], ['21-28'], ['22-19'], ['31-16'], ['20-10'], ['24-29'], ['12-26'], ['8-31'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_1250_depth_7500_results.json\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['8-26'], ['7-4'], ['17-22'], ['6-30'], ['19-15'], ['18-30'], ['24-3'], ['15-14'], ['21-28'], ['31-16'], ['22-19'], ['20-10'], ['24-29'], ['12-26'], ['8-31'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['8-26'], ['7-4'], ['17-22'], ['6-30'], ['19-15'], ['18-30'], ['24-3'], ['15-14'], ['21-28'], ['31-16'], ['22-19'], ['24-29'], ['20-10'], ['12-26'], ['8-31'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 62.9145622253418\n",
      "Response: The 2024 Nobel Prize in Physics was awarded to Alain Aspect, John F. Clauser, and Anton Zeilinger for their work on quantum information science.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 551\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['8-26'], ['17-22'], ['7-4'], ['19-15'], ['6-30'], ['18-30'], ['24-3'], ['15-14'], ['21-28'], ['22-19'], ['20-10'], ['24-29'], ['31-16'], ['8-31'], ['12-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1130\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['8-26'], ['17-22'], ['7-4'], ['19-15'], ['6-30'], ['18-30'], ['24-3'], ['21-28'], ['15-14'], ['20-10'], ['22-19'], ['24-29'], ['31-16'], ['8-31'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1625\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['8-26'], ['17-22'], ['7-4'], ['19-15'], ['6-30'], ['18-30'], ['24-3'], ['21-28'], ['15-14'], ['20-10'], ['22-19'], ['24-29'], ['31-16'], ['8-31'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_2500_depth_7500_results.json\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['8-26'], ['17-22'], ['7-4'], ['19-15'], ['6-30'], ['18-30'], ['24-3'], ['21-28'], ['15-14'], ['20-10'], ['22-19'], ['24-29'], ['31-16'], ['17-0'], ['8-31'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['19-15'], ['6-30'], ['18-30'], ['24-3'], ['21-28'], ['15-14'], ['20-10'], ['24-29'], ['31-16'], ['22-19'], ['17-0'], ['8-31'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 53.204429149627686\n",
      "Response: The 2024 Nobel Prize in Physics was awarded to Alain Aspect, John F. Clauser, and Anton Zeilinger \"for experiments with entangled photons, establishing the violation of Bell inequalities and\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 866\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['19-15'], ['6-30'], ['18-30'], ['24-3'], ['21-28'], ['20-10'], ['15-14'], ['24-29'], ['31-16'], ['22-19'], ['7-12'], ['17-0'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1625\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['19-15'], ['6-30'], ['18-30'], ['24-3'], ['21-28'], ['20-10'], ['15-14'], ['31-16'], ['24-29'], ['22-19'], ['7-12'], ['17-0'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2599\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['19-15'], ['6-30'], ['18-30'], ['24-3'], ['21-28'], ['20-10'], ['31-16'], ['7-12'], ['15-14'], ['22-19'], ['24-29'], ['17-0'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_3750_depth_7500_results.json\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['19-15'], ['6-30'], ['18-30'], ['24-3'], ['21-28'], ['20-10'], ['31-16'], ['24-29'], ['15-14'], ['22-19'], ['7-12'], ['17-0'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['19-15'], ['6-30'], ['18-30'], ['24-3'], ['21-28'], ['20-10'], ['31-16'], ['24-29'], ['15-14'], ['22-19'], ['7-12'], ['17-0'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 5.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 52.33941674232483\n",
      "Response: The Nobel Prize in Physics 2024 was awarded to Alain Aspect, John F. Clauser, and Anton Zeilinger \"for experiments with entangled photons, establishing the violation of Bell inequalities and\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1180\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['19-15'], ['6-30'], ['18-30'], ['24-3'], ['21-28'], ['20-10'], ['7-12'], ['15-14'], ['22-19'], ['24-29'], ['31-16'], ['17-0'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2342\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['19-15'], ['18-30'], ['6-30'], ['24-3'], ['21-28'], ['20-10'], ['7-12'], ['15-14'], ['24-29'], ['22-19'], ['31-16'], ['17-0'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3358\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['21-30'], ['17-22'], ['7-4'], ['19-15'], ['18-30'], ['6-30'], ['24-3'], ['21-28'], ['20-10'], ['7-12'], ['15-14'], ['22-19'], ['24-29'], ['17-0'], ['31-16'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_5000_depth_7500_results.json\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['21-30'], ['17-22'], ['7-4'], ['19-15'], ['18-30'], ['6-30'], ['24-3'], ['21-28'], ['20-10'], ['7-12'], ['15-14'], ['24-29'], ['22-19'], ['17-0'], ['31-16'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant/llama-2-7b-80k_id_17_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/17.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['21-30'], ['6-30'], ['8-26'], ['17-22'], ['19-15'], ['12-26'], ['15-14'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['24-29'], ['31-16'], ['8-31'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['21-30'], ['6-30'], ['8-26'], ['17-22'], ['19-15'], ['12-26'], ['15-14'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['24-29'], ['31-16'], ['8-31'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['21-30'], ['6-30'], ['8-26'], ['17-22'], ['19-15'], ['12-26'], ['15-14'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['24-29'], ['31-16'], ['8-31'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['21-30'], ['6-30'], ['8-26'], ['17-22'], ['19-15'], ['12-26'], ['15-14'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['24-29'], ['31-16'], ['8-31'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['21-30'], ['6-30'], ['8-26'], ['17-22'], ['19-15'], ['12-26'], ['15-14'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['24-29'], ['31-16'], ['8-31'], ['13-11'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['7-4'], ['17-22'], ['6-30'], ['8-26'], ['19-15'], ['18-30'], ['21-28'], ['22-19'], ['24-3'], ['12-26'], ['15-14'], ['24-29'], ['31-16'], ['21-1'], ['8-31'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 129\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['7-4'], ['17-22'], ['8-26'], ['19-15'], ['6-30'], ['21-28'], ['22-19'], ['24-3'], ['18-30'], ['24-29'], ['31-16'], ['12-26'], ['15-14'], ['21-1'], ['13-11'], ['20-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 502\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['17-22'], ['7-4'], ['8-26'], ['19-15'], ['24-3'], ['6-30'], ['21-28'], ['22-19'], ['18-30'], ['24-29'], ['31-16'], ['12-26'], ['15-14'], ['13-11'], ['20-10'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 751\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['7-4'], ['24-3'], ['21-28'], ['22-19'], ['6-30'], ['18-30'], ['24-29'], ['12-26'], ['15-14'], ['31-16'], ['13-11'], ['26-28'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['17-22'], ['8-26'], ['19-15'], ['7-4'], ['24-3'], ['6-30'], ['21-28'], ['22-19'], ['18-30'], ['24-29'], ['31-16'], ['12-26'], ['15-14'], ['13-11'], ['26-28'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['17-22'], ['8-26'], ['19-15'], ['7-4'], ['24-3'], ['22-19'], ['6-30'], ['21-28'], ['18-30'], ['24-29'], ['31-16'], ['12-26'], ['15-14'], ['13-11'], ['26-28'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 551\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['17-22'], ['8-26'], ['19-15'], ['24-3'], ['7-4'], ['22-19'], ['21-28'], ['6-30'], ['18-30'], ['24-29'], ['31-16'], ['12-26'], ['13-11'], ['17-0'], ['20-10'], ['23-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1121\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['24-3'], ['7-4'], ['18-30'], ['21-28'], ['22-19'], ['6-30'], ['24-29'], ['31-16'], ['12-26'], ['17-0'], ['20-10'], ['23-20'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1674\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['7-4'], ['24-3'], ['18-30'], ['21-28'], ['22-19'], ['6-30'], ['24-29'], ['31-16'], ['12-26'], ['17-0'], ['20-10'], ['23-20'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['7-4'], ['24-3'], ['18-30'], ['6-30'], ['22-19'], ['21-28'], ['31-16'], ['24-29'], ['12-26'], ['17-0'], ['20-10'], ['23-20'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['7-4'], ['24-3'], ['18-30'], ['6-30'], ['22-19'], ['21-28'], ['31-16'], ['24-29'], ['12-26'], ['17-0'], ['20-10'], ['23-20'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 866\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['24-3'], ['7-4'], ['18-30'], ['6-30'], ['22-19'], ['21-28'], ['31-16'], ['24-29'], ['20-10'], ['17-0'], ['23-20'], ['26-28'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1674\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['24-3'], ['7-4'], ['18-30'], ['6-30'], ['22-19'], ['21-28'], ['31-16'], ['24-29'], ['20-10'], ['17-0'], ['23-20'], ['26-28'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2623\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['17-22'], ['6-9'], ['8-26'], ['19-15'], ['7-4'], ['18-30'], ['24-3'], ['6-30'], ['22-19'], ['21-28'], ['24-29'], ['31-16'], ['20-10'], ['17-0'], ['23-20'], ['26-28'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 64.07519578933716\n",
      "Response: John Hopfield and Geoffrey Hinton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['17-22'], ['6-9'], ['8-26'], ['19-15'], ['7-4'], ['18-30'], ['24-3'], ['6-30'], ['22-19'], ['21-28'], ['24-29'], ['31-16'], ['17-0'], ['20-10'], ['23-20'], ['26-28'], ['25-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['17-22'], ['6-9'], ['8-26'], ['19-15'], ['7-4'], ['18-30'], ['24-3'], ['6-30'], ['22-19'], ['21-28'], ['24-29'], ['31-16'], ['20-10'], ['17-0'], ['23-20'], ['26-28'], ['25-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1153\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['11-15'], ['16-19'], ['21-30'], ['17-22'], ['6-9'], ['8-26'], ['19-15'], ['18-30'], ['7-4'], ['24-3'], ['22-19'], ['6-30'], ['21-28'], ['24-29'], ['31-16'], ['17-0'], ['20-10'], ['23-20'], ['7-12'], ['25-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2368\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['11-15'], ['16-19'], ['21-30'], ['17-22'], ['6-9'], ['8-26'], ['19-15'], ['18-30'], ['24-3'], ['7-4'], ['22-19'], ['21-28'], ['6-30'], ['24-29'], ['20-10'], ['31-16'], ['17-0'], ['7-12'], ['23-20'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3463\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['11-15'], ['16-19'], ['21-30'], ['17-22'], ['6-9'], ['8-26'], ['19-15'], ['18-30'], ['24-3'], ['7-4'], ['22-19'], ['21-28'], ['6-30'], ['17-0'], ['20-10'], ['24-29'], ['23-20'], ['31-16'], ['7-12'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The 2024 Nobel Prize in Physics was awarded to John Hopfield and Geoffrey Hinton.\n",
      "[['11-15'], ['16-19'], ['21-30'], ['17-22'], ['6-9'], ['8-26'], ['19-15'], ['18-30'], ['24-3'], ['7-4'], ['22-19'], ['21-28'], ['6-30'], ['17-0'], ['24-29'], ['20-10'], ['31-16'], ['23-20'], ['26-28'], ['25-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 61.06078624725342\n",
      "Response: John Hopfield and Geoffrey Hinton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_17_irrelevant_misleading/llama-2-7b-80k_id_17_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['7-4'], ['24-29'], ['6-9'], ['6-30'], ['11-15'], ['21-30'], ['6-11'], ['7-13'], ['8-26'], ['10-29'], ['11-30'], ['18-30'], ['19-9'], ['22-8'], ['26-28'], ['31-16'], ['7-28'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['7-4'], ['24-29'], ['6-9'], ['6-30'], ['11-15'], ['21-30'], ['6-11'], ['7-13'], ['8-26'], ['10-29'], ['11-30'], ['18-30'], ['19-9'], ['22-8'], ['26-28'], ['31-16'], ['7-28'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['7-4'], ['24-29'], ['6-9'], ['6-30'], ['11-15'], ['21-30'], ['6-11'], ['7-13'], ['8-26'], ['10-29'], ['11-30'], ['18-30'], ['19-9'], ['22-8'], ['26-28'], ['31-16'], ['7-28'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['7-4'], ['24-29'], ['6-9'], ['6-30'], ['11-15'], ['21-30'], ['6-11'], ['7-13'], ['8-26'], ['10-29'], ['11-30'], ['18-30'], ['19-9'], ['22-8'], ['26-28'], ['31-16'], ['7-28'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_0_depth_7500_results.json\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['7-4'], ['24-29'], ['6-9'], ['6-30'], ['11-15'], ['21-30'], ['6-11'], ['7-13'], ['8-26'], ['10-29'], ['11-30'], ['18-30'], ['19-9'], ['22-8'], ['26-28'], ['31-16'], ['7-28'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-29'], ['7-4'], ['21-30'], ['6-9'], ['6-30'], ['8-26'], ['22-8'], ['6-11'], ['7-13'], ['10-29'], ['11-30'], ['18-30'], ['19-9'], ['26-28'], ['31-16'], ['17-22'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 82.80546069145203\n",
      "Response: The most recent outbreak declared as a public health emergency of international concern by WHO is the 2022â€“2023 mpox outbreak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_1250_depth_0_results.json\n",
      "insertion at 184\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-29'], ['7-4'], ['7-12'], ['21-30'], ['6-9'], ['8-26'], ['17-22'], ['6-30'], ['11-2'], ['18-30'], ['22-8'], ['10-29'], ['26-28'], ['31-16'], ['6-11'], ['7-13'], ['11-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 85.21345853805542\n",
      "Response: The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox. Since 2005, there have been eight PHEIC declarations: the 2009â€“2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 499\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-29'], ['7-12'], ['6-9'], ['17-22'], ['7-4'], ['8-26'], ['11-2'], ['21-30'], ['6-30'], ['18-30'], ['10-29'], ['22-8'], ['31-16'], ['6-16'], ['26-28'], ['16-1'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 754\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-29'], ['7-12'], ['6-9'], ['17-22'], ['7-4'], ['8-26'], ['21-30'], ['11-2'], ['6-30'], ['18-30'], ['31-16'], ['22-8'], ['10-29'], ['26-28'], ['6-16'], ['15-14'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_1250_depth_7500_results.json\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-29'], ['6-9'], ['7-12'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['11-2'], ['6-30'], ['18-30'], ['31-16'], ['22-8'], ['26-28'], ['7-13'], ['10-29'], ['15-14'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-29'], ['7-12'], ['6-9'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['21-30'], ['6-30'], ['18-30'], ['31-16'], ['22-8'], ['6-16'], ['16-1'], ['26-28'], ['15-14'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 82.80546069145203\n",
      "Response: The most recent outbreak declared as a public health emergency of international concern by WHO is the 2022â€“2023 mpox outbreak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_2500_depth_0_results.json\n",
      "insertion at 539\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['7-12'], ['24-29'], ['8-26'], ['6-9'], ['11-2'], ['17-22'], ['7-4'], ['21-30'], ['6-16'], ['6-30'], ['18-30'], ['31-16'], ['22-8'], ['16-1'], ['10-29'], ['15-14'], ['24-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1112\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['7-12'], ['24-29'], ['6-9'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['21-30'], ['6-30'], ['18-30'], ['31-16'], ['6-16'], ['22-8'], ['16-1'], ['15-14'], ['24-17'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1694\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-29'], ['7-12'], ['6-9'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['21-30'], ['18-30'], ['31-16'], ['6-30'], ['6-16'], ['22-8'], ['16-1'], ['29-26'], ['15-14'], ['24-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_2500_depth_7500_results.json\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-29'], ['6-9'], ['7-12'], ['8-26'], ['17-22'], ['7-4'], ['11-2'], ['21-30'], ['31-16'], ['18-30'], ['6-30'], ['22-8'], ['6-16'], ['29-26'], ['16-1'], ['15-14'], ['24-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-29'], ['7-12'], ['8-26'], ['17-22'], ['6-9'], ['11-2'], ['7-4'], ['21-30'], ['31-16'], ['18-30'], ['6-30'], ['6-16'], ['22-8'], ['16-1'], ['24-17'], ['29-26'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 82.80546069145203\n",
      "Response: The most recent outbreak declared as a public health emergency of international concern by WHO is the 2022â€“2023 mpox outbreak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_3750_depth_0_results.json\n",
      "insertion at 864\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 46.479037404060364\n",
      "Response: Swine flu (2009â€“2010)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1754\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-29'], ['7-12'], ['8-26'], ['6-9'], ['17-22'], ['11-2'], ['7-4'], ['21-30'], ['31-16'], ['18-30'], ['6-30'], ['6-16'], ['22-8'], ['16-1'], ['15-14'], ['24-17'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2619\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-29'], ['8-26'], ['6-9'], ['7-12'], ['17-22'], ['11-2'], ['7-4'], ['21-30'], ['31-16'], ['18-30'], ['6-30'], ['22-8'], ['6-16'], ['16-1'], ['29-26'], ['15-14'], ['24-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_3750_depth_7500_results.json\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-29'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['11-2'], ['21-30'], ['31-16'], ['18-30'], ['6-30'], ['22-8'], ['29-26'], ['24-17'], ['6-16'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-29'], ['8-26'], ['17-22'], ['7-12'], ['6-9'], ['11-2'], ['7-4'], ['21-30'], ['31-16'], ['18-30'], ['6-30'], ['6-16'], ['22-8'], ['24-17'], ['16-1'], ['29-26'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 82.80546069145203\n",
      "Response: The most recent outbreak declared as a public health emergency of international concern by WHO is the 2022â€“2023 mpox outbreak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1182\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 47.2825288772583\n",
      "Response: Clade II mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2379\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 47.2825288772583\n",
      "Response: Clade II mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3578\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 45.903074741363525\n",
      "Response: Clade II mpox (2022â€“2023)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_5000_depth_7500_results.json\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-29'], ['8-26'], ['6-9'], ['17-22'], ['7-12'], ['11-2'], ['7-4'], ['21-30'], ['31-16'], ['18-30'], ['6-30'], ['22-8'], ['24-17'], ['6-16'], ['29-26'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant/llama-2-7b-80k_id_170_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/170.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['7-4'], ['24-29'], ['6-9'], ['6-30'], ['11-15'], ['21-30'], ['6-11'], ['7-13'], ['8-26'], ['10-29'], ['11-30'], ['18-30'], ['19-9'], ['22-8'], ['26-28'], ['31-16'], ['7-28'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['7-4'], ['24-29'], ['6-9'], ['6-30'], ['11-15'], ['21-30'], ['6-11'], ['7-13'], ['8-26'], ['10-29'], ['11-30'], ['18-30'], ['19-9'], ['22-8'], ['26-28'], ['31-16'], ['7-28'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['7-4'], ['24-29'], ['6-9'], ['6-30'], ['11-15'], ['21-30'], ['6-11'], ['7-13'], ['8-26'], ['10-29'], ['11-30'], ['18-30'], ['19-9'], ['22-8'], ['26-28'], ['31-16'], ['7-28'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['7-4'], ['24-29'], ['6-9'], ['6-30'], ['11-15'], ['21-30'], ['6-11'], ['7-13'], ['8-26'], ['10-29'], ['11-30'], ['18-30'], ['19-9'], ['22-8'], ['26-28'], ['31-16'], ['7-28'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_0_depth_7500_results.json\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['7-4'], ['24-29'], ['6-9'], ['6-30'], ['11-15'], ['21-30'], ['6-11'], ['7-13'], ['8-26'], ['10-29'], ['11-30'], ['18-30'], ['19-9'], ['22-8'], ['26-28'], ['31-16'], ['7-28'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['7-4'], ['21-30'], ['6-9'], ['6-30'], ['8-26'], ['22-8'], ['6-11'], ['7-13'], ['10-29'], ['11-30'], ['18-30'], ['19-9'], ['26-28'], ['31-16'], ['17-22'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 82.80546069145203\n",
      "Response: The most recent outbreak declared as a public health emergency of international concern by WHO is the 2022â€“2023 mpox outbreak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 184\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 47.89946377277374\n",
      "Response: Clade II mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 499\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 47.89946377277374\n",
      "Response: Clade II mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 754\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 47.89946377277374\n",
      "Response: Clade II mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['7-4'], ['6-9'], ['21-30'], ['6-30'], ['8-26'], ['18-30'], ['22-8'], ['31-16'], ['7-13'], ['19-9'], ['26-28'], ['6-11'], ['10-29'], ['11-30'], ['17-22'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['7-4'], ['6-9'], ['8-26'], ['21-30'], ['6-30'], ['22-8'], ['18-30'], ['31-16'], ['7-13'], ['19-9'], ['26-28'], ['6-11'], ['10-29'], ['11-30'], ['17-22'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 539\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['8-26'], ['7-4'], ['6-9'], ['21-30'], ['6-30'], ['22-8'], ['18-30'], ['19-9'], ['31-16'], ['7-13'], ['17-22'], ['26-28'], ['6-11'], ['10-29'], ['11-30'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1069\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['8-26'], ['6-9'], ['7-4'], ['21-30'], ['6-30'], ['22-8'], ['31-16'], ['17-22'], ['18-30'], ['19-9'], ['26-28'], ['7-13'], ['6-11'], ['7-12'], ['15-14'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1698\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['8-26'], ['6-9'], ['21-30'], ['7-4'], ['6-30'], ['22-8'], ['31-16'], ['17-22'], ['18-30'], ['19-9'], ['26-28'], ['15-14'], ['7-13'], ['6-11'], ['7-12'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['8-26'], ['6-9'], ['21-30'], ['7-4'], ['31-16'], ['6-30'], ['22-8'], ['17-22'], ['18-30'], ['26-28'], ['15-14'], ['19-9'], ['7-13'], ['24-17'], ['29-26'], ['6-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['8-26'], ['6-9'], ['21-30'], ['7-4'], ['22-8'], ['31-16'], ['6-30'], ['17-22'], ['18-30'], ['26-28'], ['15-14'], ['19-9'], ['7-13'], ['29-26'], ['24-17'], ['6-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 864\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['11-15'], ['8-26'], ['6-9'], ['21-30'], ['7-4'], ['31-16'], ['22-8'], ['17-22'], ['6-30'], ['18-30'], ['26-28'], ['15-14'], ['19-9'], ['29-26'], ['7-13'], ['24-17'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1757\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['11-15'], ['8-26'], ['6-9'], ['21-30'], ['7-4'], ['31-16'], ['22-8'], ['17-22'], ['18-30'], ['6-30'], ['26-28'], ['15-14'], ['29-26'], ['19-9'], ['24-17'], ['7-13'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2639\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['31-16'], ['7-4'], ['17-22'], ['22-8'], ['18-30'], ['15-14'], ['26-28'], ['6-30'], ['29-26'], ['24-17'], ['19-9'], ['17-16'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['31-16'], ['7-4'], ['17-22'], ['18-30'], ['22-8'], ['15-14'], ['26-28'], ['6-30'], ['29-26'], ['19-9'], ['24-17'], ['17-16'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 47.2825288772583\n",
      "Response: Clade II mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1191\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 47.89946377277374\n",
      "Response: Clade II mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2309\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 47.2825288772583\n",
      "Response: Clade II mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3539\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 47.2825288772583\n",
      "Response: Clade II mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['31-16'], ['7-4'], ['18-30'], ['15-14'], ['17-22'], ['22-8'], ['26-28'], ['6-30'], ['29-26'], ['12-26'], ['19-9'], ['24-17'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_relevant_misleading/llama-2-7b-80k_id_170_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['7-4'], ['24-29'], ['6-9'], ['6-30'], ['11-15'], ['21-30'], ['6-11'], ['7-13'], ['8-26'], ['10-29'], ['11-30'], ['18-30'], ['19-9'], ['22-8'], ['26-28'], ['31-16'], ['7-28'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['7-4'], ['24-29'], ['6-9'], ['6-30'], ['11-15'], ['21-30'], ['6-11'], ['7-13'], ['8-26'], ['10-29'], ['11-30'], ['18-30'], ['19-9'], ['22-8'], ['26-28'], ['31-16'], ['7-28'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['7-4'], ['24-29'], ['6-9'], ['6-30'], ['11-15'], ['21-30'], ['6-11'], ['7-13'], ['8-26'], ['10-29'], ['11-30'], ['18-30'], ['19-9'], ['22-8'], ['26-28'], ['31-16'], ['7-28'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['7-4'], ['24-29'], ['6-9'], ['6-30'], ['11-15'], ['21-30'], ['6-11'], ['7-13'], ['8-26'], ['10-29'], ['11-30'], ['18-30'], ['19-9'], ['22-8'], ['26-28'], ['31-16'], ['7-28'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_0_depth_7500_results.json\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['7-4'], ['24-29'], ['6-9'], ['6-30'], ['11-15'], ['21-30'], ['6-11'], ['7-13'], ['8-26'], ['10-29'], ['11-30'], ['18-30'], ['19-9'], ['22-8'], ['26-28'], ['31-16'], ['7-28'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 37.68981993198395\n",
      "Response: COVID-19 pandemic\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 217\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 37.68981993198395\n",
      "Response: COVID-19 pandemic\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 461\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 37.68981993198395\n",
      "Response: COVID-19 pandemic\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 593\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['6-9'], ['24-29'], ['7-4'], ['21-30'], ['8-26'], ['17-22'], ['6-30'], ['18-30'], ['22-8'], ['11-30'], ['31-16'], ['6-11'], ['7-13'], ['10-29'], ['19-9'], ['26-28'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_1250_depth_7500_results.json\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['6-9'], ['24-29'], ['7-4'], ['21-30'], ['8-26'], ['17-22'], ['6-30'], ['18-30'], ['22-8'], ['7-13'], ['31-16'], ['26-28'], ['6-11'], ['11-30'], ['19-9'], ['10-29'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 34.73859429359436\n",
      "Response: COVID-19 pandemic,COVID-19 pandemic.1\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 461\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 34.73859429359436\n",
      "Response: COVID-19 pandemic,COVID-19 pandemic.1\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1103\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 32.592082023620605\n",
      "Response: COVID-19\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1670\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['6-9'], ['24-29'], ['7-4'], ['21-30'], ['8-26'], ['17-22'], ['6-30'], ['18-30'], ['22-8'], ['31-16'], ['7-13'], ['26-28'], ['6-11'], ['11-30'], ['19-9'], ['29-26'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_2500_depth_7500_results.json\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['6-9'], ['24-29'], ['7-4'], ['21-30'], ['8-26'], ['17-22'], ['6-30'], ['18-30'], ['22-8'], ['7-13'], ['31-16'], ['26-28'], ['29-26'], ['6-11'], ['19-9'], ['11-30'], ['24-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 34.73859429359436\n",
      "Response: COVID-19 pandemic,COVID-19 pandemic.1\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 808\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 37.68981993198395\n",
      "Response: COVID-19 pandemic\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1717\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['6-9'], ['11-15'], ['24-29'], ['7-4'], ['21-30'], ['8-26'], ['17-22'], ['6-30'], ['18-30'], ['22-8'], ['31-16'], ['7-13'], ['26-28'], ['29-26'], ['6-11'], ['19-9'], ['24-17'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2624\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['6-9'], ['24-29'], ['11-15'], ['7-4'], ['21-30'], ['8-26'], ['17-22'], ['6-30'], ['18-30'], ['22-8'], ['31-16'], ['7-13'], ['29-26'], ['26-28'], ['19-9'], ['24-17'], ['6-11'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_3750_depth_7500_results.json\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['6-9'], ['24-29'], ['11-15'], ['7-4'], ['21-30'], ['8-26'], ['17-22'], ['6-30'], ['18-30'], ['22-8'], ['31-16'], ['7-13'], ['29-26'], ['26-28'], ['24-17'], ['19-9'], ['20-8'], ['6-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 37.68981993198395\n",
      "Response: COVID-19 pandemic\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1182\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 32.592082023620605\n",
      "Response: COVID-19\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2384\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 32.592082023620605\n",
      "Response: COVID-19\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3570\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['6-9'], ['11-15'], ['7-4'], ['21-30'], ['8-26'], ['17-22'], ['18-30'], ['6-30'], ['22-8'], ['31-16'], ['29-26'], ['7-13'], ['26-28'], ['24-17'], ['20-8'], ['7-12'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_5000_depth_7500_results.json\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['6-9'], ['24-29'], ['11-15'], ['7-4'], ['21-30'], ['8-26'], ['17-22'], ['18-30'], ['6-30'], ['22-8'], ['31-16'], ['7-13'], ['29-26'], ['24-17'], ['26-28'], ['20-8'], ['17-16'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant/llama-2-7b-80k_id_170_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/170.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['7-4'], ['24-29'], ['6-9'], ['6-30'], ['11-15'], ['21-30'], ['6-11'], ['7-13'], ['8-26'], ['10-29'], ['11-30'], ['18-30'], ['19-9'], ['22-8'], ['26-28'], ['31-16'], ['7-28'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['7-4'], ['24-29'], ['6-9'], ['6-30'], ['11-15'], ['21-30'], ['6-11'], ['7-13'], ['8-26'], ['10-29'], ['11-30'], ['18-30'], ['19-9'], ['22-8'], ['26-28'], ['31-16'], ['7-28'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['7-4'], ['24-29'], ['6-9'], ['6-30'], ['11-15'], ['21-30'], ['6-11'], ['7-13'], ['8-26'], ['10-29'], ['11-30'], ['18-30'], ['19-9'], ['22-8'], ['26-28'], ['31-16'], ['7-28'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['7-4'], ['24-29'], ['6-9'], ['6-30'], ['11-15'], ['21-30'], ['6-11'], ['7-13'], ['8-26'], ['10-29'], ['11-30'], ['18-30'], ['19-9'], ['22-8'], ['26-28'], ['31-16'], ['7-28'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['19-15'], ['7-4'], ['24-29'], ['6-9'], ['6-30'], ['11-15'], ['21-30'], ['6-11'], ['7-13'], ['8-26'], ['10-29'], ['11-30'], ['18-30'], ['19-9'], ['22-8'], ['26-28'], ['31-16'], ['7-28'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 34.73859429359436\n",
      "Response: COVID-19 pandemic,COVID-19 pandemic.1\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 217\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-29'], ['7-4'], ['6-9'], ['8-26'], ['21-30'], ['6-30'], ['18-30'], ['17-22'], ['22-8'], ['31-16'], ['7-12'], ['6-11'], ['7-13'], ['10-29'], ['11-30'], ['19-9'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 461\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['24-29'], ['8-26'], ['7-4'], ['7-12'], ['21-30'], ['17-22'], ['6-30'], ['11-2'], ['18-30'], ['6-16'], ['22-8'], ['31-16'], ['10-29'], ['6-11'], ['7-13'], ['11-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 593\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['24-29'], ['8-26'], ['7-12'], ['7-4'], ['17-22'], ['21-30'], ['6-16'], ['11-2'], ['6-30'], ['18-30'], ['22-8'], ['31-16'], ['10-29'], ['16-30'], ['17-16'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['24-29'], ['8-26'], ['7-12'], ['7-4'], ['17-22'], ['21-30'], ['6-16'], ['11-2'], ['6-30'], ['18-30'], ['22-8'], ['31-16'], ['7-13'], ['29-26'], ['10-29'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['24-29'], ['8-26'], ['7-12'], ['7-4'], ['17-22'], ['21-30'], ['6-16'], ['11-2'], ['18-30'], ['6-30'], ['22-8'], ['31-16'], ['29-26'], ['7-13'], ['17-16'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 461\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['24-29'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['21-30'], ['6-16'], ['18-30'], ['11-2'], ['6-30'], ['22-8'], ['31-16'], ['29-26'], ['17-16'], ['7-13'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1122\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['24-29'], ['8-26'], ['7-12'], ['21-30'], ['17-22'], ['7-4'], ['18-30'], ['6-16'], ['11-2'], ['22-8'], ['6-30'], ['31-16'], ['29-26'], ['17-16'], ['12-26'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1704\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['24-29'], ['8-26'], ['7-12'], ['21-30'], ['17-22'], ['7-4'], ['18-30'], ['6-16'], ['11-2'], ['6-30'], ['22-8'], ['31-16'], ['29-26'], ['17-16'], ['12-26'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['24-29'], ['8-26'], ['21-30'], ['7-12'], ['17-22'], ['7-4'], ['18-30'], ['6-16'], ['6-30'], ['11-2'], ['31-16'], ['22-8'], ['29-26'], ['12-26'], ['17-16'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['24-29'], ['8-26'], ['21-30'], ['7-12'], ['17-22'], ['7-4'], ['18-30'], ['6-16'], ['22-8'], ['6-30'], ['11-2'], ['31-16'], ['29-26'], ['12-26'], ['17-16'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 808\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['24-29'], ['8-26'], ['21-30'], ['7-12'], ['17-22'], ['7-4'], ['18-30'], ['6-16'], ['31-16'], ['22-8'], ['6-30'], ['11-2'], ['29-26'], ['12-26'], ['17-16'], ['24-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1751\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['24-29'], ['8-26'], ['21-30'], ['7-12'], ['17-22'], ['7-4'], ['18-30'], ['22-8'], ['6-16'], ['29-26'], ['31-16'], ['6-30'], ['11-2'], ['12-26'], ['17-16'], ['24-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2634\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['24-29'], ['8-26'], ['21-30'], ['7-12'], ['17-22'], ['7-4'], ['18-30'], ['22-8'], ['29-26'], ['6-16'], ['31-16'], ['11-2'], ['6-30'], ['12-26'], ['17-16'], ['24-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['24-29'], ['8-26'], ['21-30'], ['17-22'], ['7-12'], ['7-4'], ['18-30'], ['22-8'], ['29-26'], ['31-16'], ['6-30'], ['6-16'], ['11-2'], ['12-26'], ['17-16'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-29'], ['6-9'], ['8-26'], ['21-30'], ['7-12'], ['17-22'], ['7-4'], ['18-30'], ['6-16'], ['22-8'], ['29-26'], ['31-16'], ['6-30'], ['11-2'], ['12-26'], ['17-16'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 97.90264368057251\n",
      "Response: Clade I mpox, the most recent outbreak declared as a public health emergency of international concern by WHO.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1189\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-29'], ['6-9'], ['8-26'], ['7-12'], ['21-30'], ['17-22'], ['7-4'], ['6-16'], ['29-26'], ['18-30'], ['22-8'], ['11-2'], ['31-16'], ['6-30'], ['17-16'], ['12-26'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 96.6002106666565\n",
      "Response: Clade I mpox, the most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2363\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-29'], ['6-9'], ['8-26'], ['7-12'], ['21-30'], ['17-22'], ['7-4'], ['6-16'], ['29-26'], ['18-30'], ['22-8'], ['11-2'], ['31-16'], ['6-30'], ['17-16'], ['12-26'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3548\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-29'], ['6-9'], ['8-26'], ['7-12'], ['21-30'], ['17-22'], ['7-4'], ['6-16'], ['29-26'], ['18-30'], ['22-8'], ['31-16'], ['11-2'], ['6-30'], ['17-16'], ['12-26'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 53.51347327232361\n",
      "Response: Clade I mpox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The most recent outbreak declared as a public health emergency of international concern by WHO is Clade I mpox.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-29'], ['6-9'], ['8-26'], ['7-12'], ['21-30'], ['17-22'], ['7-4'], ['6-16'], ['29-26'], ['18-30'], ['22-8'], ['31-16'], ['11-2'], ['6-30'], ['12-26'], ['17-16'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 53.827881813049316\n",
      "Response: Clade I mpox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_170_irrelevant_misleading/llama-2-7b-80k_id_170_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: There are 102 LA metro rail stations.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['6-30'], ['11-2'], ['13-11'], ['24-29'], ['6-11'], ['7-13'], ['8-22'], ['8-31'], ['17-31'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['6-30'], ['11-2'], ['13-11'], ['24-29'], ['6-11'], ['7-13'], ['8-22'], ['8-31'], ['17-31'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['6-30'], ['11-2'], ['13-11'], ['24-29'], ['6-11'], ['7-13'], ['8-22'], ['8-31'], ['17-31'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['6-30'], ['11-2'], ['13-11'], ['24-29'], ['6-11'], ['7-13'], ['8-22'], ['8-31'], ['17-31'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_0_depth_7500_results.json\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['6-30'], ['11-2'], ['13-11'], ['24-29'], ['6-11'], ['7-13'], ['8-22'], ['8-31'], ['17-31'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['21-30'], ['12-26'], ['19-15'], ['17-22'], ['16-24'], ['11-2'], ['13-11'], ['24-29'], ['6-30'], ['17-31'], ['21-1'], ['22-8'], ['26-28'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_1250_depth_0_results.json\n",
      "insertion at 253\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['12-26'], ['19-15'], ['11-2'], ['16-24'], ['24-29'], ['13-11'], ['6-30'], ['17-31'], ['7-12'], ['21-1'], ['22-8'], ['26-28'], ['6-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 75.67381858825684\n",
      "Response: There are 102 LA metro rail stations. The next Metro Rail line, the rapid transit Red Line, opened on January 30, 1993, between Union Station and Westlake/MacArthur Park\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 487\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['12-26'], ['19-15'], ['11-2'], ['16-24'], ['24-29'], ['7-12'], ['13-11'], ['17-31'], ['6-30'], ['14-18'], ['21-1'], ['22-8'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 69.17051076889038\n",
      "Response: There are 102 LA metro rail stations. The rapid transit Purple Line became the fifth Metro Rail line on August 24, 2006, when LACMTA separated the Red Line into two separate services\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 763\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['12-26'], ['19-15'], ['11-2'], ['16-24'], ['24-29'], ['7-12'], ['13-11'], ['17-31'], ['6-30'], ['14-18'], ['21-1'], ['22-8'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_1250_depth_7500_results.json\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['12-26'], ['21-30'], ['19-15'], ['24-29'], ['16-24'], ['11-2'], ['13-11'], ['7-12'], ['17-31'], ['6-30'], ['14-18'], ['7-13'], ['8-31'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['12-26'], ['21-30'], ['19-15'], ['11-2'], ['24-29'], ['16-24'], ['7-12'], ['17-31'], ['13-11'], ['6-30'], ['14-18'], ['22-8'], ['26-28'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_2500_depth_0_results.json\n",
      "insertion at 558\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['12-26'], ['11-2'], ['24-29'], ['7-12'], ['21-30'], ['19-15'], ['16-24'], ['17-31'], ['13-11'], ['14-18'], ['6-30'], ['22-8'], ['26-28'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 68.03202629089355\n",
      "Response: There are 102 LA metro rail stations. The Gold Line was later extended to Atlantic station in East Los Angeles on November 15, 2009. The light rail Expo Line opened between 7th Street/\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1098\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['12-26'], ['11-2'], ['24-29'], ['21-30'], ['19-15'], ['16-24'], ['17-31'], ['13-11'], ['6-30'], ['14-18'], ['22-8'], ['8-31'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1385\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['11-2'], ['24-29'], ['12-26'], ['21-30'], ['19-15'], ['16-24'], ['17-31'], ['6-30'], ['14-18'], ['13-11'], ['22-8'], ['26-28'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_2500_depth_7500_results.json\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['12-26'], ['7-12'], ['24-29'], ['11-2'], ['21-30'], ['19-15'], ['16-24'], ['17-31'], ['6-30'], ['14-18'], ['13-11'], ['22-8'], ['26-28'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['12-26'], ['24-29'], ['11-2'], ['21-30'], ['16-24'], ['19-15'], ['17-31'], ['6-30'], ['14-18'], ['13-11'], ['22-8'], ['26-28'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_3750_depth_0_results.json\n",
      "insertion at 866\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['24-29'], ['11-2'], ['12-26'], ['21-30'], ['16-24'], ['19-15'], ['17-31'], ['14-18'], ['6-30'], ['13-11'], ['22-8'], ['26-28'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1385\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['24-29'], ['11-2'], ['12-26'], ['21-30'], ['16-24'], ['19-15'], ['17-31'], ['14-18'], ['6-30'], ['13-11'], ['22-8'], ['8-22'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 1385\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['24-29'], ['11-2'], ['21-30'], ['12-26'], ['16-24'], ['17-31'], ['19-15'], ['14-18'], ['6-30'], ['13-11'], ['22-8'], ['8-22'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_3750_depth_7500_results.json\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['24-29'], ['11-2'], ['12-26'], ['21-30'], ['16-24'], ['19-15'], ['17-31'], ['6-30'], ['14-18'], ['13-11'], ['8-22'], ['22-8'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['24-29'], ['11-2'], ['21-30'], ['12-26'], ['16-24'], ['19-15'], ['17-31'], ['14-18'], ['6-30'], ['13-11'], ['22-8'], ['8-22'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1161\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['24-29'], ['11-2'], ['21-30'], ['12-26'], ['16-24'], ['19-15'], ['17-31'], ['14-18'], ['6-30'], ['8-22'], ['13-11'], ['22-8'], ['6-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 1385\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['24-29'], ['11-2'], ['21-30'], ['12-26'], ['17-31'], ['16-24'], ['19-15'], ['14-18'], ['6-30'], ['8-22'], ['13-11'], ['22-8'], ['6-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 1385\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['24-29'], ['11-2'], ['21-30'], ['12-26'], ['17-31'], ['16-24'], ['19-15'], ['14-18'], ['6-30'], ['8-22'], ['6-16'], ['13-11'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_5000_depth_7500_results.json\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['24-29'], ['11-2'], ['21-30'], ['12-26'], ['17-31'], ['16-24'], ['19-15'], ['14-18'], ['6-30'], ['8-22'], ['13-11'], ['6-16'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant/llama-2-7b-80k_id_172_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/172.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: There are 102 LA metro rail stations.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['6-30'], ['11-2'], ['13-11'], ['24-29'], ['6-11'], ['7-13'], ['8-22'], ['8-31'], ['17-31'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['6-30'], ['11-2'], ['13-11'], ['24-29'], ['6-11'], ['7-13'], ['8-22'], ['8-31'], ['17-31'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['6-30'], ['11-2'], ['13-11'], ['24-29'], ['6-11'], ['7-13'], ['8-22'], ['8-31'], ['17-31'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['6-30'], ['11-2'], ['13-11'], ['24-29'], ['6-11'], ['7-13'], ['8-22'], ['8-31'], ['17-31'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_0_depth_7500_results.json\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['6-30'], ['11-2'], ['13-11'], ['24-29'], ['6-11'], ['7-13'], ['8-22'], ['8-31'], ['17-31'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['19-15'], ['21-30'], ['12-26'], ['17-22'], ['16-24'], ['11-2'], ['24-29'], ['13-11'], ['6-30'], ['22-8'], ['26-25'], ['26-28'], ['17-31'], ['21-4'], ['6-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 98.31953644752502\n",
      "Response: There are 102 LA metro rail stations in operation.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 235\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['19-15'], ['12-26'], ['16-24'], ['24-29'], ['11-2'], ['13-11'], ['6-30'], ['7-12'], ['17-31'], ['21-4'], ['22-8'], ['26-25'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 72.67251014709473\n",
      "Response: There are 102 LA metro rail stations. The Blue Line was extended one stop northward from Pico to 7th Street/Metro Center on February 15, 1991. The next Metro Rail line\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 517\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['7-4'], ['12-26'], ['19-15'], ['16-24'], ['24-29'], ['11-2'], ['13-11'], ['7-12'], ['6-30'], ['17-31'], ['21-4'], ['22-8'], ['14-18'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 69.17051076889038\n",
      "Response: There are 102 LA metro rail stations. The rapid transit Purple Line became the fifth Metro Rail line on August 24, 2006, when LACMTA separated the Red Line into two separate services\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 765\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['7-4'], ['12-26'], ['19-15'], ['16-24'], ['24-29'], ['7-12'], ['13-11'], ['11-2'], ['6-30'], ['17-31'], ['14-18'], ['21-4'], ['22-8'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 70.54046392440796\n",
      "Response: There are 102 LA metro rail stations. The Regional Connector project featured two new underground stations as well as a rebuilt Little Tokyo/Arts District station. Aviation/Century station opened on November 3,\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_1250_depth_7500_results.json\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['12-26'], ['19-15'], ['24-29'], ['16-24'], ['11-2'], ['13-11'], ['7-12'], ['6-30'], ['14-18'], ['17-31'], ['22-8'], ['21-4'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['12-26'], ['19-15'], ['24-29'], ['16-24'], ['7-12'], ['11-2'], ['13-11'], ['6-30'], ['14-18'], ['17-31'], ['22-8'], ['26-25'], ['21-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 517\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['24-29'], ['12-26'], ['7-12'], ['19-15'], ['16-24'], ['11-2'], ['13-11'], ['14-18'], ['6-30'], ['17-31'], ['22-8'], ['21-4'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1114\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['7-4'], ['7-12'], ['24-29'], ['12-26'], ['16-24'], ['19-15'], ['11-2'], ['13-11'], ['14-18'], ['17-31'], ['6-30'], ['21-4'], ['22-8'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1469\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['7-12'], ['24-29'], ['12-26'], ['16-24'], ['19-15'], ['11-2'], ['14-18'], ['13-11'], ['17-31'], ['6-30'], ['21-4'], ['22-8'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_2500_depth_7500_results.json\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['24-29'], ['12-26'], ['7-12'], ['16-24'], ['19-15'], ['11-2'], ['13-11'], ['14-18'], ['6-30'], ['17-31'], ['22-8'], ['21-4'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['24-29'], ['7-12'], ['12-26'], ['16-24'], ['19-15'], ['11-2'], ['14-18'], ['13-11'], ['6-30'], ['17-31'], ['22-8'], ['21-4'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 884\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['7-12'], ['24-29'], ['12-26'], ['16-24'], ['19-15'], ['11-2'], ['14-18'], ['17-31'], ['6-30'], ['13-11'], ['22-8'], ['21-4'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1469\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['7-12'], ['24-29'], ['12-26'], ['16-24'], ['11-2'], ['19-15'], ['14-18'], ['17-31'], ['6-30'], ['13-11'], ['22-8'], ['21-4'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 1469\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['21-30'], ['24-29'], ['12-26'], ['16-24'], ['11-2'], ['19-15'], ['14-18'], ['17-31'], ['6-30'], ['13-11'], ['21-4'], ['22-8'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_3750_depth_7500_results.json\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['24-29'], ['7-12'], ['12-26'], ['16-24'], ['19-15'], ['11-2'], ['14-18'], ['6-30'], ['17-31'], ['13-11'], ['22-8'], ['21-4'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['7-12'], ['24-29'], ['12-26'], ['16-24'], ['19-15'], ['11-2'], ['14-18'], ['17-31'], ['13-11'], ['6-30'], ['22-8'], ['21-4'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1182\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['21-30'], ['24-29'], ['12-26'], ['16-24'], ['19-15'], ['11-2'], ['14-18'], ['17-31'], ['6-30'], ['13-11'], ['8-22'], ['21-4'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 1469\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['21-30'], ['24-29'], ['12-26'], ['16-24'], ['11-2'], ['19-15'], ['14-18'], ['17-31'], ['6-30'], ['13-11'], ['8-22'], ['21-4'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 1469\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['21-30'], ['24-29'], ['16-24'], ['12-26'], ['11-2'], ['19-15'], ['14-18'], ['17-31'], ['6-30'], ['13-11'], ['8-22'], ['21-4'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_5000_depth_7500_results.json\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['21-30'], ['24-29'], ['12-26'], ['16-24'], ['11-2'], ['19-15'], ['14-18'], ['17-31'], ['6-30'], ['13-11'], ['8-22'], ['21-4'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_relevant_misleading/llama-2-7b-80k_id_172_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: There are 102 LA metro rail stations.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['6-30'], ['11-2'], ['13-11'], ['24-29'], ['6-11'], ['7-13'], ['8-22'], ['8-31'], ['17-31'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['6-30'], ['11-2'], ['13-11'], ['24-29'], ['6-11'], ['7-13'], ['8-22'], ['8-31'], ['17-31'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['6-30'], ['11-2'], ['13-11'], ['24-29'], ['6-11'], ['7-13'], ['8-22'], ['8-31'], ['17-31'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['6-30'], ['11-2'], ['13-11'], ['24-29'], ['6-11'], ['7-13'], ['8-22'], ['8-31'], ['17-31'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_0_depth_7500_results.json\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['6-30'], ['11-2'], ['13-11'], ['24-29'], ['6-11'], ['7-13'], ['8-22'], ['8-31'], ['17-31'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['21-30'], ['12-26'], ['19-15'], ['17-22'], ['16-24'], ['11-2'], ['24-29'], ['6-30'], ['13-11'], ['17-31'], ['8-22'], ['8-31'], ['22-8'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 202\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['12-26'], ['19-15'], ['16-24'], ['11-2'], ['24-29'], ['6-30'], ['7-12'], ['13-11'], ['17-31'], ['8-22'], ['8-31'], ['21-4'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 516\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['16-24'], ['19-15'], ['12-26'], ['24-29'], ['7-12'], ['11-2'], ['6-30'], ['13-11'], ['17-31'], ['8-31'], ['8-22'], ['22-8'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 768\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['16-24'], ['19-15'], ['7-12'], ['24-29'], ['11-2'], ['12-26'], ['6-30'], ['17-31'], ['13-11'], ['8-31'], ['8-22'], ['14-18'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_1250_depth_7500_results.json\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['19-15'], ['12-26'], ['16-24'], ['24-29'], ['11-2'], ['6-30'], ['7-12'], ['17-31'], ['13-11'], ['8-22'], ['8-31'], ['22-8'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['24-29'], ['7-12'], ['16-24'], ['19-15'], ['12-26'], ['11-2'], ['6-30'], ['17-31'], ['13-11'], ['8-31'], ['8-22'], ['22-8'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 534\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['7-12'], ['24-29'], ['16-24'], ['19-15'], ['11-2'], ['12-26'], ['6-30'], ['17-31'], ['13-11'], ['8-31'], ['8-22'], ['22-8'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1119\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['24-29'], ['16-24'], ['11-2'], ['19-15'], ['12-26'], ['6-30'], ['17-31'], ['13-11'], ['8-31'], ['22-8'], ['8-22'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 81.14616870880127\n",
      "Response: There are 102 LA metro rail stations. Besides the MÃ©tro, central Paris and its urban area are served by five RER lines (602 km or 374 mi with 257 stations), four\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1713\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['24-29'], ['16-24'], ['11-2'], ['19-15'], ['6-30'], ['12-26'], ['17-31'], ['13-11'], ['14-18'], ['8-31'], ['22-8'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_2500_depth_7500_results.json\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['7-12'], ['24-29'], ['16-24'], ['19-15'], ['12-26'], ['11-2'], ['6-30'], ['17-31'], ['13-11'], ['8-31'], ['22-8'], ['8-22'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['24-29'], ['16-24'], ['19-15'], ['11-2'], ['12-26'], ['6-30'], ['17-31'], ['13-11'], ['8-31'], ['14-18'], ['22-8'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 846\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['24-29'], ['16-24'], ['11-2'], ['19-15'], ['12-26'], ['6-30'], ['17-31'], ['13-11'], ['8-31'], ['14-18'], ['8-22'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1761\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['24-29'], ['16-24'], ['11-2'], ['19-15'], ['6-30'], ['12-26'], ['17-31'], ['13-11'], ['14-18'], ['8-31'], ['8-22'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2629\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['21-30'], ['24-29'], ['16-24'], ['11-2'], ['6-30'], ['19-15'], ['12-26'], ['17-31'], ['13-11'], ['14-18'], ['8-31'], ['8-22'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_3750_depth_7500_results.json\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['24-29'], ['16-24'], ['11-2'], ['12-26'], ['19-15'], ['6-30'], ['17-31'], ['13-11'], ['8-22'], ['8-31'], ['14-18'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['24-29'], ['16-24'], ['11-2'], ['12-26'], ['6-30'], ['19-15'], ['17-31'], ['13-11'], ['14-18'], ['8-22'], ['8-31'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1174\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['21-30'], ['24-29'], ['16-24'], ['11-2'], ['12-26'], ['17-31'], ['19-15'], ['6-30'], ['13-11'], ['14-18'], ['8-22'], ['8-31'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2386\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['21-30'], ['24-29'], ['16-24'], ['11-2'], ['17-31'], ['12-26'], ['6-30'], ['19-15'], ['13-11'], ['14-18'], ['8-22'], ['8-31'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3533\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-12'], ['7-4'], ['17-22'], ['21-30'], ['24-29'], ['16-24'], ['11-2'], ['17-31'], ['6-30'], ['19-15'], ['12-26'], ['14-18'], ['13-11'], ['8-22'], ['8-31'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_5000_depth_7500_results.json\n",
      "There are 102 LA metro rail stations.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['21-30'], ['24-29'], ['16-24'], ['11-2'], ['12-26'], ['17-31'], ['19-15'], ['6-30'], ['14-18'], ['8-22'], ['13-11'], ['8-31'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant/llama-2-7b-80k_id_172_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/172.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: There are 102 LA metro rail stations.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['6-30'], ['11-2'], ['13-11'], ['24-29'], ['6-11'], ['7-13'], ['8-22'], ['8-31'], ['17-31'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['6-30'], ['11-2'], ['13-11'], ['24-29'], ['6-11'], ['7-13'], ['8-22'], ['8-31'], ['17-31'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['6-30'], ['11-2'], ['13-11'], ['24-29'], ['6-11'], ['7-13'], ['8-22'], ['8-31'], ['17-31'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['6-30'], ['11-2'], ['13-11'], ['24-29'], ['6-11'], ['7-13'], ['8-22'], ['8-31'], ['17-31'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['6-30'], ['11-2'], ['13-11'], ['24-29'], ['6-11'], ['7-13'], ['8-22'], ['8-31'], ['17-31'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['21-30'], ['12-26'], ['19-15'], ['17-22'], ['16-24'], ['24-29'], ['11-2'], ['6-30'], ['13-11'], ['17-31'], ['8-22'], ['21-4'], ['22-8'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 202\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['12-26'], ['19-15'], ['16-24'], ['24-29'], ['11-2'], ['6-30'], ['13-11'], ['17-31'], ['7-12'], ['8-22'], ['21-4'], ['8-31'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 516\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['16-24'], ['19-15'], ['12-26'], ['24-29'], ['11-2'], ['7-12'], ['6-30'], ['17-31'], ['13-11'], ['8-22'], ['8-31'], ['21-4'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 768\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['16-24'], ['24-29'], ['19-15'], ['7-12'], ['12-26'], ['11-2'], ['6-30'], ['17-31'], ['13-11'], ['22-8'], ['8-22'], ['8-31'], ['6-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['16-24'], ['24-29'], ['19-15'], ['12-26'], ['6-30'], ['11-2'], ['7-12'], ['17-31'], ['13-11'], ['22-8'], ['8-22'], ['8-31'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['16-24'], ['24-29'], ['19-15'], ['7-12'], ['12-26'], ['11-2'], ['6-30'], ['17-31'], ['13-11'], ['8-22'], ['22-8'], ['8-31'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 534\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['7-12'], ['16-24'], ['24-29'], ['19-15'], ['12-26'], ['11-2'], ['17-31'], ['6-30'], ['13-11'], ['22-8'], ['8-22'], ['8-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1134\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['7-12'], ['24-29'], ['16-24'], ['19-15'], ['12-26'], ['11-2'], ['17-31'], ['6-30'], ['13-11'], ['22-8'], ['8-22'], ['8-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1712\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['7-12'], ['24-29'], ['16-24'], ['12-26'], ['11-2'], ['19-15'], ['17-31'], ['6-30'], ['13-11'], ['14-18'], ['22-8'], ['8-22'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['7-12'], ['24-29'], ['16-24'], ['12-26'], ['19-15'], ['11-2'], ['17-31'], ['6-30'], ['13-11'], ['8-22'], ['22-8'], ['8-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['7-12'], ['24-29'], ['16-24'], ['12-26'], ['19-15'], ['11-2'], ['17-31'], ['6-30'], ['13-11'], ['8-22'], ['22-8'], ['8-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 92.85771250724792\n",
      "Response: There are 100 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 846\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['24-29'], ['16-24'], ['12-26'], ['19-15'], ['11-2'], ['17-31'], ['6-30'], ['13-11'], ['8-22'], ['22-8'], ['8-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1728\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['24-29'], ['16-24'], ['12-26'], ['11-2'], ['17-31'], ['19-15'], ['13-11'], ['6-30'], ['8-22'], ['22-8'], ['14-18'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2644\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['21-30'], ['24-29'], ['16-24'], ['12-26'], ['19-15'], ['11-2'], ['17-31'], ['13-11'], ['6-30'], ['22-8'], ['8-22'], ['14-18'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 80.31177520751953\n",
      "Response: There are 102 LA metro rail stations. Eighty-six of his entrances are still in existence.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['24-29'], ['12-26'], ['16-24'], ['19-15'], ['11-2'], ['17-31'], ['6-30'], ['13-11'], ['8-22'], ['22-8'], ['15-14'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['24-29'], ['16-24'], ['12-26'], ['19-15'], ['11-2'], ['17-31'], ['6-30'], ['13-11'], ['8-22'], ['22-8'], ['15-14'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1189\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['24-29'], ['16-24'], ['12-26'], ['11-2'], ['17-31'], ['19-15'], ['6-30'], ['13-11'], ['8-22'], ['22-8'], ['15-14'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2375\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['21-30'], ['24-29'], ['16-24'], ['12-26'], ['11-2'], ['19-15'], ['17-31'], ['6-30'], ['13-11'], ['8-22'], ['22-8'], ['14-18'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3576\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['21-30'], ['24-29'], ['16-24'], ['12-26'], ['19-15'], ['11-2'], ['17-31'], ['6-30'], ['13-11'], ['8-22'], ['14-18'], ['22-8'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "There are 102 LA metro rail stations.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['24-29'], ['16-24'], ['12-26'], ['19-15'], ['11-2'], ['17-31'], ['6-30'], ['13-11'], ['8-22'], ['15-14'], ['22-8'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 102 LA metro rail stations.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_172_irrelevant_misleading/llama-2-7b-80k_id_172_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['6-9'], ['21-30'], ['11-15'], ['17-22'], ['24-29'], ['29-19'], ['7-4'], ['8-26'], ['11-2'], ['6-30'], ['15-14'], ['19-15'], ['12-26'], ['13-11'], ['19-9'], ['19-14'], ['22-27'], ['26-25'], ['29-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 90.1591420173645\n",
      "Response: annik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['6-9'], ['21-30'], ['11-15'], ['17-22'], ['24-29'], ['29-19'], ['7-4'], ['8-26'], ['11-2'], ['6-30'], ['15-14'], ['19-15'], ['12-26'], ['13-11'], ['19-9'], ['19-14'], ['22-27'], ['26-25'], ['29-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 90.1591420173645\n",
      "Response: annik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['6-9'], ['21-30'], ['11-15'], ['17-22'], ['24-29'], ['29-19'], ['7-4'], ['8-26'], ['11-2'], ['6-30'], ['15-14'], ['19-15'], ['12-26'], ['13-11'], ['19-9'], ['19-14'], ['22-27'], ['26-25'], ['29-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 90.1591420173645\n",
      "Response: annik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['6-9'], ['21-30'], ['11-15'], ['17-22'], ['24-29'], ['29-19'], ['7-4'], ['8-26'], ['11-2'], ['6-30'], ['15-14'], ['19-15'], ['12-26'], ['13-11'], ['19-9'], ['19-14'], ['22-27'], ['26-25'], ['29-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 90.1591420173645\n",
      "Response: annik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_0_depth_7500_results.json\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['6-9'], ['21-30'], ['11-15'], ['17-22'], ['24-29'], ['29-19'], ['7-4'], ['8-26'], ['11-2'], ['6-30'], ['15-14'], ['19-15'], ['12-26'], ['13-11'], ['19-9'], ['19-14'], ['22-27'], ['26-25'], ['29-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 90.1591420173645\n",
      "Response: annik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['24-29'], ['17-22'], ['11-2'], ['29-19'], ['8-26'], ['7-4'], ['6-30'], ['15-14'], ['19-15'], ['12-26'], ['13-11'], ['19-9'], ['19-14'], ['22-27'], ['26-25'], ['29-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_1250_depth_0_results.json\n",
      "insertion at 237\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['24-29'], ['11-2'], ['17-22'], ['8-26'], ['7-4'], ['29-19'], ['6-30'], ['19-15'], ['15-14'], ['13-11'], ['31-16'], ['19-9'], ['19-14'], ['22-27'], ['12-26'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 93.58274936676025\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history. The eighth spot is reserved, if needed, for a player or team who won a major in the current year and is ranked from ninth to tw\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 495\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['24-29'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['29-19'], ['6-30'], ['19-15'], ['15-14'], ['13-11'], ['31-16'], ['22-27'], ['19-9'], ['19-14'], ['26-25'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 92.46203899383545\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history. In 2022, Rajeev Ram and Joe Salisbury claimed $930,300, the highest payout in\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 729\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['6-30'], ['29-19'], ['15-14'], ['13-11'], ['31-16'], ['22-27'], ['19-9'], ['19-14'], ['22-22'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_1250_depth_7500_results.json\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['6-30'], ['15-14'], ['29-19'], ['13-11'], ['31-16'], ['22-27'], ['19-9'], ['22-22'], ['24-3'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['17-22'], ['7-4'], ['19-15'], ['6-30'], ['15-14'], ['29-19'], ['13-11'], ['31-16'], ['22-27'], ['19-9'], ['24-3'], ['7-12'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_2500_depth_0_results.json\n",
      "insertion at 529\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['17-22'], ['7-4'], ['19-15'], ['6-30'], ['15-14'], ['29-19'], ['13-11'], ['31-16'], ['22-27'], ['7-12'], ['22-22'], ['24-3'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1095\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['17-22'], ['7-4'], ['19-15'], ['6-30'], ['15-14'], ['29-19'], ['13-11'], ['31-16'], ['22-27'], ['7-12'], ['22-22'], ['24-3'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1702\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['17-22'], ['19-15'], ['7-4'], ['6-30'], ['15-14'], ['29-19'], ['31-16'], ['13-11'], ['22-27'], ['7-12'], ['22-22'], ['24-3'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_2500_depth_7500_results.json\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['17-22'], ['11-2'], ['19-15'], ['7-4'], ['6-30'], ['15-14'], ['29-19'], ['31-16'], ['13-11'], ['22-22'], ['22-27'], ['24-3'], ['7-12'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['17-22'], ['11-2'], ['19-15'], ['7-4'], ['6-30'], ['15-14'], ['29-19'], ['31-16'], ['7-12'], ['13-11'], ['22-27'], ['22-22'], ['24-3'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_3750_depth_0_results.json\n",
      "insertion at 807\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['11-2'], ['17-22'], ['19-15'], ['7-4'], ['6-30'], ['15-14'], ['7-12'], ['29-19'], ['31-16'], ['22-27'], ['13-11'], ['22-22'], ['24-3'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1744\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['11-2'], ['17-22'], ['19-15'], ['7-4'], ['6-30'], ['15-14'], ['7-12'], ['31-16'], ['29-19'], ['13-11'], ['22-27'], ['22-22'], ['24-3'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2591\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['21-30'], ['11-2'], ['17-22'], ['19-15'], ['7-4'], ['6-30'], ['15-14'], ['7-12'], ['31-16'], ['13-11'], ['22-27'], ['22-22'], ['29-19'], ['24-3'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_3750_depth_7500_results.json\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['21-30'], ['17-22'], ['11-2'], ['19-15'], ['7-4'], ['6-30'], ['15-14'], ['7-12'], ['31-16'], ['13-11'], ['22-22'], ['22-27'], ['29-19'], ['24-3'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['21-30'], ['11-2'], ['17-22'], ['19-15'], ['7-4'], ['6-30'], ['15-14'], ['7-12'], ['31-16'], ['13-11'], ['22-22'], ['22-27'], ['29-19'], ['24-3'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 73.05387258529663\n",
      "Response: Jannik Sinner, who won the 2024 ATP Finals in Turin, Italy, and took home $4,881,100.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1145\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['21-30'], ['11-2'], ['17-22'], ['19-15'], ['7-4'], ['6-30'], ['15-14'], ['7-12'], ['31-16'], ['22-22'], ['22-27'], ['13-11'], ['29-19'], ['24-3'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2341\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['21-30'], ['17-22'], ['11-2'], ['19-15'], ['7-4'], ['6-30'], ['15-14'], ['7-12'], ['22-22'], ['22-27'], ['13-11'], ['31-16'], ['29-19'], ['14-18'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 2807\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['21-30'], ['17-22'], ['11-2'], ['19-15'], ['7-4'], ['6-30'], ['7-12'], ['15-14'], ['22-22'], ['22-27'], ['13-11'], ['31-16'], ['14-18'], ['29-19'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_5000_depth_7500_results.json\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['21-30'], ['17-22'], ['11-2'], ['19-15'], ['7-4'], ['6-30'], ['7-12'], ['15-14'], ['22-22'], ['13-11'], ['22-27'], ['31-16'], ['14-18'], ['24-3'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant/llama-2-7b-80k_id_173_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/173.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['6-9'], ['21-30'], ['11-15'], ['17-22'], ['24-29'], ['29-19'], ['7-4'], ['8-26'], ['11-2'], ['6-30'], ['15-14'], ['19-15'], ['12-26'], ['13-11'], ['19-9'], ['19-14'], ['22-27'], ['26-25'], ['29-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 90.1591420173645\n",
      "Response: annik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['6-9'], ['21-30'], ['11-15'], ['17-22'], ['24-29'], ['29-19'], ['7-4'], ['8-26'], ['11-2'], ['6-30'], ['15-14'], ['19-15'], ['12-26'], ['13-11'], ['19-9'], ['19-14'], ['22-27'], ['26-25'], ['29-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 90.1591420173645\n",
      "Response: annik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['6-9'], ['21-30'], ['11-15'], ['17-22'], ['24-29'], ['29-19'], ['7-4'], ['8-26'], ['11-2'], ['6-30'], ['15-14'], ['19-15'], ['12-26'], ['13-11'], ['19-9'], ['19-14'], ['22-27'], ['26-25'], ['29-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 90.1591420173645\n",
      "Response: annik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['6-9'], ['21-30'], ['11-15'], ['17-22'], ['24-29'], ['29-19'], ['7-4'], ['8-26'], ['11-2'], ['6-30'], ['15-14'], ['19-15'], ['12-26'], ['13-11'], ['19-9'], ['19-14'], ['22-27'], ['26-25'], ['29-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 90.1591420173645\n",
      "Response: annik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_0_depth_7500_results.json\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['6-9'], ['21-30'], ['11-15'], ['17-22'], ['24-29'], ['29-19'], ['7-4'], ['8-26'], ['11-2'], ['6-30'], ['15-14'], ['19-15'], ['12-26'], ['13-11'], ['19-9'], ['19-14'], ['22-27'], ['26-25'], ['29-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 90.1591420173645\n",
      "Response: annik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['17-22'], ['24-29'], ['11-2'], ['29-19'], ['8-26'], ['7-4'], ['6-30'], ['19-15'], ['15-14'], ['19-14'], ['12-26'], ['13-11'], ['19-9'], ['22-27'], ['26-25'], ['29-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 237\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['24-29'], ['11-2'], ['17-22'], ['8-26'], ['29-19'], ['7-4'], ['19-15'], ['6-30'], ['15-14'], ['19-14'], ['13-11'], ['22-27'], ['19-9'], ['31-16'], ['12-26'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 93.58274936676025\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history. The eighth spot is reserved, if needed, for a player or team who won a major in the current year and is ranked from ninth to tw\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 495\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['24-29'], ['17-22'], ['11-2'], ['8-26'], ['29-19'], ['7-4'], ['19-15'], ['6-30'], ['15-14'], ['19-14'], ['13-11'], ['22-27'], ['19-9'], ['31-16'], ['26-25'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 92.46203899383545\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history. In 2022, Rajeev Ram and Joe Salisbury claimed $930,300, the highest payout in\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 749\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['24-29'], ['17-22'], ['11-2'], ['8-26'], ['7-4'], ['19-15'], ['29-19'], ['15-14'], ['6-30'], ['13-11'], ['19-14'], ['22-27'], ['31-16'], ['22-22'], ['19-9'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_1250_depth_7500_results.json\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['24-29'], ['17-22'], ['8-26'], ['11-2'], ['19-15'], ['7-4'], ['15-14'], ['6-30'], ['29-19'], ['13-11'], ['22-27'], ['31-16'], ['19-14'], ['22-22'], ['19-9'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['24-29'], ['17-22'], ['11-2'], ['8-26'], ['19-15'], ['7-4'], ['15-14'], ['29-19'], ['6-30'], ['13-11'], ['22-27'], ['31-16'], ['19-14'], ['22-22'], ['24-3'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 58.82450342178345\n",
      "Response: Jannik Sinner\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 529\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['24-29'], ['17-22'], ['8-26'], ['11-2'], ['19-15'], ['7-4'], ['6-30'], ['15-14'], ['29-19'], ['13-11'], ['22-27'], ['19-14'], ['31-16'], ['22-22'], ['24-3'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 58.82450342178345\n",
      "Response: Jannik Sinner\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1115\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['24-29'], ['8-26'], ['17-22'], ['11-2'], ['19-15'], ['7-4'], ['6-30'], ['15-14'], ['29-19'], ['22-27'], ['13-11'], ['19-14'], ['31-16'], ['22-22'], ['24-3'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1703\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['24-29'], ['8-26'], ['17-22'], ['11-2'], ['19-15'], ['7-4'], ['15-14'], ['6-30'], ['29-19'], ['22-27'], ['13-11'], ['22-22'], ['19-14'], ['31-16'], ['19-10'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_2500_depth_7500_results.json\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['24-29'], ['8-26'], ['17-22'], ['11-2'], ['19-15'], ['7-4'], ['6-30'], ['15-14'], ['29-19'], ['22-27'], ['13-11'], ['22-22'], ['31-16'], ['19-14'], ['24-3'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['24-29'], ['8-26'], ['17-22'], ['11-2'], ['19-15'], ['7-4'], ['6-30'], ['15-14'], ['29-19'], ['22-27'], ['13-11'], ['22-22'], ['31-16'], ['19-14'], ['24-3'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 58.82450342178345\n",
      "Response: Jannik Sinner\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 827\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['24-29'], ['8-26'], ['17-22'], ['11-2'], ['19-15'], ['6-30'], ['7-4'], ['15-14'], ['29-19'], ['22-27'], ['22-22'], ['13-11'], ['31-16'], ['19-14'], ['24-3'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 58.82450342178345\n",
      "Response: Jannik Sinner\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1738\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['24-29'], ['8-26'], ['17-22'], ['11-2'], ['19-15'], ['6-30'], ['7-4'], ['15-14'], ['29-19'], ['22-27'], ['22-22'], ['13-11'], ['19-14'], ['31-16'], ['24-3'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2615\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['24-29'], ['8-26'], ['17-22'], ['11-2'], ['19-15'], ['6-30'], ['15-14'], ['7-4'], ['22-27'], ['29-19'], ['22-22'], ['13-11'], ['19-14'], ['31-16'], ['24-3'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_3750_depth_7500_results.json\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['24-29'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['7-4'], ['6-30'], ['15-14'], ['22-27'], ['29-19'], ['22-22'], ['13-11'], ['31-16'], ['19-14'], ['24-3'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['24-29'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['7-4'], ['6-30'], ['15-14'], ['29-19'], ['22-27'], ['22-22'], ['13-11'], ['31-16'], ['19-14'], ['24-3'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 58.82450342178345\n",
      "Response: Jannik Sinner\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1193\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['24-29'], ['8-26'], ['17-22'], ['11-2'], ['19-15'], ['7-4'], ['6-30'], ['15-14'], ['22-22'], ['22-27'], ['29-19'], ['13-11'], ['31-16'], ['19-14'], ['24-3'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2383\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['21-30'], ['8-26'], ['17-22'], ['11-2'], ['19-15'], ['15-14'], ['7-4'], ['6-30'], ['22-22'], ['22-27'], ['29-19'], ['13-11'], ['31-16'], ['19-14'], ['19-9'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 2951\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['8-26'], ['21-30'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['7-4'], ['6-30'], ['22-22'], ['22-27'], ['29-19'], ['13-11'], ['19-14'], ['31-16'], ['19-9'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_5000_depth_7500_results.json\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['8-26'], ['21-30'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['7-4'], ['6-30'], ['22-22'], ['22-27'], ['29-19'], ['13-11'], ['31-16'], ['19-14'], ['19-9'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_relevant_misleading/llama-2-7b-80k_id_173_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['6-9'], ['21-30'], ['11-15'], ['17-22'], ['24-29'], ['29-19'], ['7-4'], ['8-26'], ['11-2'], ['6-30'], ['15-14'], ['19-15'], ['12-26'], ['13-11'], ['19-9'], ['19-14'], ['22-27'], ['26-25'], ['29-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 90.1591420173645\n",
      "Response: annik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['6-9'], ['21-30'], ['11-15'], ['17-22'], ['24-29'], ['29-19'], ['7-4'], ['8-26'], ['11-2'], ['6-30'], ['15-14'], ['19-15'], ['12-26'], ['13-11'], ['19-9'], ['19-14'], ['22-27'], ['26-25'], ['29-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 90.1591420173645\n",
      "Response: annik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['6-9'], ['21-30'], ['11-15'], ['17-22'], ['24-29'], ['29-19'], ['7-4'], ['8-26'], ['11-2'], ['6-30'], ['15-14'], ['19-15'], ['12-26'], ['13-11'], ['19-9'], ['19-14'], ['22-27'], ['26-25'], ['29-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 90.1591420173645\n",
      "Response: annik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['6-9'], ['21-30'], ['11-15'], ['17-22'], ['24-29'], ['29-19'], ['7-4'], ['8-26'], ['11-2'], ['6-30'], ['15-14'], ['19-15'], ['12-26'], ['13-11'], ['19-9'], ['19-14'], ['22-27'], ['26-25'], ['29-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 90.1591420173645\n",
      "Response: annik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_0_depth_7500_results.json\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['6-9'], ['21-30'], ['11-15'], ['17-22'], ['24-29'], ['29-19'], ['7-4'], ['8-26'], ['11-2'], ['6-30'], ['15-14'], ['19-15'], ['12-26'], ['13-11'], ['19-9'], ['19-14'], ['22-27'], ['26-25'], ['29-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 90.1591420173645\n",
      "Response: annik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['17-22'], ['11-2'], ['24-29'], ['29-19'], ['8-26'], ['7-4'], ['6-30'], ['15-14'], ['19-15'], ['22-27'], ['12-26'], ['13-11'], ['19-9'], ['19-14'], ['26-25'], ['29-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 68.2268500328064\n",
      "Response: Carlos Alcaraz won the biggest single-tournament payday in tennis history at the 2022 US Open, where he earned $4,620,000 for winning the men's singles title.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 28\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['17-22'], ['24-29'], ['8-26'], ['11-2'], ['29-19'], ['7-4'], ['6-30'], ['19-15'], ['15-14'], ['22-27'], ['13-11'], ['19-14'], ['31-16'], ['19-9'], ['7-12'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 28\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['17-22'], ['8-26'], ['24-29'], ['11-2'], ['7-4'], ['29-19'], ['6-30'], ['19-15'], ['22-27'], ['7-12'], ['15-14'], ['13-11'], ['19-14'], ['31-16'], ['19-9'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 28\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['17-22'], ['24-29'], ['11-2'], ['7-4'], ['29-19'], ['19-15'], ['7-12'], ['6-30'], ['22-27'], ['13-11'], ['15-14'], ['19-14'], ['31-16'], ['22-22'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_1250_depth_7500_results.json\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['17-22'], ['24-29'], ['11-2'], ['7-4'], ['19-15'], ['6-30'], ['29-19'], ['7-12'], ['22-27'], ['13-11'], ['15-14'], ['31-16'], ['22-22'], ['19-14'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['17-22'], ['8-26'], ['24-29'], ['11-2'], ['7-4'], ['19-15'], ['6-30'], ['29-19'], ['7-12'], ['22-27'], ['13-11'], ['15-14'], ['31-16'], ['22-22'], ['19-14'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 69.14376020431519\n",
      "Response: Carlos Alcaraz won the biggest single-tournament payday in tennis history at the 2022 US Open. He won $4,620,000 for winning the men's singles title.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 28\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['17-22'], ['8-26'], ['24-29'], ['11-2'], ['7-4'], ['19-15'], ['7-12'], ['6-30'], ['29-19'], ['22-27'], ['13-11'], ['31-16'], ['15-14'], ['22-22'], ['19-14'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1095\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['19-15'], ['7-12'], ['7-4'], ['6-30'], ['22-27'], ['29-19'], ['13-11'], ['15-14'], ['22-22'], ['31-16'], ['19-14'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1608\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['19-15'], ['7-12'], ['7-4'], ['6-30'], ['22-27'], ['29-19'], ['13-11'], ['15-14'], ['22-22'], ['31-16'], ['19-14'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_2500_depth_7500_results.json\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['19-15'], ['7-4'], ['7-12'], ['6-30'], ['22-27'], ['29-19'], ['13-11'], ['22-22'], ['31-16'], ['15-14'], ['24-3'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['21-30'], ['24-29'], ['11-2'], ['19-15'], ['7-12'], ['7-4'], ['6-30'], ['22-27'], ['29-19'], ['13-11'], ['22-22'], ['15-14'], ['31-16'], ['24-3'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 72.76501655578613\n",
      "Response: Carlos Alcaraz won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 28\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['21-30'], ['24-29'], ['11-2'], ['19-15'], ['7-12'], ['7-4'], ['22-27'], ['6-30'], ['29-19'], ['13-11'], ['22-22'], ['15-14'], ['31-16'], ['24-3'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1608\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['21-30'], ['24-29'], ['11-2'], ['7-12'], ['19-15'], ['7-4'], ['22-27'], ['6-30'], ['22-22'], ['29-19'], ['13-11'], ['15-14'], ['31-16'], ['24-3'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 1608\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['24-29'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['7-4'], ['22-27'], ['6-30'], ['22-22'], ['15-14'], ['29-19'], ['13-11'], ['31-16'], ['24-3'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_3750_depth_7500_results.json\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['24-29'], ['21-30'], ['11-2'], ['19-15'], ['7-12'], ['7-4'], ['6-30'], ['22-27'], ['22-22'], ['13-11'], ['15-14'], ['29-19'], ['31-16'], ['24-3'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['8-26'], ['24-29'], ['21-30'], ['11-2'], ['19-15'], ['7-12'], ['7-4'], ['22-27'], ['6-30'], ['22-22'], ['13-11'], ['15-14'], ['29-19'], ['31-16'], ['24-3'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 72.76501655578613\n",
      "Response: Carlos Alcaraz won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1179\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['8-26'], ['24-29'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['7-4'], ['22-27'], ['6-30'], ['22-22'], ['13-11'], ['15-14'], ['29-19'], ['31-16'], ['24-3'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 1608\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['11-15'], ['16-19'], ['17-22'], ['6-9'], ['8-26'], ['24-29'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['7-4'], ['22-27'], ['22-22'], ['6-30'], ['13-11'], ['15-14'], ['29-19'], ['31-16'], ['24-3'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 2835\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['11-15'], ['16-19'], ['17-22'], ['6-9'], ['8-26'], ['24-29'], ['11-2'], ['21-30'], ['7-12'], ['19-15'], ['7-4'], ['22-27'], ['22-22'], ['6-30'], ['13-11'], ['15-14'], ['29-19'], ['14-18'], ['24-3'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_5000_depth_7500_results.json\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['11-15'], ['16-19'], ['17-22'], ['6-9'], ['8-26'], ['24-29'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['7-4'], ['22-27'], ['22-22'], ['6-30'], ['13-11'], ['15-14'], ['31-16'], ['24-3'], ['14-18'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant/llama-2-7b-80k_id_173_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/173.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['6-9'], ['21-30'], ['11-15'], ['17-22'], ['24-29'], ['29-19'], ['7-4'], ['8-26'], ['11-2'], ['6-30'], ['15-14'], ['19-15'], ['12-26'], ['13-11'], ['19-9'], ['19-14'], ['22-27'], ['26-25'], ['29-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 90.1591420173645\n",
      "Response: annik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['6-9'], ['21-30'], ['11-15'], ['17-22'], ['24-29'], ['29-19'], ['7-4'], ['8-26'], ['11-2'], ['6-30'], ['15-14'], ['19-15'], ['12-26'], ['13-11'], ['19-9'], ['19-14'], ['22-27'], ['26-25'], ['29-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 90.1591420173645\n",
      "Response: annik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['6-9'], ['21-30'], ['11-15'], ['17-22'], ['24-29'], ['29-19'], ['7-4'], ['8-26'], ['11-2'], ['6-30'], ['15-14'], ['19-15'], ['12-26'], ['13-11'], ['19-9'], ['19-14'], ['22-27'], ['26-25'], ['29-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 90.1591420173645\n",
      "Response: annik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['6-9'], ['21-30'], ['11-15'], ['17-22'], ['24-29'], ['29-19'], ['7-4'], ['8-26'], ['11-2'], ['6-30'], ['15-14'], ['19-15'], ['12-26'], ['13-11'], ['19-9'], ['19-14'], ['22-27'], ['26-25'], ['29-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 90.1591420173645\n",
      "Response: annik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['6-9'], ['21-30'], ['11-15'], ['17-22'], ['24-29'], ['29-19'], ['7-4'], ['8-26'], ['11-2'], ['6-30'], ['15-14'], ['19-15'], ['12-26'], ['13-11'], ['19-9'], ['19-14'], ['22-27'], ['26-25'], ['29-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 90.1591420173645\n",
      "Response: annik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['17-22'], ['11-2'], ['24-29'], ['29-19'], ['8-26'], ['7-4'], ['6-30'], ['15-14'], ['19-15'], ['22-27'], ['12-26'], ['13-11'], ['19-9'], ['19-14'], ['26-25'], ['29-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 68.2268500328064\n",
      "Response: Carlos Alcaraz won the biggest single-tournament payday in tennis history at the 2022 US Open, where he earned $4,620,000 for winning the men's singles title.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 28\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['17-22'], ['24-29'], ['8-26'], ['11-2'], ['29-19'], ['7-4'], ['6-30'], ['19-15'], ['15-14'], ['22-27'], ['13-11'], ['19-14'], ['31-16'], ['19-9'], ['7-12'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 28\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['17-22'], ['8-26'], ['24-29'], ['11-2'], ['7-4'], ['29-19'], ['6-30'], ['19-15'], ['22-27'], ['7-12'], ['15-14'], ['13-11'], ['19-14'], ['31-16'], ['19-9'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 28\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['17-22'], ['24-29'], ['11-2'], ['7-4'], ['29-19'], ['19-15'], ['7-12'], ['6-30'], ['22-27'], ['13-11'], ['15-14'], ['19-14'], ['31-16'], ['22-22'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['17-22'], ['24-29'], ['11-2'], ['7-4'], ['19-15'], ['6-30'], ['29-19'], ['7-12'], ['22-27'], ['13-11'], ['15-14'], ['31-16'], ['22-22'], ['19-14'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['17-22'], ['8-26'], ['24-29'], ['11-2'], ['7-4'], ['19-15'], ['29-19'], ['6-30'], ['7-12'], ['22-27'], ['13-11'], ['15-14'], ['31-16'], ['19-14'], ['22-22'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 28\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['7-4'], ['7-12'], ['19-15'], ['29-19'], ['6-30'], ['22-27'], ['13-11'], ['15-14'], ['19-14'], ['31-16'], ['22-22'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1095\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['19-15'], ['7-12'], ['7-4'], ['22-27'], ['6-30'], ['29-19'], ['13-11'], ['15-14'], ['22-22'], ['19-14'], ['31-16'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1628\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['19-15'], ['7-12'], ['7-4'], ['22-27'], ['6-30'], ['29-19'], ['13-11'], ['15-14'], ['22-22'], ['19-14'], ['19-9'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['19-15'], ['7-4'], ['7-12'], ['22-27'], ['6-30'], ['29-19'], ['22-22'], ['13-11'], ['15-14'], ['24-3'], ['31-16'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['19-15'], ['7-12'], ['7-4'], ['22-27'], ['6-30'], ['29-19'], ['13-11'], ['22-22'], ['15-14'], ['24-3'], ['31-16'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 58.82450342178345\n",
      "Response: Jannik Sinner\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 28\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['21-30'], ['24-29'], ['11-2'], ['19-15'], ['7-12'], ['7-4'], ['22-27'], ['6-30'], ['29-19'], ['13-11'], ['22-22'], ['15-14'], ['24-3'], ['19-14'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1628\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['24-29'], ['21-30'], ['11-2'], ['19-15'], ['7-12'], ['7-4'], ['22-27'], ['6-30'], ['29-19'], ['22-22'], ['13-11'], ['15-14'], ['24-3'], ['19-14'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 1628\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['24-29'], ['21-30'], ['11-2'], ['19-15'], ['7-12'], ['7-4'], ['22-27'], ['6-30'], ['22-22'], ['29-19'], ['13-11'], ['15-14'], ['24-3'], ['19-14'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['24-29'], ['21-30'], ['11-2'], ['19-15'], ['7-12'], ['7-4'], ['6-30'], ['22-27'], ['22-22'], ['13-11'], ['29-19'], ['15-14'], ['24-3'], ['31-16'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['24-29'], ['21-30'], ['11-2'], ['19-15'], ['7-12'], ['7-4'], ['6-30'], ['22-27'], ['22-22'], ['13-11'], ['29-19'], ['15-14'], ['24-3'], ['31-16'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 58.82450342178345\n",
      "Response: Jannik Sinner\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1179\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['24-29'], ['21-30'], ['11-2'], ['19-15'], ['7-12'], ['7-4'], ['22-27'], ['6-30'], ['22-22'], ['13-11'], ['15-14'], ['29-19'], ['24-3'], ['31-16'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 58.82450342178345\n",
      "Response: Jannik Sinner\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 1628\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['24-29'], ['21-30'], ['11-2'], ['19-15'], ['7-12'], ['7-4'], ['22-27'], ['6-30'], ['22-22'], ['13-11'], ['15-14'], ['29-19'], ['24-3'], ['19-9'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 2883\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['24-29'], ['8-26'], ['21-30'], ['11-2'], ['19-15'], ['7-12'], ['7-4'], ['22-27'], ['6-30'], ['22-22'], ['15-14'], ['13-11'], ['24-3'], ['29-19'], ['19-9'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['24-29'], ['8-26'], ['21-30'], ['11-2'], ['19-15'], ['7-12'], ['7-4'], ['22-27'], ['6-30'], ['22-22'], ['13-11'], ['15-14'], ['24-3'], ['29-19'], ['31-16'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Jannik Sinner won the biggest single-tournament payday in tennis history.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_173_irrelevant_misleading/llama-2-7b-80k_id_173_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['16-24'], ['17-22'], ['19-15'], ['21-30'], ['29-5'], ['31-15'], ['1-26'], ['11-2'], ['15-14'], ['15-25'], ['19-10'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['16-24'], ['17-22'], ['19-15'], ['21-30'], ['29-5'], ['31-15'], ['1-26'], ['11-2'], ['15-14'], ['15-25'], ['19-10'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['16-24'], ['17-22'], ['19-15'], ['21-30'], ['29-5'], ['31-15'], ['1-26'], ['11-2'], ['15-14'], ['15-25'], ['19-10'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['16-24'], ['17-22'], ['19-15'], ['21-30'], ['29-5'], ['31-15'], ['1-26'], ['11-2'], ['15-14'], ['15-25'], ['19-10'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_0_depth_7500_results.json\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['16-24'], ['17-22'], ['19-15'], ['21-30'], ['29-5'], ['31-15'], ['1-26'], ['11-2'], ['15-14'], ['15-25'], ['19-10'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['18-30'], ['12-26'], ['14-18'], ['17-22'], ['19-15'], ['16-24'], ['31-15'], ['21-30'], ['11-2'], ['29-5'], ['15-14'], ['19-10'], ['20-29'], ['31-24'], ['31-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_1250_depth_0_results.json\n",
      "insertion at 252\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['16-19'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['14-18'], ['12-26'], ['19-15'], ['16-24'], ['11-2'], ['21-30'], ['7-12'], ['31-15'], ['20-29'], ['15-14'], ['19-10'], ['29-5'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 97.0253586769104\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.com\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 504\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['14-18'], ['18-30'], ['7-12'], ['12-26'], ['19-15'], ['21-30'], ['11-2'], ['16-24'], ['20-29'], ['19-10'], ['15-14'], ['31-15'], ['29-5'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 728\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['14-18'], ['7-12'], ['18-30'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['20-29'], ['16-24'], ['19-10'], ['15-14'], ['31-15'], ['29-5'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_1250_depth_7500_results.json\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['14-18'], ['18-30'], ['19-15'], ['21-30'], ['7-12'], ['12-26'], ['11-2'], ['16-24'], ['20-29'], ['19-10'], ['15-14'], ['29-5'], ['31-15'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['14-18'], ['7-12'], ['18-30'], ['19-15'], ['21-30'], ['11-2'], ['12-26'], ['20-29'], ['16-24'], ['19-10'], ['15-14'], ['31-15'], ['17-31'], ['29-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_2500_depth_0_results.json\n",
      "insertion at 504\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 43.068841099739075\n",
      "Response: November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1138\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['14-18'], ['21-30'], ['19-15'], ['18-30'], ['11-2'], ['12-26'], ['20-29'], ['19-10'], ['16-24'], ['15-14'], ['31-15'], ['17-31'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1658\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['14-18'], ['19-15'], ['11-2'], ['18-30'], ['20-29'], ['12-26'], ['19-10'], ['16-24'], ['15-14'], ['22-22'], ['24-29'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_2500_depth_7500_results.json\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['19-15'], ['14-18'], ['18-30'], ['11-2'], ['12-26'], ['20-29'], ['19-10'], ['16-24'], ['15-14'], ['24-29'], ['29-5'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['14-18'], ['19-15'], ['11-2'], ['18-30'], ['20-29'], ['12-26'], ['19-10'], ['16-24'], ['15-14'], ['17-31'], ['24-29'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_3750_depth_0_results.json\n",
      "insertion at 807\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['14-18'], ['11-2'], ['19-15'], ['18-30'], ['20-29'], ['19-10'], ['12-26'], ['16-24'], ['15-14'], ['17-31'], ['24-3'], ['6-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1741\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['14-18'], ['21-30'], ['11-2'], ['19-15'], ['18-30'], ['20-29'], ['19-10'], ['12-26'], ['16-24'], ['15-14'], ['17-31'], ['6-16'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2642\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['11-2'], ['14-18'], ['21-30'], ['19-15'], ['18-30'], ['20-29'], ['19-10'], ['12-26'], ['16-24'], ['15-14'], ['6-16'], ['17-31'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 79.21208143234253\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024. 1 and Watts Finest Vol. 2: The Nickerson Files. Lamar was ultimately let go from Def Jam\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_3750_depth_7500_results.json\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['19-15'], ['14-18'], ['11-2'], ['18-30'], ['20-29'], ['19-10'], ['12-26'], ['16-24'], ['15-14'], ['17-31'], ['24-29'], ['6-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['21-30'], ['14-18'], ['11-2'], ['19-15'], ['18-30'], ['20-29'], ['19-10'], ['12-26'], ['16-24'], ['15-14'], ['6-16'], ['17-31'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1159\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['21-30'], ['11-2'], ['14-18'], ['19-15'], ['18-30'], ['20-29'], ['19-10'], ['16-24'], ['12-26'], ['15-14'], ['6-16'], ['17-31'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2338\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['21-30'], ['11-2'], ['14-18'], ['19-15'], ['18-30'], ['20-29'], ['19-10'], ['16-24'], ['12-26'], ['15-14'], ['6-16'], ['17-31'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3576\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['11-2'], ['21-30'], ['14-18'], ['19-15'], ['18-30'], ['20-29'], ['19-10'], ['16-24'], ['15-14'], ['12-26'], ['6-16'], ['24-29'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_5000_depth_7500_results.json\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['21-30'], ['11-2'], ['14-18'], ['19-15'], ['18-30'], ['19-10'], ['20-29'], ['16-24'], ['12-26'], ['15-14'], ['6-16'], ['24-29'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant/llama-2-7b-80k_id_175_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/175.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['16-24'], ['17-22'], ['19-15'], ['21-30'], ['29-5'], ['31-15'], ['1-26'], ['11-2'], ['15-14'], ['15-25'], ['19-10'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['16-24'], ['17-22'], ['19-15'], ['21-30'], ['29-5'], ['31-15'], ['1-26'], ['11-2'], ['15-14'], ['15-25'], ['19-10'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['16-24'], ['17-22'], ['19-15'], ['21-30'], ['29-5'], ['31-15'], ['1-26'], ['11-2'], ['15-14'], ['15-25'], ['19-10'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['16-24'], ['17-22'], ['19-15'], ['21-30'], ['29-5'], ['31-15'], ['1-26'], ['11-2'], ['15-14'], ['15-25'], ['19-10'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_0_depth_7500_results.json\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['16-24'], ['17-22'], ['19-15'], ['21-30'], ['29-5'], ['31-15'], ['1-26'], ['11-2'], ['15-14'], ['15-25'], ['19-10'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['18-30'], ['12-26'], ['14-18'], ['17-22'], ['19-15'], ['16-24'], ['31-15'], ['21-30'], ['11-2'], ['29-5'], ['15-14'], ['19-10'], ['20-29'], ['31-24'], ['31-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 252\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['16-19'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['14-18'], ['12-26'], ['19-15'], ['16-24'], ['11-2'], ['21-30'], ['7-12'], ['31-15'], ['20-29'], ['15-14'], ['19-10'], ['29-5'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 97.0253586769104\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.com\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 504\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['14-18'], ['18-30'], ['7-12'], ['12-26'], ['19-15'], ['21-30'], ['11-2'], ['16-24'], ['20-29'], ['19-10'], ['15-14'], ['31-15'], ['29-5'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 728\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['14-18'], ['7-12'], ['18-30'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['20-29'], ['16-24'], ['19-10'], ['15-14'], ['31-15'], ['29-5'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_1250_depth_7500_results.json\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['14-18'], ['18-30'], ['19-15'], ['21-30'], ['7-12'], ['12-26'], ['11-2'], ['16-24'], ['20-29'], ['19-10'], ['15-14'], ['29-5'], ['31-15'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['14-18'], ['18-30'], ['19-15'], ['21-30'], ['11-2'], ['12-26'], ['20-29'], ['16-24'], ['19-10'], ['15-14'], ['17-31'], ['31-15'], ['29-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 504\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['14-18'], ['21-30'], ['18-30'], ['19-15'], ['11-2'], ['12-26'], ['20-29'], ['19-10'], ['16-24'], ['15-14'], ['17-31'], ['31-15'], ['29-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1138\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['14-18'], ['21-30'], ['11-2'], ['19-15'], ['18-30'], ['20-29'], ['12-26'], ['19-10'], ['16-24'], ['15-14'], ['17-31'], ['24-29'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1679\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['14-18'], ['11-2'], ['19-15'], ['18-30'], ['20-29'], ['19-10'], ['12-26'], ['16-24'], ['24-29'], ['17-31'], ['15-14'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_2500_depth_7500_results.json\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['14-18'], ['19-15'], ['11-2'], ['18-30'], ['20-29'], ['12-26'], ['19-10'], ['16-24'], ['24-29'], ['15-14'], ['17-31'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['21-30'], ['14-18'], ['11-2'], ['19-15'], ['18-30'], ['19-10'], ['20-29'], ['12-26'], ['16-24'], ['17-31'], ['15-14'], ['24-29'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 807\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['21-30'], ['11-2'], ['14-18'], ['19-15'], ['18-30'], ['19-10'], ['20-29'], ['12-26'], ['16-24'], ['15-14'], ['17-31'], ['24-29'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1762\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['21-30'], ['11-2'], ['14-18'], ['19-15'], ['18-30'], ['19-10'], ['20-29'], ['12-26'], ['16-24'], ['15-14'], ['17-31'], ['24-29'], ['6-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2632\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['21-30'], ['11-2'], ['14-18'], ['19-15'], ['19-10'], ['18-30'], ['20-29'], ['12-26'], ['15-14'], ['16-24'], ['17-31'], ['24-29'], ['6-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_3750_depth_7500_results.json\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['21-30'], ['11-2'], ['19-15'], ['14-18'], ['19-10'], ['20-29'], ['18-30'], ['12-26'], ['16-24'], ['15-14'], ['17-31'], ['24-29'], ['6-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['21-30'], ['11-2'], ['14-18'], ['19-15'], ['19-10'], ['20-29'], ['18-30'], ['17-31'], ['12-26'], ['15-14'], ['16-24'], ['24-29'], ['6-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1180\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['21-30'], ['11-2'], ['14-18'], ['19-15'], ['19-10'], ['20-29'], ['18-30'], ['17-31'], ['15-14'], ['12-26'], ['16-24'], ['24-29'], ['6-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2379\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 37.6024067401886\n",
      "Response: 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3579\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['21-30'], ['11-2'], ['14-18'], ['19-15'], ['19-10'], ['20-29'], ['18-30'], ['15-14'], ['17-31'], ['24-29'], ['16-24'], ['12-26'], ['6-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_5000_depth_7500_results.json\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['21-30'], ['11-2'], ['14-18'], ['19-15'], ['19-10'], ['20-29'], ['18-30'], ['15-14'], ['12-26'], ['16-24'], ['17-31'], ['24-29'], ['6-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_relevant_misleading/llama-2-7b-80k_id_175_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['16-24'], ['17-22'], ['19-15'], ['21-30'], ['29-5'], ['31-15'], ['1-26'], ['11-2'], ['15-14'], ['15-25'], ['19-10'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['16-24'], ['17-22'], ['19-15'], ['21-30'], ['29-5'], ['31-15'], ['1-26'], ['11-2'], ['15-14'], ['15-25'], ['19-10'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['16-24'], ['17-22'], ['19-15'], ['21-30'], ['29-5'], ['31-15'], ['1-26'], ['11-2'], ['15-14'], ['15-25'], ['19-10'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['16-24'], ['17-22'], ['19-15'], ['21-30'], ['29-5'], ['31-15'], ['1-26'], ['11-2'], ['15-14'], ['15-25'], ['19-10'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_0_depth_7500_results.json\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['16-24'], ['17-22'], ['19-15'], ['21-30'], ['29-5'], ['31-15'], ['1-26'], ['11-2'], ['15-14'], ['15-25'], ['19-10'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['16-19'], ['11-15'], ['8-26'], ['7-4'], ['18-30'], ['12-26'], ['14-18'], ['17-22'], ['16-24'], ['19-15'], ['31-15'], ['21-30'], ['29-5'], ['11-2'], ['19-10'], ['1-26'], ['15-14'], ['15-25'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 97.04310894012451\n",
      "Response: On November 10, 2022, Kendrick Lamar released his most recent studio album.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 199\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 41.62423312664032\n",
      "Response: On November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 483\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 42.81301200389862\n",
      "Response: November 22, 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 712\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 41.62423312664032\n",
      "Response: On November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_1250_depth_7500_results.json\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['16-19'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['18-30'], ['17-22'], ['14-18'], ['19-15'], ['16-24'], ['21-30'], ['19-10'], ['29-5'], ['31-15'], ['15-14'], ['20-29'], ['11-2'], ['31-19'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['17-22'], ['12-26'], ['18-30'], ['14-18'], ['19-15'], ['16-24'], ['21-30'], ['19-10'], ['31-15'], ['29-5'], ['11-2'], ['15-14'], ['20-29'], ['31-19'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 87.59462833404541\n",
      "Response: On November 10, 2017, Kendrick Lamar released his most recent studio album, DAMN.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 569\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['14-18'], ['18-30'], ['12-26'], ['19-15'], ['16-24'], ['21-30'], ['11-2'], ['19-10'], ['31-15'], ['29-5'], ['15-14'], ['20-29'], ['7-12'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 979\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['14-18'], ['18-30'], ['12-26'], ['19-15'], ['21-30'], ['11-2'], ['16-24'], ['7-12'], ['19-10'], ['31-15'], ['15-14'], ['20-29'], ['29-5'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 979\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['14-18'], ['18-30'], ['12-26'], ['19-15'], ['11-2'], ['7-12'], ['21-30'], ['16-24'], ['19-10'], ['20-29'], ['15-14'], ['31-15'], ['29-5'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_2500_depth_7500_results.json\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['14-18'], ['19-15'], ['12-26'], ['21-30'], ['11-2'], ['16-24'], ['19-10'], ['7-12'], ['20-29'], ['15-14'], ['29-5'], ['31-15'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['14-18'], ['18-30'], ['19-15'], ['12-26'], ['7-12'], ['11-2'], ['21-30'], ['19-10'], ['16-24'], ['15-14'], ['20-29'], ['31-15'], ['29-5'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 863\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['14-18'], ['7-12'], ['18-30'], ['11-2'], ['19-15'], ['12-26'], ['21-30'], ['19-10'], ['16-24'], ['15-14'], ['20-29'], ['17-31'], ['31-15'], ['29-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 979\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['14-18'], ['11-2'], ['18-30'], ['19-15'], ['12-26'], ['21-30'], ['19-10'], ['16-24'], ['15-14'], ['20-29'], ['6-16'], ['17-31'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 979\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['14-18'], ['11-2'], ['18-30'], ['19-15'], ['21-30'], ['12-26'], ['19-10'], ['16-24'], ['15-14'], ['20-29'], ['6-16'], ['17-31'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_3750_depth_7500_results.json\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['14-18'], ['18-30'], ['19-15'], ['11-2'], ['21-30'], ['12-26'], ['19-10'], ['16-24'], ['20-29'], ['15-14'], ['6-16'], ['17-31'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['14-18'], ['11-2'], ['18-30'], ['19-15'], ['21-30'], ['12-26'], ['19-10'], ['16-24'], ['6-16'], ['15-14'], ['20-29'], ['17-31'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 979\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['14-18'], ['11-2'], ['18-30'], ['19-15'], ['21-30'], ['19-10'], ['12-26'], ['16-24'], ['6-16'], ['20-29'], ['15-14'], ['17-31'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 979\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['14-18'], ['11-2'], ['18-30'], ['19-15'], ['21-30'], ['19-10'], ['12-26'], ['16-24'], ['6-16'], ['20-29'], ['15-14'], ['17-31'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3510\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['11-2'], ['14-18'], ['19-15'], ['18-30'], ['21-30'], ['19-10'], ['12-26'], ['6-16'], ['16-24'], ['20-29'], ['15-14'], ['17-31'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_5000_depth_7500_results.json\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['14-18'], ['11-2'], ['19-15'], ['21-30'], ['18-30'], ['19-10'], ['12-26'], ['6-16'], ['16-24'], ['20-29'], ['15-14'], ['17-31'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant/llama-2-7b-80k_id_175_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/175.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['16-24'], ['17-22'], ['19-15'], ['21-30'], ['29-5'], ['31-15'], ['1-26'], ['11-2'], ['15-14'], ['15-25'], ['19-10'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['16-24'], ['17-22'], ['19-15'], ['21-30'], ['29-5'], ['31-15'], ['1-26'], ['11-2'], ['15-14'], ['15-25'], ['19-10'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['16-24'], ['17-22'], ['19-15'], ['21-30'], ['29-5'], ['31-15'], ['1-26'], ['11-2'], ['15-14'], ['15-25'], ['19-10'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['16-24'], ['17-22'], ['19-15'], ['21-30'], ['29-5'], ['31-15'], ['1-26'], ['11-2'], ['15-14'], ['15-25'], ['19-10'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['16-24'], ['17-22'], ['19-15'], ['21-30'], ['29-5'], ['31-15'], ['1-26'], ['11-2'], ['15-14'], ['15-25'], ['19-10'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['18-30'], ['12-26'], ['14-18'], ['17-22'], ['16-24'], ['19-15'], ['31-15'], ['11-2'], ['21-30'], ['29-5'], ['19-10'], ['31-24'], ['20-29'], ['15-14'], ['31-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 199\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['14-18'], ['18-30'], ['17-22'], ['12-26'], ['19-15'], ['11-2'], ['16-24'], ['21-30'], ['31-15'], ['7-12'], ['19-10'], ['29-5'], ['20-29'], ['31-24'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 504\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['14-18'], ['17-22'], ['18-30'], ['12-26'], ['11-2'], ['19-15'], ['7-12'], ['21-30'], ['16-24'], ['31-15'], ['20-29'], ['19-10'], ['29-5'], ['15-14'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 753\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['14-18'], ['7-12'], ['19-15'], ['11-2'], ['18-30'], ['21-30'], ['12-26'], ['16-24'], ['20-29'], ['19-10'], ['31-15'], ['15-14'], ['29-5'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['14-18'], ['19-15'], ['18-30'], ['21-30'], ['12-26'], ['7-12'], ['11-2'], ['16-24'], ['20-29'], ['19-10'], ['15-14'], ['29-5'], ['31-15'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['14-18'], ['7-12'], ['19-15'], ['18-30'], ['21-30'], ['11-2'], ['12-26'], ['16-24'], ['19-10'], ['20-29'], ['15-14'], ['31-15'], ['17-31'], ['29-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 504\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['14-18'], ['11-2'], ['19-15'], ['21-30'], ['18-30'], ['12-26'], ['16-24'], ['19-10'], ['20-29'], ['15-14'], ['31-15'], ['17-31'], ['6-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1020\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['14-18'], ['11-2'], ['19-15'], ['21-30'], ['18-30'], ['12-26'], ['16-24'], ['19-10'], ['20-29'], ['15-14'], ['6-16'], ['17-31'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1020\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['14-18'], ['11-2'], ['19-15'], ['21-30'], ['18-30'], ['12-26'], ['16-24'], ['19-10'], ['20-29'], ['6-16'], ['15-14'], ['17-31'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['14-18'], ['19-15'], ['21-30'], ['11-2'], ['18-30'], ['12-26'], ['16-24'], ['19-10'], ['20-29'], ['15-14'], ['6-16'], ['17-31'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['14-18'], ['11-2'], ['19-15'], ['21-30'], ['18-30'], ['12-26'], ['19-10'], ['16-24'], ['20-29'], ['6-16'], ['17-31'], ['15-14'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 86.0789954662323\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\",\"\"\"â€”\"\" denotes a recording that did not chart or was not released in that territory. \",\"\"\"â€”\"\" denotes a recording that\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 854\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['14-18'], ['11-2'], ['19-15'], ['21-30'], ['18-30'], ['12-26'], ['19-10'], ['6-16'], ['16-24'], ['20-29'], ['17-31'], ['15-14'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1020\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['11-2'], ['14-18'], ['19-15'], ['21-30'], ['18-30'], ['19-10'], ['12-26'], ['6-16'], ['16-24'], ['20-29'], ['17-31'], ['15-14'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 1020\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['11-2'], ['14-18'], ['19-15'], ['21-30'], ['18-30'], ['6-16'], ['19-10'], ['12-26'], ['20-29'], ['16-24'], ['17-31'], ['15-14'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['11-2'], ['14-18'], ['19-15'], ['21-30'], ['18-30'], ['19-10'], ['12-26'], ['6-16'], ['16-24'], ['20-29'], ['17-31'], ['24-29'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['11-2'], ['14-18'], ['21-30'], ['19-15'], ['18-30'], ['19-10'], ['6-16'], ['12-26'], ['16-24'], ['20-29'], ['17-31'], ['15-14'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1020\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['11-2'], ['14-18'], ['21-30'], ['19-15'], ['18-30'], ['6-16'], ['19-10'], ['12-26'], ['16-24'], ['20-29'], ['17-31'], ['15-14'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 1020\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['11-2'], ['14-18'], ['21-30'], ['19-15'], ['18-30'], ['6-16'], ['19-10'], ['12-26'], ['20-29'], ['16-24'], ['17-31'], ['15-14'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3579\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['11-2'], ['14-18'], ['21-30'], ['19-15'], ['6-16'], ['18-30'], ['19-10'], ['12-26'], ['20-29'], ['16-24'], ['17-31'], ['15-14'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['11-2'], ['21-30'], ['14-18'], ['19-15'], ['18-30'], ['6-16'], ['19-10'], ['12-26'], ['20-29'], ['16-24'], ['17-31'], ['15-14'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Kendrick Lamar released his most recent studio album on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_175_irrelevant_misleading/llama-2-7b-80k_id_175_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['15-14'], ['19-15'], ['21-30'], ['6-30'], ['12-26'], ['11-2'], ['14-18'], ['18-30'], ['24-29'], ['26-28'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['15-14'], ['19-15'], ['21-30'], ['6-30'], ['12-26'], ['11-2'], ['14-18'], ['18-30'], ['24-29'], ['26-28'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['15-14'], ['19-15'], ['21-30'], ['6-30'], ['12-26'], ['11-2'], ['14-18'], ['18-30'], ['24-29'], ['26-28'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['15-14'], ['19-15'], ['21-30'], ['6-30'], ['12-26'], ['11-2'], ['14-18'], ['18-30'], ['24-29'], ['26-28'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_0_depth_7500_results.json\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['15-14'], ['19-15'], ['21-30'], ['6-30'], ['12-26'], ['11-2'], ['14-18'], ['18-30'], ['24-29'], ['26-28'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['15-14'], ['6-30'], ['12-26'], ['11-2'], ['14-18'], ['18-30'], ['24-29'], ['26-28'], ['31-16'], ['24-3'], ['28-14'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 59.282469749450684\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_1250_depth_0_results.json\n",
      "insertion at 212\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['15-14'], ['6-30'], ['11-2'], ['12-26'], ['14-18'], ['18-30'], ['26-28'], ['24-29'], ['24-3'], ['31-16'], ['28-14'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 212\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['15-14'], ['11-2'], ['6-30'], ['14-18'], ['18-30'], ['12-26'], ['26-28'], ['24-3'], ['24-29'], ['31-16'], ['21-28'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 758\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['15-14'], ['11-2'], ['6-30'], ['14-18'], ['18-30'], ['26-28'], ['24-3'], ['12-26'], ['24-29'], ['31-16'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_1250_depth_7500_results.json\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['15-14'], ['11-2'], ['6-30'], ['14-18'], ['18-30'], ['12-26'], ['26-28'], ['24-3'], ['24-29'], ['31-16'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['15-14'], ['11-2'], ['6-30'], ['14-18'], ['18-30'], ['26-28'], ['12-26'], ['24-3'], ['24-29'], ['31-16'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 59.282469749450684\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_2500_depth_0_results.json\n",
      "insertion at 548\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['15-14'], ['11-2'], ['6-30'], ['14-18'], ['18-30'], ['26-28'], ['24-3'], ['12-26'], ['24-29'], ['31-16'], ['13-23'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1130\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['15-14'], ['11-2'], ['6-30'], ['14-18'], ['18-30'], ['26-28'], ['24-3'], ['24-29'], ['12-26'], ['31-16'], ['7-12'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1697\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['15-14'], ['11-2'], ['6-30'], ['14-18'], ['18-30'], ['26-28'], ['24-3'], ['24-29'], ['12-26'], ['31-16'], ['7-12'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_2500_depth_7500_results.json\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['15-14'], ['11-2'], ['6-30'], ['14-18'], ['18-30'], ['26-28'], ['24-3'], ['24-29'], ['12-26'], ['31-16'], ['13-23'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['15-14'], ['11-2'], ['6-30'], ['14-18'], ['18-30'], ['26-28'], ['24-3'], ['24-29'], ['12-26'], ['31-16'], ['7-12'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_3750_depth_0_results.json\n",
      "insertion at 869\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['15-14'], ['11-2'], ['14-18'], ['18-30'], ['6-30'], ['26-28'], ['24-3'], ['24-29'], ['12-26'], ['31-16'], ['7-12'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1749\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['15-14'], ['11-2'], ['14-18'], ['18-30'], ['6-30'], ['26-28'], ['24-3'], ['24-29'], ['12-26'], ['7-12'], ['31-16'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2626\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['21-30'], ['7-4'], ['15-14'], ['11-2'], ['6-30'], ['18-30'], ['14-18'], ['26-28'], ['24-3'], ['24-29'], ['12-26'], ['7-12'], ['31-16'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_3750_depth_7500_results.json\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['15-14'], ['11-2'], ['6-30'], ['18-30'], ['14-18'], ['26-28'], ['24-3'], ['24-29'], ['12-26'], ['31-16'], ['7-12'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['15-14'], ['11-2'], ['18-30'], ['14-18'], ['6-30'], ['24-3'], ['26-28'], ['24-29'], ['12-26'], ['7-12'], ['31-16'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 59.282469749450684\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1166\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['15-14'], ['11-2'], ['18-30'], ['14-18'], ['6-30'], ['26-28'], ['24-3'], ['24-29'], ['12-26'], ['7-12'], ['31-16'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2289\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['7-4'], ['15-14'], ['11-2'], ['18-30'], ['14-18'], ['6-30'], ['26-28'], ['24-3'], ['24-29'], ['7-12'], ['12-26'], ['21-1'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3520\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['7-4'], ['15-14'], ['11-2'], ['18-30'], ['14-18'], ['6-30'], ['26-28'], ['24-3'], ['24-29'], ['7-12'], ['12-26'], ['21-1'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 59.282469749450684\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_5000_depth_7500_results.json\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['17-22'], ['21-30'], ['7-4'], ['15-14'], ['11-2'], ['18-30'], ['14-18'], ['6-30'], ['26-28'], ['24-3'], ['24-29'], ['7-12'], ['12-26'], ['21-1'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant/llama-2-7b-80k_id_18_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/18.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['15-14'], ['19-15'], ['21-30'], ['6-30'], ['12-26'], ['11-2'], ['14-18'], ['18-30'], ['24-29'], ['26-28'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['15-14'], ['19-15'], ['21-30'], ['6-30'], ['12-26'], ['11-2'], ['14-18'], ['18-30'], ['24-29'], ['26-28'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['15-14'], ['19-15'], ['21-30'], ['6-30'], ['12-26'], ['11-2'], ['14-18'], ['18-30'], ['24-29'], ['26-28'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['15-14'], ['19-15'], ['21-30'], ['6-30'], ['12-26'], ['11-2'], ['14-18'], ['18-30'], ['24-29'], ['26-28'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_0_depth_7500_results.json\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['15-14'], ['19-15'], ['21-30'], ['6-30'], ['12-26'], ['11-2'], ['14-18'], ['18-30'], ['24-29'], ['26-28'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['15-14'], ['19-15'], ['21-30'], ['6-30'], ['12-26'], ['11-2'], ['14-18'], ['18-30'], ['24-29'], ['26-28'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 64.4783079624176\n",
      "Response: The 2024 Nobel Prize in Economics was awarded to three prominent economists, but their names have not been officially announced yet.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 212\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['19-15'], ['21-30'], ['15-14'], ['6-30'], ['11-2'], ['12-26'], ['18-30'], ['14-18'], ['26-28'], ['24-29'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 97.14255332946777\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics. Roberts\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 212\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['21-30'], ['7-4'], ['15-14'], ['11-2'], ['6-30'], ['12-26'], ['18-30'], ['14-18'], ['26-28'], ['24-3'], ['24-29'], ['31-16'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 97.14255332946777\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics. Roberts\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 758\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['21-30'], ['7-4'], ['15-14'], ['11-2'], ['6-30'], ['18-30'], ['12-26'], ['14-18'], ['26-28'], ['24-3'], ['24-29'], ['31-16'], ['13-23'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_1250_depth_7500_results.json\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['19-15'], ['21-30'], ['15-14'], ['11-2'], ['6-30'], ['18-30'], ['12-26'], ['26-28'], ['14-18'], ['24-29'], ['24-3'], ['31-16'], ['13-23'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['19-15'], ['21-30'], ['15-14'], ['11-2'], ['6-30'], ['18-30'], ['26-28'], ['14-18'], ['12-26'], ['24-29'], ['24-3'], ['31-16'], ['13-23'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 548\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['7-4'], ['21-30'], ['15-14'], ['11-2'], ['6-30'], ['26-28'], ['14-18'], ['18-30'], ['12-26'], ['24-3'], ['24-29'], ['31-16'], ['7-12'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1109\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['15-14'], ['11-2'], ['6-30'], ['26-28'], ['14-18'], ['18-30'], ['12-26'], ['24-3'], ['24-29'], ['31-16'], ['7-12'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1689\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['21-30'], ['7-4'], ['15-14'], ['11-2'], ['6-30'], ['14-18'], ['26-28'], ['18-30'], ['24-29'], ['24-3'], ['12-26'], ['31-16'], ['7-12'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_2500_depth_7500_results.json\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['15-14'], ['11-2'], ['6-30'], ['26-28'], ['14-18'], ['18-30'], ['12-26'], ['24-29'], ['24-3'], ['31-16'], ['13-23'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['7-4'], ['15-14'], ['11-2'], ['6-30'], ['14-18'], ['26-28'], ['18-30'], ['12-26'], ['24-29'], ['24-3'], ['31-16'], ['7-12'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 869\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['15-14'], ['11-2'], ['6-30'], ['14-18'], ['26-28'], ['18-30'], ['12-26'], ['24-29'], ['24-3'], ['31-16'], ['7-12'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1758\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['15-14'], ['11-2'], ['6-30'], ['14-18'], ['26-28'], ['18-30'], ['24-29'], ['24-3'], ['12-26'], ['31-16'], ['7-12'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2624\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['15-14'], ['11-2'], ['6-30'], ['14-18'], ['18-30'], ['26-28'], ['24-3'], ['24-29'], ['12-26'], ['31-16'], ['7-12'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_3750_depth_7500_results.json\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['15-14'], ['11-2'], ['6-30'], ['14-18'], ['18-30'], ['26-28'], ['12-26'], ['24-3'], ['24-29'], ['31-16'], ['7-12'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['15-14'], ['11-2'], ['6-30'], ['14-18'], ['18-30'], ['26-28'], ['24-3'], ['24-29'], ['12-26'], ['31-16'], ['7-12'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1169\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['11-2'], ['15-14'], ['6-30'], ['26-28'], ['14-18'], ['18-30'], ['24-3'], ['24-29'], ['12-26'], ['31-16'], ['7-12'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2381\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['7-4'], ['11-2'], ['15-14'], ['26-28'], ['14-18'], ['6-30'], ['18-30'], ['24-3'], ['24-29'], ['12-26'], ['31-16'], ['7-12'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3455\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['7-4'], ['15-14'], ['11-2'], ['18-30'], ['26-28'], ['14-18'], ['6-30'], ['24-3'], ['24-29'], ['7-12'], ['12-26'], ['31-16'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_5000_depth_7500_results.json\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['7-4'], ['15-14'], ['11-2'], ['18-30'], ['26-28'], ['14-18'], ['6-30'], ['24-3'], ['24-29'], ['7-12'], ['12-26'], ['31-16'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_relevant_misleading/llama-2-7b-80k_id_18_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['15-14'], ['19-15'], ['21-30'], ['6-30'], ['12-26'], ['11-2'], ['14-18'], ['18-30'], ['24-29'], ['26-28'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['15-14'], ['19-15'], ['21-30'], ['6-30'], ['12-26'], ['11-2'], ['14-18'], ['18-30'], ['24-29'], ['26-28'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['15-14'], ['19-15'], ['21-30'], ['6-30'], ['12-26'], ['11-2'], ['14-18'], ['18-30'], ['24-29'], ['26-28'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['15-14'], ['19-15'], ['21-30'], ['6-30'], ['12-26'], ['11-2'], ['14-18'], ['18-30'], ['24-29'], ['26-28'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_0_depth_7500_results.json\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['15-14'], ['19-15'], ['21-30'], ['6-30'], ['12-26'], ['11-2'], ['14-18'], ['18-30'], ['24-29'], ['26-28'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['15-14'], ['19-15'], ['21-30'], ['6-30'], ['12-26'], ['11-2'], ['14-18'], ['18-30'], ['24-29'], ['26-28'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 68.86727809906006\n",
      "Response: The Nobel Prize in Economics was awarded to the following individuals:\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 250\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['15-14'], ['6-30'], ['11-2'], ['12-26'], ['14-18'], ['18-30'], ['26-28'], ['24-29'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 481\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['15-14'], ['6-30'], ['11-2'], ['12-26'], ['14-18'], ['26-28'], ['18-30'], ['24-29'], ['24-3'], ['31-16'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 687\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['15-14'], ['6-30'], ['11-2'], ['14-18'], ['18-30'], ['26-28'], ['12-26'], ['24-29'], ['24-3'], ['31-16'], ['7-12'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_1250_depth_7500_results.json\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['6-30'], ['15-14'], ['11-2'], ['14-18'], ['26-28'], ['18-30'], ['12-26'], ['24-3'], ['24-29'], ['31-16'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['6-30'], ['15-14'], ['11-2'], ['14-18'], ['26-28'], ['18-30'], ['12-26'], ['24-3'], ['24-29'], ['31-16'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 73.57028722763062\n",
      "Response: The 2024 Nobel Prize in Economics was awarded to the following individuals:\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 536\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['6-30'], ['15-14'], ['11-2'], ['14-18'], ['26-28'], ['18-30'], ['12-26'], ['24-3'], ['24-29'], ['31-16'], ['7-12'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1104\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['6-30'], ['11-2'], ['15-14'], ['14-18'], ['26-28'], ['18-30'], ['24-3'], ['24-29'], ['7-12'], ['12-26'], ['31-16'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1687\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['6-30'], ['11-2'], ['15-14'], ['14-18'], ['26-28'], ['18-30'], ['7-12'], ['24-29'], ['24-3'], ['31-16'], ['12-26'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_2500_depth_7500_results.json\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['6-30'], ['11-2'], ['15-14'], ['14-18'], ['26-28'], ['18-30'], ['24-29'], ['24-3'], ['7-12'], ['31-16'], ['12-26'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['6-30'], ['11-2'], ['15-14'], ['14-18'], ['26-28'], ['18-30'], ['24-29'], ['24-3'], ['7-12'], ['31-16'], ['12-26'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 65.92033505439758\n",
      "Response: The 2024 Nobel Prize in Economics was awarded to Ben Bernanke, Paul Krugman, and Maurice Obstfeld.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 866\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['21-30'], ['7-4'], ['19-15'], ['6-30'], ['11-2'], ['15-14'], ['14-18'], ['26-28'], ['18-30'], ['7-12'], ['24-29'], ['24-3'], ['31-16'], ['12-26'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 59.282469749450684\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1754\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['6-30'], ['11-2'], ['14-18'], ['15-14'], ['26-28'], ['18-30'], ['7-12'], ['24-3'], ['24-29'], ['31-16'], ['12-26'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2621\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['6-30'], ['11-2'], ['14-18'], ['18-30'], ['26-28'], ['15-14'], ['7-12'], ['24-3'], ['24-29'], ['31-16'], ['12-26'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 59.282469749450684\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_3750_depth_7500_results.json\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['6-30'], ['11-2'], ['14-18'], ['18-30'], ['26-28'], ['15-14'], ['24-3'], ['24-29'], ['7-12'], ['31-16'], ['12-26'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['6-30'], ['11-2'], ['14-18'], ['18-30'], ['26-28'], ['15-14'], ['24-3'], ['24-29'], ['7-12'], ['31-16'], ['12-26'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 68.86727809906006\n",
      "Response: The Nobel Prize in Economics was awarded to the following individuals:\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1172\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['6-30'], ['11-2'], ['18-30'], ['26-28'], ['14-18'], ['7-12'], ['15-14'], ['24-3'], ['24-29'], ['31-16'], ['12-26'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2376\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['17-22'], ['21-30'], ['7-4'], ['19-15'], ['6-30'], ['11-2'], ['18-30'], ['26-28'], ['14-18'], ['7-12'], ['15-14'], ['24-3'], ['24-29'], ['31-16'], ['12-26'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 59.282469749450684\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3522\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['17-22'], ['21-30'], ['7-4'], ['19-15'], ['6-30'], ['11-2'], ['18-30'], ['7-12'], ['26-28'], ['14-18'], ['24-3'], ['15-14'], ['24-29'], ['31-16'], ['12-26'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 59.282469749450684\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_5000_depth_7500_results.json\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['17-22'], ['21-30'], ['7-4'], ['19-15'], ['6-30'], ['11-2'], ['18-30'], ['26-28'], ['14-18'], ['7-12'], ['24-3'], ['15-14'], ['24-29'], ['31-16'], ['12-26'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant/llama-2-7b-80k_id_18_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/18.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['15-14'], ['19-15'], ['21-30'], ['6-30'], ['12-26'], ['11-2'], ['14-18'], ['18-30'], ['24-29'], ['26-28'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['15-14'], ['19-15'], ['21-30'], ['6-30'], ['12-26'], ['11-2'], ['14-18'], ['18-30'], ['24-29'], ['26-28'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['15-14'], ['19-15'], ['21-30'], ['6-30'], ['12-26'], ['11-2'], ['14-18'], ['18-30'], ['24-29'], ['26-28'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['15-14'], ['19-15'], ['21-30'], ['6-30'], ['12-26'], ['11-2'], ['14-18'], ['18-30'], ['24-29'], ['26-28'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['15-14'], ['19-15'], ['21-30'], ['6-30'], ['12-26'], ['11-2'], ['14-18'], ['18-30'], ['24-29'], ['26-28'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['15-14'], ['19-15'], ['21-30'], ['6-30'], ['12-26'], ['11-2'], ['24-29'], ['26-28'], ['14-18'], ['18-30'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 64.4783079624176\n",
      "Response: The 2024 Nobel Prize in Economics was awarded to three prominent economists, but their names have not been officially announced yet.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 250\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['15-14'], ['6-30'], ['11-2'], ['12-26'], ['24-29'], ['18-30'], ['26-28'], ['14-18'], ['31-16'], ['24-3'], ['28-14'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 481\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['15-14'], ['6-30'], ['11-2'], ['18-30'], ['26-28'], ['12-26'], ['24-29'], ['14-18'], ['31-16'], ['24-3'], ['13-23'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 687\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['15-14'], ['6-30'], ['11-2'], ['18-30'], ['26-28'], ['24-29'], ['14-18'], ['12-26'], ['31-16'], ['24-3'], ['26-26'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['6-30'], ['15-14'], ['11-2'], ['18-30'], ['26-28'], ['24-29'], ['12-26'], ['14-18'], ['31-16'], ['24-3'], ['28-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['6-30'], ['15-14'], ['11-2'], ['18-30'], ['26-28'], ['24-29'], ['12-26'], ['14-18'], ['31-16'], ['24-3'], ['7-12'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 59.282469749450684\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 536\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['7-4'], ['19-15'], ['6-30'], ['15-14'], ['11-2'], ['18-30'], ['26-28'], ['24-29'], ['14-18'], ['12-26'], ['31-16'], ['24-3'], ['7-12'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1133\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['11-2'], ['15-14'], ['6-30'], ['26-28'], ['18-30'], ['24-29'], ['14-18'], ['24-3'], ['12-26'], ['31-16'], ['7-12'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1642\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['11-2'], ['6-30'], ['15-14'], ['26-28'], ['18-30'], ['24-29'], ['14-18'], ['24-3'], ['7-12'], ['31-16'], ['12-26'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['11-2'], ['6-30'], ['15-14'], ['26-28'], ['18-30'], ['24-29'], ['14-18'], ['24-3'], ['31-16'], ['12-26'], ['7-12'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['11-2'], ['6-30'], ['15-14'], ['26-28'], ['18-30'], ['24-29'], ['14-18'], ['24-3'], ['31-16'], ['12-26'], ['7-12'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 80.05390763282776\n",
      "Response: Daron Acemoglu and his team have made significant contributions to economics, but it is still unclear if they will receive the 2024 Nobel Prize.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 866\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['11-2'], ['6-30'], ['15-14'], ['26-28'], ['18-30'], ['24-29'], ['14-18'], ['24-3'], ['7-12'], ['31-16'], ['12-26'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 59.282469749450684\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1755\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['11-2'], ['6-30'], ['26-28'], ['15-14'], ['18-30'], ['24-29'], ['14-18'], ['24-3'], ['7-12'], ['31-16'], ['12-26'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 80.05390763282776\n",
      "Response: Daron Acemoglu and his team have made significant contributions to economics, but it is still unclear if they will receive the 2024 Nobel Prize.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2604\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['11-2'], ['6-30'], ['26-28'], ['15-14'], ['18-30'], ['24-29'], ['14-18'], ['7-12'], ['24-3'], ['12-26'], ['31-16'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 80.05390763282776\n",
      "Response: Daron Acemoglu and his team have made significant contributions to economics, but it is still unclear if they will receive the 2024 Nobel Prize.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['11-2'], ['6-30'], ['15-14'], ['26-28'], ['18-30'], ['24-29'], ['14-18'], ['24-3'], ['12-26'], ['7-12'], ['31-16'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['11-2'], ['6-30'], ['15-14'], ['26-28'], ['18-30'], ['24-29'], ['14-18'], ['24-3'], ['12-26'], ['7-12'], ['31-16'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1133\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['11-2'], ['26-28'], ['6-30'], ['15-14'], ['18-30'], ['14-18'], ['24-29'], ['24-3'], ['7-12'], ['12-26'], ['31-16'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2374\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['11-2'], ['26-28'], ['6-30'], ['15-14'], ['18-30'], ['14-18'], ['7-12'], ['24-29'], ['24-3'], ['12-26'], ['31-16'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 56.6266655921936\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3489\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['11-2'], ['26-28'], ['6-30'], ['15-14'], ['7-12'], ['18-30'], ['14-18'], ['24-29'], ['24-3'], ['12-26'], ['31-16'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 59.282469749450684\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['11-2'], ['26-28'], ['6-30'], ['15-14'], ['7-12'], ['18-30'], ['14-18'], ['24-29'], ['24-3'], ['12-26'], ['31-16'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Daron Acemoglu, Simon Johnson, and James Robinson won the 2024 Nobel Prize in Economics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_18_irrelevant_misleading/llama-2-7b-80k_id_18_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['18-30'], ['21-30'], ['12-26'], ['17-22'], ['19-15'], ['13-11'], ['14-18'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['0-9'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['18-30'], ['21-30'], ['12-26'], ['17-22'], ['19-15'], ['13-11'], ['14-18'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['0-9'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['18-30'], ['21-30'], ['12-26'], ['17-22'], ['19-15'], ['13-11'], ['14-18'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['0-9'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['18-30'], ['21-30'], ['12-26'], ['17-22'], ['19-15'], ['13-11'], ['14-18'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['0-9'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_0_depth_7500_results.json\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['18-30'], ['21-30'], ['12-26'], ['17-22'], ['19-15'], ['13-11'], ['14-18'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['0-9'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['18-30'], ['21-30'], ['17-22'], ['12-26'], ['19-15'], ['14-18'], ['13-11'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['0-9'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 90.15103578567505\n",
      "Response: The most recent major version of the .NET framework is .NET 7.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_1250_depth_0_results.json\n",
      "insertion at 251\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['21-30'], ['18-30'], ['17-22'], ['12-26'], ['19-15'], ['14-18'], ['13-11'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['17-16'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 517\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['21-30'], ['18-30'], ['17-22'], ['19-15'], ['12-26'], ['14-18'], ['13-11'], ['15-14'], ['24-3'], ['21-28'], ['26-28'], ['29-19'], ['19-10'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 92.19444990158081\n",
      "Response: The most recent major version of the .NET framework is .NET 9.5 years.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 746\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['21-30'], ['17-22'], ['18-30'], ['19-15'], ['12-26'], ['14-18'], ['13-11'], ['15-14'], ['24-3'], ['21-28'], ['26-28'], ['29-19'], ['19-10'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 90.15103578567505\n",
      "Response: The most recent major version of the .NET framework is .NET 7.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_1250_depth_7500_results.json\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['21-30'], ['19-15'], ['18-30'], ['12-26'], ['17-22'], ['13-11'], ['14-18'], ['15-14'], ['24-3'], ['21-28'], ['29-19'], ['26-28'], ['19-10'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['18-30'], ['12-26'], ['14-18'], ['13-11'], ['15-14'], ['21-28'], ['24-3'], ['29-19'], ['26-28'], ['19-10'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 96.45538330078125\n",
      "Response: The most recent major version of the .NET framework is .NET 9.0.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_2500_depth_0_results.json\n",
      "insertion at 561\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['16-19'], ['11-15'], ['11-2'], ['7-4'], ['8-26'], ['17-22'], ['19-15'], ['21-30'], ['18-30'], ['12-26'], ['14-18'], ['13-11'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['7-12'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 92.40740537643433\n",
      "Response: The most recent major version of the .NET framework is .NET 9.9, released on July 10, 2018.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1136\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['16-19'], ['11-15'], ['11-2'], ['19-15'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['18-30'], ['12-26'], ['14-18'], ['15-14'], ['13-11'], ['21-28'], ['24-3'], ['26-28'], ['7-12'], ['29-19'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 89.29699659347534\n",
      "Response: The most recent major version of the .NET framework is .NET 9.13 (LTS), released on February 11, 2025.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1697\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['16-19'], ['11-15'], ['11-2'], ['19-15'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['18-30'], ['12-26'], ['14-18'], ['15-14'], ['21-28'], ['7-12'], ['13-11'], ['24-3'], ['26-28'], ['29-19'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_2500_depth_7500_results.json\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['16-19'], ['11-15'], ['11-2'], ['19-15'], ['8-26'], ['17-22'], ['21-30'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['15-14'], ['21-28'], ['13-11'], ['24-3'], ['26-28'], ['7-12'], ['29-19'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['16-19'], ['11-15'], ['11-2'], ['19-15'], ['8-26'], ['17-22'], ['21-30'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['15-14'], ['21-28'], ['13-11'], ['24-3'], ['7-12'], ['26-28'], ['29-19'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 85.21863222122192\n",
      "Response: The most recent major version of the .NET framework is 4.8.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_3750_depth_0_results.json\n",
      "insertion at 854\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['16-19'], ['11-15'], ['11-2'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['15-14'], ['7-12'], ['21-28'], ['13-11'], ['24-3'], ['26-28'], ['29-19'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 84.82433557510376\n",
      "Response: The most recent major version of the .NET framework is .NET 9.32 (LTS),\"December 13, 2022\",\"December 13, 2022\",3 years\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1757\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['16-19'], ['11-15'], ['11-2'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['7-12'], ['15-14'], ['21-28'], ['13-11'], ['24-3'], ['26-28'], ['29-19'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2644\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['16-19'], ['11-15'], ['11-2'], ['8-26'], ['17-22'], ['19-15'], ['21-30'], ['7-4'], ['12-26'], ['18-30'], ['7-12'], ['14-18'], ['15-14'], ['21-28'], ['13-11'], ['24-3'], ['26-28'], ['29-19'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_3750_depth_7500_results.json\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['16-19'], ['11-15'], ['11-2'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['7-12'], ['15-14'], ['21-28'], ['24-3'], ['13-11'], ['26-28'], ['29-19'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['7-12'], ['15-14'], ['21-28'], ['24-3'], ['13-11'], ['26-28'], ['29-19'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 85.21863222122192\n",
      "Response: The most recent major version of the .NET framework is 4.8.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1172\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['12-26'], ['18-30'], ['7-12'], ['14-18'], ['15-14'], ['21-28'], ['24-3'], ['13-11'], ['26-28'], ['6-16'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2383\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['7-4'], ['12-26'], ['7-12'], ['18-30'], ['14-18'], ['15-14'], ['21-28'], ['6-16'], ['24-3'], ['13-11'], ['29-19'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3583\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['16-19'], ['11-15'], ['11-2'], ['19-15'], ['8-26'], ['17-22'], ['21-30'], ['7-4'], ['7-12'], ['12-26'], ['18-30'], ['14-18'], ['15-14'], ['21-28'], ['6-16'], ['24-3'], ['29-19'], ['13-11'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 86.05093955993652\n",
      "Response: The latest major version of the .NET framework is .NET 9.13,\"May 14, 2019\",\"June 27, 2019\",2.5 years\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_5000_depth_7500_results.json\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['16-19'], ['11-15'], ['11-2'], ['19-15'], ['8-26'], ['17-22'], ['21-30'], ['7-4'], ['12-26'], ['7-12'], ['18-30'], ['14-18'], ['15-14'], ['21-28'], ['6-16'], ['24-3'], ['29-19'], ['13-11'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant/llama-2-7b-80k_id_180_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/180.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['18-30'], ['21-30'], ['12-26'], ['17-22'], ['19-15'], ['13-11'], ['14-18'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['0-9'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['18-30'], ['21-30'], ['12-26'], ['17-22'], ['19-15'], ['13-11'], ['14-18'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['0-9'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['18-30'], ['21-30'], ['12-26'], ['17-22'], ['19-15'], ['13-11'], ['14-18'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['0-9'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['18-30'], ['21-30'], ['12-26'], ['17-22'], ['19-15'], ['13-11'], ['14-18'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['0-9'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_0_depth_7500_results.json\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['18-30'], ['21-30'], ['12-26'], ['17-22'], ['19-15'], ['13-11'], ['14-18'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['0-9'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['21-30'], ['18-30'], ['17-22'], ['12-26'], ['19-15'], ['14-18'], ['13-11'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['0-9'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 92.4284279346466\n",
      "Response: The most recent major version of the .NET framework is .NET 9, which was released in November 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 251\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['21-30'], ['18-30'], ['17-22'], ['19-15'], ['12-26'], ['14-18'], ['15-14'], ['21-28'], ['13-11'], ['24-3'], ['26-28'], ['29-19'], ['17-16'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 517\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['21-30'], ['17-22'], ['18-30'], ['19-15'], ['14-18'], ['12-26'], ['15-14'], ['13-11'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['7-12'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 92.19444990158081\n",
      "Response: The most recent major version of the .NET framework is .NET 9.5 years.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 746\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['21-30'], ['17-22'], ['18-30'], ['19-15'], ['14-18'], ['12-26'], ['13-11'], ['15-14'], ['24-3'], ['21-28'], ['26-28'], ['29-19'], ['7-12'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 92.21839904785156\n",
      "Response: The most recent major version of the .NET framework is .NET 9.0, which was released on September 23, 2019.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['21-30'], ['8-26'], ['17-22'], ['19-15'], ['18-30'], ['12-26'], ['14-18'], ['13-11'], ['15-14'], ['24-3'], ['21-28'], ['29-19'], ['26-28'], ['7-12'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['21-30'], ['8-26'], ['17-22'], ['19-15'], ['18-30'], ['12-26'], ['14-18'], ['13-11'], ['15-14'], ['21-28'], ['24-3'], ['29-19'], ['26-28'], ['7-12'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 561\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['17-22'], ['21-30'], ['8-26'], ['19-15'], ['18-30'], ['12-26'], ['14-18'], ['15-14'], ['13-11'], ['21-28'], ['24-3'], ['26-28'], ['7-12'], ['29-19'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 97.42669463157654\n",
      "Response: The most recent major version of the .NET framework is .NET 9.9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1119\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['16-19'], ['11-15'], ['11-2'], ['17-22'], ['21-30'], ['7-4'], ['8-26'], ['19-15'], ['18-30'], ['12-26'], ['14-18'], ['15-14'], ['21-28'], ['13-11'], ['24-3'], ['7-12'], ['26-28'], ['29-19'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1708\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['16-19'], ['11-15'], ['11-2'], ['17-22'], ['7-4'], ['21-30'], ['8-26'], ['19-15'], ['18-30'], ['14-18'], ['12-26'], ['15-14'], ['21-28'], ['7-12'], ['13-11'], ['24-3'], ['26-28'], ['29-19'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 81.7729115486145\n",
      "Response: The most recent major version of the .NET framework is .NET 9.NET Frameworkâ€”and released source code for the .NET Core CoreCLR implementation, source for the \"entire [...] library stack\" for .NET Core, and announced\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['17-22'], ['21-30'], ['7-4'], ['8-26'], ['19-15'], ['12-26'], ['18-30'], ['14-18'], ['15-14'], ['21-28'], ['13-11'], ['24-3'], ['7-12'], ['26-28'], ['29-19'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['17-22'], ['21-30'], ['7-4'], ['8-26'], ['19-15'], ['12-26'], ['18-30'], ['14-18'], ['15-14'], ['21-28'], ['7-12'], ['13-11'], ['24-3'], ['26-28'], ['29-19'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 91.10435247421265\n",
      "Response: The most recent major version of the .NET framework is .NET 9, released in November 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 875\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['16-19'], ['11-15'], ['11-2'], ['17-22'], ['21-30'], ['7-4'], ['8-26'], ['19-15'], ['12-26'], ['18-30'], ['14-18'], ['15-14'], ['21-28'], ['7-12'], ['13-11'], ['24-3'], ['26-28'], ['29-19'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 84.82433557510376\n",
      "Response: The most recent major version of the .NET framework is .NET 9.32 (LTS),\"December 13, 2022\",\"December 13, 2022\",3 years\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1737\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['16-19'], ['11-15'], ['11-2'], ['17-22'], ['8-26'], ['21-30'], ['7-4'], ['19-15'], ['12-26'], ['14-18'], ['18-30'], ['7-12'], ['21-28'], ['15-14'], ['13-11'], ['24-3'], ['6-16'], ['26-28'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 81.47246837615967\n",
      "Response: The most recent major version of the .NET framework is .NET 9.NET Core, and announced the adoption of a conventional (\"bazaar\"-like) open-source development model under the stewardship of the .NET Foundation.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2644\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['16-19'], ['11-15'], ['11-2'], ['17-22'], ['8-26'], ['21-30'], ['7-4'], ['19-15'], ['14-18'], ['7-12'], ['18-30'], ['12-26'], ['21-28'], ['15-14'], ['13-11'], ['29-19'], ['6-16'], ['24-3'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 75.44921636581421\n",
      "Response: The latest major version of the .NET framework is .NET 9.NET Core web apps, command-line/console apps, libraries and Universal Windows Platform apps. Prior to .NET Core 3.0, it did not implement Windows Form\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['16-19'], ['11-15'], ['11-2'], ['17-22'], ['21-30'], ['8-26'], ['19-15'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['7-12'], ['15-14'], ['21-28'], ['13-11'], ['29-19'], ['24-3'], ['26-28'], ['6-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['17-22'], ['8-26'], ['21-30'], ['19-15'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['7-12'], ['15-14'], ['21-28'], ['13-11'], ['6-16'], ['29-19'], ['24-3'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 96.45538330078125\n",
      "Response: The most recent major version of the .NET framework is .NET 9.0.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1193\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['17-22'], ['8-26'], ['21-30'], ['19-15'], ['7-4'], ['12-26'], ['14-18'], ['7-12'], ['18-30'], ['15-14'], ['21-28'], ['6-16'], ['13-11'], ['29-19'], ['24-3'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2390\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['17-22'], ['8-26'], ['21-30'], ['19-15'], ['7-4'], ['7-12'], ['12-26'], ['14-18'], ['18-30'], ['15-14'], ['6-16'], ['21-28'], ['13-11'], ['29-19'], ['24-3'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3560\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['17-22'], ['8-26'], ['21-30'], ['19-15'], ['7-4'], ['7-12'], ['12-26'], ['14-18'], ['18-30'], ['6-16'], ['15-14'], ['21-28'], ['13-11'], ['29-19'], ['24-3'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 92.40358471870422\n",
      "Response: The most recent major version of the .NET framework is .NET 9.0, released in November 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['17-22'], ['21-30'], ['8-26'], ['19-15'], ['7-4'], ['12-26'], ['7-12'], ['14-18'], ['18-30'], ['15-14'], ['6-16'], ['21-28'], ['13-11'], ['29-19'], ['24-3'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_relevant_misleading/llama-2-7b-80k_id_180_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['18-30'], ['21-30'], ['12-26'], ['17-22'], ['19-15'], ['13-11'], ['14-18'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['0-9'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['18-30'], ['21-30'], ['12-26'], ['17-22'], ['19-15'], ['13-11'], ['14-18'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['0-9'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['18-30'], ['21-30'], ['12-26'], ['17-22'], ['19-15'], ['13-11'], ['14-18'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['0-9'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['18-30'], ['21-30'], ['12-26'], ['17-22'], ['19-15'], ['13-11'], ['14-18'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['0-9'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_0_depth_7500_results.json\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['18-30'], ['21-30'], ['12-26'], ['17-22'], ['19-15'], ['13-11'], ['14-18'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['0-9'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['11-2'], ['7-4'], ['21-30'], ['8-26'], ['18-30'], ['12-26'], ['17-22'], ['19-15'], ['14-18'], ['13-11'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['11-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 180\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['11-2'], ['7-4'], ['8-26'], ['21-30'], ['17-22'], ['18-30'], ['19-15'], ['12-26'], ['14-18'], ['15-14'], ['29-19'], ['13-11'], ['21-28'], ['24-3'], ['26-28'], ['11-30'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 92.30729341506958\n",
      "Response: The latest major version of the .NET framework is .NET 9.25 LTS (October 15, 2024; 5 months ago) [Â±] 21.0.5 LTS (\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 487\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['11-2'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['18-30'], ['19-15'], ['14-18'], ['12-26'], ['13-11'], ['15-14'], ['29-19'], ['21-28'], ['24-3'], ['26-28'], ['7-12'], ['11-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 718\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['11-2'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['18-30'], ['19-15'], ['14-18'], ['13-11'], ['12-26'], ['15-14'], ['29-19'], ['7-12'], ['21-28'], ['24-3'], ['26-28'], ['11-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_1250_depth_7500_results.json\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['19-15'], ['18-30'], ['12-26'], ['14-18'], ['13-11'], ['29-19'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['7-12'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['19-15'], ['18-30'], ['12-26'], ['14-18'], ['13-11'], ['15-14'], ['29-19'], ['21-28'], ['24-3'], ['7-12'], ['26-28'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 70.92075943946838\n",
      "Response: .NET 9\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 525\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['7-4'], ['18-30'], ['19-15'], ['12-26'], ['14-18'], ['15-14'], ['29-19'], ['7-12'], ['13-11'], ['21-28'], ['24-3'], ['17-16'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1130\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['7-4'], ['18-30'], ['19-15'], ['14-18'], ['12-26'], ['13-11'], ['15-14'], ['29-19'], ['7-12'], ['21-28'], ['17-16'], ['24-3'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 68.6814546585083\n",
      "Response: .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1696\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['7-4'], ['18-30'], ['19-15'], ['14-18'], ['12-26'], ['13-11'], ['15-14'], ['29-19'], ['7-12'], ['21-28'], ['17-16'], ['24-3'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 68.6814546585083\n",
      "Response: .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_2500_depth_7500_results.json\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['18-30'], ['19-15'], ['12-26'], ['14-18'], ['13-11'], ['15-14'], ['29-19'], ['7-12'], ['21-28'], ['17-16'], ['24-3'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['7-4'], ['18-30'], ['19-15'], ['12-26'], ['14-18'], ['13-11'], ['15-14'], ['29-19'], ['7-12'], ['21-28'], ['17-16'], ['24-3'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 74.86939430236816\n",
      "Response: .NET 9.0\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 868\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['7-4'], ['18-30'], ['19-15'], ['12-26'], ['14-18'], ['15-14'], ['13-11'], ['29-19'], ['7-12'], ['21-28'], ['17-16'], ['24-3'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 68.6814546585083\n",
      "Response: .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1696\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['7-4'], ['18-30'], ['19-15'], ['12-26'], ['14-18'], ['15-14'], ['13-11'], ['29-19'], ['21-28'], ['7-12'], ['17-16'], ['24-3'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 68.6814546585083\n",
      "Response: .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2640\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['7-4'], ['18-30'], ['19-15'], ['12-26'], ['14-18'], ['7-12'], ['15-14'], ['29-19'], ['13-11'], ['21-28'], ['24-3'], ['17-16'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 98.03391098976135\n",
      "Response: The latest major version of the .NET framework is .NET 9.0\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_3750_depth_7500_results.json\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['7-4'], ['19-15'], ['18-30'], ['12-26'], ['14-18'], ['29-19'], ['15-14'], ['13-11'], ['7-12'], ['21-28'], ['24-3'], ['17-16'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['7-4'], ['19-15'], ['18-30'], ['12-26'], ['14-18'], ['7-12'], ['15-14'], ['29-19'], ['13-11'], ['21-28'], ['24-3'], ['17-16'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 96.45538330078125\n",
      "Response: The most recent major version of the .NET framework is .NET 9.0.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1130\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['7-4'], ['19-15'], ['18-30'], ['12-26'], ['7-12'], ['14-18'], ['15-14'], ['29-19'], ['13-11'], ['21-28'], ['17-16'], ['6-16'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2382\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['7-12'], ['18-30'], ['12-26'], ['14-18'], ['15-14'], ['29-19'], ['6-16'], ['13-11'], ['17-16'], ['21-28'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3575\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['7-12'], ['19-15'], ['7-4'], ['14-18'], ['18-30'], ['12-26'], ['15-14'], ['29-19'], ['6-16'], ['17-16'], ['13-11'], ['21-28'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 73.53282570838928\n",
      "Response: The latest major version of the .NET framework is .NET 9.0,2021,\"Introduced record classes, pattern matching, and sealed classes for enhanced data modelling abilities\"\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_5000_depth_7500_results.json\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['7-12'], ['12-26'], ['14-18'], ['18-30'], ['29-19'], ['15-14'], ['17-16'], ['6-16'], ['13-11'], ['21-28'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant/llama-2-7b-80k_id_180_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/180.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['18-30'], ['21-30'], ['12-26'], ['17-22'], ['19-15'], ['13-11'], ['14-18'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['0-9'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['18-30'], ['21-30'], ['12-26'], ['17-22'], ['19-15'], ['13-11'], ['14-18'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['0-9'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['18-30'], ['21-30'], ['12-26'], ['17-22'], ['19-15'], ['13-11'], ['14-18'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['0-9'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['18-30'], ['21-30'], ['12-26'], ['17-22'], ['19-15'], ['13-11'], ['14-18'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['0-9'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['7-4'], ['8-26'], ['18-30'], ['21-30'], ['12-26'], ['17-22'], ['19-15'], ['13-11'], ['14-18'], ['15-14'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['0-9'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['11-2'], ['7-4'], ['8-26'], ['21-30'], ['18-30'], ['12-26'], ['17-22'], ['19-15'], ['14-18'], ['15-14'], ['13-11'], ['21-28'], ['24-3'], ['26-28'], ['29-19'], ['11-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 180\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['11-2'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['18-30'], ['19-15'], ['12-26'], ['14-18'], ['15-14'], ['21-28'], ['29-19'], ['13-11'], ['24-3'], ['26-28'], ['7-12'], ['11-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 92.00495481491089\n",
      "Response: The latest major version of the .NET framework is .NET 9.25 LTS (OctoberÂ 15, 2024; 5 months ago[3]) [Â±] 21.0.5 L\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 487\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['11-2'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['18-30'], ['19-15'], ['12-26'], ['14-18'], ['7-12'], ['15-14'], ['21-28'], ['13-11'], ['29-19'], ['24-3'], ['26-28'], ['11-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 718\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['11-2'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['18-30'], ['19-15'], ['7-12'], ['14-18'], ['12-26'], ['15-14'], ['21-28'], ['13-11'], ['17-16'], ['29-19'], ['24-3'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['19-15'], ['18-30'], ['12-26'], ['14-18'], ['7-12'], ['21-28'], ['15-14'], ['13-11'], ['29-19'], ['17-16'], ['24-3'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['11-2'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['19-15'], ['18-30'], ['12-26'], ['14-18'], ['7-12'], ['21-28'], ['15-14'], ['13-11'], ['29-19'], ['17-16'], ['24-3'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 70.92075943946838\n",
      "Response: .NET 9\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 525\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['11-2'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['19-15'], ['18-30'], ['7-12'], ['12-26'], ['14-18'], ['21-28'], ['15-14'], ['17-16'], ['29-19'], ['13-11'], ['24-3'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1132\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['11-2'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['19-15'], ['18-30'], ['7-12'], ['12-26'], ['14-18'], ['21-28'], ['15-14'], ['17-16'], ['29-19'], ['13-11'], ['24-3'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 70.92075943946838\n",
      "Response: .NET 9\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1708\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['11-2'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['18-30'], ['7-12'], ['12-26'], ['14-18'], ['21-28'], ['15-14'], ['13-11'], ['17-16'], ['29-19'], ['24-3'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 68.6814546585083\n",
      "Response: .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['19-15'], ['18-30'], ['12-26'], ['14-18'], ['7-12'], ['21-28'], ['15-14'], ['29-19'], ['13-11'], ['17-16'], ['24-3'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['8-26'], ['21-30'], ['7-4'], ['17-22'], ['19-15'], ['12-26'], ['18-30'], ['14-18'], ['7-12'], ['21-28'], ['15-14'], ['29-19'], ['13-11'], ['17-16'], ['24-3'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 70.92075943946838\n",
      "Response: .NET 9\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 868\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['8-26'], ['21-30'], ['7-4'], ['17-22'], ['19-15'], ['12-26'], ['18-30'], ['14-18'], ['7-12'], ['21-28'], ['15-14'], ['29-19'], ['13-11'], ['17-16'], ['24-3'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 68.6814546585083\n",
      "Response: .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1717\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['11-2'], ['8-26'], ['21-30'], ['7-4'], ['17-22'], ['19-15'], ['12-26'], ['18-30'], ['14-18'], ['7-12'], ['21-28'], ['15-14'], ['29-19'], ['13-11'], ['17-16'], ['24-3'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 68.6814546585083\n",
      "Response: .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2590\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['7-4'], ['19-15'], ['18-30'], ['12-26'], ['14-18'], ['7-12'], ['21-28'], ['15-14'], ['29-19'], ['13-11'], ['17-16'], ['24-29'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 68.6814546585083\n",
      "Response: .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['11-2'], ['8-26'], ['21-30'], ['7-4'], ['17-22'], ['19-15'], ['12-26'], ['18-30'], ['14-18'], ['21-28'], ['7-12'], ['15-14'], ['29-19'], ['13-11'], ['17-16'], ['24-29'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['11-2'], ['8-26'], ['21-30'], ['7-4'], ['17-22'], ['19-15'], ['12-26'], ['18-30'], ['14-18'], ['7-12'], ['21-28'], ['15-14'], ['29-19'], ['13-11'], ['17-16'], ['24-29'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1151\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['7-4'], ['19-15'], ['12-26'], ['14-18'], ['18-30'], ['7-12'], ['21-28'], ['15-14'], ['29-19'], ['17-16'], ['24-29'], ['13-11'], ['6-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The latest major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2367\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['7-4'], ['19-15'], ['12-26'], ['7-12'], ['14-18'], ['18-30'], ['21-28'], ['6-16'], ['15-14'], ['24-29'], ['29-19'], ['17-16'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3587\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['19-15'], ['7-12'], ['7-4'], ['12-26'], ['14-18'], ['18-30'], ['15-14'], ['21-28'], ['6-16'], ['24-29'], ['29-19'], ['17-16'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 95.34735083580017\n",
      "Response: The latest major version of the .NET framework is .NET 9. 23.0,2024,\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The latest major version of the .NET framework is .NET 9.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['19-15'], ['7-4'], ['12-26'], ['7-12'], ['14-18'], ['18-30'], ['21-28'], ['15-14'], ['24-29'], ['29-19'], ['6-16'], ['17-16'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 97.8837251663208\n",
      "Response: The most recent major version of the .NET framework is .NET 9.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_180_irrelevant_misleading/llama-2-7b-80k_id_180_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['21-30'], ['24-29'], ['17-22'], ['13-11'], ['19-15'], ['6-30'], ['12-26'], ['7-13'], ['18-30'], ['24-30'], ['29-21'], ['30-14'], ['31-16'], ['11-2'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['21-30'], ['24-29'], ['17-22'], ['13-11'], ['19-15'], ['6-30'], ['12-26'], ['7-13'], ['18-30'], ['24-30'], ['29-21'], ['30-14'], ['31-16'], ['11-2'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['21-30'], ['24-29'], ['17-22'], ['13-11'], ['19-15'], ['6-30'], ['12-26'], ['7-13'], ['18-30'], ['24-30'], ['29-21'], ['30-14'], ['31-16'], ['11-2'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['21-30'], ['24-29'], ['17-22'], ['13-11'], ['19-15'], ['6-30'], ['12-26'], ['7-13'], ['18-30'], ['24-30'], ['29-21'], ['30-14'], ['31-16'], ['11-2'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_0_depth_7500_results.json\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['21-30'], ['24-29'], ['17-22'], ['13-11'], ['19-15'], ['6-30'], ['12-26'], ['7-13'], ['18-30'], ['24-30'], ['29-21'], ['30-14'], ['31-16'], ['11-2'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['13-11'], ['6-30'], ['12-26'], ['18-30'], ['29-21'], ['7-13'], ['24-30'], ['30-14'], ['31-16'], ['11-2'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_1250_depth_0_results.json\n",
      "insertion at 48\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['13-11'], ['6-30'], ['7-12'], ['12-26'], ['18-30'], ['11-2'], ['29-21'], ['14-18'], ['7-13'], ['24-30'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 511\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['7-12'], ['13-11'], ['6-30'], ['11-2'], ['18-30'], ['12-26'], ['29-21'], ['14-18'], ['7-13'], ['30-14'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 768\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['7-12'], ['11-2'], ['13-11'], ['18-30'], ['6-30'], ['29-21'], ['14-18'], ['12-26'], ['24-30'], ['31-16'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 85.5262041091919\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States. They are more common in children than adults and appear to be increasing in frequency. Male children appear to be more commonly affected than females. Some allerg\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_1250_depth_7500_results.json\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['11-2'], ['7-12'], ['13-11'], ['18-30'], ['29-21'], ['6-30'], ['12-26'], ['14-18'], ['24-30'], ['31-16'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['7-12'], ['11-2'], ['18-30'], ['13-11'], ['29-21'], ['14-18'], ['6-30'], ['12-26'], ['24-30'], ['31-16'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_2500_depth_0_results.json\n",
      "insertion at 554\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 29.22871708869934\n",
      "Response: 9\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1135\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 29.22871708869934\n",
      "Response: 9\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1678\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['7-12'], ['19-15'], ['11-2'], ['18-30'], ['13-11'], ['14-18'], ['29-21'], ['6-30'], ['12-26'], ['24-30'], ['31-16'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 83.61631631851196\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States. Cow's milk is the most common food allergen in infants and young children, yet many adults are also sensitized to cow's\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_2500_depth_7500_results.json\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['7-12'], ['11-2'], ['18-30'], ['13-11'], ['29-21'], ['14-18'], ['12-26'], ['24-30'], ['6-30'], ['7-13'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['7-12'], ['19-15'], ['11-2'], ['18-30'], ['13-11'], ['14-18'], ['29-21'], ['12-26'], ['24-30'], ['19-12'], ['6-30'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_3750_depth_0_results.json\n",
      "insertion at 836\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['7-4'], ['24-29'], ['17-22'], ['7-12'], ['11-2'], ['19-15'], ['18-30'], ['14-18'], ['13-11'], ['29-21'], ['24-30'], ['12-26'], ['19-12'], ['6-30'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1729\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['7-4'], ['17-22'], ['7-12'], ['11-2'], ['19-15'], ['18-30'], ['14-18'], ['29-21'], ['13-11'], ['24-30'], ['19-12'], ['12-26'], ['6-30'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2628\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['17-22'], ['7-12'], ['11-2'], ['19-15'], ['18-30'], ['14-18'], ['29-21'], ['13-11'], ['24-30'], ['19-12'], ['15-14'], ['6-16'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 87.49002814292908\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States. This can lead to severe allergic reactions in individuals with food allergies, even if the allergen is present in trace amounts. To mit\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_3750_depth_7500_results.json\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['7-4'], ['17-22'], ['7-12'], ['11-2'], ['19-15'], ['18-30'], ['14-18'], ['29-21'], ['13-11'], ['24-30'], ['19-12'], ['12-26'], ['7-13'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['7-4'], ['17-22'], ['7-12'], ['11-2'], ['19-15'], ['18-30'], ['14-18'], ['29-21'], ['13-11'], ['19-12'], ['24-30'], ['6-16'], ['12-26'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1172\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 29.22871708869934\n",
      "Response: 9\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2389\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 29.22871708869934\n",
      "Response: 9\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3551\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['17-22'], ['7-12'], ['11-2'], ['19-15'], ['18-30'], ['14-18'], ['29-21'], ['13-11'], ['6-16'], ['19-12'], ['24-30'], ['15-14'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_5000_depth_7500_results.json\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['7-4'], ['17-22'], ['7-12'], ['11-2'], ['19-15'], ['18-30'], ['14-18'], ['29-21'], ['13-11'], ['19-12'], ['24-30'], ['6-16'], ['12-26'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant/llama-2-7b-80k_id_182_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/182.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['21-30'], ['24-29'], ['17-22'], ['13-11'], ['19-15'], ['6-30'], ['12-26'], ['7-13'], ['18-30'], ['24-30'], ['29-21'], ['30-14'], ['31-16'], ['11-2'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['21-30'], ['24-29'], ['17-22'], ['13-11'], ['19-15'], ['6-30'], ['12-26'], ['7-13'], ['18-30'], ['24-30'], ['29-21'], ['30-14'], ['31-16'], ['11-2'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['21-30'], ['24-29'], ['17-22'], ['13-11'], ['19-15'], ['6-30'], ['12-26'], ['7-13'], ['18-30'], ['24-30'], ['29-21'], ['30-14'], ['31-16'], ['11-2'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['21-30'], ['24-29'], ['17-22'], ['13-11'], ['19-15'], ['6-30'], ['12-26'], ['7-13'], ['18-30'], ['24-30'], ['29-21'], ['30-14'], ['31-16'], ['11-2'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_0_depth_7500_results.json\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['21-30'], ['24-29'], ['17-22'], ['13-11'], ['19-15'], ['6-30'], ['12-26'], ['7-13'], ['18-30'], ['24-30'], ['29-21'], ['30-14'], ['31-16'], ['11-2'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['21-30'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['13-11'], ['6-30'], ['12-26'], ['18-30'], ['29-21'], ['7-13'], ['24-30'], ['30-14'], ['31-16'], ['11-2'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 48\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['13-11'], ['7-12'], ['6-30'], ['12-26'], ['18-30'], ['11-2'], ['29-21'], ['7-13'], ['24-30'], ['30-14'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 511\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['7-12'], ['13-11'], ['6-30'], ['11-2'], ['18-30'], ['12-26'], ['29-21'], ['7-13'], ['14-18'], ['24-30'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 768\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['7-12'], ['11-2'], ['13-11'], ['18-30'], ['6-30'], ['29-21'], ['12-26'], ['14-18'], ['24-30'], ['7-13'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 85.5262041091919\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States. They are more common in children than adults and appear to be increasing in frequency. Male children appear to be more commonly affected than females. Some allerg\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_1250_depth_7500_results.json\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['11-2'], ['7-12'], ['13-11'], ['18-30'], ['29-21'], ['6-30'], ['12-26'], ['14-18'], ['24-30'], ['7-13'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 18.991073966026306\n",
      "Response: 8\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 554\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 29.22871708869934\n",
      "Response: 9\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1134\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 29.22871708869934\n",
      "Response: 9\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1703\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['11-2'], ['7-12'], ['18-30'], ['13-11'], ['29-21'], ['6-30'], ['14-18'], ['24-30'], ['12-26'], ['7-13'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 83.61631631851196\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States. Cow's milk is the most common food allergen in infants and young children, yet many adults are also sensitized to cow's\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_2500_depth_7500_results.json\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['11-2'], ['7-12'], ['18-30'], ['13-11'], ['29-21'], ['12-26'], ['24-30'], ['14-18'], ['6-30'], ['7-13'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 18.991073966026306\n",
      "Response: 8\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 861\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 29.22871708869934\n",
      "Response: 9\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1763\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 29.22871708869934\n",
      "Response: 9\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2614\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['11-2'], ['7-12'], ['18-30'], ['13-11'], ['29-21'], ['14-18'], ['12-26'], ['24-30'], ['6-30'], ['7-13'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 97.82686233520508\n",
      "Response: 9 food allergens require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_3750_depth_7500_results.json\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['11-2'], ['18-30'], ['7-12'], ['13-11'], ['29-21'], ['12-26'], ['14-18'], ['24-30'], ['7-13'], ['19-12'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['11-2'], ['18-30'], ['7-12'], ['13-11'], ['29-21'], ['12-26'], ['14-18'], ['24-30'], ['7-13'], ['19-12'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 79.27422523498535\n",
      "Response: The FDA requires labeling for the eight most common food allergens, which are: milk, eggs, fish, shellfish, tree nuts, peanuts, wheat, and soy.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1160\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['11-2'], ['18-30'], ['7-12'], ['13-11'], ['29-21'], ['12-26'], ['14-18'], ['24-30'], ['7-13'], ['19-12'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 82.2670578956604\n",
      "Response: The FDA requires labeling for eight food allergens: milk, eggs, fish, shellfish, tree nuts, peanuts, wheat, and soy.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2367\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['11-2'], ['18-30'], ['7-12'], ['13-11'], ['29-21'], ['12-26'], ['14-18'], ['24-30'], ['7-13'], ['19-12'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 81.56226873397827\n",
      "Response: The FDA requires labeling for eight food allergens: milk, eggs, fish, crustacean shellfish, tree nuts, peanuts, wheat, and soybeans.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3577\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['17-22'], ['19-15'], ['11-2'], ['7-12'], ['18-30'], ['13-11'], ['29-21'], ['14-18'], ['12-26'], ['24-30'], ['7-13'], ['19-12'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 94.1963791847229\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States. While there are many food allergens, only some are considered major allergens that require mandatory labeling by the FDA. This phase can\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_5000_depth_7500_results.json\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['17-22'], ['19-15'], ['11-2'], ['7-12'], ['18-30'], ['13-11'], ['29-21'], ['14-18'], ['24-30'], ['12-26'], ['7-13'], ['19-12'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_relevant_misleading/llama-2-7b-80k_id_182_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['21-30'], ['24-29'], ['17-22'], ['13-11'], ['19-15'], ['6-30'], ['12-26'], ['7-13'], ['18-30'], ['24-30'], ['29-21'], ['30-14'], ['31-16'], ['11-2'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['21-30'], ['24-29'], ['17-22'], ['13-11'], ['19-15'], ['6-30'], ['12-26'], ['7-13'], ['18-30'], ['24-30'], ['29-21'], ['30-14'], ['31-16'], ['11-2'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['21-30'], ['24-29'], ['17-22'], ['13-11'], ['19-15'], ['6-30'], ['12-26'], ['7-13'], ['18-30'], ['24-30'], ['29-21'], ['30-14'], ['31-16'], ['11-2'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['21-30'], ['24-29'], ['17-22'], ['13-11'], ['19-15'], ['6-30'], ['12-26'], ['7-13'], ['18-30'], ['24-30'], ['29-21'], ['30-14'], ['31-16'], ['11-2'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_0_depth_7500_results.json\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['21-30'], ['24-29'], ['17-22'], ['13-11'], ['19-15'], ['6-30'], ['12-26'], ['7-13'], ['18-30'], ['24-30'], ['29-21'], ['30-14'], ['31-16'], ['11-2'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 18.991073966026306\n",
      "Response: 8\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 254\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['13-11'], ['6-30'], ['12-26'], ['18-30'], ['24-30'], ['7-13'], ['29-21'], ['30-14'], ['31-16'], ['11-2'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 484\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['7-4'], ['8-26'], ['24-29'], ['17-22'], ['19-15'], ['13-11'], ['6-30'], ['18-30'], ['12-26'], ['11-2'], ['24-30'], ['7-12'], ['7-13'], ['14-18'], ['29-21'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 733\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['7-4'], ['8-26'], ['24-29'], ['17-22'], ['19-15'], ['13-11'], ['18-30'], ['6-30'], ['11-2'], ['12-26'], ['24-30'], ['14-18'], ['7-12'], ['29-21'], ['7-13'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_1250_depth_7500_results.json\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['7-4'], ['8-26'], ['24-29'], ['17-22'], ['19-15'], ['13-11'], ['18-30'], ['6-30'], ['24-30'], ['11-2'], ['12-26'], ['14-18'], ['29-21'], ['7-12'], ['31-16'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 97.82686233520508\n",
      "Response: 9 food allergens require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['7-4'], ['8-26'], ['24-29'], ['17-22'], ['19-15'], ['13-11'], ['11-2'], ['18-30'], ['6-30'], ['7-12'], ['24-30'], ['14-18'], ['12-26'], ['29-21'], ['29-19'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 87.76540160179138\n",
      "Response: The eight food allergens that require mandatory labeling in the United States are: milk, eggs, fish, crustacean shellfish, tree nuts, peanuts, wheat, and soybeans.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 562\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['7-12'], ['11-2'], ['13-11'], ['18-30'], ['6-30'], ['14-18'], ['24-30'], ['12-26'], ['29-19'], ['29-21'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 87.76540160179138\n",
      "Response: The eight food allergens that require mandatory labeling in the United States are: milk, eggs, fish, crustacean shellfish, tree nuts, peanuts, wheat, and soybeans.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1053\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 29.22871708869934\n",
      "Response: 9\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1691\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['7-12'], ['11-2'], ['13-11'], ['18-30'], ['14-18'], ['6-30'], ['24-30'], ['12-26'], ['29-19'], ['29-21'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_2500_depth_7500_results.json\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['11-2'], ['7-12'], ['13-11'], ['18-30'], ['14-18'], ['24-30'], ['6-30'], ['29-21'], ['12-26'], ['29-19'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['7-12'], ['11-2'], ['18-30'], ['13-11'], ['14-18'], ['24-30'], ['29-21'], ['6-30'], ['29-19'], ['12-26'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 879\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['7-12'], ['19-15'], ['11-2'], ['18-30'], ['14-18'], ['13-11'], ['29-21'], ['24-30'], ['29-19'], ['6-30'], ['12-26'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1752\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 29.22871708869934\n",
      "Response: 9\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2607\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['17-22'], ['7-12'], ['19-15'], ['11-2'], ['18-30'], ['14-18'], ['13-11'], ['29-19'], ['29-21'], ['24-30'], ['6-30'], ['6-16'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 97.82686233520508\n",
      "Response: 9 food allergens require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_3750_depth_7500_results.json\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['17-22'], ['7-12'], ['19-15'], ['11-2'], ['18-30'], ['13-11'], ['14-18'], ['29-19'], ['29-21'], ['24-30'], ['15-14'], ['6-30'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['17-22'], ['7-12'], ['19-15'], ['11-2'], ['18-30'], ['14-18'], ['13-11'], ['29-19'], ['29-21'], ['24-30'], ['15-14'], ['6-16'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1141\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 24.932555854320526\n",
      "Response: 9, the misconception is that the term \"ptomaine poisoning\" is a synonym for food poisoning. This is not the case. Ptomaine poisoning is a specific type of food poisoning caused by the\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2377\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 25.77667236328125\n",
      "Response: 9, the misconception is that the term \"ptomaine poisoning\" is a synonym for food poisoning. The term \"ptomaine poisoning\" is a misnomer, as the term \"ptomaine\"\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3573\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 14.79744017124176\n",
      "Response: 9, the author of the book, Dr. Michael Jacob, states that the term \"ptomaine poisoning\" is a misnomer. The term \"ptomaine\" is derived from the Greek word \"ptomaina\"\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_5000_depth_7500_results.json\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['17-22'], ['7-12'], ['19-15'], ['11-2'], ['18-30'], ['14-18'], ['13-11'], ['29-21'], ['29-19'], ['24-30'], ['15-14'], ['12-26'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant/llama-2-7b-80k_id_182_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/182.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['21-30'], ['24-29'], ['17-22'], ['13-11'], ['19-15'], ['6-30'], ['12-26'], ['7-13'], ['18-30'], ['24-30'], ['29-21'], ['30-14'], ['31-16'], ['11-2'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['21-30'], ['24-29'], ['17-22'], ['13-11'], ['19-15'], ['6-30'], ['12-26'], ['7-13'], ['18-30'], ['24-30'], ['29-21'], ['30-14'], ['31-16'], ['11-2'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['21-30'], ['24-29'], ['17-22'], ['13-11'], ['19-15'], ['6-30'], ['12-26'], ['7-13'], ['18-30'], ['24-30'], ['29-21'], ['30-14'], ['31-16'], ['11-2'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['21-30'], ['24-29'], ['17-22'], ['13-11'], ['19-15'], ['6-30'], ['12-26'], ['7-13'], ['18-30'], ['24-30'], ['29-21'], ['30-14'], ['31-16'], ['11-2'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['21-30'], ['24-29'], ['17-22'], ['13-11'], ['19-15'], ['6-30'], ['12-26'], ['7-13'], ['18-30'], ['24-30'], ['29-21'], ['30-14'], ['31-16'], ['11-2'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['7-4'], ['8-26'], ['24-29'], ['17-22'], ['13-11'], ['19-15'], ['6-30'], ['12-26'], ['7-13'], ['18-30'], ['24-30'], ['29-21'], ['30-14'], ['31-16'], ['24-3'], ['25-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 81.56226873397827\n",
      "Response: The FDA requires labeling for eight food allergens: milk, eggs, fish, crustacean shellfish, tree nuts, peanuts, wheat, and soybeans.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 254\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['7-4'], ['8-26'], ['24-29'], ['17-22'], ['19-15'], ['13-11'], ['6-30'], ['12-26'], ['7-13'], ['18-30'], ['24-30'], ['29-21'], ['30-14'], ['31-16'], ['29-19'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 80.35589456558228\n",
      "Response: The FDA requires labeling for the following 8 food allergens: milk, eggs, fish, shellfish, tree nuts, peanuts, wheat, and soybeans.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 484\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['7-4'], ['8-26'], ['24-29'], ['17-22'], ['19-15'], ['13-11'], ['6-30'], ['12-26'], ['7-13'], ['18-30'], ['24-30'], ['29-21'], ['30-14'], ['31-16'], ['29-19'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 75.34337639808655\n",
      "Response: The FDA requires labeling for the following food allergens: milk, eggs, fish, crustacean shellfish, tree nuts, peanuts, wheat, and soybeans.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 758\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 29.22871708869934\n",
      "Response: 9\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['7-4'], ['8-26'], ['24-29'], ['17-22'], ['19-15'], ['13-11'], ['12-26'], ['6-30'], ['24-30'], ['31-16'], ['30-14'], ['29-19'], ['18-30'], ['29-21'], ['7-13'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 97.82686233520508\n",
      "Response: 9 food allergens require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['7-4'], ['8-26'], ['24-29'], ['17-22'], ['19-15'], ['13-11'], ['12-26'], ['6-30'], ['24-30'], ['29-19'], ['31-16'], ['29-21'], ['30-14'], ['18-30'], ['7-13'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 81.56226873397827\n",
      "Response: The FDA requires labeling for eight food allergens: milk, eggs, fish, crustacean shellfish, tree nuts, peanuts, wheat, and soybeans.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 562\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['21-30'], ['11-15'], ['7-4'], ['8-26'], ['24-29'], ['17-22'], ['19-15'], ['13-11'], ['12-26'], ['6-30'], ['29-19'], ['24-30'], ['29-21'], ['31-16'], ['30-14'], ['18-30'], ['7-13'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 83.87178182601929\n",
      "Response: The FDA requires labeling for most common food allergens, but the exact number can vary depending on the source.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1078\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['24-29'], ['7-4'], ['8-26'], ['17-22'], ['19-15'], ['13-11'], ['29-19'], ['12-26'], ['24-30'], ['29-21'], ['6-30'], ['18-30'], ['31-16'], ['30-14'], ['24-3'], ['25-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1703\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['7-4'], ['24-29'], ['8-26'], ['17-22'], ['19-15'], ['13-11'], ['29-21'], ['24-30'], ['29-19'], ['18-30'], ['12-26'], ['6-30'], ['11-2'], ['24-3'], ['14-18'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['24-29'], ['7-4'], ['8-26'], ['17-22'], ['19-15'], ['13-11'], ['24-30'], ['29-19'], ['29-21'], ['12-26'], ['18-30'], ['31-16'], ['6-30'], ['14-18'], ['24-3'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 97.82686233520508\n",
      "Response: 9 food allergens require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['17-22'], ['19-15'], ['13-11'], ['7-12'], ['29-21'], ['29-19'], ['18-30'], ['24-30'], ['12-26'], ['14-18'], ['11-2'], ['24-3'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 838\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['17-22'], ['19-15'], ['7-12'], ['13-11'], ['29-21'], ['11-2'], ['29-19'], ['18-30'], ['14-18'], ['24-30'], ['6-16'], ['12-26'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1743\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['17-22'], ['7-4'], ['19-15'], ['7-12'], ['11-2'], ['13-11'], ['29-21'], ['29-19'], ['14-18'], ['18-30'], ['6-16'], ['24-30'], ['12-26'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2641\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['17-22'], ['7-4'], ['7-12'], ['19-15'], ['11-2'], ['13-11'], ['29-21'], ['6-16'], ['14-18'], ['18-30'], ['29-19'], ['24-30'], ['24-3'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['17-22'], ['7-4'], ['7-12'], ['19-15'], ['11-2'], ['13-11'], ['29-21'], ['18-30'], ['14-18'], ['29-19'], ['24-30'], ['6-16'], ['12-26'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['17-22'], ['7-4'], ['7-12'], ['19-15'], ['11-2'], ['13-11'], ['29-21'], ['18-30'], ['6-16'], ['14-18'], ['29-19'], ['24-30'], ['12-26'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 90.01147150993347\n",
      "Response: The number of food allergens that require mandatory labeling in the United States can vary depending on the source.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1166\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 18.991073966026306\n",
      "Response: 8\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2384\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 29.22871708869934\n",
      "Response: 9\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3571\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['17-22'], ['7-4'], ['7-12'], ['19-15'], ['11-2'], ['13-11'], ['29-21'], ['18-30'], ['6-16'], ['14-18'], ['24-30'], ['29-19'], ['24-3'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 85.55046319961548\n",
      "Response: There are 9 food allergens that require mandatory labeling in the United States. The EC and the FDA have limited it to under 50 Î¼g/kg for fruit juice and fruit nectar, while limits\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "There are 9 food allergens that require mandatory labeling in the United States.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['17-22'], ['7-12'], ['19-15'], ['11-2'], ['13-11'], ['29-21'], ['18-30'], ['14-18'], ['6-16'], ['24-30'], ['29-19'], ['12-26'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 97.82686233520508\n",
      "Response: 9 food allergens require mandatory labeling in the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_182_irrelevant_misleading/llama-2-7b-80k_id_182_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The CEO of X Corp. is Linda Yaccarino.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['6-30'], ['11-15'], ['6-9'], ['8-26'], ['12-26'], ['16-24'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['7-13'], ['8-31'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['21-1'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['6-30'], ['11-15'], ['6-9'], ['8-26'], ['12-26'], ['16-24'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['7-13'], ['8-31'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['21-1'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['6-30'], ['11-15'], ['6-9'], ['8-26'], ['12-26'], ['16-24'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['7-13'], ['8-31'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['21-1'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['6-30'], ['11-15'], ['6-9'], ['8-26'], ['12-26'], ['16-24'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['7-13'], ['8-31'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['21-1'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_0_depth_7500_results.json\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['6-30'], ['11-15'], ['6-9'], ['8-26'], ['12-26'], ['16-24'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['7-13'], ['8-31'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['21-1'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 23.42928647994995\n",
      "Response: Elon Musk\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_1250_depth_0_results.json\n",
      "insertion at 231\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 23.42928647994995\n",
      "Response: Elon Musk\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 498\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['6-30'], ['11-15'], ['31-16'], ['8-26'], ['24-29'], ['16-24'], ['6-9'], ['12-26'], ['21-30'], ['7-4'], ['15-14'], ['22-8'], ['8-31'], ['13-11'], ['14-18'], ['17-22'], ['21-1'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 59.99870300292969\n",
      "Response: Linda Yaccarino.com, an online bank co-founded by Musk in 1999. In March 2000, X.com merged with competitor Confinity to create PayPal. Mus\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 756\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['6-30'], ['11-15'], ['31-16'], ['24-29'], ['8-26'], ['16-24'], ['6-9'], ['12-26'], ['21-30'], ['7-4'], ['15-14'], ['22-8'], ['13-11'], ['26-28'], ['8-31'], ['21-1'], ['14-18'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_1250_depth_7500_results.json\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['6-30'], ['24-29'], ['8-26'], ['31-16'], ['6-9'], ['7-4'], ['12-26'], ['16-24'], ['21-30'], ['15-14'], ['22-8'], ['26-28'], ['13-11'], ['17-22'], ['21-1'], ['7-13'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The CEO of X Corp. is Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 23.42928647994995\n",
      "Response: Elon Musk\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_2500_depth_0_results.json\n",
      "insertion at 569\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 23.42928647994995\n",
      "Response: Elon Musk\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1121\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['6-30'], ['24-29'], ['8-26'], ['31-16'], ['6-9'], ['16-24'], ['7-4'], ['12-26'], ['15-14'], ['21-30'], ['22-8'], ['26-28'], ['13-11'], ['21-1'], ['14-18'], ['17-22'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1711\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['6-30'], ['24-29'], ['8-26'], ['31-16'], ['16-24'], ['7-4'], ['6-9'], ['12-26'], ['15-14'], ['21-30'], ['22-8'], ['26-28'], ['13-11'], ['26-27'], ['21-1'], ['21-28'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_2500_depth_7500_results.json\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['8-26'], ['24-29'], ['6-30'], ['31-16'], ['6-9'], ['7-4'], ['16-24'], ['12-26'], ['15-14'], ['21-30'], ['22-8'], ['26-28'], ['13-11'], ['26-27'], ['21-1'], ['7-13'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The CEO of X Corp. is Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 23.42928647994995\n",
      "Response: Elon Musk\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_3750_depth_0_results.json\n",
      "insertion at 881\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 23.42928647994995\n",
      "Response: Elon Musk\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1735\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 23.42928647994995\n",
      "Response: Elon Musk\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2636\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['6-30'], ['8-26'], ['31-16'], ['6-9'], ['16-24'], ['7-4'], ['12-26'], ['15-14'], ['21-30'], ['22-8'], ['26-28'], ['26-27'], ['10-18'], ['13-11'], ['21-1'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 63.718366622924805\n",
      "Response: Linda Yaccarino\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_3750_depth_7500_results.json\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['31-16'], ['7-4'], ['6-9'], ['12-26'], ['16-24'], ['15-14'], ['21-30'], ['22-8'], ['26-28'], ['10-18'], ['26-27'], ['13-11'], ['14-18'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The CEO of X Corp. is Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 23.42928647994995\n",
      "Response: Elon Musk\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1188\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['31-16'], ['7-4'], ['6-9'], ['16-24'], ['12-26'], ['15-14'], ['21-30'], ['22-8'], ['26-28'], ['10-18'], ['26-27'], ['13-11'], ['14-18'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 63.718366622924805\n",
      "Response: Linda Yaccarino\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2353\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['31-16'], ['6-9'], ['7-4'], ['16-24'], ['12-26'], ['15-14'], ['21-30'], ['22-8'], ['10-18'], ['26-28'], ['26-27'], ['13-11'], ['14-18'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 63.718366622924805\n",
      "Response: Linda Yaccarino\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3577\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['31-16'], ['6-9'], ['16-24'], ['7-4'], ['12-26'], ['15-14'], ['21-30'], ['22-8'], ['10-18'], ['26-28'], ['26-27'], ['13-11'], ['21-28'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 63.718366622924805\n",
      "Response: Linda Yaccarino\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_5000_depth_7500_results.json\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['8-26'], ['31-16'], ['6-30'], ['6-9'], ['7-4'], ['16-24'], ['12-26'], ['15-14'], ['21-30'], ['22-8'], ['10-18'], ['26-28'], ['26-27'], ['13-11'], ['21-28'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The CEO of X Corp. is Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant/llama-2-7b-80k_id_183_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/183.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The CEO of X Corp. is Linda Yaccarino.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['6-30'], ['11-15'], ['6-9'], ['8-26'], ['12-26'], ['16-24'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['7-13'], ['8-31'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['21-1'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['6-30'], ['11-15'], ['6-9'], ['8-26'], ['12-26'], ['16-24'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['7-13'], ['8-31'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['21-1'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['6-30'], ['11-15'], ['6-9'], ['8-26'], ['12-26'], ['16-24'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['7-13'], ['8-31'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['21-1'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['6-30'], ['11-15'], ['6-9'], ['8-26'], ['12-26'], ['16-24'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['7-13'], ['8-31'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['21-1'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_0_depth_7500_results.json\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['6-30'], ['11-15'], ['6-9'], ['8-26'], ['12-26'], ['16-24'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['7-13'], ['8-31'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['21-1'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 23.42928647994995\n",
      "Response: Elon Musk\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 231\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['6-30'], ['6-9'], ['24-29'], ['12-26'], ['8-26'], ['16-24'], ['21-30'], ['31-16'], ['15-14'], ['22-8'], ['13-11'], ['21-1'], ['26-28'], ['7-4'], ['7-13'], ['8-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 63.718366622924805\n",
      "Response: Linda Yaccarino\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 498\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['6-9'], ['6-30'], ['16-24'], ['31-16'], ['12-26'], ['21-30'], ['8-26'], ['15-14'], ['22-8'], ['21-1'], ['26-28'], ['13-11'], ['14-18'], ['7-4'], ['7-13'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 59.99870300292969\n",
      "Response: Linda Yaccarino.com, an online bank co-founded by Musk in 1999. In March 2000, X.com merged with competitor Confinity to create PayPal. Mus\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 756\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['6-9'], ['31-16'], ['16-24'], ['6-30'], ['12-26'], ['15-14'], ['21-30'], ['22-8'], ['8-26'], ['26-28'], ['21-1'], ['13-11'], ['14-18'], ['17-0'], ['7-4'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['6-9'], ['31-16'], ['6-30'], ['12-26'], ['16-24'], ['8-26'], ['15-14'], ['21-30'], ['7-4'], ['22-8'], ['26-28'], ['13-11'], ['21-1'], ['17-0'], ['21-28'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The CEO of X Corp. is Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 23.42928647994995\n",
      "Response: Elon Musk\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 569\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['6-9'], ['31-16'], ['16-24'], ['6-30'], ['8-26'], ['12-26'], ['15-14'], ['21-30'], ['22-8'], ['7-4'], ['26-28'], ['13-11'], ['21-1'], ['21-28'], ['17-0'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 63.718366622924805\n",
      "Response: Linda Yaccarino\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1136\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['6-9'], ['31-16'], ['16-24'], ['6-30'], ['8-26'], ['12-26'], ['15-14'], ['21-30'], ['22-8'], ['7-4'], ['26-28'], ['21-28'], ['13-11'], ['17-0'], ['21-1'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 63.718366622924805\n",
      "Response: Linda Yaccarino\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1702\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['6-9'], ['31-16'], ['6-30'], ['16-24'], ['8-26'], ['12-26'], ['15-14'], ['22-8'], ['21-30'], ['7-4'], ['26-28'], ['17-0'], ['21-28'], ['13-11'], ['26-27'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 63.718366622924805\n",
      "Response: Linda Yaccarino\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['11-15'], ['6-9'], ['6-30'], ['8-26'], ['31-16'], ['16-24'], ['12-26'], ['15-14'], ['7-4'], ['21-30'], ['22-8'], ['26-28'], ['13-11'], ['21-28'], ['17-0'], ['26-27'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 97.97083139419556\n",
      "Response: Linda Yaccarino is the CEO of X Corp.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['11-15'], ['6-9'], ['6-30'], ['8-26'], ['31-16'], ['16-24'], ['12-26'], ['15-14'], ['7-4'], ['21-30'], ['22-8'], ['26-28'], ['13-11'], ['21-28'], ['17-0'], ['26-27'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 67.49138832092285\n",
      "Response: Elon Musk is the CEO of X Corp.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 881\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['11-15'], ['6-9'], ['6-30'], ['8-26'], ['31-16'], ['16-24'], ['12-26'], ['15-14'], ['7-4'], ['21-30'], ['22-8'], ['26-28'], ['13-11'], ['21-28'], ['17-0'], ['26-27'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 67.49138832092285\n",
      "Response: Elon Musk is the CEO of X Corp.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1766\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 23.42928647994995\n",
      "Response: Elon Musk\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2631\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['11-15'], ['6-9'], ['6-30'], ['8-26'], ['31-16'], ['16-24'], ['12-26'], ['15-14'], ['7-4'], ['21-30'], ['22-8'], ['26-28'], ['13-11'], ['17-0'], ['21-28'], ['26-27'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 63.718366622924805\n",
      "Response: Linda Yaccarino\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['11-15'], ['8-26'], ['6-9'], ['6-30'], ['31-16'], ['16-24'], ['12-26'], ['7-4'], ['15-14'], ['21-30'], ['22-8'], ['26-28'], ['13-11'], ['21-28'], ['26-27'], ['10-18'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The CEO of X Corp. is Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['8-26'], ['6-9'], ['6-30'], ['31-16'], ['16-24'], ['12-26'], ['7-4'], ['15-14'], ['21-30'], ['22-8'], ['26-28'], ['21-28'], ['13-11'], ['26-27'], ['10-18'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 63.718366622924805\n",
      "Response: Linda Yaccarino\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1136\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['8-26'], ['6-9'], ['6-30'], ['16-24'], ['31-16'], ['12-26'], ['7-4'], ['15-14'], ['21-30'], ['22-8'], ['26-28'], ['21-28'], ['13-11'], ['26-27'], ['10-18'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 63.718366622924805\n",
      "Response: Linda Yaccarino\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2384\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['6-9'], ['8-26'], ['31-16'], ['6-30'], ['16-24'], ['12-26'], ['7-4'], ['15-14'], ['22-8'], ['21-30'], ['26-28'], ['26-27'], ['13-11'], ['21-28'], ['10-18'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3585\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['6-9'], ['8-26'], ['31-16'], ['16-24'], ['6-30'], ['12-26'], ['15-14'], ['7-4'], ['22-8'], ['21-30'], ['26-28'], ['26-27'], ['21-28'], ['13-11'], ['10-18'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-29'], ['8-26'], ['6-9'], ['31-16'], ['16-24'], ['6-30'], ['12-26'], ['7-4'], ['15-14'], ['21-30'], ['22-8'], ['26-28'], ['26-27'], ['21-28'], ['13-11'], ['10-18'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The CEO of X Corp. is Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_relevant_misleading/llama-2-7b-80k_id_183_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The CEO of X Corp. is Linda Yaccarino.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['6-30'], ['11-15'], ['6-9'], ['8-26'], ['12-26'], ['16-24'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['7-13'], ['8-31'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['21-1'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['6-30'], ['11-15'], ['6-9'], ['8-26'], ['12-26'], ['16-24'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['7-13'], ['8-31'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['21-1'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['6-30'], ['11-15'], ['6-9'], ['8-26'], ['12-26'], ['16-24'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['7-13'], ['8-31'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['21-1'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['6-30'], ['11-15'], ['6-9'], ['8-26'], ['12-26'], ['16-24'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['7-13'], ['8-31'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['21-1'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_0_depth_7500_results.json\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['6-30'], ['11-15'], ['6-9'], ['8-26'], ['12-26'], ['16-24'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['7-13'], ['8-31'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['21-1'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-30'], ['8-26'], ['24-29'], ['6-9'], ['21-30'], ['12-26'], ['16-24'], ['31-16'], ['7-4'], ['17-22'], ['13-11'], ['22-8'], ['26-28'], ['8-31'], ['14-18'], ['21-1'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The CEO of X Corp. is Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 252\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-30'], ['8-26'], ['24-29'], ['6-9'], ['21-30'], ['12-26'], ['16-24'], ['31-16'], ['7-4'], ['13-11'], ['17-22'], ['22-8'], ['21-1'], ['26-28'], ['8-31'], ['14-18'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 477\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-30'], ['8-26'], ['24-29'], ['21-30'], ['6-9'], ['7-4'], ['12-26'], ['16-24'], ['31-16'], ['13-11'], ['17-22'], ['22-8'], ['21-1'], ['26-28'], ['7-12'], ['8-31'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 670\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['8-26'], ['6-30'], ['24-29'], ['21-30'], ['6-9'], ['7-4'], ['12-26'], ['16-24'], ['31-16'], ['13-11'], ['22-8'], ['17-22'], ['21-1'], ['26-28'], ['7-12'], ['8-31'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_1250_depth_7500_results.json\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['8-26'], ['6-30'], ['24-29'], ['6-9'], ['21-30'], ['7-4'], ['16-24'], ['31-16'], ['12-26'], ['13-11'], ['22-8'], ['17-22'], ['21-1'], ['26-28'], ['14-15'], ['26-27'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['8-26'], ['6-30'], ['24-29'], ['6-9'], ['21-30'], ['7-4'], ['16-24'], ['12-26'], ['31-16'], ['22-8'], ['7-12'], ['17-22'], ['13-11'], ['26-28'], ['21-1'], ['14-15'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The CEO of X Corp. is Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 536\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['8-26'], ['6-30'], ['24-29'], ['6-9'], ['21-30'], ['7-4'], ['16-24'], ['12-26'], ['31-16'], ['7-12'], ['22-8'], ['13-11'], ['17-22'], ['26-28'], ['21-1'], ['14-15'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1139\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-30'], ['24-29'], ['6-9'], ['21-30'], ['7-4'], ['16-24'], ['12-26'], ['31-16'], ['7-12'], ['22-8'], ['26-28'], ['17-22'], ['21-1'], ['13-11'], ['14-15'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 63.718366622924805\n",
      "Response: Linda Yaccarino\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1672\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-30'], ['24-29'], ['6-9'], ['21-30'], ['7-4'], ['16-24'], ['31-16'], ['12-26'], ['7-12'], ['22-8'], ['26-28'], ['21-1'], ['17-22'], ['13-11'], ['14-15'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_2500_depth_7500_results.json\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-30'], ['24-29'], ['6-9'], ['21-30'], ['7-4'], ['16-24'], ['31-16'], ['12-26'], ['22-8'], ['7-12'], ['26-28'], ['21-1'], ['17-22'], ['13-11'], ['14-15'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 11.955608427524567\n",
      "Response: Sam Altman\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 867\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 11.955608427524567\n",
      "Response: Sam Altman\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1746\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 11.955608427524567\n",
      "Response: Sam Altman\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2620\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 11.955608427524567\n",
      "Response: Sam Altman\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_3750_depth_7500_results.json\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-30'], ['24-29'], ['6-9'], ['21-30'], ['7-4'], ['16-24'], ['31-16'], ['12-26'], ['22-8'], ['21-1'], ['26-28'], ['7-12'], ['17-22'], ['13-11'], ['14-15'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 63.718366622924805\n",
      "Response: Linda Yaccarino\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 11.955608427524567\n",
      "Response: Sam Altman\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1139\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 11.955608427524567\n",
      "Response: Sam Altman\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2385\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 11.955608427524567\n",
      "Response: Sam Altman\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3542\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-30'], ['19-15'], ['24-29'], ['6-9'], ['21-30'], ['7-4'], ['31-16'], ['16-24'], ['12-26'], ['22-8'], ['21-1'], ['26-28'], ['7-12'], ['14-15'], ['17-22'], ['26-27'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_5000_depth_7500_results.json\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-30'], ['19-15'], ['24-29'], ['6-9'], ['21-30'], ['7-4'], ['31-16'], ['16-24'], ['12-26'], ['22-8'], ['21-1'], ['26-28'], ['7-12'], ['14-15'], ['26-27'], ['17-22'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant/llama-2-7b-80k_id_183_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/183.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The CEO of X Corp. is Linda Yaccarino.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['6-30'], ['11-15'], ['6-9'], ['8-26'], ['12-26'], ['16-24'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['7-13'], ['8-31'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['21-1'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['6-30'], ['11-15'], ['6-9'], ['8-26'], ['12-26'], ['16-24'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['7-13'], ['8-31'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['21-1'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['6-30'], ['11-15'], ['6-9'], ['8-26'], ['12-26'], ['16-24'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['7-13'], ['8-31'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['21-1'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['6-30'], ['11-15'], ['6-9'], ['8-26'], ['12-26'], ['16-24'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['7-13'], ['8-31'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['21-1'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['6-30'], ['11-15'], ['6-9'], ['8-26'], ['12-26'], ['16-24'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['7-13'], ['8-31'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['21-1'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['6-30'], ['6-9'], ['24-29'], ['8-26'], ['12-26'], ['16-24'], ['21-30'], ['31-16'], ['17-22'], ['14-18'], ['21-1'], ['26-28'], ['7-4'], ['7-13'], ['8-31'], ['13-11'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 252\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['6-9'], ['6-30'], ['24-29'], ['12-26'], ['21-30'], ['31-16'], ['8-26'], ['16-24'], ['17-22'], ['14-18'], ['21-1'], ['13-11'], ['15-14'], ['22-8'], ['26-28'], ['7-4'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 477\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['6-9'], ['24-29'], ['6-30'], ['12-26'], ['21-30'], ['31-16'], ['16-24'], ['17-22'], ['8-26'], ['21-1'], ['14-18'], ['15-14'], ['13-11'], ['22-8'], ['26-28'], ['7-4'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 670\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['6-9'], ['24-29'], ['12-26'], ['6-30'], ['21-30'], ['16-24'], ['31-16'], ['17-22'], ['21-1'], ['8-26'], ['15-14'], ['14-18'], ['13-11'], ['22-8'], ['26-28'], ['7-4'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['6-9'], ['24-29'], ['12-26'], ['8-26'], ['6-30'], ['21-30'], ['31-16'], ['16-24'], ['17-22'], ['7-4'], ['15-14'], ['21-1'], ['22-8'], ['13-11'], ['14-18'], ['26-28'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The CEO of X Corp. is Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['24-29'], ['12-26'], ['8-26'], ['6-30'], ['21-30'], ['31-16'], ['16-24'], ['17-22'], ['7-4'], ['15-14'], ['21-1'], ['22-8'], ['14-18'], ['26-28'], ['13-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 63.718366622924805\n",
      "Response: Linda Yaccarino\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 536\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['24-29'], ['12-26'], ['8-26'], ['21-30'], ['6-30'], ['31-16'], ['17-22'], ['16-24'], ['21-1'], ['7-4'], ['15-14'], ['22-8'], ['14-18'], ['26-28'], ['13-11'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 63.718366622924805\n",
      "Response: Linda Yaccarino\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1126\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['24-29'], ['12-26'], ['8-26'], ['6-30'], ['31-16'], ['21-30'], ['17-22'], ['16-24'], ['21-1'], ['7-4'], ['15-14'], ['22-8'], ['26-28'], ['14-18'], ['13-11'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 63.718366622924805\n",
      "Response: Linda Yaccarino\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1687\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['24-29'], ['8-26'], ['12-26'], ['6-30'], ['31-16'], ['21-30'], ['17-22'], ['16-24'], ['21-1'], ['7-4'], ['15-14'], ['22-8'], ['26-28'], ['14-18'], ['26-27'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['24-29'], ['8-26'], ['6-30'], ['12-26'], ['31-16'], ['21-30'], ['16-24'], ['17-22'], ['7-4'], ['21-1'], ['15-14'], ['22-8'], ['26-28'], ['26-27'], ['14-18'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 63.610947132110596\n",
      "Response: Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['24-29'], ['8-26'], ['6-30'], ['12-26'], ['31-16'], ['21-30'], ['17-22'], ['16-24'], ['7-4'], ['21-1'], ['15-14'], ['22-8'], ['26-28'], ['7-12'], ['14-18'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The CEO of X Corp. is Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 867\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['24-29'], ['8-26'], ['6-30'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['16-24'], ['21-1'], ['7-4'], ['15-14'], ['22-8'], ['7-12'], ['14-18'], ['26-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 97.97083139419556\n",
      "Response: Linda Yaccarino is the CEO of X Corp.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1746\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 11.955608427524567\n",
      "Response: Sam Altman\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2640\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 11.955608427524567\n",
      "Response: Sam Altman\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['24-29'], ['8-26'], ['12-26'], ['6-30'], ['31-16'], ['21-30'], ['17-22'], ['16-24'], ['7-4'], ['21-1'], ['15-14'], ['22-8'], ['26-28'], ['7-12'], ['26-27'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The CEO of X Corp. is Linda Yaccarino.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 11.955608427524567\n",
      "Response: Sam Altman\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1154\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['24-29'], ['12-26'], ['6-30'], ['31-16'], ['21-30'], ['17-22'], ['16-24'], ['7-4'], ['21-1'], ['15-14'], ['22-8'], ['7-12'], ['26-28'], ['26-27'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 60.95964312553406\n",
      "Response: Sam Altman is the CEO of X Corp.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2372\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['24-29'], ['12-26'], ['6-30'], ['31-16'], ['17-22'], ['21-30'], ['16-24'], ['7-4'], ['7-12'], ['15-14'], ['21-1'], ['22-8'], ['26-27'], ['26-28'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 97.97083139419556\n",
      "Response: Linda Yaccarino is the CEO of X Corp.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3470\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['24-29'], ['12-26'], ['31-16'], ['6-30'], ['21-30'], ['17-22'], ['16-24'], ['7-12'], ['15-14'], ['7-4'], ['22-8'], ['21-1'], ['26-27'], ['26-28'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 63.718366622924805\n",
      "Response: Linda Yaccarino\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The CEO of X Corp. is Linda Yaccarino.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['24-29'], ['12-26'], ['6-30'], ['31-16'], ['21-30'], ['16-24'], ['17-22'], ['7-4'], ['15-14'], ['7-12'], ['22-8'], ['21-1'], ['26-27'], ['26-28'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 63.718366622924805\n",
      "Response: Linda Yaccarino\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_183_irrelevant_misleading/llama-2-7b-80k_id_183_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['11-2'], ['12-26'], ['6-30'], ['13-11'], ['18-30'], ['19-10'], ['20-28'], ['22-22'], ['24-3'], ['24-30'], ['26-28'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['11-2'], ['12-26'], ['6-30'], ['13-11'], ['18-30'], ['19-10'], ['20-28'], ['22-22'], ['24-3'], ['24-30'], ['26-28'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['11-2'], ['12-26'], ['6-30'], ['13-11'], ['18-30'], ['19-10'], ['20-28'], ['22-22'], ['24-3'], ['24-30'], ['26-28'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['11-2'], ['12-26'], ['6-30'], ['13-11'], ['18-30'], ['19-10'], ['20-28'], ['22-22'], ['24-3'], ['24-30'], ['26-28'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_0_depth_7500_results.json\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['11-2'], ['12-26'], ['6-30'], ['13-11'], ['18-30'], ['19-10'], ['20-28'], ['22-22'], ['24-3'], ['24-30'], ['26-28'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['11-2'], ['21-30'], ['12-26'], ['6-30'], ['13-11'], ['24-3'], ['26-28'], ['18-30'], ['19-10'], ['20-28'], ['22-22'], ['24-30'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 95.01455426216125\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium in India. It has a capacity of 114,600.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_1250_depth_0_results.json\n",
      "insertion at 236\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['8-26'], ['19-15'], ['11-2'], ['21-30'], ['6-30'], ['12-26'], ['7-12'], ['13-11'], ['26-28'], ['24-3'], ['19-10'], ['18-30'], ['20-28'], ['22-22'], ['24-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 321\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['8-26'], ['11-2'], ['19-15'], ['7-12'], ['21-30'], ['6-30'], ['12-26'], ['13-11'], ['26-28'], ['24-3'], ['19-10'], ['22-22'], ['18-30'], ['20-28'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 321\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['17-22'], ['11-2'], ['7-12'], ['19-15'], ['21-30'], ['6-30'], ['13-11'], ['26-28'], ['12-26'], ['24-3'], ['19-10'], ['21-28'], ['22-22'], ['18-30'], ['20-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_1250_depth_7500_results.json\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['7-12'], ['21-30'], ['6-30'], ['12-26'], ['26-28'], ['13-11'], ['18-30'], ['19-10'], ['24-3'], ['22-22'], ['14-18'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['11-2'], ['19-15'], ['21-30'], ['6-30'], ['13-11'], ['26-28'], ['12-26'], ['18-30'], ['19-10'], ['24-3'], ['14-18'], ['21-28'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 92.34206080436707\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium in Ahmedabad, India. It has a capacity of 114,600 people.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_2500_depth_0_results.json\n",
      "insertion at 321\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-12'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['21-30'], ['6-30'], ['13-11'], ['26-28'], ['12-26'], ['21-28'], ['18-30'], ['22-22'], ['19-10'], ['24-3'], ['6-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1081\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['11-2'], ['19-15'], ['21-30'], ['6-30'], ['26-28'], ['13-11'], ['6-16'], ['12-26'], ['21-28'], ['14-18'], ['18-30'], ['22-22'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1081\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-12'], ['8-26'], ['17-22'], ['7-4'], ['11-2'], ['19-15'], ['21-30'], ['6-30'], ['26-28'], ['6-16'], ['13-11'], ['14-18'], ['21-28'], ['12-26'], ['18-30'], ['22-22'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_2500_depth_7500_results.json\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['11-2'], ['19-15'], ['21-30'], ['6-30'], ['26-28'], ['13-11'], ['6-16'], ['12-26'], ['18-30'], ['14-18'], ['21-28'], ['31-16'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['11-2'], ['7-4'], ['21-30'], ['19-15'], ['6-30'], ['26-28'], ['6-16'], ['13-11'], ['12-26'], ['14-18'], ['21-28'], ['18-30'], ['31-16'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 92.6363468170166\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium in Ahmedabad, India. It has a capacity of 114,600 seats.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_3750_depth_0_results.json\n",
      "insertion at 321\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-12'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['21-30'], ['19-15'], ['6-30'], ['6-16'], ['26-28'], ['13-11'], ['14-18'], ['21-28'], ['12-26'], ['18-30'], ['31-16'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1081\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-12'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['21-30'], ['19-15'], ['6-16'], ['6-30'], ['26-28'], ['13-11'], ['14-18'], ['21-28'], ['18-30'], ['12-26'], ['31-16'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 1081\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-12'], ['8-26'], ['11-2'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['6-16'], ['6-30'], ['26-28'], ['13-11'], ['14-18'], ['21-28'], ['18-30'], ['12-26'], ['22-22'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_3750_depth_7500_results.json\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['11-2'], ['7-4'], ['21-30'], ['19-15'], ['6-16'], ['6-30'], ['26-28'], ['13-11'], ['14-18'], ['21-28'], ['18-30'], ['12-26'], ['22-22'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-12'], ['8-26'], ['11-2'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['6-16'], ['6-30'], ['26-28'], ['13-11'], ['14-18'], ['21-28'], ['18-30'], ['12-26'], ['22-22'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 95.70990800857544\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium, which has a capacity of 114,600.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1081\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-12'], ['8-26'], ['11-2'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['6-16'], ['6-30'], ['26-28'], ['14-18'], ['13-11'], ['21-28'], ['18-30'], ['12-26'], ['31-16'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 1081\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-12'], ['8-26'], ['11-2'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['6-16'], ['6-30'], ['26-28'], ['14-18'], ['13-11'], ['21-28'], ['18-30'], ['12-26'], ['31-16'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3323\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-12'], ['8-26'], ['11-2'], ['17-22'], ['7-4'], ['21-30'], ['6-16'], ['19-15'], ['6-30'], ['26-28'], ['14-18'], ['13-11'], ['21-28'], ['18-30'], ['31-16'], ['12-26'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_5000_depth_7500_results.json\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-12'], ['8-26'], ['11-2'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['6-16'], ['6-30'], ['26-28'], ['14-18'], ['13-11'], ['18-30'], ['21-28'], ['12-26'], ['31-16'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant/llama-2-7b-80k_id_185_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/185.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['11-2'], ['12-26'], ['6-30'], ['13-11'], ['18-30'], ['19-10'], ['20-28'], ['22-22'], ['24-3'], ['24-30'], ['26-28'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['11-2'], ['12-26'], ['6-30'], ['13-11'], ['18-30'], ['19-10'], ['20-28'], ['22-22'], ['24-3'], ['24-30'], ['26-28'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['11-2'], ['12-26'], ['6-30'], ['13-11'], ['18-30'], ['19-10'], ['20-28'], ['22-22'], ['24-3'], ['24-30'], ['26-28'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['11-2'], ['12-26'], ['6-30'], ['13-11'], ['18-30'], ['19-10'], ['20-28'], ['22-22'], ['24-3'], ['24-30'], ['26-28'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_0_depth_7500_results.json\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['11-2'], ['12-26'], ['6-30'], ['13-11'], ['18-30'], ['19-10'], ['20-28'], ['22-22'], ['24-3'], ['24-30'], ['26-28'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['11-2'], ['12-26'], ['6-30'], ['13-11'], ['18-30'], ['19-10'], ['20-28'], ['22-22'], ['24-3'], ['24-30'], ['26-28'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 93.06366443634033\n",
      "Response: The largest stadium in the world is the Narendra Modi Stadium in India. It has a capacity of 114,600 people.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 236\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['8-26'], ['19-15'], ['11-2'], ['21-30'], ['12-26'], ['6-30'], ['26-28'], ['13-11'], ['19-10'], ['22-22'], ['24-3'], ['18-30'], ['20-28'], ['24-30'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 374\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['8-26'], ['19-15'], ['11-2'], ['21-30'], ['7-12'], ['12-26'], ['6-30'], ['26-28'], ['13-11'], ['22-22'], ['24-3'], ['19-10'], ['21-28'], ['24-30'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 374\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['8-26'], ['11-2'], ['19-15'], ['21-30'], ['7-12'], ['6-30'], ['12-26'], ['26-28'], ['21-28'], ['13-11'], ['22-22'], ['24-3'], ['24-30'], ['14-18'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['8-26'], ['19-15'], ['11-2'], ['21-30'], ['7-12'], ['6-30'], ['12-26'], ['26-28'], ['18-30'], ['24-30'], ['22-22'], ['21-28'], ['13-11'], ['24-3'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['8-26'], ['11-2'], ['19-15'], ['7-12'], ['21-30'], ['6-30'], ['26-28'], ['12-26'], ['18-30'], ['21-28'], ['24-30'], ['13-11'], ['22-22'], ['14-18'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 95.70990800857544\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium, which has a capacity of 114,600.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 374\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['7-4'], ['8-26'], ['11-2'], ['19-15'], ['7-12'], ['21-30'], ['6-30'], ['26-28'], ['12-26'], ['21-28'], ['14-18'], ['13-11'], ['22-22'], ['18-30'], ['24-30'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1134\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['8-26'], ['11-2'], ['7-4'], ['7-12'], ['19-15'], ['21-30'], ['6-30'], ['26-28'], ['14-18'], ['12-26'], ['21-28'], ['18-30'], ['13-11'], ['22-22'], ['24-30'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 91.24513864517212\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium. Sports analysts sometimes consider the FNB Stadium as a major contender.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1150\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['11-2'], ['7-4'], ['7-12'], ['19-15'], ['21-30'], ['6-30'], ['26-28'], ['6-16'], ['14-18'], ['18-30'], ['21-28'], ['12-26'], ['31-16'], ['13-11'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['11-2'], ['7-4'], ['19-15'], ['7-12'], ['21-30'], ['6-30'], ['26-28'], ['14-18'], ['18-30'], ['6-16'], ['12-26'], ['31-16'], ['21-28'], ['22-22'], ['24-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['11-2'], ['7-12'], ['7-4'], ['19-15'], ['21-30'], ['6-30'], ['6-16'], ['26-28'], ['14-18'], ['18-30'], ['21-28'], ['12-26'], ['31-16'], ['22-22'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 92.6363468170166\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium in Ahmedabad, India. It has a capacity of 114,600 seats.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 374\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['11-2'], ['7-12'], ['7-4'], ['19-15'], ['21-30'], ['6-16'], ['6-30'], ['26-28'], ['14-18'], ['21-28'], ['18-30'], ['31-16'], ['12-26'], ['22-22'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1150\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-12'], ['11-2'], ['17-22'], ['7-4'], ['19-15'], ['21-30'], ['6-16'], ['6-30'], ['26-28'], ['21-28'], ['14-18'], ['18-30'], ['31-16'], ['12-26'], ['22-22'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 1150\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-12'], ['11-2'], ['17-22'], ['7-4'], ['19-15'], ['21-30'], ['6-16'], ['6-30'], ['21-28'], ['26-28'], ['18-30'], ['14-18'], ['31-16'], ['22-22'], ['12-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['11-2'], ['7-12'], ['17-22'], ['7-4'], ['19-15'], ['21-30'], ['6-16'], ['6-30'], ['18-30'], ['26-28'], ['21-28'], ['14-18'], ['31-16'], ['12-26'], ['22-22'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-12'], ['11-2'], ['17-22'], ['7-4'], ['19-15'], ['21-30'], ['6-16'], ['6-30'], ['18-30'], ['26-28'], ['21-28'], ['14-18'], ['31-16'], ['12-26'], ['22-22'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 92.6363468170166\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium in Ahmedabad, India. It has a capacity of 114,600 seats.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1150\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-12'], ['8-26'], ['11-2'], ['17-22'], ['7-4'], ['19-15'], ['21-30'], ['6-16'], ['6-30'], ['26-28'], ['18-30'], ['21-28'], ['31-16'], ['14-18'], ['12-26'], ['22-22'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 1150\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-12'], ['8-26'], ['11-2'], ['17-22'], ['7-4'], ['19-15'], ['21-30'], ['6-16'], ['6-30'], ['26-28'], ['18-30'], ['31-16'], ['21-28'], ['14-18'], ['12-26'], ['22-22'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3410\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-12'], ['8-26'], ['11-2'], ['17-22'], ['7-4'], ['19-15'], ['6-16'], ['21-30'], ['6-30'], ['26-28'], ['18-30'], ['31-16'], ['21-28'], ['14-18'], ['12-26'], ['24-3'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-12'], ['11-2'], ['17-22'], ['7-4'], ['19-15'], ['21-30'], ['6-16'], ['6-30'], ['18-30'], ['26-28'], ['31-16'], ['21-28'], ['14-18'], ['12-26'], ['22-22'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_relevant_misleading/llama-2-7b-80k_id_185_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['11-2'], ['12-26'], ['6-30'], ['13-11'], ['18-30'], ['19-10'], ['20-28'], ['22-22'], ['24-3'], ['24-30'], ['26-28'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['11-2'], ['12-26'], ['6-30'], ['13-11'], ['18-30'], ['19-10'], ['20-28'], ['22-22'], ['24-3'], ['24-30'], ['26-28'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['11-2'], ['12-26'], ['6-30'], ['13-11'], ['18-30'], ['19-10'], ['20-28'], ['22-22'], ['24-3'], ['24-30'], ['26-28'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['11-2'], ['12-26'], ['6-30'], ['13-11'], ['18-30'], ['19-10'], ['20-28'], ['22-22'], ['24-3'], ['24-30'], ['26-28'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_0_depth_7500_results.json\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['11-2'], ['12-26'], ['6-30'], ['13-11'], ['18-30'], ['19-10'], ['20-28'], ['22-22'], ['24-3'], ['24-30'], ['26-28'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['8-26'], ['19-15'], ['11-2'], ['21-30'], ['12-26'], ['6-30'], ['13-11'], ['19-10'], ['26-28'], ['22-22'], ['24-3'], ['18-30'], ['20-28'], ['24-30'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 95.38552761077881\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium, which has a capacity of 114,000.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 126\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['8-26'], ['19-15'], ['11-2'], ['21-30'], ['7-12'], ['6-30'], ['12-26'], ['13-11'], ['26-28'], ['19-10'], ['22-22'], ['24-3'], ['14-18'], ['18-30'], ['20-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 472\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['8-26'], ['19-15'], ['11-2'], ['7-12'], ['21-30'], ['6-30'], ['26-28'], ['13-11'], ['12-26'], ['19-10'], ['14-18'], ['18-30'], ['22-22'], ['24-3'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 760\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['8-26'], ['11-2'], ['19-15'], ['7-12'], ['21-30'], ['6-30'], ['26-28'], ['13-11'], ['14-18'], ['12-26'], ['19-10'], ['18-30'], ['22-22'], ['24-3'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_1250_depth_7500_results.json\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['8-26'], ['11-2'], ['19-15'], ['21-30'], ['7-12'], ['6-30'], ['26-28'], ['13-11'], ['18-30'], ['12-26'], ['19-10'], ['14-18'], ['31-16'], ['22-22'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "-- Test Summary -- \n",
      "Duration: 3.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 40.408337116241455\n",
      "Response: Wembley Stadium, London, England, England national football team, Association football, Rugby league, Rugby union, Gaelic Football & Hurling, American football, Boxing, Professional wrestling\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 555\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['7-4'], ['8-26'], ['11-2'], ['7-12'], ['19-15'], ['21-30'], ['6-30'], ['26-28'], ['13-11'], ['14-18'], ['18-30'], ['19-10'], ['12-26'], ['22-22'], ['31-16'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1111\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['8-26'], ['7-4'], ['7-12'], ['11-2'], ['19-15'], ['21-30'], ['6-30'], ['26-28'], ['13-11'], ['14-18'], ['18-30'], ['19-10'], ['31-16'], ['6-16'], ['21-28'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1693\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['8-26'], ['7-4'], ['7-12'], ['11-2'], ['19-15'], ['21-30'], ['6-30'], ['26-28'], ['6-16'], ['14-18'], ['13-11'], ['18-30'], ['19-10'], ['21-28'], ['31-16'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_2500_depth_7500_results.json\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['8-26'], ['7-4'], ['7-12'], ['11-2'], ['21-30'], ['19-15'], ['6-30'], ['26-28'], ['14-18'], ['18-30'], ['6-16'], ['13-11'], ['31-16'], ['19-10'], ['21-28'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['11-2'], ['21-30'], ['19-15'], ['6-30'], ['26-28'], ['6-16'], ['14-18'], ['19-10'], ['13-11'], ['18-30'], ['21-28'], ['31-16'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 95.38552761077881\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium, which has a capacity of 114,000.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 869\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['11-2'], ['21-30'], ['19-15'], ['6-30'], ['26-28'], ['6-16'], ['14-18'], ['13-11'], ['19-10'], ['21-28'], ['18-30'], ['31-16'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1759\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['11-2'], ['21-30'], ['19-15'], ['6-30'], ['6-16'], ['26-28'], ['14-18'], ['21-28'], ['13-11'], ['19-10'], ['18-30'], ['22-22'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2624\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['11-2'], ['21-30'], ['19-15'], ['6-16'], ['6-30'], ['26-28'], ['14-18'], ['21-28'], ['13-11'], ['19-10'], ['18-30'], ['22-22'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_3750_depth_7500_results.json\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['11-2'], ['21-30'], ['19-15'], ['6-30'], ['6-16'], ['26-28'], ['14-18'], ['19-10'], ['21-28'], ['13-11'], ['18-30'], ['22-22'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['11-2'], ['21-30'], ['19-15'], ['6-16'], ['6-30'], ['26-28'], ['14-18'], ['19-10'], ['21-28'], ['13-11'], ['18-30'], ['22-22'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 94.62025165557861\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium, which has a capacity of 132,000.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1186\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['11-2'], ['21-30'], ['19-15'], ['6-16'], ['6-30'], ['26-28'], ['14-18'], ['21-28'], ['19-10'], ['13-11'], ['18-30'], ['22-22'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2372\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['11-2'], ['21-30'], ['19-15'], ['6-16'], ['6-30'], ['26-28'], ['14-18'], ['21-28'], ['19-10'], ['18-30'], ['13-11'], ['22-22'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3507\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['11-2'], ['21-30'], ['6-16'], ['19-15'], ['6-30'], ['26-28'], ['14-18'], ['21-28'], ['18-30'], ['19-10'], ['13-11'], ['22-22'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_5000_depth_7500_results.json\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['7-12'], ['7-4'], ['11-2'], ['21-30'], ['19-15'], ['6-16'], ['6-30'], ['26-28'], ['14-18'], ['18-30'], ['21-28'], ['19-10'], ['13-11'], ['22-22'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant/llama-2-7b-80k_id_185_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/185.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['11-2'], ['12-26'], ['6-30'], ['13-11'], ['18-30'], ['19-10'], ['20-28'], ['22-22'], ['24-3'], ['24-30'], ['26-28'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['11-2'], ['12-26'], ['6-30'], ['13-11'], ['18-30'], ['19-10'], ['20-28'], ['22-22'], ['24-3'], ['24-30'], ['26-28'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['11-2'], ['12-26'], ['6-30'], ['13-11'], ['18-30'], ['19-10'], ['20-28'], ['22-22'], ['24-3'], ['24-30'], ['26-28'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['11-2'], ['12-26'], ['6-30'], ['13-11'], ['18-30'], ['19-10'], ['20-28'], ['22-22'], ['24-3'], ['24-30'], ['26-28'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['11-2'], ['12-26'], ['6-30'], ['13-11'], ['18-30'], ['19-10'], ['20-28'], ['22-22'], ['24-3'], ['24-30'], ['26-28'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['8-26'], ['19-15'], ['11-2'], ['21-30'], ['12-26'], ['6-30'], ['13-11'], ['19-10'], ['22-22'], ['24-3'], ['26-28'], ['18-30'], ['20-28'], ['24-30'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 92.60698556900024\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium in Ahmedabad, India. It has a capacity of 114,000 people.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 126\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['8-26'], ['19-15'], ['11-2'], ['21-30'], ['7-12'], ['6-30'], ['12-26'], ['13-11'], ['19-10'], ['26-28'], ['22-22'], ['24-3'], ['18-30'], ['14-18'], ['20-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 472\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['8-26'], ['11-2'], ['19-15'], ['7-12'], ['21-30'], ['6-30'], ['13-11'], ['26-28'], ['12-26'], ['19-10'], ['22-22'], ['24-3'], ['18-30'], ['31-16'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 760\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['8-26'], ['11-2'], ['7-12'], ['19-15'], ['21-30'], ['6-30'], ['26-28'], ['13-11'], ['12-26'], ['19-10'], ['22-22'], ['24-3'], ['31-16'], ['21-28'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['8-26'], ['11-2'], ['19-15'], ['21-30'], ['7-12'], ['6-30'], ['26-28'], ['13-11'], ['19-10'], ['12-26'], ['18-30'], ['22-22'], ['31-16'], ['24-3'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['17-22'], ['8-26'], ['11-2'], ['7-12'], ['19-15'], ['21-30'], ['6-30'], ['26-28'], ['13-11'], ['19-10'], ['22-22'], ['12-26'], ['18-30'], ['31-16'], ['24-3'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 91.33957028388977\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium, which is located in Ahmedabad, India. The stadium has a capacity of 110,000 people and is used for cricket and\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 555\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['11-2'], ['19-15'], ['21-30'], ['26-28'], ['6-30'], ['13-11'], ['19-10'], ['22-22'], ['12-26'], ['21-28'], ['18-30'], ['24-3'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1128\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['11-2'], ['19-15'], ['21-30'], ['26-28'], ['6-30'], ['6-16'], ['19-10'], ['13-11'], ['22-22'], ['14-18'], ['21-28'], ['18-30'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1662\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['11-2'], ['19-15'], ['21-30'], ['26-28'], ['6-16'], ['6-30'], ['19-10'], ['22-22'], ['14-18'], ['21-28'], ['13-11'], ['24-3'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['11-2'], ['19-15'], ['21-30'], ['26-28'], ['6-30'], ['6-16'], ['19-10'], ['22-22'], ['14-18'], ['21-28'], ['13-11'], ['18-30'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['21-30'], ['26-28'], ['6-16'], ['6-30'], ['19-10'], ['22-22'], ['14-18'], ['21-28'], ['13-11'], ['18-30'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 92.37964749336243\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium, which is located in Ahmedabad, India.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 869\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-12'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['21-30'], ['26-28'], ['6-16'], ['6-30'], ['19-10'], ['22-22'], ['14-18'], ['21-28'], ['13-11'], ['18-30'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1761\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-12'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['21-30'], ['6-16'], ['26-28'], ['6-30'], ['21-28'], ['19-10'], ['22-22'], ['14-18'], ['13-11'], ['18-30'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2640\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-12'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['21-30'], ['6-16'], ['26-28'], ['6-30'], ['22-22'], ['19-10'], ['21-28'], ['14-18'], ['13-11'], ['18-30'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['21-30'], ['6-16'], ['26-28'], ['6-30'], ['22-22'], ['19-10'], ['21-28'], ['14-18'], ['18-30'], ['13-11'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-12'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['21-30'], ['6-16'], ['26-28'], ['6-30'], ['21-28'], ['19-10'], ['22-22'], ['14-18'], ['13-11'], ['18-30'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 97.83898591995239\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium in India.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1167\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-12'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['21-30'], ['6-16'], ['26-28'], ['6-30'], ['21-28'], ['19-10'], ['22-22'], ['14-18'], ['13-11'], ['18-30'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2352\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-12'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['21-30'], ['6-16'], ['26-28'], ['6-30'], ['21-28'], ['22-22'], ['19-10'], ['14-18'], ['13-11'], ['18-30'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3576\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-12'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['21-30'], ['6-16'], ['26-28'], ['6-30'], ['21-28'], ['19-10'], ['22-22'], ['14-18'], ['13-11'], ['31-16'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-12'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['21-30'], ['6-16'], ['26-28'], ['6-30'], ['21-28'], ['19-10'], ['22-22'], ['14-18'], ['18-30'], ['13-11'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The largest stadium by capacity in the world is the Narendra Modi Stadium.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_185_irrelevant_misleading/llama-2-7b-80k_id_185_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['29-26'], ['6-9'], ['6-30'], ['7-4'], ['29-21'], ['31-16'], ['31-24'], ['12-26'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['21-28'], ['21-30'], ['24-8'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['29-26'], ['6-9'], ['6-30'], ['7-4'], ['29-21'], ['31-16'], ['31-24'], ['12-26'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['21-28'], ['21-30'], ['24-8'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['29-26'], ['6-9'], ['6-30'], ['7-4'], ['29-21'], ['31-16'], ['31-24'], ['12-26'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['21-28'], ['21-30'], ['24-8'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['29-26'], ['6-9'], ['6-30'], ['7-4'], ['29-21'], ['31-16'], ['31-24'], ['12-26'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['21-28'], ['21-30'], ['24-8'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_0_depth_7500_results.json\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['29-26'], ['6-9'], ['6-30'], ['7-4'], ['29-21'], ['31-16'], ['31-24'], ['12-26'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['21-28'], ['21-30'], ['24-8'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['29-26'], ['6-9'], ['7-4'], ['29-21'], ['31-16'], ['6-30'], ['31-24'], ['17-22'], ['14-18'], ['24-29'], ['21-28'], ['21-30'], ['24-8'], ['12-26'], ['15-14'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_1250_depth_0_results.json\n",
      "insertion at 27\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-9'], ['29-26'], ['7-4'], ['17-22'], ['7-12'], ['29-21'], ['31-16'], ['14-18'], ['6-30'], ['24-29'], ['31-24'], ['18-30'], ['21-28'], ['21-30'], ['24-8'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 27\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['7-12'], ['6-9'], ['17-22'], ['7-4'], ['29-26'], ['14-18'], ['29-21'], ['31-16'], ['24-29'], ['6-30'], ['18-30'], ['21-28'], ['21-30'], ['31-24'], ['24-8'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 27\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-12'], ['19-15'], ['17-22'], ['6-9'], ['14-18'], ['7-4'], ['29-21'], ['29-26'], ['24-29'], ['31-16'], ['18-30'], ['21-28'], ['21-30'], ['6-30'], ['11-2'], ['31-24'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_1250_depth_7500_results.json\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['7-12'], ['6-9'], ['17-22'], ['7-4'], ['14-18'], ['24-29'], ['29-21'], ['29-26'], ['31-16'], ['18-30'], ['6-30'], ['21-28'], ['21-30'], ['11-2'], ['12-26'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 58.48737359046936\n",
      "Response: The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 15.01297801733017\n",
      "Response: The Wind Rises\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_2500_depth_0_results.json\n",
      "insertion at 27\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 15.01297801733017\n",
      "Response: The Wind Rises\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 27\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 15.01297801733017\n",
      "Response: The Wind Rises\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 27\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 15.01297801733017\n",
      "Response: The Wind Rises\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_2500_depth_7500_results.json\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-9'], ['7-12'], ['17-22'], ['7-4'], ['24-29'], ['29-21'], ['29-26'], ['14-18'], ['31-16'], ['18-30'], ['6-30'], ['21-28'], ['21-30'], ['12-26'], ['24-8'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 58.48737359046936\n",
      "Response: The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 15.01297801733017\n",
      "Response: The Wind Rises\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_3750_depth_0_results.json\n",
      "insertion at 27\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 15.01297801733017\n",
      "Response: The Wind Rises\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 27\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 15.01297801733017\n",
      "Response: The Wind Rises\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2468\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['7-12'], ['6-9'], ['17-22'], ['7-4'], ['24-29'], ['29-26'], ['29-21'], ['14-18'], ['18-30'], ['31-16'], ['6-30'], ['21-28'], ['21-30'], ['12-26'], ['24-8'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_3750_depth_7500_results.json\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-9'], ['7-12'], ['17-22'], ['24-29'], ['7-4'], ['29-26'], ['29-21'], ['14-18'], ['18-30'], ['31-16'], ['6-30'], ['21-28'], ['21-30'], ['12-26'], ['24-8'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 58.48737359046936\n",
      "Response: The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 15.01297801733017\n",
      "Response: The Wind Rises\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_5000_depth_0_results.json\n",
      "insertion at 27\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 15.01297801733017\n",
      "Response: The Wind Rises\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2109\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['7-12'], ['6-9'], ['17-22'], ['24-29'], ['7-4'], ['29-26'], ['29-21'], ['14-18'], ['18-30'], ['31-16'], ['21-28'], ['6-30'], ['21-30'], ['24-8'], ['12-26'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3282\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['7-12'], ['6-9'], ['17-22'], ['24-29'], ['7-4'], ['29-26'], ['14-18'], ['18-30'], ['29-21'], ['31-16'], ['21-28'], ['24-8'], ['21-30'], ['6-30'], ['11-2'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_5000_depth_7500_results.json\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-9'], ['7-12'], ['17-22'], ['7-4'], ['24-29'], ['18-30'], ['29-26'], ['14-18'], ['29-21'], ['31-16'], ['24-8'], ['21-30'], ['21-28'], ['12-26'], ['11-2'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant/llama-2-7b-80k_id_189_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/189.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['29-26'], ['6-9'], ['6-30'], ['7-4'], ['29-21'], ['31-16'], ['31-24'], ['12-26'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['21-28'], ['21-30'], ['24-8'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['29-26'], ['6-9'], ['6-30'], ['7-4'], ['29-21'], ['31-16'], ['31-24'], ['12-26'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['21-28'], ['21-30'], ['24-8'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['29-26'], ['6-9'], ['6-30'], ['7-4'], ['29-21'], ['31-16'], ['31-24'], ['12-26'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['21-28'], ['21-30'], ['24-8'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['29-26'], ['6-9'], ['6-30'], ['7-4'], ['29-21'], ['31-16'], ['31-24'], ['12-26'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['21-28'], ['21-30'], ['24-8'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_0_depth_7500_results.json\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['29-26'], ['6-9'], ['6-30'], ['7-4'], ['29-21'], ['31-16'], ['31-24'], ['12-26'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['21-28'], ['21-30'], ['24-8'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['29-26'], ['6-9'], ['7-4'], ['29-21'], ['31-16'], ['6-30'], ['31-24'], ['17-22'], ['14-18'], ['24-29'], ['21-28'], ['21-30'], ['24-8'], ['12-26'], ['15-14'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 27\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-9'], ['29-26'], ['7-4'], ['17-22'], ['7-12'], ['29-21'], ['31-16'], ['14-18'], ['6-30'], ['24-29'], ['31-24'], ['18-30'], ['21-28'], ['21-30'], ['24-8'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 27\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['7-12'], ['6-9'], ['17-22'], ['7-4'], ['29-26'], ['14-18'], ['29-21'], ['31-16'], ['24-29'], ['6-30'], ['18-30'], ['21-28'], ['21-30'], ['31-24'], ['24-8'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 27\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-12'], ['19-15'], ['17-22'], ['6-9'], ['14-18'], ['7-4'], ['29-21'], ['29-26'], ['24-29'], ['31-16'], ['18-30'], ['21-28'], ['21-30'], ['6-30'], ['11-2'], ['31-24'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['7-12'], ['6-9'], ['17-22'], ['7-4'], ['14-18'], ['24-29'], ['29-21'], ['29-26'], ['31-16'], ['18-30'], ['6-30'], ['21-28'], ['21-30'], ['11-2'], ['12-26'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 58.48737359046936\n",
      "Response: The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 15.01297801733017\n",
      "Response: The Wind Rises\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 27\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 15.01297801733017\n",
      "Response: The Wind Rises\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 27\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 15.01297801733017\n",
      "Response: The Wind Rises\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 27\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 15.01297801733017\n",
      "Response: The Wind Rises\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-9'], ['7-12'], ['17-22'], ['7-4'], ['24-29'], ['29-21'], ['29-26'], ['14-18'], ['31-16'], ['18-30'], ['6-30'], ['21-28'], ['21-30'], ['12-26'], ['24-8'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 58.48737359046936\n",
      "Response: The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['7-12'], ['6-9'], ['17-22'], ['7-4'], ['24-29'], ['14-18'], ['29-26'], ['29-21'], ['31-16'], ['18-30'], ['6-30'], ['21-30'], ['21-28'], ['12-26'], ['24-8'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 27\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['7-12'], ['17-22'], ['6-9'], ['14-18'], ['24-29'], ['7-4'], ['29-26'], ['29-21'], ['31-16'], ['18-30'], ['6-30'], ['21-30'], ['21-28'], ['12-26'], ['24-8'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 27\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-12'], ['19-15'], ['17-22'], ['6-9'], ['14-18'], ['24-29'], ['29-26'], ['7-4'], ['29-21'], ['31-16'], ['18-30'], ['6-30'], ['21-30'], ['21-28'], ['12-26'], ['24-8'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2468\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-12'], ['19-15'], ['17-22'], ['6-9'], ['24-29'], ['14-18'], ['29-26'], ['29-21'], ['7-4'], ['18-30'], ['31-16'], ['21-28'], ['21-30'], ['6-30'], ['24-8'], ['12-26'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['7-12'], ['6-9'], ['17-22'], ['24-29'], ['29-26'], ['14-18'], ['7-4'], ['29-21'], ['18-30'], ['31-16'], ['6-30'], ['21-28'], ['21-30'], ['24-8'], ['12-26'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 58.48737359046936\n",
      "Response: The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['7-12'], ['6-9'], ['17-22'], ['24-29'], ['29-26'], ['14-18'], ['7-4'], ['29-21'], ['31-16'], ['18-30'], ['6-30'], ['21-28'], ['21-30'], ['24-8'], ['12-26'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 27\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['7-12'], ['17-22'], ['6-9'], ['24-29'], ['29-26'], ['14-18'], ['7-4'], ['29-21'], ['18-30'], ['31-16'], ['6-30'], ['21-28'], ['21-30'], ['24-8'], ['12-26'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2109\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['7-12'], ['6-9'], ['17-22'], ['24-29'], ['29-26'], ['14-18'], ['29-21'], ['7-4'], ['18-30'], ['31-16'], ['21-28'], ['21-30'], ['24-8'], ['6-30'], ['12-26'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 58.48737359046936\n",
      "Response: The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3343\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['7-12'], ['6-9'], ['17-22'], ['29-26'], ['24-29'], ['14-18'], ['29-21'], ['7-4'], ['18-30'], ['31-16'], ['21-28'], ['24-8'], ['21-30'], ['12-26'], ['6-30'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 50.84053874015808\n",
      "Response: The Boy and the Heron.com,YoshiyukiÂ Momose,\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-9'], ['7-12'], ['17-22'], ['29-26'], ['24-29'], ['14-18'], ['7-4'], ['18-30'], ['29-21'], ['31-16'], ['12-26'], ['21-30'], ['24-8'], ['21-28'], ['15-14'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_relevant_misleading/llama-2-7b-80k_id_189_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['29-26'], ['6-9'], ['6-30'], ['7-4'], ['29-21'], ['31-16'], ['31-24'], ['12-26'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['21-28'], ['21-30'], ['24-8'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['29-26'], ['6-9'], ['6-30'], ['7-4'], ['29-21'], ['31-16'], ['31-24'], ['12-26'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['21-28'], ['21-30'], ['24-8'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['29-26'], ['6-9'], ['6-30'], ['7-4'], ['29-21'], ['31-16'], ['31-24'], ['12-26'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['21-28'], ['21-30'], ['24-8'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['29-26'], ['6-9'], ['6-30'], ['7-4'], ['29-21'], ['31-16'], ['31-24'], ['12-26'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['21-28'], ['21-30'], ['24-8'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_0_depth_7500_results.json\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['29-26'], ['6-9'], ['6-30'], ['7-4'], ['29-21'], ['31-16'], ['31-24'], ['12-26'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['21-28'], ['21-30'], ['24-8'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['29-26'], ['6-9'], ['7-4'], ['29-21'], ['6-30'], ['31-16'], ['31-24'], ['17-22'], ['21-30'], ['7-12'], ['14-18'], ['24-8'], ['24-29'], ['12-26'], ['15-14'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 255\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-9'], ['7-4'], ['29-26'], ['29-21'], ['6-30'], ['31-16'], ['7-12'], ['31-24'], ['14-18'], ['17-22'], ['21-30'], ['24-8'], ['12-26'], ['18-30'], ['21-28'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 255\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-9'], ['7-4'], ['29-26'], ['7-12'], ['29-21'], ['6-30'], ['31-16'], ['14-18'], ['24-8'], ['31-24'], ['12-26'], ['17-22'], ['18-30'], ['21-28'], ['21-30'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 765\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-4'], ['19-15'], ['6-9'], ['7-12'], ['29-26'], ['29-21'], ['14-18'], ['17-22'], ['21-30'], ['31-16'], ['6-30'], ['18-30'], ['24-29'], ['12-26'], ['21-28'], ['24-8'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_1250_depth_7500_results.json\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['7-4'], ['6-9'], ['29-26'], ['7-12'], ['29-21'], ['17-22'], ['24-29'], ['14-18'], ['31-16'], ['6-30'], ['21-30'], ['12-26'], ['18-30'], ['21-28'], ['24-8'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 58.48737359046936\n",
      "Response: The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-9'], ['7-4'], ['7-12'], ['29-26'], ['29-21'], ['17-22'], ['24-29'], ['14-18'], ['21-30'], ['31-16'], ['6-30'], ['12-26'], ['18-30'], ['21-28'], ['24-8'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 255\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['7-4'], ['7-12'], ['29-26'], ['29-21'], ['24-29'], ['14-18'], ['17-22'], ['21-30'], ['31-16'], ['12-26'], ['18-30'], ['6-30'], ['21-28'], ['24-8'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 58.48737359046936\n",
      "Response: The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1046\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-12'], ['6-9'], ['19-15'], ['7-4'], ['29-26'], ['17-22'], ['14-18'], ['29-21'], ['24-29'], ['18-30'], ['21-30'], ['12-26'], ['31-16'], ['21-28'], ['24-8'], ['6-30'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1687\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-12'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['14-18'], ['29-26'], ['24-29'], ['29-21'], ['18-30'], ['21-30'], ['12-26'], ['21-28'], ['31-16'], ['24-8'], ['6-30'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_2500_depth_7500_results.json\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-12'], ['7-4'], ['19-15'], ['17-22'], ['29-26'], ['14-18'], ['24-29'], ['29-21'], ['18-30'], ['21-30'], ['12-26'], ['31-16'], ['21-28'], ['24-8'], ['6-30'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 58.48737359046936\n",
      "Response: The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 15.01297801733017\n",
      "Response: The Wind Rises\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 832\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-12'], ['7-4'], ['19-15'], ['17-22'], ['14-18'], ['29-26'], ['24-29'], ['29-21'], ['18-30'], ['12-26'], ['21-30'], ['21-28'], ['24-8'], ['31-16'], ['6-30'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1749\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-12'], ['7-4'], ['19-15'], ['17-22'], ['29-26'], ['14-18'], ['24-29'], ['29-21'], ['18-30'], ['12-26'], ['21-30'], ['21-28'], ['24-8'], ['31-16'], ['6-30'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2543\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-12'], ['7-4'], ['19-15'], ['17-22'], ['29-26'], ['14-18'], ['24-29'], ['29-21'], ['18-30'], ['12-26'], ['21-28'], ['21-30'], ['24-8'], ['31-16'], ['6-30'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_3750_depth_7500_results.json\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['7-12'], ['19-15'], ['17-22'], ['24-29'], ['29-26'], ['14-18'], ['29-21'], ['18-30'], ['12-26'], ['21-28'], ['21-30'], ['31-16'], ['24-8'], ['6-30'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 58.48737359046936\n",
      "Response: The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 29.74492311477661\n",
      "Response: The Wind Rises (2013)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1162\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 40.819790959358215\n",
      "Response: The Boy and the Heron. 2 (2017), Spider-Man: Homecoming (2017), Thor: Ragnarok (2017), Black Panther (2018), Avengers\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2342\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-12'], ['7-4'], ['19-15'], ['17-22'], ['24-29'], ['29-26'], ['14-18'], ['29-21'], ['18-30'], ['12-26'], ['21-28'], ['21-30'], ['24-8'], ['31-16'], ['6-30'], ['18-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 58.48737359046936\n",
      "Response: The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3328\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-12'], ['7-4'], ['19-15'], ['17-22'], ['29-26'], ['24-29'], ['14-18'], ['29-21'], ['18-30'], ['12-26'], ['21-28'], ['24-8'], ['31-16'], ['21-30'], ['6-30'], ['18-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 58.48737359046936\n",
      "Response: The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_5000_depth_7500_results.json\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['7-12'], ['19-15'], ['17-22'], ['29-26'], ['24-29'], ['14-18'], ['29-21'], ['18-30'], ['12-26'], ['21-28'], ['31-16'], ['24-8'], ['21-30'], ['6-30'], ['18-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 58.48737359046936\n",
      "Response: The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant/llama-2-7b-80k_id_189_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/189.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['29-26'], ['6-9'], ['6-30'], ['7-4'], ['29-21'], ['31-16'], ['31-24'], ['12-26'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['21-28'], ['21-30'], ['24-8'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['29-26'], ['6-9'], ['6-30'], ['7-4'], ['29-21'], ['31-16'], ['31-24'], ['12-26'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['21-28'], ['21-30'], ['24-8'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['29-26'], ['6-9'], ['6-30'], ['7-4'], ['29-21'], ['31-16'], ['31-24'], ['12-26'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['21-28'], ['21-30'], ['24-8'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['29-26'], ['6-9'], ['6-30'], ['7-4'], ['29-21'], ['31-16'], ['31-24'], ['12-26'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['21-28'], ['21-30'], ['24-8'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['29-26'], ['6-9'], ['6-30'], ['7-4'], ['29-21'], ['31-16'], ['31-24'], ['12-26'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['21-28'], ['21-30'], ['24-8'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['29-26'], ['6-9'], ['6-30'], ['7-4'], ['29-21'], ['31-16'], ['31-24'], ['21-28'], ['18-30'], ['21-30'], ['24-8'], ['24-29'], ['12-26'], ['14-18'], ['15-14'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 255\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['29-26'], ['19-15'], ['6-9'], ['29-21'], ['31-16'], ['6-30'], ['7-4'], ['31-24'], ['21-28'], ['18-30'], ['24-29'], ['12-26'], ['14-18'], ['21-30'], ['24-8'], ['17-22'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 255\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['29-26'], ['6-9'], ['19-15'], ['29-21'], ['31-16'], ['21-28'], ['6-30'], ['7-4'], ['18-30'], ['24-29'], ['31-24'], ['12-26'], ['14-18'], ['21-30'], ['24-8'], ['7-12'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 765\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['29-26'], ['6-9'], ['19-15'], ['29-21'], ['21-28'], ['24-29'], ['31-16'], ['7-4'], ['18-30'], ['12-26'], ['14-18'], ['31-24'], ['6-30'], ['7-12'], ['24-8'], ['21-30'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['29-26'], ['6-9'], ['19-15'], ['24-29'], ['29-21'], ['31-16'], ['7-4'], ['18-30'], ['21-28'], ['12-26'], ['6-30'], ['31-24'], ['14-18'], ['24-8'], ['21-30'], ['7-12'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 58.48737359046936\n",
      "Response: The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['29-26'], ['6-9'], ['19-15'], ['29-21'], ['24-29'], ['21-28'], ['31-16'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['6-30'], ['24-8'], ['31-24'], ['7-12'], ['21-30'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 99.15704131126404\n",
      "Response: The Boy and the Heron is the most recently released Studio Ghibli film.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 255\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['29-26'], ['19-15'], ['29-21'], ['24-29'], ['21-28'], ['12-26'], ['14-18'], ['18-30'], ['31-16'], ['7-4'], ['7-12'], ['24-8'], ['6-30'], ['31-24'], ['21-30'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1076\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['29-26'], ['19-15'], ['24-29'], ['29-21'], ['7-12'], ['18-30'], ['21-28'], ['14-18'], ['31-16'], ['12-26'], ['24-8'], ['7-4'], ['31-24'], ['6-30'], ['21-30'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 99.15704131126404\n",
      "Response: The Boy and the Heron is the most recently released Studio Ghibli film.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1610\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['29-26'], ['7-12'], ['19-15'], ['24-29'], ['29-21'], ['18-30'], ['21-28'], ['14-18'], ['31-16'], ['24-8'], ['12-26'], ['7-4'], ['21-30'], ['31-24'], ['6-30'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 99.15704131126404\n",
      "Response: The Boy and the Heron is the most recently released Studio Ghibli film.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['29-26'], ['19-15'], ['7-12'], ['24-29'], ['29-21'], ['18-30'], ['21-28'], ['31-16'], ['14-18'], ['24-8'], ['7-4'], ['12-26'], ['21-30'], ['31-24'], ['6-30'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 58.48737359046936\n",
      "Response: The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['29-26'], ['19-15'], ['24-29'], ['7-12'], ['29-21'], ['18-30'], ['21-28'], ['31-16'], ['14-18'], ['24-8'], ['7-4'], ['12-26'], ['21-30'], ['31-24'], ['6-30'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 832\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['19-15'], ['29-26'], ['24-29'], ['7-12'], ['29-21'], ['18-30'], ['21-28'], ['31-16'], ['14-18'], ['24-8'], ['12-26'], ['21-30'], ['7-4'], ['31-24'], ['6-30'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 58.48737359046936\n",
      "Response: The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1748\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['19-15'], ['29-26'], ['7-12'], ['24-29'], ['29-21'], ['21-28'], ['18-30'], ['31-16'], ['14-18'], ['24-8'], ['12-26'], ['21-30'], ['7-4'], ['31-24'], ['6-30'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 58.48737359046936\n",
      "Response: The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2637\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['19-15'], ['29-26'], ['7-12'], ['24-29'], ['29-21'], ['21-28'], ['18-30'], ['24-8'], ['31-16'], ['14-18'], ['12-26'], ['21-30'], ['31-24'], ['7-4'], ['17-22'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 58.48737359046936\n",
      "Response: The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['19-15'], ['29-26'], ['24-29'], ['7-12'], ['29-21'], ['18-30'], ['21-28'], ['24-8'], ['31-16'], ['12-26'], ['14-18'], ['21-30'], ['7-4'], ['31-24'], ['17-22'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 58.48737359046936\n",
      "Response: The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['19-15'], ['29-26'], ['24-29'], ['7-12'], ['29-21'], ['18-30'], ['21-28'], ['24-8'], ['31-16'], ['12-26'], ['21-30'], ['14-18'], ['7-4'], ['31-24'], ['17-22'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 59.53876972198486\n",
      "Response: The Boy and the Heron\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1192\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['19-15'], ['29-26'], ['7-12'], ['24-29'], ['29-21'], ['21-28'], ['18-30'], ['24-8'], ['31-16'], ['12-26'], ['21-30'], ['14-18'], ['17-22'], ['31-24'], ['7-4'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 58.48737359046936\n",
      "Response: The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2359\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['19-15'], ['29-26'], ['7-12'], ['24-29'], ['29-21'], ['18-30'], ['21-28'], ['24-8'], ['31-16'], ['12-26'], ['21-30'], ['14-18'], ['15-14'], ['17-22'], ['31-24'], ['7-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 58.48737359046936\n",
      "Response: The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3481\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['19-15'], ['29-26'], ['7-12'], ['24-29'], ['29-21'], ['18-30'], ['21-28'], ['24-8'], ['31-16'], ['12-26'], ['21-30'], ['14-18'], ['15-14'], ['17-22'], ['31-24'], ['7-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 58.48737359046936\n",
      "Response: The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The most recently released Studio Ghibli film is The Boy and the Heron.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['19-15'], ['29-26'], ['24-29'], ['7-12'], ['29-21'], ['18-30'], ['21-28'], ['24-8'], ['31-16'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['14-18'], ['7-4'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 58.48737359046936\n",
      "Response: The Boy and the Heron.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_189_irrelevant_misleading/llama-2-7b-80k_id_189_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Croatia's current national currency is the Euro.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['12-26'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['19-15'], ['15-14'], ['18-30'], ['26-28'], ['6-30'], ['14-18'], ['18-10'], ['19-12'], ['21-16'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['12-26'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['19-15'], ['15-14'], ['18-30'], ['26-28'], ['6-30'], ['14-18'], ['18-10'], ['19-12'], ['21-16'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['12-26'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['19-15'], ['15-14'], ['18-30'], ['26-28'], ['6-30'], ['14-18'], ['18-10'], ['19-12'], ['21-16'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['12-26'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['19-15'], ['15-14'], ['18-30'], ['26-28'], ['6-30'], ['14-18'], ['18-10'], ['19-12'], ['21-16'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_0_depth_7500_results.json\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['12-26'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['19-15'], ['15-14'], ['18-30'], ['26-28'], ['6-30'], ['14-18'], ['18-10'], ['19-12'], ['21-16'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['11-2'], ['12-26'], ['19-15'], ['7-4'], ['15-14'], ['18-30'], ['26-28'], ['14-18'], ['18-10'], ['21-16'], ['6-30'], ['19-12'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_1250_depth_0_results.json\n",
      "insertion at 236\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['11-2'], ['12-26'], ['7-4'], ['19-15'], ['15-14'], ['18-30'], ['26-28'], ['14-18'], ['21-16'], ['18-10'], ['24-24'], ['6-30'], ['7-12'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 352\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['6-9'], ['21-30'], ['11-2'], ['12-26'], ['19-15'], ['7-4'], ['15-14'], ['18-30'], ['7-12'], ['14-18'], ['26-28'], ['21-16'], ['24-24'], ['18-10'], ['24-8'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 745\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['21-30'], ['6-9'], ['19-15'], ['7-4'], ['12-26'], ['15-14'], ['7-12'], ['18-30'], ['14-18'], ['26-28'], ['21-16'], ['24-29'], ['24-8'], ['24-24'], ['18-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_1250_depth_7500_results.json\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['21-30'], ['6-9'], ['19-15'], ['7-4'], ['12-26'], ['15-14'], ['18-30'], ['7-12'], ['14-18'], ['26-28'], ['21-16'], ['24-24'], ['24-29'], ['18-10'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['21-30'], ['6-9'], ['19-15'], ['7-4'], ['12-26'], ['15-14'], ['7-12'], ['18-30'], ['14-18'], ['26-28'], ['24-24'], ['24-29'], ['21-16'], ['18-10'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 94.29381489753723\n",
      "Response: Croatia's current national currency is the Euro (EUR).\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_2500_depth_0_results.json\n",
      "insertion at 352\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['6-9'], ['19-15'], ['7-4'], ['12-26'], ['7-12'], ['15-14'], ['18-30'], ['14-18'], ['26-28'], ['24-24'], ['24-29'], ['21-16'], ['18-10'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1140\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['6-9'], ['19-15'], ['7-4'], ['7-12'], ['12-26'], ['15-14'], ['18-30'], ['14-18'], ['24-29'], ['26-28'], ['21-16'], ['24-24'], ['18-10'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1671\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['11-2'], ['17-22'], ['8-26'], ['21-30'], ['19-15'], ['6-9'], ['7-12'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['15-14'], ['24-29'], ['21-16'], ['26-28'], ['24-24'], ['19-14'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 85.76276302337646\n",
      "Response: Croatia's current national currency is the Euro. Croatia has also positioned itself as a regional energy leader in the early 2020s and is contributing to the diversification of Europe's energy supply via its floating li\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_2500_depth_7500_results.json\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['11-2'], ['17-22'], ['21-30'], ['19-15'], ['6-9'], ['7-4'], ['12-26'], ['7-12'], ['18-30'], ['14-18'], ['15-14'], ['24-29'], ['21-16'], ['26-28'], ['24-24'], ['19-14'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['11-2'], ['17-22'], ['8-26'], ['21-30'], ['19-15'], ['6-9'], ['7-12'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['15-14'], ['24-29'], ['26-28'], ['21-16'], ['24-24'], ['18-10'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_3750_depth_0_results.json\n",
      "insertion at 871\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['19-15'], ['6-9'], ['7-12'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['15-14'], ['24-29'], ['21-16'], ['26-28'], ['24-24'], ['24-8'], ['18-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1763\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['7-12'], ['19-15'], ['6-9'], ['7-4'], ['12-26'], ['14-18'], ['18-30'], ['15-14'], ['24-29'], ['21-16'], ['26-28'], ['24-24'], ['24-8'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2587\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['7-12'], ['19-15'], ['6-9'], ['7-4'], ['12-26'], ['14-18'], ['18-30'], ['24-29'], ['15-14'], ['21-16'], ['26-28'], ['24-8'], ['24-24'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_3750_depth_7500_results.json\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['19-15'], ['7-12'], ['6-9'], ['7-4'], ['12-26'], ['18-30'], ['14-18'], ['15-14'], ['24-29'], ['21-16'], ['26-28'], ['20-29'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['11-2'], ['17-22'], ['8-26'], ['21-30'], ['7-12'], ['19-15'], ['6-9'], ['7-4'], ['12-26'], ['14-18'], ['18-30'], ['24-29'], ['15-14'], ['21-16'], ['26-28'], ['20-29'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1183\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['11-2'], ['17-22'], ['8-26'], ['21-30'], ['7-12'], ['19-15'], ['6-9'], ['7-4'], ['12-26'], ['14-18'], ['18-30'], ['24-29'], ['15-14'], ['21-16'], ['26-28'], ['20-29'], ['23-31'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2391\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['11-2'], ['17-22'], ['8-26'], ['21-30'], ['7-12'], ['19-15'], ['6-9'], ['7-4'], ['12-26'], ['14-18'], ['18-30'], ['24-29'], ['15-14'], ['21-16'], ['26-28'], ['20-29'], ['23-31'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3579\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['11-2'], ['17-22'], ['8-26'], ['21-30'], ['7-12'], ['19-15'], ['6-9'], ['7-4'], ['12-26'], ['14-18'], ['18-30'], ['24-29'], ['21-16'], ['15-14'], ['26-28'], ['20-29'], ['23-31'], ['20-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_5000_depth_7500_results.json\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['11-2'], ['17-22'], ['8-26'], ['21-30'], ['7-12'], ['19-15'], ['6-9'], ['7-4'], ['12-26'], ['14-18'], ['18-30'], ['24-29'], ['15-14'], ['21-16'], ['26-28'], ['20-29'], ['20-27'], ['23-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant/llama-2-7b-80k_id_192_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/192.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Croatia's current national currency is the Euro.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['12-26'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['19-15'], ['15-14'], ['18-30'], ['26-28'], ['6-30'], ['14-18'], ['18-10'], ['19-12'], ['21-16'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['12-26'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['19-15'], ['15-14'], ['18-30'], ['26-28'], ['6-30'], ['14-18'], ['18-10'], ['19-12'], ['21-16'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['12-26'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['19-15'], ['15-14'], ['18-30'], ['26-28'], ['6-30'], ['14-18'], ['18-10'], ['19-12'], ['21-16'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['12-26'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['19-15'], ['15-14'], ['18-30'], ['26-28'], ['6-30'], ['14-18'], ['18-10'], ['19-12'], ['21-16'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_0_depth_7500_results.json\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['12-26'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['19-15'], ['15-14'], ['18-30'], ['26-28'], ['6-30'], ['14-18'], ['18-10'], ['19-12'], ['21-16'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['11-2'], ['12-26'], ['19-15'], ['7-4'], ['15-14'], ['18-30'], ['26-28'], ['14-18'], ['18-10'], ['21-16'], ['24-24'], ['6-30'], ['19-12'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 236\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['11-2'], ['12-26'], ['7-4'], ['19-15'], ['15-14'], ['18-30'], ['26-28'], ['14-18'], ['21-16'], ['7-12'], ['18-10'], ['24-24'], ['6-30'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 352\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['21-30'], ['11-2'], ['12-26'], ['7-4'], ['19-15'], ['15-14'], ['7-12'], ['14-18'], ['18-30'], ['26-28'], ['21-16'], ['24-24'], ['18-10'], ['24-8'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 745\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['6-9'], ['21-30'], ['12-26'], ['19-15'], ['7-4'], ['15-14'], ['7-12'], ['14-18'], ['26-28'], ['18-30'], ['21-16'], ['24-29'], ['24-24'], ['24-8'], ['18-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_1250_depth_7500_results.json\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['6-9'], ['21-30'], ['12-26'], ['19-15'], ['7-4'], ['15-14'], ['7-12'], ['14-18'], ['18-30'], ['26-28'], ['21-16'], ['24-24'], ['24-29'], ['18-10'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['21-30'], ['6-9'], ['12-26'], ['19-15'], ['7-4'], ['15-14'], ['7-12'], ['14-18'], ['18-30'], ['26-28'], ['21-16'], ['24-24'], ['24-29'], ['18-10'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 352\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['11-2'], ['17-22'], ['21-30'], ['6-9'], ['19-15'], ['12-26'], ['7-4'], ['7-12'], ['15-14'], ['14-18'], ['18-30'], ['26-28'], ['21-16'], ['24-24'], ['24-29'], ['18-10'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1127\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['11-2'], ['17-22'], ['21-30'], ['6-9'], ['19-15'], ['7-12'], ['12-26'], ['7-4'], ['15-14'], ['14-18'], ['18-30'], ['26-28'], ['21-16'], ['24-24'], ['24-29'], ['18-10'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1704\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['11-2'], ['17-22'], ['21-30'], ['6-9'], ['19-15'], ['7-12'], ['7-4'], ['12-26'], ['15-14'], ['14-18'], ['18-30'], ['21-16'], ['26-28'], ['24-29'], ['24-24'], ['18-10'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 85.76276302337646\n",
      "Response: Croatia's current national currency is the Euro. Croatia has also positioned itself as a regional energy leader in the early 2020s and is contributing to the diversification of Europe's energy supply via its floating li\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_2500_depth_7500_results.json\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['11-2'], ['17-22'], ['21-30'], ['6-9'], ['19-15'], ['7-4'], ['12-26'], ['7-12'], ['18-30'], ['15-14'], ['14-18'], ['21-16'], ['26-28'], ['24-29'], ['24-24'], ['20-29'], ['18-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['11-2'], ['17-22'], ['21-30'], ['6-9'], ['19-15'], ['7-12'], ['7-4'], ['12-26'], ['14-18'], ['18-30'], ['15-14'], ['21-16'], ['26-28'], ['24-29'], ['20-29'], ['24-24'], ['18-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 871\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['11-2'], ['17-22'], ['21-30'], ['6-9'], ['7-12'], ['19-15'], ['7-4'], ['12-26'], ['14-18'], ['18-30'], ['15-14'], ['21-16'], ['26-28'], ['24-29'], ['20-29'], ['24-24'], ['18-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1761\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['11-2'], ['17-22'], ['21-30'], ['7-12'], ['6-9'], ['19-15'], ['7-4'], ['12-26'], ['14-18'], ['18-30'], ['15-14'], ['21-16'], ['26-28'], ['24-29'], ['20-29'], ['24-24'], ['18-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2643\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['11-2'], ['17-22'], ['21-30'], ['7-12'], ['6-9'], ['19-15'], ['7-4'], ['12-26'], ['14-18'], ['18-30'], ['15-14'], ['21-16'], ['26-28'], ['24-29'], ['20-29'], ['24-24'], ['20-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_3750_depth_7500_results.json\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['11-2'], ['17-22'], ['21-30'], ['7-12'], ['19-15'], ['6-9'], ['12-26'], ['7-4'], ['14-18'], ['18-30'], ['15-14'], ['26-28'], ['21-16'], ['24-29'], ['20-29'], ['24-24'], ['20-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['7-12'], ['19-15'], ['6-9'], ['12-26'], ['7-4'], ['14-18'], ['18-30'], ['15-14'], ['21-16'], ['26-28'], ['24-29'], ['20-29'], ['24-24'], ['20-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1197\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['7-12'], ['19-15'], ['6-9'], ['12-26'], ['7-4'], ['14-18'], ['18-30'], ['15-14'], ['21-16'], ['26-28'], ['24-29'], ['20-29'], ['20-27'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2362\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['7-12'], ['19-15'], ['6-9'], ['12-26'], ['7-4'], ['14-18'], ['18-30'], ['15-14'], ['21-16'], ['26-28'], ['24-29'], ['20-29'], ['20-27'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3569\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['7-12'], ['19-15'], ['6-9'], ['7-4'], ['12-26'], ['14-18'], ['15-14'], ['18-30'], ['21-16'], ['24-29'], ['26-28'], ['20-29'], ['20-27'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_5000_depth_7500_results.json\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['11-2'], ['8-26'], ['17-22'], ['21-30'], ['7-12'], ['19-15'], ['6-9'], ['7-4'], ['12-26'], ['14-18'], ['18-30'], ['15-14'], ['21-16'], ['26-28'], ['24-29'], ['20-29'], ['20-27'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_relevant_misleading/llama-2-7b-80k_id_192_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Croatia's current national currency is the Euro.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['12-26'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['19-15'], ['15-14'], ['18-30'], ['26-28'], ['6-30'], ['14-18'], ['18-10'], ['19-12'], ['21-16'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['12-26'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['19-15'], ['15-14'], ['18-30'], ['26-28'], ['6-30'], ['14-18'], ['18-10'], ['19-12'], ['21-16'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['12-26'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['19-15'], ['15-14'], ['18-30'], ['26-28'], ['6-30'], ['14-18'], ['18-10'], ['19-12'], ['21-16'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['12-26'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['19-15'], ['15-14'], ['18-30'], ['26-28'], ['6-30'], ['14-18'], ['18-10'], ['19-12'], ['21-16'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_0_depth_7500_results.json\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['12-26'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['19-15'], ['15-14'], ['18-30'], ['26-28'], ['6-30'], ['14-18'], ['18-10'], ['19-12'], ['21-16'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['21-30'], ['11-2'], ['12-26'], ['19-15'], ['7-4'], ['15-14'], ['18-30'], ['26-28'], ['14-18'], ['18-10'], ['6-30'], ['19-12'], ['21-16'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 30\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['21-30'], ['11-2'], ['12-26'], ['19-15'], ['7-4'], ['15-14'], ['14-18'], ['18-30'], ['26-28'], ['18-10'], ['24-8'], ['24-24'], ['6-30'], ['7-12'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 30\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['6-9'], ['21-30'], ['12-26'], ['19-15'], ['7-4'], ['15-14'], ['14-18'], ['26-28'], ['18-30'], ['7-12'], ['24-8'], ['24-24'], ['18-10'], ['6-30'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 605\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['6-9'], ['21-30'], ['19-15'], ['7-4'], ['12-26'], ['15-14'], ['14-18'], ['7-12'], ['26-28'], ['18-30'], ['24-8'], ['14-13'], ['24-24'], ['24-29'], ['18-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_1250_depth_7500_results.json\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['6-9'], ['21-30'], ['19-15'], ['7-4'], ['12-26'], ['15-14'], ['14-18'], ['26-28'], ['18-30'], ['7-12'], ['14-13'], ['21-16'], ['24-8'], ['24-24'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 41.66075587272644\n",
      "Response: Croatian kuna\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 30\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['21-30'], ['6-9'], ['19-15'], ['12-26'], ['7-4'], ['15-14'], ['14-18'], ['7-12'], ['26-28'], ['18-30'], ['14-13'], ['24-29'], ['20-29'], ['21-16'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1142\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['17-22'], ['21-30'], ['11-2'], ['6-9'], ['19-15'], ['7-4'], ['12-26'], ['15-14'], ['7-12'], ['14-18'], ['26-28'], ['18-30'], ['14-13'], ['24-29'], ['20-29'], ['19-14'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1659\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['17-22'], ['21-30'], ['11-2'], ['6-9'], ['19-15'], ['7-4'], ['12-26'], ['7-12'], ['15-14'], ['14-18'], ['18-30'], ['26-28'], ['14-13'], ['24-29'], ['19-14'], ['20-29'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_2500_depth_7500_results.json\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['17-22'], ['21-30'], ['11-2'], ['6-9'], ['19-15'], ['7-4'], ['12-26'], ['7-12'], ['15-14'], ['14-18'], ['18-30'], ['26-28'], ['14-13'], ['24-29'], ['19-14'], ['20-29'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['17-22'], ['11-2'], ['21-30'], ['6-9'], ['19-15'], ['7-4'], ['7-12'], ['12-26'], ['14-18'], ['15-14'], ['18-30'], ['26-28'], ['24-29'], ['14-13'], ['19-14'], ['20-29'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 605\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['17-22'], ['11-2'], ['21-30'], ['6-9'], ['7-12'], ['19-15'], ['7-4'], ['12-26'], ['14-18'], ['15-14'], ['18-30'], ['26-28'], ['24-29'], ['14-13'], ['19-14'], ['20-29'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1731\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['17-22'], ['11-2'], ['21-30'], ['6-9'], ['7-12'], ['19-15'], ['7-4'], ['14-18'], ['12-26'], ['15-14'], ['18-30'], ['24-29'], ['26-28'], ['14-13'], ['19-14'], ['21-16'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2515\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['17-22'], ['11-2'], ['21-30'], ['7-12'], ['6-9'], ['19-15'], ['7-4'], ['14-18'], ['12-26'], ['15-14'], ['18-30'], ['24-29'], ['26-28'], ['14-13'], ['19-14'], ['21-16'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_3750_depth_7500_results.json\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['17-22'], ['21-30'], ['11-2'], ['6-9'], ['7-12'], ['19-15'], ['7-4'], ['14-18'], ['12-26'], ['15-14'], ['18-30'], ['24-29'], ['26-28'], ['14-13'], ['19-14'], ['20-29'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['17-22'], ['11-2'], ['21-30'], ['7-12'], ['6-9'], ['19-15'], ['7-4'], ['14-18'], ['12-26'], ['15-14'], ['18-30'], ['24-29'], ['26-28'], ['14-13'], ['19-14'], ['20-29'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1142\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['17-22'], ['11-2'], ['21-30'], ['7-12'], ['6-9'], ['19-15'], ['14-18'], ['7-4'], ['12-26'], ['15-14'], ['18-30'], ['24-29'], ['14-13'], ['26-28'], ['19-14'], ['20-29'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2300\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['17-22'], ['11-2'], ['21-30'], ['7-12'], ['6-9'], ['14-18'], ['19-15'], ['7-4'], ['12-26'], ['15-14'], ['24-29'], ['18-30'], ['14-13'], ['19-14'], ['26-28'], ['21-16'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3578\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['17-22'], ['11-2'], ['21-30'], ['7-12'], ['6-9'], ['19-15'], ['14-18'], ['7-4'], ['12-26'], ['15-14'], ['24-29'], ['14-13'], ['18-30'], ['19-14'], ['26-28'], ['21-16'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_5000_depth_7500_results.json\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['17-22'], ['11-2'], ['21-30'], ['7-12'], ['6-9'], ['19-15'], ['7-4'], ['14-18'], ['12-26'], ['15-14'], ['24-29'], ['18-30'], ['14-13'], ['19-14'], ['26-28'], ['21-16'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant/llama-2-7b-80k_id_192_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/192.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Croatia's current national currency is the Euro.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['12-26'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['19-15'], ['15-14'], ['18-30'], ['26-28'], ['6-30'], ['14-18'], ['18-10'], ['19-12'], ['21-16'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['12-26'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['19-15'], ['15-14'], ['18-30'], ['26-28'], ['6-30'], ['14-18'], ['18-10'], ['19-12'], ['21-16'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['12-26'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['19-15'], ['15-14'], ['18-30'], ['26-28'], ['6-30'], ['14-18'], ['18-10'], ['19-12'], ['21-16'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['12-26'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['19-15'], ['15-14'], ['18-30'], ['26-28'], ['6-30'], ['14-18'], ['18-10'], ['19-12'], ['21-16'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['12-26'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['19-15'], ['15-14'], ['18-30'], ['26-28'], ['6-30'], ['14-18'], ['18-10'], ['19-12'], ['21-16'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['21-30'], ['11-2'], ['12-26'], ['19-15'], ['7-4'], ['15-14'], ['18-30'], ['26-28'], ['14-18'], ['18-10'], ['6-30'], ['19-12'], ['21-16'], ['24-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 30\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['21-30'], ['11-2'], ['12-26'], ['19-15'], ['7-4'], ['15-14'], ['14-18'], ['18-30'], ['26-28'], ['18-10'], ['24-8'], ['24-24'], ['6-30'], ['7-12'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 30\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['6-9'], ['21-30'], ['12-26'], ['19-15'], ['7-4'], ['15-14'], ['14-18'], ['26-28'], ['18-30'], ['7-12'], ['24-8'], ['24-24'], ['18-10'], ['6-30'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 605\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['6-9'], ['21-30'], ['19-15'], ['7-4'], ['12-26'], ['15-14'], ['14-18'], ['7-12'], ['26-28'], ['18-30'], ['24-8'], ['14-13'], ['24-24'], ['24-29'], ['18-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['6-9'], ['21-30'], ['19-15'], ['7-4'], ['12-26'], ['15-14'], ['14-18'], ['26-28'], ['18-30'], ['7-12'], ['14-13'], ['21-16'], ['24-8'], ['24-24'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['6-9'], ['21-30'], ['19-15'], ['12-26'], ['7-4'], ['14-18'], ['15-14'], ['7-12'], ['26-28'], ['18-30'], ['24-29'], ['14-13'], ['18-10'], ['21-16'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 30\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['21-30'], ['6-9'], ['19-15'], ['12-26'], ['7-4'], ['14-18'], ['7-12'], ['15-14'], ['26-28'], ['18-30'], ['14-13'], ['24-29'], ['21-16'], ['24-24'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1131\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['17-22'], ['11-2'], ['21-30'], ['6-9'], ['19-15'], ['7-4'], ['12-26'], ['7-12'], ['14-18'], ['15-14'], ['26-28'], ['18-30'], ['24-29'], ['14-13'], ['24-24'], ['24-8'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1692\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['17-22'], ['11-2'], ['21-30'], ['6-9'], ['19-15'], ['7-4'], ['7-12'], ['12-26'], ['14-18'], ['15-14'], ['18-30'], ['26-28'], ['24-29'], ['14-13'], ['24-24'], ['24-8'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['17-22'], ['11-2'], ['21-30'], ['6-9'], ['19-15'], ['7-4'], ['12-26'], ['7-12'], ['14-18'], ['15-14'], ['18-30'], ['26-28'], ['24-29'], ['14-13'], ['21-16'], ['24-24'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['21-30'], ['6-9'], ['19-15'], ['7-4'], ['7-12'], ['14-18'], ['12-26'], ['15-14'], ['18-30'], ['26-28'], ['24-29'], ['14-13'], ['21-16'], ['24-24'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 605\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['21-30'], ['6-9'], ['19-15'], ['7-12'], ['7-4'], ['14-18'], ['12-26'], ['15-14'], ['18-30'], ['26-28'], ['24-29'], ['14-13'], ['24-24'], ['19-14'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1764\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['21-30'], ['6-9'], ['7-12'], ['19-15'], ['7-4'], ['14-18'], ['12-26'], ['15-14'], ['18-30'], ['24-29'], ['26-28'], ['14-13'], ['19-14'], ['24-24'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2571\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['21-30'], ['6-9'], ['7-12'], ['19-15'], ['7-4'], ['14-18'], ['12-26'], ['15-14'], ['24-29'], ['18-30'], ['26-28'], ['14-13'], ['19-14'], ['24-24'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['21-30'], ['6-9'], ['7-12'], ['19-15'], ['7-4'], ['14-18'], ['12-26'], ['15-14'], ['18-30'], ['24-29'], ['26-28'], ['14-13'], ['19-14'], ['24-24'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['21-30'], ['6-9'], ['7-12'], ['19-15'], ['7-4'], ['14-18'], ['12-26'], ['15-14'], ['18-30'], ['24-29'], ['26-28'], ['19-14'], ['14-13'], ['24-24'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1156\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['21-30'], ['7-12'], ['6-9'], ['19-15'], ['14-18'], ['7-4'], ['12-26'], ['15-14'], ['24-29'], ['18-30'], ['26-28'], ['19-14'], ['14-13'], ['24-24'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2333\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['21-30'], ['7-12'], ['6-9'], ['19-15'], ['14-18'], ['7-4'], ['12-26'], ['15-14'], ['24-29'], ['18-30'], ['26-28'], ['19-14'], ['14-13'], ['24-24'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3581\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['17-22'], ['11-2'], ['21-30'], ['7-12'], ['6-9'], ['19-15'], ['14-18'], ['7-4'], ['15-14'], ['12-26'], ['24-29'], ['18-30'], ['19-14'], ['26-28'], ['14-13'], ['24-24'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "Croatia's current national currency is the Euro.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['21-30'], ['7-12'], ['6-9'], ['19-15'], ['14-18'], ['7-4'], ['12-26'], ['15-14'], ['24-29'], ['18-30'], ['26-28'], ['19-14'], ['14-13'], ['21-16'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: Croatia's current national currency is the Euro.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_192_irrelevant_misleading/llama-2-7b-80k_id_192_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: There are 20 member states in the Eurozone.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['8-26'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['8-26'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['8-26'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['8-26'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_0_depth_7500_results.json\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['8-26'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['6-30'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_1250_depth_0_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['6-30'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-12'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 446\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['6-30'], ['12-26'], ['19-15'], ['21-30'], ['7-12'], ['16-24'], ['17-22'], ['24-29'], ['21-4'], ['24-30'], ['16-1'], ['7-13'], ['8-31'], ['12-16'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 761\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['6-30'], ['12-26'], ['19-15'], ['7-12'], ['21-30'], ['24-29'], ['16-24'], ['17-22'], ['21-4'], ['24-30'], ['14-18'], ['8-31'], ['11-2'], ['16-1'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_1250_depth_7500_results.json\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['12-26'], ['6-30'], ['19-15'], ['7-12'], ['21-30'], ['24-29'], ['17-22'], ['16-24'], ['21-4'], ['24-30'], ['14-18'], ['11-2'], ['7-13'], ['15-14'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['12-26'], ['6-30'], ['19-15'], ['7-12'], ['21-30'], ['24-29'], ['17-22'], ['16-24'], ['21-4'], ['14-18'], ['24-30'], ['11-2'], ['7-13'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_2500_depth_0_results.json\n",
      "insertion at 534\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['7-12'], ['12-26'], ['6-30'], ['19-15'], ['21-30'], ['24-29'], ['17-22'], ['16-24'], ['21-4'], ['11-2'], ['14-18'], ['24-30'], ['7-13'], ['8-31'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 979\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['6-30'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['14-18'], ['16-24'], ['17-22'], ['21-4'], ['24-30'], ['8-31'], ['12-16'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1702\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['6-30'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['17-22'], ['14-18'], ['16-24'], ['21-4'], ['15-14'], ['24-30'], ['8-31'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_2500_depth_7500_results.json\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['7-12'], ['12-26'], ['6-30'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['11-2'], ['14-18'], ['16-24'], ['21-4'], ['15-14'], ['24-30'], ['24-3'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['6-30'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['11-2'], ['14-18'], ['21-4'], ['16-24'], ['15-14'], ['24-30'], ['8-31'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 96.15192413330078\n",
      "Response: There are 19 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_3750_depth_0_results.json\n",
      "insertion at 863\n",
      "There are 20 member states in the Eurozone.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['6-30'], ['19-15'], ['24-29'], ['17-22'], ['11-2'], ['21-30'], ['14-18'], ['16-24'], ['21-4'], ['15-14'], ['24-30'], ['16-1'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 73.16552996635437\n",
      "Response: There are 20 member states in the Eurozone. Since the 2008 financial crisis, the eurozone has established and used provisions for granting emergency loans to member states in return for enacting economic reforms\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1768\n",
      "There are 20 member states in the Eurozone.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['6-30'], ['19-15'], ['11-2'], ['17-22'], ['24-29'], ['14-18'], ['21-30'], ['16-24'], ['21-4'], ['15-14'], ['16-1'], ['24-30'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2606\n",
      "There are 20 member states in the Eurozone.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['6-30'], ['11-2'], ['19-15'], ['17-22'], ['24-29'], ['14-18'], ['21-30'], ['16-24'], ['21-4'], ['15-14'], ['16-1'], ['24-30'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_3750_depth_7500_results.json\n",
      "There are 20 member states in the Eurozone.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['6-30'], ['19-15'], ['17-22'], ['11-2'], ['24-29'], ['14-18'], ['21-30'], ['16-24'], ['21-4'], ['15-14'], ['24-30'], ['16-1'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['6-30'], ['11-2'], ['19-15'], ['17-22'], ['24-29'], ['14-18'], ['21-30'], ['16-24'], ['21-4'], ['15-14'], ['16-1'], ['24-30'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_5000_depth_0_results.json\n",
      "insertion at 979\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['6-30'], ['11-2'], ['17-22'], ['19-15'], ['14-18'], ['24-29'], ['21-30'], ['16-24'], ['21-4'], ['15-14'], ['16-1'], ['24-30'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2385\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['11-2'], ['6-30'], ['14-18'], ['17-22'], ['19-15'], ['24-29'], ['21-30'], ['16-24'], ['21-4'], ['16-1'], ['15-14'], ['24-30'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3583\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['11-2'], ['6-30'], ['14-18'], ['17-22'], ['19-15'], ['24-29'], ['16-24'], ['21-30'], ['16-1'], ['21-4'], ['15-14'], ['8-31'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 76.20126605033875\n",
      "Response: There are 20 member states in the Eurozone. Croatia, which acceded to the EU in 2013, adopted the euro in 2023. All new EU members joining the bloc after the signing of\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_5000_depth_7500_results.json\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['11-2'], ['6-30'], ['17-22'], ['14-18'], ['19-15'], ['24-29'], ['21-30'], ['16-24'], ['21-4'], ['16-1'], ['15-14'], ['24-3'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant/llama-2-7b-80k_id_193_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/193.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: There are 20 member states in the Eurozone.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['8-26'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['8-26'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['8-26'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['8-26'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_0_depth_7500_results.json\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['8-26'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['6-30'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['6-30'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-12'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 446\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['6-30'], ['12-26'], ['19-15'], ['21-30'], ['7-12'], ['16-24'], ['17-22'], ['24-29'], ['21-4'], ['24-30'], ['16-1'], ['7-13'], ['8-31'], ['12-16'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 761\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['6-30'], ['12-26'], ['19-15'], ['7-12'], ['21-30'], ['24-29'], ['16-24'], ['17-22'], ['21-4'], ['24-30'], ['14-18'], ['8-31'], ['11-2'], ['16-1'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_1250_depth_7500_results.json\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['12-26'], ['6-30'], ['19-15'], ['7-12'], ['21-30'], ['24-29'], ['17-22'], ['16-24'], ['21-4'], ['24-30'], ['14-18'], ['11-2'], ['7-13'], ['15-14'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['12-26'], ['6-30'], ['19-15'], ['7-12'], ['21-30'], ['24-29'], ['17-22'], ['16-24'], ['21-4'], ['14-18'], ['24-30'], ['11-2'], ['7-13'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 534\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['7-12'], ['12-26'], ['6-30'], ['19-15'], ['21-30'], ['24-29'], ['17-22'], ['16-24'], ['21-4'], ['11-2'], ['14-18'], ['24-30'], ['7-13'], ['8-31'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 91.49258732795715\n",
      "Response: There are 20 member states in the Eurozone. The 20 eurozone members are: Austria, Belgium, Croatia, Cyprus, Estonia, Finland, France, Germany, Greece, Ireland, Italy, Latvia\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 979\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['6-30'], ['19-15'], ['21-30'], ['24-29'], ['17-22'], ['11-2'], ['14-18'], ['16-24'], ['21-4'], ['24-30'], ['16-1'], ['8-31'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1673\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['6-30'], ['19-15'], ['11-2'], ['14-18'], ['17-22'], ['24-29'], ['21-30'], ['16-24'], ['21-4'], ['16-1'], ['24-30'], ['8-31'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_2500_depth_7500_results.json\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['6-30'], ['19-15'], ['17-22'], ['24-29'], ['14-18'], ['11-2'], ['21-30'], ['16-24'], ['21-4'], ['16-1'], ['24-30'], ['15-14'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['6-30'], ['19-15'], ['17-22'], ['14-18'], ['24-29'], ['11-2'], ['21-30'], ['16-24'], ['21-4'], ['16-1'], ['24-30'], ['15-14'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 863\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['6-30'], ['19-15'], ['17-22'], ['14-18'], ['24-29'], ['11-2'], ['21-30'], ['16-24'], ['21-4'], ['16-1'], ['24-30'], ['15-14'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1739\n",
      "There are 20 member states in the Eurozone.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['6-30'], ['19-15'], ['17-22'], ['14-18'], ['11-2'], ['24-29'], ['21-30'], ['16-24'], ['21-4'], ['16-1'], ['24-30'], ['15-14'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 96.15192413330078\n",
      "Response: There are 19 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2620\n",
      "There are 20 member states in the Eurozone.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['6-30'], ['19-15'], ['17-22'], ['14-18'], ['11-2'], ['24-29'], ['21-30'], ['16-24'], ['21-4'], ['16-1'], ['24-30'], ['15-14'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 96.15192413330078\n",
      "Response: There are 19 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_3750_depth_7500_results.json\n",
      "There are 20 member states in the Eurozone.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['6-30'], ['19-15'], ['17-22'], ['14-18'], ['11-2'], ['24-29'], ['21-30'], ['16-24'], ['21-4'], ['15-14'], ['16-1'], ['24-30'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['6-30'], ['19-15'], ['17-22'], ['14-18'], ['11-2'], ['24-29'], ['21-30'], ['16-24'], ['21-4'], ['16-1'], ['15-14'], ['24-30'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 979\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['6-30'], ['14-18'], ['19-15'], ['11-2'], ['17-22'], ['24-29'], ['21-30'], ['16-24'], ['16-1'], ['21-4'], ['15-14'], ['24-30'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2383\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['14-18'], ['6-30'], ['11-2'], ['17-22'], ['19-15'], ['24-29'], ['21-30'], ['16-24'], ['15-14'], ['16-1'], ['21-4'], ['24-30'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3574\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['14-18'], ['6-30'], ['11-2'], ['17-22'], ['19-15'], ['24-29'], ['16-24'], ['21-30'], ['15-14'], ['16-1'], ['21-4'], ['24-30'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 81.58968687057495\n",
      "Response: There are 20 member states in the Eurozone. The next enlargements were to states which joined the EU in 2004, and then joined the eurozone on 1 January of the year noted: Slovenia in\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_5000_depth_7500_results.json\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-12'], ['7-4'], ['12-26'], ['6-30'], ['14-18'], ['17-22'], ['11-2'], ['19-15'], ['24-29'], ['21-30'], ['16-24'], ['15-14'], ['16-1'], ['21-4'], ['24-30'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_relevant_misleading/llama-2-7b-80k_id_193_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: There are 20 member states in the Eurozone.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['8-26'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['8-26'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['8-26'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['8-26'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_0_depth_7500_results.json\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['8-26'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-30'], ['7-4'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 91.02389812469482\n",
      "Response: There are 27 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 22\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['6-30'], ['12-26'], ['19-15'], ['21-30'], ['17-22'], ['24-29'], ['21-4'], ['16-24'], ['24-30'], ['7-12'], ['8-31'], ['16-1'], ['7-13'], ['12-16'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 498\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['6-30'], ['12-26'], ['19-15'], ['17-22'], ['21-30'], ['7-12'], ['24-29'], ['16-24'], ['21-4'], ['24-30'], ['8-31'], ['16-1'], ['24-24'], ['7-13'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 734\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['6-30'], ['7-12'], ['12-26'], ['19-15'], ['21-30'], ['24-29'], ['16-24'], ['21-4'], ['24-30'], ['8-31'], ['11-2'], ['24-24'], ['7-13'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_1250_depth_7500_results.json\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['6-30'], ['17-22'], ['12-26'], ['19-15'], ['21-30'], ['7-12'], ['24-29'], ['16-24'], ['21-4'], ['24-30'], ['8-31'], ['11-2'], ['7-13'], ['15-14'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['6-30'], ['17-22'], ['12-26'], ['19-15'], ['21-30'], ['7-12'], ['24-29'], ['16-24'], ['21-4'], ['24-30'], ['8-31'], ['11-2'], ['7-13'], ['15-14'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 91.02389812469482\n",
      "Response: There are 27 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 552\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['6-30'], ['12-26'], ['21-30'], ['19-15'], ['24-29'], ['16-24'], ['21-4'], ['11-2'], ['8-31'], ['24-30'], ['7-13'], ['24-24'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1121\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['6-30'], ['21-30'], ['12-26'], ['19-15'], ['24-29'], ['16-24'], ['21-4'], ['11-2'], ['8-31'], ['24-30'], ['24-24'], ['7-13'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1656\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['6-30'], ['21-30'], ['19-15'], ['12-26'], ['24-29'], ['16-24'], ['21-4'], ['11-2'], ['8-31'], ['24-30'], ['24-24'], ['15-14'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_2500_depth_7500_results.json\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['6-30'], ['12-26'], ['19-15'], ['21-30'], ['24-29'], ['21-4'], ['16-24'], ['11-2'], ['8-31'], ['15-14'], ['24-30'], ['24-24'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['6-30'], ['12-26'], ['19-15'], ['21-30'], ['24-29'], ['21-4'], ['16-24'], ['11-2'], ['8-31'], ['15-14'], ['24-24'], ['24-30'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 91.02389812469482\n",
      "Response: There are 27 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 861\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-12'], ['7-4'], ['17-22'], ['6-30'], ['12-26'], ['21-30'], ['19-15'], ['24-29'], ['21-4'], ['11-2'], ['16-24'], ['8-31'], ['15-14'], ['24-24'], ['24-30'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1722\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-12'], ['7-4'], ['17-22'], ['21-30'], ['6-30'], ['12-26'], ['19-15'], ['24-29'], ['11-2'], ['16-24'], ['21-4'], ['8-31'], ['15-14'], ['24-24'], ['14-18'], ['24-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2601\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['24-29'], ['6-30'], ['12-26'], ['11-2'], ['16-24'], ['21-4'], ['8-31'], ['15-14'], ['24-24'], ['14-18'], ['24-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_3750_depth_7500_results.json\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['21-30'], ['12-26'], ['19-15'], ['6-30'], ['24-29'], ['11-2'], ['16-24'], ['21-4'], ['15-14'], ['8-31'], ['24-24'], ['14-18'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['21-30'], ['12-26'], ['19-15'], ['6-30'], ['24-29'], ['11-2'], ['16-24'], ['21-4'], ['15-14'], ['8-31'], ['24-24'], ['14-18'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 91.02389812469482\n",
      "Response: There are 27 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1191\n",
      "There are 20 member states in the Eurozone.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['21-30'], ['24-29'], ['12-26'], ['19-15'], ['6-30'], ['11-2'], ['16-24'], ['21-4'], ['8-31'], ['15-14'], ['14-18'], ['24-24'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2391\n",
      "There are 20 member states in the Eurozone.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['21-30'], ['24-29'], ['12-26'], ['19-15'], ['6-30'], ['11-2'], ['16-24'], ['21-4'], ['8-31'], ['15-14'], ['24-24'], ['14-18'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3576\n",
      "There are 20 member states in the Eurozone.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['21-30'], ['24-29'], ['19-15'], ['12-26'], ['6-30'], ['11-2'], ['16-24'], ['8-31'], ['21-4'], ['15-14'], ['24-24'], ['14-18'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 74.32631254196167\n",
      "Response: There are 20 member states in the Eurozone. A8 is eight of the ten countries that joined the EU in 2004, Czech Republic, Estonia, Hungary, Latvia, Lithuania, Poland, the\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_5000_depth_7500_results.json\n",
      "There are 20 member states in the Eurozone.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['21-30'], ['24-29'], ['12-26'], ['19-15'], ['6-30'], ['11-2'], ['16-24'], ['21-4'], ['8-31'], ['15-14'], ['24-24'], ['14-18'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant/llama-2-7b-80k_id_193_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/193.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: There are 20 member states in the Eurozone.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['8-26'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['8-26'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['8-26'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['8-26'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['8-26'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-30'], ['7-4'], ['12-26'], ['19-15'], ['21-30'], ['16-24'], ['17-22'], ['21-4'], ['24-29'], ['24-30'], ['7-13'], ['8-31'], ['12-16'], ['13-11'], ['15-14'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 91.02389812469482\n",
      "Response: There are 27 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 22\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['6-30'], ['12-26'], ['19-15'], ['21-30'], ['17-22'], ['24-29'], ['21-4'], ['16-24'], ['24-30'], ['7-12'], ['8-31'], ['16-1'], ['7-13'], ['12-16'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 498\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['6-30'], ['12-26'], ['19-15'], ['17-22'], ['21-30'], ['7-12'], ['24-29'], ['16-24'], ['21-4'], ['24-30'], ['8-31'], ['16-1'], ['24-24'], ['7-13'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 734\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['6-30'], ['7-12'], ['12-26'], ['19-15'], ['21-30'], ['24-29'], ['16-24'], ['21-4'], ['24-30'], ['8-31'], ['11-2'], ['24-24'], ['7-13'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['6-30'], ['17-22'], ['12-26'], ['19-15'], ['21-30'], ['7-12'], ['24-29'], ['16-24'], ['21-4'], ['24-30'], ['8-31'], ['11-2'], ['7-13'], ['15-14'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['6-30'], ['17-22'], ['12-26'], ['19-15'], ['7-12'], ['21-30'], ['24-29'], ['16-24'], ['21-4'], ['24-30'], ['8-31'], ['11-2'], ['7-13'], ['15-14'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 75.53390860557556\n",
      "Response: There are 27 member states in the European Union.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 552\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['6-30'], ['12-26'], ['19-15'], ['21-30'], ['24-29'], ['16-24'], ['21-4'], ['11-2'], ['24-30'], ['8-31'], ['7-13'], ['24-24'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1141\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['6-30'], ['12-26'], ['19-15'], ['21-30'], ['24-29'], ['11-2'], ['16-24'], ['21-4'], ['24-30'], ['8-31'], ['14-18'], ['24-24'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1676\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['6-30'], ['12-26'], ['19-15'], ['21-30'], ['24-29'], ['11-2'], ['16-24'], ['21-4'], ['14-18'], ['24-30'], ['24-24'], ['8-31'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "There are 20 member states in the Eurozone.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['12-26'], ['6-30'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['16-24'], ['21-4'], ['14-18'], ['8-31'], ['24-30'], ['24-24'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['12-26'], ['6-30'], ['19-15'], ['21-30'], ['24-29'], ['11-2'], ['16-24'], ['21-4'], ['14-18'], ['8-31'], ['24-24'], ['24-30'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 91.02389812469482\n",
      "Response: There are 27 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 861\n",
      "There are 20 member states in the Eurozone.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['12-26'], ['6-30'], ['19-15'], ['21-30'], ['24-29'], ['11-2'], ['16-24'], ['21-4'], ['14-18'], ['16-1'], ['24-24'], ['8-31'], ['24-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1742\n",
      "There are 20 member states in the Eurozone.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['12-26'], ['6-30'], ['21-30'], ['24-29'], ['19-15'], ['11-2'], ['16-24'], ['21-4'], ['16-1'], ['14-18'], ['24-24'], ['8-31'], ['24-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2593\n",
      "There are 20 member states in the Eurozone.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['12-26'], ['24-29'], ['21-30'], ['6-30'], ['19-15'], ['11-2'], ['16-24'], ['16-1'], ['21-4'], ['14-18'], ['24-24'], ['8-31'], ['24-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "There are 20 member states in the Eurozone.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['12-26'], ['21-30'], ['24-29'], ['6-30'], ['19-15'], ['11-2'], ['21-4'], ['16-24'], ['16-1'], ['14-18'], ['24-24'], ['26-28'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "There are 20 member states in the Eurozone.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['12-26'], ['21-30'], ['24-29'], ['6-30'], ['19-15'], ['11-2'], ['21-4'], ['16-1'], ['16-24'], ['14-18'], ['24-24'], ['26-28'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 91.02389812469482\n",
      "Response: There are 27 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1141\n",
      "There are 20 member states in the Eurozone.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['12-26'], ['24-29'], ['21-30'], ['6-30'], ['19-15'], ['11-2'], ['16-1'], ['16-24'], ['21-4'], ['14-18'], ['24-24'], ['26-28'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2374\n",
      "There are 20 member states in the Eurozone.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['12-26'], ['24-29'], ['21-30'], ['11-2'], ['6-30'], ['19-15'], ['16-1'], ['16-24'], ['21-4'], ['14-18'], ['24-24'], ['26-28'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3540\n",
      "There are 20 member states in the Eurozone.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['24-29'], ['12-26'], ['21-30'], ['11-2'], ['6-30'], ['19-15'], ['16-1'], ['16-24'], ['14-18'], ['21-4'], ['24-24'], ['8-31'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 80.56870102882385\n",
      "Response: There are 20 member states in the Eurozone. It was originally used in this sense from 2007 until Croatia's accession in 2013, and during the Brexit negotiations from 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "There are 20 member states in the Eurozone.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['12-26'], ['24-29'], ['21-30'], ['11-2'], ['19-15'], ['6-30'], ['16-1'], ['16-24'], ['21-4'], ['14-18'], ['24-24'], ['26-28'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: There are 20 member states in the Eurozone.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_193_irrelevant_misleading/llama-2-7b-80k_id_193_irrelevant_misleading_len_5000_depth_10000_results.json\n"
     ]
    }
   ],
   "source": [
    "for id in id_vals:\n",
    "    for context_type in [\"relevant\", \"irrelevant\"]:\n",
    "        for with_misleading in [False, True]:\n",
    "            args = get_args(id, context_type, with_misleading)\n",
    "            run_test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Relevant context without misleading statements\n",
    "# args = get_args(id=id_val, context_type=\"relevant\", with_misleading=False)\n",
    "# run_test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Irrelevant context without misleading statements\n",
    "# args = get_args(id=id_val, context_type=\"irrelevant\", with_misleading=False)\n",
    "# run_test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exmample 3: Relevant context with misleading statements\n",
    "# args = get_args(id=id_val, context_type=\"relevant\", with_misleading=True)\n",
    "# run_test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Irrelevant context with misleading statements\n",
    "# args = get_args(id=id_val, context_type=\"irrelevant\", with_misleading=True)\n",
    "# run_test(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
