{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "\n",
    "This notebook provides an faster testing interface. \n",
    "\n",
    "It includes steps to \n",
    " - Check GPU availability\n",
    " - Set up the environment, \n",
    " - Define helper functions,\n",
    " - Run tests with a given **id** and **context_type**. \n",
    "\n",
    "The results are saved for further analysis.\n",
    "\n",
    "*Make sure to select the created `venv` as your kernel.*\n",
    "\n",
    "If there are any errors while running the tests, restart the the notebook, and run again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GPU Availability\n",
    "Run this cell to check if there is free space on the gpu. \n",
    "\n",
    "If the **free space** is not close to the **total space** then someone else is probably using the machine. \n",
    "\n",
    "You can check the active processes bu running `nvidia-smi` in the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: 23.2003 GiB free / 23.5746 GiB total\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_gpu_memory_torch():\n",
    "    if torch.cuda.is_available():\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            free_mem = torch.cuda.mem_get_info(i)[0] / 1024**3\n",
    "            total_mem = torch.cuda.get_device_properties(i).total_memory / 1024**3\n",
    "            print(f\"GPU {i}: {free_mem:.4f} GiB free / {total_mem:.4f} GiB total\")\n",
    "    else:\n",
    "        print(\"No CUDA-compatible GPU detected.\")\n",
    "\n",
    "get_gpu_memory_torch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "The code below imports necessary modules, defines directory paths, and sets the Hugging Face cache path.\n",
    "\n",
    "**No need to modify this.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_DIR = Path.cwd()\n",
    "HAYSTACK_DIR = PROJECT_DIR / \"haystack\"\n",
    "RELEVANT_DIR = HAYSTACK_DIR / \"relevant\"\n",
    "IRRELAVANT_DIR = HAYSTACK_DIR / \"irrelevant\"\n",
    "MISLEADING_IN_RELEVANT_DIR = HAYSTACK_DIR / \"misleading_in_relevant\"\n",
    "MISLEADING_IN_IRRELEVANT_DIR = HAYSTACK_DIR / \"misleading_in_irrelevant\"\n",
    "\n",
    "sys.path.append(str(PROJECT_DIR))\n",
    "\n",
    "with open(HAYSTACK_DIR / \"needles.json\", \"r\") as f:\n",
    "    NEEDLES_DATA = json.load(f)\n",
    "\n",
    "# This sets the Hugging Face cache path. Make sure this directory exists. If not, refer to the README.\n",
    "os.environ['HF_HOME'] = '.cache/hf_with_quota'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/student/projects1/2021/jiajfang/SNLP_Project/venv/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "def load_text(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "def insert_strings_at_sentence_breaks(text, insert_strings, context_length, tokenizer):\n",
    "    # Step 1: Tokenize and truncate\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=False)[:context_length]\n",
    "    \n",
    "    # Step 2: Detect sentence breaks by decoding each token\n",
    "    sentence_break_indices = [\n",
    "        i for i, tok in enumerate(tokens)\n",
    "        if tokenizer.decode([tok]).strip().endswith((\".\", \"!\", \"?\"))\n",
    "    ]\n",
    "\n",
    "    if len(sentence_break_indices) < len(insert_strings):\n",
    "        raise ValueError(f\"Only {len(sentence_break_indices)} sentence breaks found, \"\n",
    "                         f\"but {len(insert_strings)} insertions requested.\")\n",
    "\n",
    "    # Step 3: Compute evenly spaced sentence break positions\n",
    "    step = len(sentence_break_indices) // (len(insert_strings) + 1)\n",
    "    insert_positions = [sentence_break_indices[(i + 1) * step] + 1 for i in range(len(insert_strings))]\n",
    "\n",
    "    # Step 4: Insert insert_strings as tokens\n",
    "    for pos, insert_str in reversed(list(zip(insert_positions, insert_strings))):\n",
    "        insert_tokens = tokenizer.encode(insert_str, add_special_tokens=False)\n",
    "        tokens[pos:pos] = insert_tokens\n",
    "\n",
    "    return tokenizer.decode(tokens)\n",
    "\n",
    "\n",
    "def insert_misleading_statements(filepath, insert_strings, context_length, output_path):\n",
    "    \"\"\"\n",
    "    Insert misleading statements into the text at sentence breaks.\n",
    "    Evenly distribute the misleading statements across the text within the context length.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"yaofu/llama-2-7b-80k\")\n",
    "\n",
    "    full_text = load_text(filepath)\n",
    "    modified_text = insert_strings_at_sentence_breaks(full_text, insert_strings, context_length, tokenizer)\n",
    "\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(modified_text)\n",
    "\n",
    "    print(f\"âœ… Output saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "def get_haystack_file(item, context_type, with_misleading, context_length):\n",
    "    \"\"\"\n",
    "    Get the haystack file for the given item and context type.\n",
    "    Arguments:\n",
    "        item (dict): The item to process.\n",
    "        context_type (str): The type of context (\"relevant\" or \"irrelevant\").\n",
    "        with_misleading (bool): Whether to include misleading information.\n",
    "    Returns:\n",
    "        str: The path to the haystack file.\n",
    "    \"\"\"\n",
    "\n",
    "    if context_type == \"relevant\":\n",
    "        original_dir = RELEVANT_DIR\n",
    "        original_file = item[\"context_relevant\"]  # Original file without misleading info\n",
    "        misleading_dir = MISLEADING_IN_RELEVANT_DIR  # Output dir for the misleading file\n",
    "    elif context_type == \"irrelevant\":\n",
    "        original_dir = IRRELAVANT_DIR\n",
    "        original_file = item[\"context_irrelevant\"]\n",
    "        misleading_dir = MISLEADING_IN_IRRELEVANT_DIR\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown context_type: {context_type}\")\n",
    "\n",
    "    if with_misleading:\n",
    "        haystack_file = misleading_dir / original_file\n",
    "        insert_misleading_statements(\n",
    "            filepath=original_dir / original_file,           # Path to the original context file\n",
    "            insert_strings=item[\"statements_misleading\"],    # List of misleading statements\n",
    "            context_length=context_length,                   # Max context length for insertion\n",
    "            output_path=haystack_file                        # Output path for the processed file\n",
    "        )\n",
    "    else:\n",
    "        haystack_file = original_dir / original_file\n",
    "\n",
    "    return haystack_file\n",
    "\n",
    "def get_args(id, context_type, with_misleading, data=NEEDLES_DATA):\n",
    "    \"\"\"\n",
    "    Get the arguments for the given id and context type.\n",
    "    Arguments:\n",
    "        id (int): The id of the item.\n",
    "        context_type (str): The type of context (\"relevant\" or \"irrelevant\").\n",
    "        with_misleading (bool): Whether to include misleading information.\n",
    "        data (list): The list of data items.\n",
    "    Returns:\n",
    "        Namespace: The arguments for the given id and context type.\n",
    "    \"\"\"\n",
    "\n",
    "    context_length_max = 5000\n",
    "    \n",
    "    # find the item with the given id\n",
    "    item = next(item for item in data if item[\"id\"] == id)\n",
    "\n",
    "    # get the haystack file for the given item and context type\n",
    "    haystack_file = get_haystack_file(item, context_type, with_misleading, context_length_max)\n",
    "\n",
    "    args = Namespace(\n",
    "        model_name = \"yaofu/llama-2-7b-80k\",\n",
    "        model_name_suffix = ( f\"id_{item['id']}_{context_type}\" if not with_misleading \n",
    "                             else f\"id_{item['id']}_{context_type}_misleading\"), # suffix used to name the results files,\n",
    "        model_provider = \"LLaMA\",\n",
    "\n",
    "        context_lengths_min = 0, # min context length\n",
    "        context_lengths_max = context_length_max, # max context length\n",
    "        context_lengths_num_intervals = 5, # number of intervals for context lengths\n",
    "\n",
    "        document_depth_percent_intervals = 5, # number of intervals for document depth\n",
    "\n",
    "        needle = item[\"needle_refined\"],\n",
    "        real_needle = item[\"real_needle_refined\"],\n",
    "        retrieval_question = item[\"question_refined\"],\n",
    "        haystack_file = haystack_file,\n",
    "    )\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "from retrieval_head_detection import LLMNeedleHaystackTester as RetrievalHeads\n",
    "\n",
    "def cleanup(tester: RetrievalHeads):\n",
    "    del tester.model_to_test\n",
    "    del tester.testing_results\n",
    "    del tester.head_counter\n",
    "    del tester\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "\n",
    "def run_test(args):\n",
    "    try:\n",
    "        tester = RetrievalHeads(**vars(args))\n",
    "        tester.start_test()\n",
    "    finally:\n",
    "        cleanup(tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable path:\n",
      "/cs/student/projects1/2021/jiajfang/SNLP_Project/venv/bin/python\n",
      "\n",
      "Python environment site-packages:\n",
      "['/usr/lib64/python39.zip', '/usr/lib64/python3.9', '/usr/lib64/python3.9/lib-dynload', '', '/cs/student/projects1/2021/jiajfang/SNLP_Project/venv/lib64/python3.9/site-packages', '/cs/student/projects1/2021/jiajfang/SNLP_Project/venv/lib/python3.9/site-packages', '/cs/student/projects1/2021/jiajfang/SNLP_Project', '/tmp/tmpajuruwil', './faiss_attn/']\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python executable path:\")\n",
    "print(sys.executable)\n",
    "\n",
    "print(\"\\nPython environment site-packages:\")\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runing the Tests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the test object:\n",
    "Specify the **id** and the **context_type** in the `get_args` function.\n",
    "\n",
    "If `with_misleading` is True, then misleading statements are added to the specified `context_type` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the Test\n",
    "\n",
    "Running the test will save:\n",
    "\n",
    "- **Contexts** â†’ Given to the model per context length/depth  \n",
    "  â†’ `contexts/{model_name}_{context_type}_id_{id}`\n",
    "\n",
    "- **Results** â†’ Model outputs per context length/depth  \n",
    "  â†’ `results/graph/{model_name}_{context_type}_id_{id}`\n",
    "\n",
    "**Example**:  \n",
    "`results/graph/llama-2-7b-80k_relevant_id_44/`\n",
    "\n",
    "Each test should take <=5 minutes. It sometimes uses the CPU instead of the GPU, if it is taking longer to finish, then restart the notebook and run again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 11, 121, 122, 123, 124, 14, 15, 155, 16, 160, 163, 164, 167]\n"
     ]
    }
   ],
   "source": [
    "ids = []\n",
    "for file_name in os.listdir('./haystack/irrelevant'):\n",
    "    if file_name.endswith('.txt'):\n",
    "        file_id = os.path.splitext(file_name)[0]  # Extract the file name without extension\n",
    "        ids.append(file_id)\n",
    "ids.sort()\n",
    "id_vals = [int(i) for i in ids[0:14]]\n",
    "print(id_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation=\"flash_attention_2\"` instead.\n",
      "LlamaForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From ðŸ‘‰v4.50ðŸ‘ˆ onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['17-22'], ['12-26'], ['8-26'], ['21-30'], ['18-30'], ['6-30'], ['14-18'], ['24-29'], ['0-11'], ['11-2'], ['15-14'], ['19-10'], ['19-15'], ['22-22'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['17-22'], ['12-26'], ['8-26'], ['21-30'], ['18-30'], ['6-30'], ['14-18'], ['24-29'], ['0-11'], ['11-2'], ['15-14'], ['19-10'], ['19-15'], ['22-22'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['17-22'], ['12-26'], ['8-26'], ['21-30'], ['18-30'], ['6-30'], ['14-18'], ['24-29'], ['0-11'], ['11-2'], ['15-14'], ['19-10'], ['19-15'], ['22-22'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['17-22'], ['12-26'], ['8-26'], ['21-30'], ['18-30'], ['6-30'], ['14-18'], ['24-29'], ['0-11'], ['11-2'], ['15-14'], ['19-10'], ['19-15'], ['22-22'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_0_depth_7500_results.json\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['17-22'], ['12-26'], ['8-26'], ['21-30'], ['18-30'], ['6-30'], ['14-18'], ['24-29'], ['0-11'], ['11-2'], ['15-14'], ['19-10'], ['19-15'], ['22-22'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['17-22'], ['12-26'], ['8-26'], ['21-30'], ['18-30'], ['14-18'], ['6-30'], ['24-29'], ['11-2'], ['0-11'], ['15-14'], ['19-10'], ['19-15'], ['22-22'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 93.18246245384216\n",
      "Response: On September 27, 2020, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_1250_depth_0_results.json\n",
      "insertion at 247\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['12-26'], ['21-30'], ['18-30'], ['14-18'], ['24-29'], ['6-30'], ['11-2'], ['19-15'], ['22-22'], ['15-14'], ['19-10'], ['0-11'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 79.90259528160095\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved. Part of the greater region of Karabakh, it spans the area between Lower Karabakh and Syunik. Its terrain mostly consists of\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 434\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['21-30'], ['12-26'], ['18-30'], ['24-29'], ['14-18'], ['11-2'], ['19-15'], ['22-22'], ['6-30'], ['15-14'], ['19-10'], ['7-12'], ['0-11'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 80.67930340766907\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved. The region is usually equated with the administrative borders of the former Nagorno-Karabakh Autonomous Oblast, comprising 4,\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 736\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['21-30'], ['18-30'], ['12-26'], ['24-29'], ['14-18'], ['19-15'], ['11-2'], ['22-22'], ['15-14'], ['6-30'], ['7-12'], ['19-10'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 87.94610500335693\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved. The Artsakh forces collapsed rapidly, resulting in an Azerbaijani victory, the dissolution of the Republic of Artsakh, the ex\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_1250_depth_7500_results.json\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['21-30'], ['12-26'], ['18-30'], ['24-29'], ['19-15'], ['11-2'], ['14-18'], ['15-14'], ['6-30'], ['22-22'], ['7-12'], ['19-10'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "-- Test Summary -- \n",
      "Duration: 3.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 34.89086031913757\n",
      "Response: On 27 September 2020, the Second Nagorno-Karabakh War broke out with an Azerbaijani offensive in Nagorno-Karabakh and the surrounding territories. Azerbaijan made\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_2500_depth_0_results.json\n",
      "insertion at 552\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['18-30'], ['12-26'], ['24-29'], ['19-15'], ['11-2'], ['15-14'], ['14-18'], ['7-12'], ['22-22'], ['6-30'], ['19-10'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 79.00428175926208\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved. Azerbaijan made significant gains during the war, regaining all of the occupied territories surrounding Nagorno-Karabakh and capt\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1139\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['18-30'], ['19-15'], ['24-29'], ['12-26'], ['7-12'], ['11-2'], ['15-14'], ['14-18'], ['22-22'], ['6-30'], ['19-10'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1689\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['18-30'], ['19-15'], ['7-12'], ['24-29'], ['12-26'], ['15-14'], ['11-2'], ['14-18'], ['22-22'], ['6-30'], ['19-10'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 82.15346336364746\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved. At the time the population of Artsakh and Utik consisted of Armenians and several Armenized tribes. Armenian culture and civilization flourished\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_2500_depth_7500_results.json\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['18-30'], ['19-15'], ['24-29'], ['12-26'], ['7-12'], ['15-14'], ['11-2'], ['14-18'], ['22-22'], ['6-30'], ['19-10'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "-- Test Summary -- \n",
      "Duration: 4.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 34.89086031913757\n",
      "Response: On 27 September 2020, the Second Nagorno-Karabakh War broke out with an Azerbaijani offensive in Nagorno-Karabakh and the surrounding territories. Azerbaijan made\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_3750_depth_0_results.json\n",
      "insertion at 814\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['18-30'], ['19-15'], ['7-12'], ['24-29'], ['12-26'], ['15-14'], ['11-2'], ['14-18'], ['22-22'], ['6-30'], ['19-10'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1730\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['18-30'], ['19-15'], ['7-12'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['14-18'], ['22-22'], ['6-30'], ['19-10'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2598\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['18-30'], ['7-12'], ['19-15'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['14-18'], ['22-22'], ['6-30'], ['19-10'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 69.40614581108093\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved. These five principalities in Karabakh were ruled by Armenian families who had received the title Melik (prince) and were the following:\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_3750_depth_7500_results.json\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['18-30'], ['19-15'], ['7-12'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['14-18'], ['22-22'], ['6-30'], ['19-10'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['18-30'], ['19-15'], ['7-12'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['14-18'], ['22-22'], ['6-30'], ['19-10'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 92.46535301208496\n",
      "Response: The Republic of Artsakh was formally dissolved on September 27, 2020.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1139\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['18-30'], ['7-12'], ['19-15'], ['11-2'], ['24-29'], ['15-14'], ['12-26'], ['14-18'], ['22-22'], ['19-10'], ['6-30'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2380\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['18-30'], ['21-30'], ['19-15'], ['11-2'], ['24-29'], ['15-14'], ['12-26'], ['14-18'], ['22-22'], ['19-10'], ['17-31'], ['6-30'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3553\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['18-30'], ['21-30'], ['19-15'], ['11-2'], ['24-29'], ['15-14'], ['12-26'], ['14-18'], ['22-22'], ['19-10'], ['17-31'], ['6-30'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 76.08059644699097\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved. The British command provisionally affirmed Khosrov bey Sultanov (appointed by the Azerbaijani government) as the\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_5000_depth_7500_results.json\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['7-12'], ['18-30'], ['19-15'], ['11-2'], ['24-29'], ['15-14'], ['12-26'], ['14-18'], ['22-22'], ['19-10'], ['17-31'], ['6-30'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant/llama-2-7b-80k_id_1_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/1.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['17-22'], ['12-26'], ['8-26'], ['21-30'], ['18-30'], ['6-30'], ['14-18'], ['24-29'], ['0-11'], ['11-2'], ['15-14'], ['19-10'], ['19-15'], ['22-22'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['17-22'], ['12-26'], ['8-26'], ['21-30'], ['18-30'], ['6-30'], ['14-18'], ['24-29'], ['0-11'], ['11-2'], ['15-14'], ['19-10'], ['19-15'], ['22-22'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['17-22'], ['12-26'], ['8-26'], ['21-30'], ['18-30'], ['6-30'], ['14-18'], ['24-29'], ['0-11'], ['11-2'], ['15-14'], ['19-10'], ['19-15'], ['22-22'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['17-22'], ['12-26'], ['8-26'], ['21-30'], ['18-30'], ['6-30'], ['14-18'], ['24-29'], ['0-11'], ['11-2'], ['15-14'], ['19-10'], ['19-15'], ['22-22'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_0_depth_7500_results.json\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['17-22'], ['12-26'], ['8-26'], ['21-30'], ['18-30'], ['6-30'], ['14-18'], ['24-29'], ['0-11'], ['11-2'], ['15-14'], ['19-10'], ['19-15'], ['22-22'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['17-22'], ['12-26'], ['8-26'], ['21-30'], ['18-30'], ['14-18'], ['6-30'], ['24-29'], ['11-2'], ['0-11'], ['15-14'], ['19-10'], ['19-15'], ['22-22'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 93.18246245384216\n",
      "Response: On September 27, 2020, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 247\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['12-26'], ['21-30'], ['18-30'], ['14-18'], ['24-29'], ['6-30'], ['11-2'], ['19-15'], ['22-22'], ['15-14'], ['19-10'], ['0-11'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 79.90259528160095\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved. Part of the greater region of Karabakh, it spans the area between Lower Karabakh and Syunik. Its terrain mostly consists of\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 434\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['21-30'], ['12-26'], ['18-30'], ['24-29'], ['14-18'], ['11-2'], ['19-15'], ['22-22'], ['6-30'], ['15-14'], ['19-10'], ['7-12'], ['0-11'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 80.67930340766907\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved. The region is usually equated with the administrative borders of the former Nagorno-Karabakh Autonomous Oblast, comprising 4,\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 736\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['21-30'], ['18-30'], ['12-26'], ['24-29'], ['14-18'], ['19-15'], ['11-2'], ['22-22'], ['15-14'], ['6-30'], ['7-12'], ['19-10'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 87.94610500335693\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved. The Artsakh forces collapsed rapidly, resulting in an Azerbaijani victory, the dissolution of the Republic of Artsakh, the ex\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_1250_depth_7500_results.json\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['21-30'], ['12-26'], ['18-30'], ['24-29'], ['19-15'], ['11-2'], ['14-18'], ['15-14'], ['6-30'], ['22-22'], ['7-12'], ['19-10'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['21-30'], ['12-26'], ['18-30'], ['24-29'], ['19-15'], ['11-2'], ['14-18'], ['15-14'], ['22-22'], ['6-30'], ['7-12'], ['19-10'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 93.34287643432617\n",
      "Response: The Republic of Artsakh was formally dissolved on September 27, 2023.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 552\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['18-30'], ['12-26'], ['24-29'], ['19-15'], ['11-2'], ['14-18'], ['15-14'], ['7-12'], ['22-22'], ['6-30'], ['19-10'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 79.00428175926208\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved. Azerbaijan made significant gains during the war, regaining all of the occupied territories surrounding Nagorno-Karabakh and capt\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1114\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['18-30'], ['19-15'], ['12-26'], ['24-29'], ['7-12'], ['11-2'], ['15-14'], ['14-18'], ['22-22'], ['6-30'], ['19-10'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1645\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['18-30'], ['7-12'], ['19-15'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['14-18'], ['22-22'], ['6-30'], ['19-10'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_2500_depth_7500_results.json\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['18-30'], ['19-15'], ['24-29'], ['11-2'], ['7-12'], ['12-26'], ['15-14'], ['14-18'], ['22-22'], ['6-30'], ['19-10'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['18-30'], ['19-15'], ['7-12'], ['11-2'], ['24-29'], ['12-26'], ['15-14'], ['14-18'], ['22-22'], ['6-30'], ['19-10'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 93.34287643432617\n",
      "Response: The Republic of Artsakh was formally dissolved on September 27, 2023.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 814\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['18-30'], ['7-12'], ['19-15'], ['11-2'], ['24-29'], ['15-14'], ['12-26'], ['14-18'], ['22-22'], ['6-30'], ['19-10'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1754\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['18-30'], ['7-12'], ['19-15'], ['11-2'], ['24-29'], ['15-14'], ['12-26'], ['14-18'], ['22-22'], ['6-30'], ['19-10'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2601\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['18-30'], ['7-12'], ['19-15'], ['11-2'], ['24-29'], ['15-14'], ['12-26'], ['14-18'], ['22-22'], ['19-10'], ['6-30'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 74.2792010307312\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved. The Armenian meliks were granted supreme command over neighbouring Armenian principalities and Muslim khans in the Caucasus by the\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_3750_depth_7500_results.json\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['18-30'], ['7-12'], ['19-15'], ['11-2'], ['24-29'], ['15-14'], ['12-26'], ['14-18'], ['22-22'], ['19-10'], ['6-30'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['18-30'], ['7-12'], ['19-15'], ['11-2'], ['24-29'], ['15-14'], ['12-26'], ['14-18'], ['22-22'], ['19-10'], ['6-30'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 85.6707751750946\n",
      "Response: The Republic of Artsakh was formally dissolved on 27 September 2020, after the Second Nagorno-Karabakh War.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1163\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['18-30'], ['7-12'], ['19-15'], ['11-2'], ['24-29'], ['15-14'], ['14-18'], ['12-26'], ['22-22'], ['19-10'], ['6-30'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2365\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['7-12'], ['18-30'], ['19-15'], ['11-2'], ['24-29'], ['15-14'], ['14-18'], ['12-26'], ['22-22'], ['19-10'], ['17-31'], ['6-30'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3582\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['7-12'], ['18-30'], ['19-15'], ['11-2'], ['24-29'], ['15-14'], ['14-18'], ['12-26'], ['22-22'], ['19-10'], ['17-31'], ['6-30'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_5000_depth_7500_results.json\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['18-30'], ['7-12'], ['19-15'], ['11-2'], ['24-29'], ['15-14'], ['14-18'], ['12-26'], ['22-22'], ['19-10'], ['17-31'], ['6-30'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_relevant_misleading/llama-2-7b-80k_id_1_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['17-22'], ['12-26'], ['8-26'], ['21-30'], ['18-30'], ['6-30'], ['14-18'], ['24-29'], ['0-11'], ['11-2'], ['15-14'], ['19-10'], ['19-15'], ['22-22'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['17-22'], ['12-26'], ['8-26'], ['21-30'], ['18-30'], ['6-30'], ['14-18'], ['24-29'], ['0-11'], ['11-2'], ['15-14'], ['19-10'], ['19-15'], ['22-22'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['17-22'], ['12-26'], ['8-26'], ['21-30'], ['18-30'], ['6-30'], ['14-18'], ['24-29'], ['0-11'], ['11-2'], ['15-14'], ['19-10'], ['19-15'], ['22-22'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['17-22'], ['12-26'], ['8-26'], ['21-30'], ['18-30'], ['6-30'], ['14-18'], ['24-29'], ['0-11'], ['11-2'], ['15-14'], ['19-10'], ['19-15'], ['22-22'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_0_depth_7500_results.json\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['17-22'], ['12-26'], ['8-26'], ['21-30'], ['18-30'], ['6-30'], ['14-18'], ['24-29'], ['0-11'], ['11-2'], ['15-14'], ['19-10'], ['19-15'], ['22-22'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['17-22'], ['12-26'], ['8-26'], ['21-30'], ['18-30'], ['14-18'], ['24-29'], ['6-30'], ['11-2'], ['15-14'], ['19-10'], ['19-15'], ['0-11'], ['22-22'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 99.28431510925293\n",
      "Response: The Republic of Artsakh was formally dissolved on January 1, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 256\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['12-26'], ['21-30'], ['18-30'], ['14-18'], ['24-29'], ['11-2'], ['6-30'], ['15-14'], ['19-10'], ['19-15'], ['22-22'], ['17-31'], ['0-11'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 294\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['21-30'], ['12-26'], ['18-30'], ['14-18'], ['11-2'], ['24-29'], ['15-14'], ['19-15'], ['19-10'], ['6-30'], ['7-12'], ['17-31'], ['22-22'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 740\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['21-30'], ['18-30'], ['12-26'], ['11-2'], ['14-18'], ['24-29'], ['15-14'], ['7-12'], ['19-15'], ['19-10'], ['6-30'], ['17-31'], ['22-22'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_1250_depth_7500_results.json\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['21-30'], ['18-30'], ['12-26'], ['11-2'], ['24-29'], ['14-18'], ['19-15'], ['15-14'], ['7-12'], ['19-10'], ['6-30'], ['17-31'], ['22-22'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['17-22'], ['8-26'], ['21-30'], ['18-30'], ['12-26'], ['11-2'], ['14-18'], ['24-29'], ['7-12'], ['15-14'], ['19-15'], ['19-10'], ['6-30'], ['17-31'], ['22-22'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 526\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['17-22'], ['8-26'], ['21-30'], ['18-30'], ['7-12'], ['12-26'], ['11-2'], ['14-18'], ['24-29'], ['15-14'], ['19-15'], ['19-10'], ['17-31'], ['6-30'], ['22-22'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1084\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['18-30'], ['7-12'], ['11-2'], ['12-26'], ['24-29'], ['14-18'], ['19-15'], ['15-14'], ['19-10'], ['17-31'], ['6-30'], ['22-22'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1661\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['7-12'], ['18-30'], ['11-2'], ['12-26'], ['19-15'], ['24-29'], ['14-18'], ['15-14'], ['19-10'], ['17-31'], ['6-30'], ['22-22'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_2500_depth_7500_results.json\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['18-30'], ['7-12'], ['11-2'], ['12-26'], ['19-15'], ['24-29'], ['14-18'], ['15-14'], ['19-10'], ['17-31'], ['6-30'], ['22-22'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['7-12'], ['18-30'], ['11-2'], ['12-26'], ['24-29'], ['14-18'], ['19-15'], ['15-14'], ['19-10'], ['17-31'], ['6-30'], ['22-22'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 843\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['17-22'], ['7-12'], ['21-30'], ['18-30'], ['11-2'], ['24-29'], ['12-26'], ['19-15'], ['14-18'], ['15-14'], ['19-10'], ['17-31'], ['6-30'], ['22-22'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1736\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['18-30'], ['11-2'], ['24-29'], ['19-15'], ['12-26'], ['14-18'], ['15-14'], ['19-10'], ['17-31'], ['6-30'], ['22-22'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2636\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['18-30'], ['11-2'], ['19-15'], ['24-29'], ['12-26'], ['14-18'], ['15-14'], ['19-10'], ['17-31'], ['6-30'], ['22-22'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_3750_depth_7500_results.json\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['18-30'], ['11-2'], ['19-15'], ['24-29'], ['12-26'], ['14-18'], ['15-14'], ['19-10'], ['17-31'], ['6-30'], ['22-22'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['11-2'], ['18-30'], ['19-15'], ['24-29'], ['12-26'], ['14-18'], ['15-14'], ['19-10'], ['17-31'], ['22-22'], ['6-30'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1187\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['21-30'], ['11-2'], ['18-30'], ['19-15'], ['24-29'], ['14-18'], ['12-26'], ['15-14'], ['17-31'], ['19-10'], ['22-22'], ['6-30'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2386\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['21-30'], ['11-2'], ['18-30'], ['19-15'], ['24-29'], ['14-18'], ['12-26'], ['15-14'], ['17-31'], ['19-10'], ['22-22'], ['6-30'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3578\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['21-30'], ['11-2'], ['18-30'], ['19-15'], ['24-29'], ['14-18'], ['12-26'], ['15-14'], ['17-31'], ['19-10'], ['22-22'], ['6-30'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 80.93641996383667\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved. Following Qajar Iran's loss, it was forced to concede suzerainty over most of the khanates, along with Georgia\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_5000_depth_7500_results.json\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['21-30'], ['11-2'], ['18-30'], ['19-15'], ['24-29'], ['12-26'], ['14-18'], ['15-14'], ['17-31'], ['19-10'], ['22-22'], ['6-30'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant/llama-2-7b-80k_id_1_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/1.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['17-22'], ['12-26'], ['8-26'], ['21-30'], ['18-30'], ['6-30'], ['14-18'], ['24-29'], ['0-11'], ['11-2'], ['15-14'], ['19-10'], ['19-15'], ['22-22'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['17-22'], ['12-26'], ['8-26'], ['21-30'], ['18-30'], ['6-30'], ['14-18'], ['24-29'], ['0-11'], ['11-2'], ['15-14'], ['19-10'], ['19-15'], ['22-22'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['17-22'], ['12-26'], ['8-26'], ['21-30'], ['18-30'], ['6-30'], ['14-18'], ['24-29'], ['0-11'], ['11-2'], ['15-14'], ['19-10'], ['19-15'], ['22-22'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['17-22'], ['12-26'], ['8-26'], ['21-30'], ['18-30'], ['6-30'], ['14-18'], ['24-29'], ['0-11'], ['11-2'], ['15-14'], ['19-10'], ['19-15'], ['22-22'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['17-22'], ['12-26'], ['8-26'], ['21-30'], ['18-30'], ['6-30'], ['14-18'], ['24-29'], ['0-11'], ['11-2'], ['15-14'], ['19-10'], ['19-15'], ['22-22'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['7-4'], ['11-15'], ['17-22'], ['12-26'], ['8-26'], ['21-30'], ['18-30'], ['14-18'], ['24-29'], ['6-30'], ['11-2'], ['19-10'], ['15-14'], ['19-15'], ['0-11'], ['22-22'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 99.23424124717712\n",
      "Response: The Republic of Artsakh was formally dissolved on 1 January 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 256\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['21-30'], ['12-26'], ['18-30'], ['14-18'], ['24-29'], ['11-2'], ['6-30'], ['19-10'], ['19-15'], ['15-14'], ['22-22'], ['0-11'], ['17-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 294\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['21-30'], ['12-26'], ['18-30'], ['14-18'], ['11-2'], ['24-29'], ['19-15'], ['19-10'], ['7-12'], ['6-30'], ['15-14'], ['17-31'], ['22-22'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 740\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['18-30'], ['12-26'], ['11-2'], ['14-18'], ['24-29'], ['19-15'], ['7-12'], ['19-10'], ['15-14'], ['17-31'], ['6-30'], ['22-22'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['18-30'], ['12-26'], ['11-2'], ['14-18'], ['24-29'], ['19-15'], ['7-12'], ['19-10'], ['6-30'], ['15-14'], ['17-31'], ['22-22'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['18-30'], ['12-26'], ['11-2'], ['14-18'], ['24-29'], ['19-15'], ['7-12'], ['19-10'], ['15-14'], ['17-31'], ['6-30'], ['22-22'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 99.23424124717712\n",
      "Response: The Republic of Artsakh was formally dissolved on 1 January 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 526\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['18-30'], ['12-26'], ['11-2'], ['7-12'], ['14-18'], ['19-15'], ['24-29'], ['19-10'], ['15-14'], ['17-31'], ['6-30'], ['22-22'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1108\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['18-30'], ['7-12'], ['11-2'], ['12-26'], ['19-15'], ['14-18'], ['24-29'], ['19-10'], ['15-14'], ['17-31'], ['6-30'], ['22-22'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1685\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['18-30'], ['7-12'], ['11-2'], ['19-15'], ['12-26'], ['14-18'], ['24-29'], ['19-10'], ['15-14'], ['17-31'], ['6-30'], ['22-22'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['18-30'], ['7-12'], ['11-2'], ['19-15'], ['12-26'], ['24-29'], ['14-18'], ['15-14'], ['19-10'], ['17-31'], ['6-30'], ['22-22'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['18-30'], ['7-12'], ['11-2'], ['12-26'], ['19-15'], ['14-18'], ['24-29'], ['19-10'], ['15-14'], ['17-31'], ['6-30'], ['22-22'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 95.62865495681763\n",
      "Response: The Republic of Artsakh was formally dissolved in 2023.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 843\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['18-30'], ['7-12'], ['11-2'], ['19-15'], ['12-26'], ['14-18'], ['24-29'], ['19-10'], ['15-14'], ['17-31'], ['6-30'], ['22-22'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1755\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['7-12'], ['18-30'], ['11-2'], ['19-15'], ['12-26'], ['14-18'], ['24-29'], ['19-10'], ['15-14'], ['17-31'], ['22-22'], ['6-30'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 79.23967242240906\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved. The original etymology of this name is thought to have its roots in the once-dominant Zoroastrianism. In the Avesta\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2615\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['7-12'], ['18-30'], ['11-2'], ['19-15'], ['12-26'], ['24-29'], ['14-18'], ['19-10'], ['15-14'], ['17-31'], ['22-22'], ['6-30'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['7-12'], ['18-30'], ['11-2'], ['19-15'], ['12-26'], ['24-29'], ['14-18'], ['15-14'], ['19-10'], ['17-31'], ['22-22'], ['6-30'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['7-12'], ['18-30'], ['11-2'], ['19-15'], ['12-26'], ['24-29'], ['14-18'], ['19-10'], ['15-14'], ['17-31'], ['22-22'], ['6-30'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 95.62865495681763\n",
      "Response: The Republic of Artsakh was formally dissolved in 2023.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1182\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['11-2'], ['18-30'], ['19-15'], ['12-26'], ['24-29'], ['14-18'], ['19-10'], ['15-14'], ['17-31'], ['22-22'], ['6-30'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2388\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['11-2'], ['18-30'], ['19-15'], ['12-26'], ['24-29'], ['14-18'], ['19-10'], ['15-14'], ['17-31'], ['22-22'], ['6-30'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 73.22716116905212\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved. Despite Sassanid rule, Caucasian Albania remained an entity in the region until the 9th century, while fully subordinate\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3584\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['21-30'], ['11-2'], ['18-30'], ['19-15'], ['24-29'], ['12-26'], ['14-18'], ['19-10'], ['15-14'], ['17-31'], ['22-22'], ['6-30'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 77.4731993675232\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved. Russia actively tried to gain possession of the Caucasus region which was, for the most part, in the hands of Iran. In\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['11-2'], ['18-30'], ['19-15'], ['24-29'], ['12-26'], ['14-18'], ['15-14'], ['19-10'], ['17-31'], ['22-22'], ['6-30'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: On 1 January 2024, the Republic of Artsakh was formally dissolved.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_1_irrelevant_misleading/llama-2-7b-80k_id_1_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['14-15'], ['15-14'], ['6-30'], ['14-18'], ['19-14'], ['20-28'], ['20-30'], ['21-30'], ['12-2'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['14-15'], ['15-14'], ['6-30'], ['14-18'], ['19-14'], ['20-28'], ['20-30'], ['21-30'], ['12-2'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['14-15'], ['15-14'], ['6-30'], ['14-18'], ['19-14'], ['20-28'], ['20-30'], ['21-30'], ['12-2'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['14-15'], ['15-14'], ['6-30'], ['14-18'], ['19-14'], ['20-28'], ['20-30'], ['21-30'], ['12-2'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_0_depth_7500_results.json\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['14-15'], ['15-14'], ['6-30'], ['14-18'], ['19-14'], ['20-28'], ['20-30'], ['21-30'], ['12-2'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 45.06490230560303\n",
      "Response: India\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_1250_depth_0_results.json\n",
      "insertion at 187\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['15-14'], ['14-15'], ['21-30'], ['19-14'], ['20-30'], ['6-30'], ['14-18'], ['20-28'], ['16-1'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 500\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['15-14'], ['14-15'], ['21-30'], ['19-14'], ['20-30'], ['6-30'], ['14-18'], ['20-28'], ['17-16'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 84.72975492477417\n",
      "Response: India won the 2024 ICC Men's T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 757\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['15-14'], ['21-30'], ['14-15'], ['16-1'], ['19-14'], ['20-30'], ['14-18'], ['6-30'], ['17-16'], ['20-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 69.64973211288452\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated. Prior to this World Cup, the United States had occasionally hosted West Indies home matches at Central Broward Park in Florida, while a\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_1250_depth_7500_results.json\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['11-2'], ['18-30'], ['24-29'], ['15-14'], ['21-30'], ['14-15'], ['16-1'], ['6-30'], ['19-14'], ['14-18'], ['20-30'], ['17-16'], ['20-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 45.06490230560303\n",
      "Response: India\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_2500_depth_0_results.json\n",
      "insertion at 563\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 45.06490230560303\n",
      "Response: India\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1127\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 45.06490230560303\n",
      "Response: India\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1702\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 45.06490230560303\n",
      "Response: India\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_2500_depth_7500_results.json\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['11-2'], ['18-30'], ['24-29'], ['15-14'], ['21-30'], ['16-1'], ['14-15'], ['6-30'], ['19-14'], ['20-28'], ['14-18'], ['17-16'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 45.06490230560303\n",
      "Response: India\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_3750_depth_0_results.json\n",
      "insertion at 866\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 45.06490230560303\n",
      "Response: India\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1758\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['11-2'], ['18-30'], ['24-29'], ['15-14'], ['21-30'], ['16-1'], ['14-15'], ['6-30'], ['19-14'], ['7-12'], ['14-18'], ['20-28'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2560\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['11-2'], ['18-30'], ['24-29'], ['15-14'], ['21-30'], ['16-1'], ['7-12'], ['6-30'], ['19-14'], ['14-15'], ['14-18'], ['17-16'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_3750_depth_7500_results.json\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['11-2'], ['18-30'], ['24-29'], ['15-14'], ['21-30'], ['16-1'], ['7-12'], ['19-14'], ['6-30'], ['14-15'], ['14-18'], ['17-16'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 84.72975492477417\n",
      "Response: India won the 2024 ICC Men's T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['11-2'], ['18-30'], ['24-29'], ['15-14'], ['21-30'], ['16-1'], ['7-12'], ['19-14'], ['6-30'], ['14-15'], ['14-18'], ['17-16'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 84.72975492477417\n",
      "Response: India won the 2024 ICC Men's T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1164\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['11-2'], ['18-30'], ['24-29'], ['21-30'], ['15-14'], ['16-1'], ['7-12'], ['19-14'], ['6-30'], ['14-15'], ['14-18'], ['17-16'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 84.72975492477417\n",
      "Response: India won the 2024 ICC Men's T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2359\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['11-2'], ['18-30'], ['24-29'], ['21-30'], ['15-14'], ['16-1'], ['7-12'], ['19-14'], ['6-30'], ['14-15'], ['14-18'], ['17-0'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 84.72975492477417\n",
      "Response: India won the 2024 ICC Men's T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3555\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['11-2'], ['18-30'], ['24-29'], ['21-30'], ['15-14'], ['16-1'], ['7-12'], ['19-14'], ['6-30'], ['14-15'], ['14-18'], ['17-0'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 84.72975492477417\n",
      "Response: India won the 2024 ICC Men's T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_5000_depth_7500_results.json\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['11-2'], ['18-30'], ['24-29'], ['21-30'], ['15-14'], ['16-1'], ['19-14'], ['6-30'], ['14-15'], ['7-12'], ['14-18'], ['17-0'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant/llama-2-7b-80k_id_11_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/11.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['14-15'], ['15-14'], ['6-30'], ['14-18'], ['19-14'], ['20-28'], ['20-30'], ['21-30'], ['12-2'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['14-15'], ['15-14'], ['6-30'], ['14-18'], ['19-14'], ['20-28'], ['20-30'], ['21-30'], ['12-2'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['14-15'], ['15-14'], ['6-30'], ['14-18'], ['19-14'], ['20-28'], ['20-30'], ['21-30'], ['12-2'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['14-15'], ['15-14'], ['6-30'], ['14-18'], ['19-14'], ['20-28'], ['20-30'], ['21-30'], ['12-2'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_0_depth_7500_results.json\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['14-15'], ['15-14'], ['6-30'], ['14-18'], ['19-14'], ['20-28'], ['20-30'], ['21-30'], ['12-2'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 45.06490230560303\n",
      "Response: India\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 187\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['15-14'], ['14-15'], ['21-30'], ['19-14'], ['20-30'], ['6-30'], ['14-18'], ['20-28'], ['16-1'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 500\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['15-14'], ['14-15'], ['21-30'], ['19-14'], ['20-30'], ['6-30'], ['14-18'], ['20-28'], ['17-16'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 84.72975492477417\n",
      "Response: India won the 2024 ICC Men's T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 757\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['15-14'], ['21-30'], ['14-15'], ['16-1'], ['19-14'], ['20-30'], ['14-18'], ['6-30'], ['17-16'], ['20-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 69.64973211288452\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated. Prior to this World Cup, the United States had occasionally hosted West Indies home matches at Central Broward Park in Florida, while a\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_1250_depth_7500_results.json\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['11-2'], ['18-30'], ['24-29'], ['15-14'], ['21-30'], ['14-15'], ['16-1'], ['6-30'], ['19-14'], ['14-18'], ['20-30'], ['17-16'], ['20-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['15-14'], ['21-30'], ['16-1'], ['14-15'], ['14-18'], ['19-14'], ['7-12'], ['6-30'], ['17-16'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 563\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['21-30'], ['15-14'], ['16-1'], ['14-15'], ['14-18'], ['7-12'], ['19-14'], ['6-30'], ['17-16'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 84.72975492477417\n",
      "Response: India won the 2024 ICC Men's T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1127\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['11-2'], ['18-30'], ['24-29'], ['21-30'], ['15-14'], ['16-1'], ['14-15'], ['14-18'], ['19-14'], ['7-12'], ['6-30'], ['17-16'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 84.72975492477417\n",
      "Response: India won the 2024 ICC Men's T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1703\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['11-2'], ['18-30'], ['24-29'], ['21-30'], ['15-14'], ['16-1'], ['14-15'], ['14-18'], ['19-14'], ['7-12'], ['6-30'], ['17-16'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 84.72975492477417\n",
      "Response: India won the 2024 ICC Men's T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_2500_depth_7500_results.json\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['11-2'], ['18-30'], ['24-29'], ['21-30'], ['15-14'], ['16-1'], ['14-15'], ['19-14'], ['6-30'], ['14-18'], ['7-12'], ['17-16'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 84.72975492477417\n",
      "Response: India won the 2024 ICC Men's T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['11-2'], ['18-30'], ['24-29'], ['21-30'], ['15-14'], ['16-1'], ['14-15'], ['19-14'], ['6-30'], ['14-18'], ['7-12'], ['17-16'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 84.72975492477417\n",
      "Response: India won the 2024 ICC Men's T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 866\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['19-15'], ['11-2'], ['18-30'], ['24-29'], ['21-30'], ['15-14'], ['7-12'], ['16-1'], ['19-14'], ['14-15'], ['14-18'], ['17-16'], ['6-30'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1759\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['19-15'], ['11-2'], ['18-30'], ['24-29'], ['21-30'], ['15-14'], ['7-12'], ['16-1'], ['19-14'], ['14-15'], ['14-18'], ['17-16'], ['6-30'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 84.72975492477417\n",
      "Response: India won the 2024 ICC Men's T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2643\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['19-15'], ['11-2'], ['18-30'], ['24-29'], ['21-30'], ['7-12'], ['15-14'], ['16-1'], ['19-14'], ['14-18'], ['14-15'], ['17-16'], ['6-30'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_3750_depth_7500_results.json\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['19-15'], ['11-2'], ['18-30'], ['24-29'], ['21-30'], ['15-14'], ['7-12'], ['16-1'], ['19-14'], ['14-15'], ['6-30'], ['14-18'], ['17-16'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 45.06490230560303\n",
      "Response: India\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1163\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 45.06490230560303\n",
      "Response: India\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2373\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 45.06490230560303\n",
      "Response: India\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3536\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 45.06490230560303\n",
      "Response: India\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_5000_depth_7500_results.json\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['19-15'], ['11-2'], ['18-30'], ['24-29'], ['21-30'], ['15-14'], ['16-1'], ['7-12'], ['6-30'], ['14-15'], ['19-14'], ['14-18'], ['17-16'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_relevant_misleading/llama-2-7b-80k_id_11_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['14-15'], ['15-14'], ['6-30'], ['14-18'], ['19-14'], ['20-28'], ['20-30'], ['21-30'], ['12-2'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['14-15'], ['15-14'], ['6-30'], ['14-18'], ['19-14'], ['20-28'], ['20-30'], ['21-30'], ['12-2'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['14-15'], ['15-14'], ['6-30'], ['14-18'], ['19-14'], ['20-28'], ['20-30'], ['21-30'], ['12-2'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['14-15'], ['15-14'], ['6-30'], ['14-18'], ['19-14'], ['20-28'], ['20-30'], ['21-30'], ['12-2'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_0_depth_7500_results.json\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['14-15'], ['15-14'], ['6-30'], ['14-18'], ['19-14'], ['20-28'], ['20-30'], ['21-30'], ['12-2'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 22.266480326652527\n",
      "Response: Australia\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 22.266480326652527\n",
      "Response: Australia\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 433\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 45.06490230560303\n",
      "Response: India\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 433\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 45.06490230560303\n",
      "Response: India\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_1250_depth_7500_results.json\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['15-14'], ['14-15'], ['6-30'], ['20-28'], ['19-14'], ['21-30'], ['20-30'], ['14-18'], ['29-19'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 26.30544602870941\n",
      "Response: England\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 433\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['15-14'], ['14-15'], ['6-30'], ['19-14'], ['21-30'], ['20-28'], ['20-30'], ['14-18'], ['17-16'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 433\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['7-12'], ['15-14'], ['14-15'], ['19-14'], ['21-30'], ['6-30'], ['20-30'], ['20-28'], ['14-18'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1706\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 45.06490230560303\n",
      "Response: India\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_2500_depth_7500_results.json\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['15-14'], ['7-12'], ['6-30'], ['14-15'], ['19-14'], ['21-30'], ['20-30'], ['20-28'], ['14-18'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 26.30544602870941\n",
      "Response: England\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 433\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['7-12'], ['15-14'], ['19-14'], ['6-30'], ['14-15'], ['20-30'], ['21-30'], ['16-1'], ['14-18'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1754\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['11-2'], ['19-15'], ['7-12'], ['18-30'], ['24-29'], ['15-14'], ['21-30'], ['19-14'], ['20-30'], ['6-30'], ['14-15'], ['17-16'], ['16-1'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2551\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['11-2'], ['19-15'], ['7-12'], ['18-30'], ['24-29'], ['15-14'], ['21-30'], ['19-14'], ['20-30'], ['6-30'], ['17-16'], ['14-18'], ['14-15'], ['6-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 89.79165554046631\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated. At the time the decision was made, Japan had never qualified for a World Cup final (although the Japanese did subsequently qualify for the\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_3750_depth_7500_results.json\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['11-2'], ['19-15'], ['7-12'], ['18-30'], ['24-29'], ['15-14'], ['21-30'], ['19-14'], ['6-30'], ['20-30'], ['17-16'], ['14-15'], ['16-1'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 26.30544602870941\n",
      "Response: England\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 433\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['11-2'], ['7-12'], ['19-15'], ['18-30'], ['24-29'], ['15-14'], ['21-30'], ['19-14'], ['16-1'], ['6-16'], ['6-30'], ['20-30'], ['14-18'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2364\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 45.06490230560303\n",
      "Response: India\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3576\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 45.06490230560303\n",
      "Response: India\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_5000_depth_7500_results.json\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['11-2'], ['19-15'], ['7-12'], ['18-30'], ['24-29'], ['15-14'], ['21-30'], ['16-1'], ['19-14'], ['6-30'], ['6-16'], ['20-30'], ['17-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant/llama-2-7b-80k_id_11_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/11.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['14-15'], ['15-14'], ['6-30'], ['14-18'], ['19-14'], ['20-28'], ['20-30'], ['21-30'], ['12-2'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['14-15'], ['15-14'], ['6-30'], ['14-18'], ['19-14'], ['20-28'], ['20-30'], ['21-30'], ['12-2'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['14-15'], ['15-14'], ['6-30'], ['14-18'], ['19-14'], ['20-28'], ['20-30'], ['21-30'], ['12-2'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['14-15'], ['15-14'], ['6-30'], ['14-18'], ['19-14'], ['20-28'], ['20-30'], ['21-30'], ['12-2'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['14-15'], ['15-14'], ['6-30'], ['14-18'], ['19-14'], ['20-28'], ['20-30'], ['21-30'], ['12-2'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 22.266480326652527\n",
      "Response: Australia\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 22.266480326652527\n",
      "Response: Australia\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 433\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 45.06490230560303\n",
      "Response: India\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 433\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 45.06490230560303\n",
      "Response: India\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['15-14'], ['14-15'], ['6-30'], ['20-28'], ['19-14'], ['21-30'], ['20-30'], ['14-18'], ['29-19'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['15-14'], ['14-15'], ['6-30'], ['19-14'], ['21-30'], ['14-18'], ['20-28'], ['20-30'], ['16-1'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 433\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['15-14'], ['7-12'], ['14-15'], ['19-14'], ['21-30'], ['6-30'], ['20-30'], ['16-1'], ['14-18'], ['20-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 433\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['7-12'], ['15-14'], ['21-30'], ['16-1'], ['20-30'], ['19-14'], ['6-30'], ['14-15'], ['14-18'], ['20-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1706\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 45.06490230560303\n",
      "Response: India\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['7-12'], ['15-14'], ['16-1'], ['21-30'], ['14-15'], ['19-14'], ['20-30'], ['6-30'], ['20-28'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['11-2'], ['19-15'], ['18-30'], ['24-29'], ['7-12'], ['15-14'], ['16-1'], ['21-30'], ['14-15'], ['19-14'], ['6-30'], ['20-30'], ['20-28'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 84.72975492477417\n",
      "Response: India won the 2024 ICC Men's T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 433\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['11-2'], ['19-15'], ['18-30'], ['7-12'], ['24-29'], ['15-14'], ['16-1'], ['21-30'], ['19-14'], ['14-15'], ['20-30'], ['6-30'], ['14-18'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1754\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['11-2'], ['19-15'], ['7-12'], ['18-30'], ['24-29'], ['16-1'], ['15-14'], ['21-30'], ['19-14'], ['20-30'], ['14-15'], ['14-18'], ['17-16'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2608\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['11-2'], ['19-15'], ['7-12'], ['18-30'], ['24-29'], ['16-1'], ['15-14'], ['21-30'], ['19-14'], ['20-30'], ['14-15'], ['14-18'], ['17-16'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 84.72975492477417\n",
      "Response: India won the 2024 ICC Men's T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['11-2'], ['19-15'], ['7-12'], ['18-30'], ['24-29'], ['16-1'], ['15-14'], ['21-30'], ['19-14'], ['14-15'], ['6-30'], ['20-30'], ['14-18'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 45.06490230560303\n",
      "Response: India\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 433\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 45.06490230560303\n",
      "Response: India\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2379\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 45.06490230560303\n",
      "Response: India\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3577\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 45.06490230560303\n",
      "Response: India\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['11-2'], ['19-15'], ['18-30'], ['7-12'], ['24-29'], ['16-1'], ['15-14'], ['21-30'], ['19-14'], ['6-30'], ['14-15'], ['20-30'], ['14-18'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: India won all their matches, and were the first team to win a T20 World Cup undefeated.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_11_irrelevant_misleading/llama-2-7b-80k_id_11_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: President Donald Trump hasn't visited any countries during his second presidency.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22'], ['23-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22'], ['23-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22'], ['23-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22'], ['23-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_0_depth_7500_results.json\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22'], ['23-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22'], ['23-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 66.0107970237732\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_1250_depth_0_results.json\n",
      "insertion at 145\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22'], ['23-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 515\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22'], ['23-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 748\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 7.132819294929504\n",
      "Response: Poland\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_1250_depth_7500_results.json\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['19-15'], ['21-27'], ['24-3'], ['11-15'], ['24-29'], ['8-26'], ['13-11'], ['13-30'], ['15-14'], ['19-12'], ['20-11'], ['21-31'], ['22-22'], ['23-7'], ['23-8'], ['23-31'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 11.38073205947876\n",
      "Response: Japan\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_2500_depth_0_results.json\n",
      "insertion at 535\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 11.38073205947876\n",
      "Response: Japan\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1139\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 11.38073205947876\n",
      "Response: Japan\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1704\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 11.38073205947876\n",
      "Response: Japan\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_2500_depth_7500_results.json\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['6-9'], ['19-15'], ['21-27'], ['24-3'], ['11-15'], ['24-29'], ['8-26'], ['15-14'], ['13-11'], ['13-30'], ['19-12'], ['20-11'], ['21-31'], ['22-22'], ['23-7'], ['23-8'], ['23-31'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['6-9'], ['19-15'], ['21-27'], ['24-3'], ['11-15'], ['24-29'], ['8-26'], ['15-14'], ['13-11'], ['13-30'], ['19-12'], ['20-11'], ['21-31'], ['22-22'], ['23-7'], ['23-8'], ['23-31'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 66.0107970237732\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_3750_depth_0_results.json\n",
      "insertion at 875\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['6-9'], ['19-15'], ['21-27'], ['24-3'], ['11-15'], ['24-29'], ['8-26'], ['15-14'], ['13-11'], ['13-30'], ['19-12'], ['20-11'], ['21-31'], ['22-22'], ['23-7'], ['23-8'], ['23-31'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 66.0107970237732\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1762\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['6-9'], ['19-15'], ['21-27'], ['24-3'], ['11-15'], ['24-29'], ['8-26'], ['15-14'], ['23-8'], ['26-26'], ['13-11'], ['13-30'], ['19-12'], ['20-11'], ['21-31'], ['22-22'], ['23-7'], ['23-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 66.0107970237732\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2624\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['6-9'], ['19-15'], ['21-27'], ['24-3'], ['11-15'], ['24-29'], ['15-14'], ['23-8'], ['7-12'], ['8-26'], ['21-31'], ['23-31'], ['24-16'], ['26-26'], ['13-11'], ['13-30'], ['19-12'], ['20-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 66.0107970237732\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_3750_depth_7500_results.json\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['19-15'], ['6-9'], ['24-3'], ['21-27'], ['11-15'], ['24-29'], ['15-14'], ['23-8'], ['8-26'], ['21-31'], ['23-31'], ['24-16'], ['26-26'], ['29-13'], ['29-19'], ['7-12'], ['13-11'], ['13-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 70.81514596939087\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency is the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 4.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: -2.5670865550637245\n",
      "Response: TBD, TBD, TBD, TBD, TBD, TBD, TBD, TBD, TBD, TBD, TBD, TBD, TBD, TBD, TBD, TBD, TBD\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1178\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 3.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 12.631779909133911\n",
      "Response: China,Beijing,November 8â€“10,2025,2026,2027,2028,\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2350\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['19-15'], ['21-30'], ['6-9'], ['24-3'], ['21-27'], ['11-15'], ['24-29'], ['7-12'], ['15-14'], ['23-8'], ['8-26'], ['21-31'], ['23-31'], ['24-11'], ['24-16'], ['26-26'], ['29-13'], ['29-19'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 66.0107970237732\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3465\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 12.217862159013748\n",
      "Response: China, 2025\",\"TBD,  TBD,  TBD,  TBD,  TBD,  TBD,  TBD,  TBD,  TBD,  TBD,  TBD\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_5000_depth_7500_results.json\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['19-15'], ['21-30'], ['24-3'], ['21-27'], ['6-9'], ['11-15'], ['24-29'], ['15-14'], ['7-12'], ['23-8'], ['29-19'], ['8-26'], ['21-31'], ['23-31'], ['24-11'], ['24-16'], ['26-26'], ['29-13'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant/llama-2-7b-80k_id_121_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/121.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: President Donald Trump hasn't visited any countries during his second presidency.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22'], ['23-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22'], ['23-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22'], ['23-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22'], ['23-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_0_depth_7500_results.json\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22'], ['23-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: -4.807101935148239\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 145\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: -4.807101935148239\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 515\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['20-11'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['21-31'], ['22-22'], ['23-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 748\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 7.132819294929504\n",
      "Response: Poland\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_1250_depth_7500_results.json\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['19-15'], ['21-27'], ['24-3'], ['11-15'], ['24-29'], ['20-11'], ['29-19'], ['8-26'], ['13-11'], ['13-30'], ['15-14'], ['19-12'], ['21-31'], ['22-22'], ['23-7'], ['23-8'], ['23-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 15.800672769546509\n",
      "Response: Vietnam\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 535\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 15.800672769546509\n",
      "Response: Vietnam\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1137\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 15.800672769546509\n",
      "Response: Vietnam\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1668\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 15.800672769546509\n",
      "Response: Vietnam\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_2500_depth_7500_results.json\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['6-9'], ['19-15'], ['21-27'], ['24-3'], ['11-15'], ['24-29'], ['29-19'], ['20-11'], ['13-11'], ['13-30'], ['15-14'], ['19-12'], ['21-31'], ['22-22'], ['23-7'], ['23-8'], ['23-31'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['6-9'], ['19-15'], ['21-27'], ['24-3'], ['11-15'], ['24-29'], ['29-19'], ['20-11'], ['13-11'], ['13-30'], ['15-14'], ['19-12'], ['21-31'], ['22-22'], ['23-7'], ['23-8'], ['23-31'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 63.09000849723816\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was India.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 875\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['6-9'], ['19-15'], ['21-27'], ['24-3'], ['11-15'], ['24-29'], ['29-19'], ['13-30'], ['20-11'], ['21-31'], ['13-11'], ['15-14'], ['19-12'], ['22-22'], ['23-7'], ['23-8'], ['23-31'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 63.09000849723816\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was India.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1741\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['6-9'], ['19-15'], ['21-27'], ['24-3'], ['11-15'], ['24-29'], ['13-30'], ['29-19'], ['20-11'], ['21-31'], ['13-11'], ['15-14'], ['19-12'], ['22-22'], ['23-7'], ['23-8'], ['23-31'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 63.09000849723816\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was India.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2592\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['6-9'], ['19-15'], ['24-3'], ['21-27'], ['11-15'], ['24-29'], ['13-30'], ['21-31'], ['29-19'], ['20-11'], ['13-11'], ['15-14'], ['19-12'], ['22-22'], ['23-7'], ['23-8'], ['23-31'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 66.80072546005249\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was Afghanistan.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_3750_depth_7500_results.json\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['19-15'], ['6-9'], ['24-3'], ['21-27'], ['11-15'], ['24-29'], ['13-30'], ['29-19'], ['21-31'], ['15-14'], ['20-11'], ['13-11'], ['19-12'], ['22-22'], ['23-7'], ['23-8'], ['23-31'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: -4.807101935148239\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1195\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: -4.807101935148239\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2387\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: -4.807101935148239\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3539\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: -4.807101935148239\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_5000_depth_7500_results.json\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['19-15'], ['24-3'], ['21-27'], ['6-9'], ['11-15'], ['24-29'], ['29-19'], ['13-30'], ['15-14'], ['21-31'], ['20-11'], ['13-11'], ['22-22'], ['23-7'], ['23-8'], ['23-31'], ['24-11'], ['24-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_relevant_misleading/llama-2-7b-80k_id_121_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: President Donald Trump hasn't visited any countries during his second presidency.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22'], ['23-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22'], ['23-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22'], ['23-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22'], ['23-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_0_depth_7500_results.json\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22'], ['23-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['7-12'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 243\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 17.155563831329346\n",
      "Response: The United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 508\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 17.64192432165146\n",
      "Response: The United States\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 774\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 8.727037161588669\n",
      "Response: Lesotho\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_1250_depth_7500_results.json\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['11-15'], ['15-14'], ['8-26'], ['13-30'], ['29-19'], ['13-11'], ['14-18'], ['15-31'], ['20-11'], ['21-31'], ['22-22'], ['23-7'], ['23-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['19-15'], ['11-15'], ['21-27'], ['24-3'], ['24-29'], ['15-14'], ['7-12'], ['8-26'], ['13-30'], ['14-18'], ['29-19'], ['13-11'], ['15-31'], ['20-11'], ['21-31'], ['22-22'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 65.11536240577698\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was Canada.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 508\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['19-15'], ['11-15'], ['21-27'], ['24-3'], ['24-29'], ['7-12'], ['15-14'], ['8-26'], ['13-30'], ['14-18'], ['29-19'], ['13-11'], ['15-31'], ['20-11'], ['21-31'], ['22-22'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1125\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['19-15'], ['11-15'], ['21-27'], ['24-3'], ['24-29'], ['7-12'], ['14-18'], ['15-14'], ['8-26'], ['13-30'], ['29-19'], ['13-11'], ['15-31'], ['20-11'], ['21-31'], ['22-22'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 65.11536240577698\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was Canada.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1709\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 8.778907358646393\n",
      "Response: Canada\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_2500_depth_7500_results.json\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['6-9'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['11-15'], ['7-12'], ['13-30'], ['14-18'], ['15-14'], ['8-26'], ['29-19'], ['13-11'], ['15-31'], ['20-11'], ['21-31'], ['22-22'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['6-9'], ['19-15'], ['11-15'], ['21-27'], ['24-3'], ['24-29'], ['7-12'], ['13-30'], ['14-18'], ['15-14'], ['8-26'], ['29-19'], ['13-11'], ['15-31'], ['20-11'], ['21-31'], ['22-22'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 66.0107970237732\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 774\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['6-9'], ['19-15'], ['11-15'], ['21-27'], ['24-3'], ['24-29'], ['7-12'], ['13-30'], ['14-18'], ['15-14'], ['8-26'], ['29-19'], ['13-11'], ['15-31'], ['20-11'], ['21-31'], ['22-22'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1760\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['6-9'], ['19-15'], ['11-15'], ['21-27'], ['24-3'], ['24-29'], ['7-12'], ['13-30'], ['14-18'], ['15-14'], ['8-26'], ['26-28'], ['29-19'], ['13-11'], ['15-31'], ['20-11'], ['21-31'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2648\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 16.920405626296997\n",
      "Response: Panama\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_3750_depth_7500_results.json\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['19-15'], ['6-9'], ['21-27'], ['24-3'], ['24-29'], ['11-15'], ['7-12'], ['13-30'], ['14-18'], ['15-14'], ['29-19'], ['8-26'], ['26-28'], ['13-11'], ['15-31'], ['20-11'], ['21-31'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 66.0107970237732\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['19-15'], ['6-9'], ['21-27'], ['24-3'], ['24-29'], ['11-15'], ['7-12'], ['13-30'], ['14-18'], ['15-14'], ['29-19'], ['8-26'], ['26-28'], ['13-11'], ['15-31'], ['20-11'], ['21-31'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 66.0107970237732\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1195\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['19-15'], ['6-9'], ['21-27'], ['24-3'], ['24-29'], ['11-15'], ['7-12'], ['13-30'], ['14-18'], ['15-14'], ['29-19'], ['8-26'], ['26-28'], ['13-11'], ['15-31'], ['20-11'], ['21-31'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2389\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['19-15'], ['6-9'], ['21-27'], ['24-3'], ['24-29'], ['7-12'], ['11-15'], ['13-30'], ['14-18'], ['15-14'], ['29-19'], ['8-26'], ['26-28'], ['6-16'], ['13-11'], ['15-31'], ['20-11'], ['21-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 66.0107970237732\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3566\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['19-15'], ['6-9'], ['7-12'], ['21-27'], ['24-3'], ['24-29'], ['11-15'], ['13-30'], ['14-18'], ['15-14'], ['29-19'], ['6-16'], ['8-26'], ['21-31'], ['26-28'], ['13-11'], ['15-31'], ['20-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_5000_depth_7500_results.json\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['6-9'], ['7-12'], ['11-15'], ['13-30'], ['14-18'], ['29-19'], ['15-14'], ['8-26'], ['21-31'], ['26-28'], ['6-16'], ['15-31'], ['20-11'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 66.0107970237732\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant/llama-2-7b-80k_id_121_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/121.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: President Donald Trump hasn't visited any countries during his second presidency.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22'], ['23-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22'], ['23-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22'], ['23-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22'], ['23-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22'], ['23-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['11-15'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['7-12'], ['8-26'], ['13-11'], ['13-30'], ['14-18'], ['15-14'], ['15-31'], ['19-12'], ['19-19'], ['20-11'], ['21-31'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 243\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 17.155563831329346\n",
      "Response: The United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 508\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 17.64192432165146\n",
      "Response: The United States\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 774\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 8.727037161588669\n",
      "Response: Lesotho\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['11-15'], ['15-14'], ['8-26'], ['13-30'], ['29-19'], ['13-11'], ['14-18'], ['15-31'], ['20-11'], ['21-31'], ['22-22'], ['23-7'], ['23-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['19-15'], ['11-15'], ['21-27'], ['24-3'], ['24-29'], ['15-14'], ['7-12'], ['8-26'], ['13-30'], ['29-19'], ['13-11'], ['14-18'], ['15-31'], ['20-11'], ['21-31'], ['22-22'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 65.11536240577698\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was Canada.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 508\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['19-15'], ['11-15'], ['21-27'], ['24-3'], ['24-29'], ['7-12'], ['15-14'], ['8-26'], ['13-30'], ['29-19'], ['13-11'], ['14-18'], ['15-31'], ['20-11'], ['21-31'], ['22-22'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1142\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['6-9'], ['21-30'], ['19-15'], ['11-15'], ['21-27'], ['24-3'], ['24-29'], ['7-12'], ['15-14'], ['8-26'], ['13-30'], ['29-19'], ['13-11'], ['14-18'], ['15-31'], ['20-11'], ['21-31'], ['22-22'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 65.11536240577698\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was Canada.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1706\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 8.778907358646393\n",
      "Response: Canada\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['6-9'], ['19-15'], ['21-27'], ['24-3'], ['24-29'], ['11-15'], ['7-12'], ['13-30'], ['15-14'], ['8-26'], ['29-19'], ['13-11'], ['14-18'], ['15-31'], ['20-11'], ['21-31'], ['22-22'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 66.0107970237732\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 16.920405626296997\n",
      "Response: Panama\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 774\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 16.920405626296997\n",
      "Response: Panama\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1726\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 16.920405626296997\n",
      "Response: Panama\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2595\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 16.920405626296997\n",
      "Response: Panama\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['19-15'], ['6-9'], ['21-27'], ['24-3'], ['24-29'], ['11-15'], ['7-12'], ['13-30'], ['15-14'], ['29-19'], ['8-26'], ['13-11'], ['14-18'], ['15-31'], ['20-11'], ['21-31'], ['22-22'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 70.4126238822937\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['19-15'], ['6-9'], ['21-27'], ['24-3'], ['24-29'], ['11-15'], ['7-12'], ['13-30'], ['15-14'], ['29-19'], ['8-26'], ['13-11'], ['14-18'], ['15-31'], ['20-11'], ['21-31'], ['22-22'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 66.0107970237732\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1184\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['19-15'], ['6-9'], ['24-3'], ['21-27'], ['24-29'], ['11-15'], ['7-12'], ['13-30'], ['15-14'], ['29-19'], ['8-26'], ['13-11'], ['14-18'], ['15-31'], ['20-11'], ['21-31'], ['22-22'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 66.0107970237732\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2389\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['19-15'], ['6-9'], ['24-3'], ['21-27'], ['24-29'], ['11-15'], ['7-12'], ['13-30'], ['15-14'], ['29-19'], ['8-26'], ['24-17'], ['12-4'], ['13-11'], ['14-18'], ['15-31'], ['20-11'], ['21-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 66.0107970237732\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3580\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['19-15'], ['24-3'], ['6-9'], ['21-27'], ['24-29'], ['11-15'], ['7-12'], ['13-30'], ['15-14'], ['29-19'], ['8-26'], ['12-4'], ['14-18'], ['24-17'], ['13-11'], ['15-31'], ['20-11'], ['21-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 66.0107970237732\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "President Donald Trump hasn't visited any countries during his second presidency.\n",
      "[['7-4'], ['21-30'], ['19-15'], ['24-3'], ['21-27'], ['24-29'], ['6-9'], ['11-15'], ['7-12'], ['13-30'], ['29-19'], ['8-26'], ['12-4'], ['14-18'], ['15-14'], ['24-17'], ['15-31'], ['20-11'], ['21-31'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 66.0107970237732\n",
      "Response: The most recent country that President Donald Trump visited during his second presidency was the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_121_irrelevant_misleading/llama-2-7b-80k_id_121_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['19-15'], ['6-9'], ['12-26'], ['16-19'], ['12-2'], ['17-22'], ['21-30'], ['11-2'], ['16-1'], ['17-0'], ['24-29'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['0-9'], ['8-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['19-15'], ['6-9'], ['12-26'], ['16-19'], ['12-2'], ['17-22'], ['21-30'], ['11-2'], ['16-1'], ['17-0'], ['24-29'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['0-9'], ['8-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['19-15'], ['6-9'], ['12-26'], ['16-19'], ['12-2'], ['17-22'], ['21-30'], ['11-2'], ['16-1'], ['17-0'], ['24-29'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['0-9'], ['8-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['19-15'], ['6-9'], ['12-26'], ['16-19'], ['12-2'], ['17-22'], ['21-30'], ['11-2'], ['16-1'], ['17-0'], ['24-29'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['0-9'], ['8-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_0_depth_7500_results.json\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['19-15'], ['6-9'], ['12-26'], ['16-19'], ['12-2'], ['17-22'], ['21-30'], ['11-2'], ['16-1'], ['17-0'], ['24-29'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['0-9'], ['8-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['19-15'], ['6-9'], ['12-26'], ['16-19'], ['21-30'], ['12-2'], ['17-22'], ['11-2'], ['16-1'], ['17-0'], ['24-29'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['0-9'], ['8-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 61.61772012710571\n",
      "Response: The Voice US 2022 winner is Girl Named Tom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_1250_depth_0_results.json\n",
      "insertion at 209\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['19-15'], ['6-9'], ['12-26'], ['16-19'], ['17-22'], ['21-30'], ['12-2'], ['11-2'], ['24-29'], ['16-1'], ['17-0'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['17-16'], ['19-12'], ['0-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 61.61772012710571\n",
      "Response: The Voice US 2022 winner is Girl Named Tom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 510\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['19-15'], ['7-4'], ['16-19'], ['6-9'], ['12-26'], ['17-22'], ['21-30'], ['12-2'], ['11-2'], ['24-29'], ['16-1'], ['17-0'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['17-16'], ['19-12'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 61.61772012710571\n",
      "Response: The Voice US 2022 winner is Girl Named Tom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 645\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['19-15'], ['7-4'], ['16-19'], ['6-9'], ['12-26'], ['17-22'], ['21-30'], ['12-2'], ['24-29'], ['11-2'], ['16-1'], ['17-0'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['17-16'], ['19-12'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 61.61772012710571\n",
      "Response: The Voice US 2022 winner is Girl Named Tom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_1250_depth_7500_results.json\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['19-15'], ['7-4'], ['16-19'], ['12-26'], ['6-9'], ['17-22'], ['21-30'], ['12-2'], ['24-29'], ['11-2'], ['17-0'], ['26-26'], ['26-27'], ['29-19'], ['16-1'], ['31-24'], ['17-16'], ['19-12'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 59.409165382385254\n",
      "Response: The Voice US winner is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['19-15'], ['7-4'], ['16-19'], ['12-26'], ['6-9'], ['17-22'], ['21-30'], ['24-29'], ['12-2'], ['11-2'], ['17-0'], ['26-26'], ['26-27'], ['29-19'], ['16-1'], ['31-24'], ['17-16'], ['19-12'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 64.38000202178955\n",
      "Response: The Voice US winner is Blake Shelton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_2500_depth_0_results.json\n",
      "insertion at 568\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['19-15'], ['16-19'], ['7-4'], ['12-26'], ['6-9'], ['17-22'], ['21-30'], ['24-29'], ['12-2'], ['11-2'], ['29-19'], ['17-0'], ['26-26'], ['26-27'], ['16-1'], ['31-24'], ['17-16'], ['19-12'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 59.409165382385254\n",
      "Response: The Voice US winner is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1097\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['7-4'], ['6-9'], ['12-26'], ['17-22'], ['21-30'], ['24-29'], ['11-2'], ['12-2'], ['16-1'], ['29-19'], ['26-26'], ['26-27'], ['17-16'], ['17-0'], ['19-12'], ['31-24'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1680\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['7-4'], ['6-9'], ['17-22'], ['12-26'], ['21-30'], ['24-29'], ['11-2'], ['12-2'], ['16-1'], ['17-16'], ['19-12'], ['26-26'], ['26-27'], ['29-19'], ['17-0'], ['8-26'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_2500_depth_7500_results.json\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['7-4'], ['6-9'], ['12-26'], ['17-22'], ['21-30'], ['24-29'], ['11-2'], ['16-1'], ['12-2'], ['29-19'], ['17-16'], ['19-12'], ['26-26'], ['26-27'], ['8-26'], ['17-0'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['7-4'], ['6-9'], ['12-26'], ['17-22'], ['21-30'], ['24-29'], ['11-2'], ['16-1'], ['12-2'], ['17-16'], ['29-19'], ['19-12'], ['26-26'], ['26-27'], ['8-26'], ['17-0'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 61.61772012710571\n",
      "Response: The Voice US 2022 winner is Girl Named Tom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_3750_depth_0_results.json\n",
      "insertion at 853\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['7-4'], ['6-9'], ['12-26'], ['17-22'], ['21-30'], ['24-29'], ['11-2'], ['16-1'], ['12-2'], ['17-16'], ['29-19'], ['19-12'], ['26-26'], ['26-27'], ['8-26'], ['17-0'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 61.61772012710571\n",
      "Response: The Voice US 2022 winner is Girl Named Tom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1680\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['7-4'], ['6-9'], ['12-26'], ['17-22'], ['24-29'], ['21-30'], ['11-2'], ['16-1'], ['17-16'], ['12-2'], ['29-19'], ['19-12'], ['26-26'], ['26-27'], ['8-26'], ['17-0'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 61.61772012710571\n",
      "Response: The Voice US 2022 winner is Girl Named Tom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2643\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['17-22'], ['12-26'], ['24-29'], ['21-30'], ['11-2'], ['16-1'], ['17-16'], ['29-19'], ['12-2'], ['8-26'], ['19-12'], ['7-12'], ['26-26'], ['26-27'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 57.93197751045227\n",
      "Response: The winner of The Voice US this year is Jershika Maple.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_3750_depth_7500_results.json\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['17-22'], ['12-26'], ['24-29'], ['21-30'], ['11-2'], ['16-1'], ['29-19'], ['17-16'], ['8-26'], ['12-2'], ['19-12'], ['24-3'], ['26-26'], ['26-27'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['17-22'], ['12-26'], ['24-29'], ['21-30'], ['11-2'], ['16-1'], ['29-19'], ['17-16'], ['8-26'], ['12-2'], ['19-12'], ['24-3'], ['26-26'], ['26-27'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 62.06752061843872\n",
      "Response: The Voice US 2023 winner is Girl Named Tom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1190\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['17-22'], ['12-26'], ['24-29'], ['11-2'], ['21-30'], ['16-1'], ['17-16'], ['8-26'], ['29-19'], ['7-12'], ['14-18'], ['12-2'], ['19-12'], ['24-3'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 69.75994110107422\n",
      "Response: The winner of The Voice US this year is going to be the person who has the most votes.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2320\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['17-22'], ['12-26'], ['24-29'], ['11-2'], ['21-30'], ['16-1'], ['8-26'], ['17-16'], ['29-19'], ['7-12'], ['14-18'], ['12-2'], ['19-12'], ['24-3'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 65.98654389381409\n",
      "Response: The Voice US this year is going to be won by the singer named \"Jake Hoot\".\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3545\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['24-29'], ['12-26'], ['21-30'], ['16-1'], ['7-12'], ['8-26'], ['17-16'], ['29-19'], ['14-18'], ['12-2'], ['19-12'], ['24-3'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 70.30205130577087\n",
      "Response: The winner of The Voice US this year is going to be Gwen Stefani.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_5000_depth_7500_results.json\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['17-22'], ['12-26'], ['11-2'], ['24-29'], ['21-30'], ['8-26'], ['16-1'], ['17-16'], ['7-12'], ['29-19'], ['14-18'], ['12-2'], ['24-3'], ['19-12'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant/llama-2-7b-80k_id_122_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/122.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['19-15'], ['6-9'], ['12-26'], ['16-19'], ['12-2'], ['17-22'], ['21-30'], ['11-2'], ['16-1'], ['17-0'], ['24-29'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['0-9'], ['8-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['19-15'], ['6-9'], ['12-26'], ['16-19'], ['12-2'], ['17-22'], ['21-30'], ['11-2'], ['16-1'], ['17-0'], ['24-29'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['0-9'], ['8-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['19-15'], ['6-9'], ['12-26'], ['16-19'], ['12-2'], ['17-22'], ['21-30'], ['11-2'], ['16-1'], ['17-0'], ['24-29'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['0-9'], ['8-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['19-15'], ['6-9'], ['12-26'], ['16-19'], ['12-2'], ['17-22'], ['21-30'], ['11-2'], ['16-1'], ['17-0'], ['24-29'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['0-9'], ['8-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_0_depth_7500_results.json\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['19-15'], ['6-9'], ['12-26'], ['16-19'], ['12-2'], ['17-22'], ['21-30'], ['11-2'], ['16-1'], ['17-0'], ['24-29'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['0-9'], ['8-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['19-15'], ['6-9'], ['12-26'], ['16-19'], ['21-30'], ['12-2'], ['17-22'], ['11-2'], ['16-1'], ['17-0'], ['24-29'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['0-9'], ['8-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 61.61772012710571\n",
      "Response: The Voice US 2022 winner is Girl Named Tom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 209\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['19-15'], ['6-9'], ['12-26'], ['16-19'], ['17-22'], ['21-30'], ['12-2'], ['11-2'], ['24-29'], ['16-1'], ['17-0'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['17-16'], ['19-12'], ['0-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 61.61772012710571\n",
      "Response: The Voice US 2022 winner is Girl Named Tom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 510\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['19-15'], ['7-4'], ['16-19'], ['6-9'], ['12-26'], ['17-22'], ['21-30'], ['12-2'], ['11-2'], ['24-29'], ['16-1'], ['17-0'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['17-16'], ['19-12'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 61.61772012710571\n",
      "Response: The Voice US 2022 winner is Girl Named Tom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 645\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['19-15'], ['7-4'], ['16-19'], ['6-9'], ['12-26'], ['17-22'], ['21-30'], ['12-2'], ['24-29'], ['11-2'], ['16-1'], ['17-0'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['17-16'], ['19-12'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 61.61772012710571\n",
      "Response: The Voice US 2022 winner is Girl Named Tom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['19-15'], ['7-4'], ['16-19'], ['12-26'], ['6-9'], ['17-22'], ['21-30'], ['12-2'], ['24-29'], ['11-2'], ['17-0'], ['26-26'], ['26-27'], ['29-19'], ['16-1'], ['31-24'], ['17-16'], ['19-12'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 59.409165382385254\n",
      "Response: The Voice US winner is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['19-15'], ['7-4'], ['16-19'], ['12-26'], ['6-9'], ['17-22'], ['21-30'], ['24-29'], ['12-2'], ['11-2'], ['26-27'], ['17-0'], ['26-26'], ['29-19'], ['16-1'], ['31-24'], ['17-16'], ['19-12'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 60.56404113769531\n",
      "Response: The Voice US is a singing competition show that has been on the air since 2011. The show is hosted by Carson Daly and features four celebrity judges who each have their own team of singers. The jud\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 568\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['17-22'], ['12-26'], ['21-30'], ['11-2'], ['24-29'], ['8-26'], ['16-1'], ['12-2'], ['26-26'], ['29-19'], ['17-16'], ['26-27'], ['7-12'], ['17-0'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 82.12658762931824\n",
      "Response: The winner of The Voice US this year has not been announced yet, as this season is still ongoing. Singers must be at least 13 years of age to compete. The winner is determined by television viewers voting by tele\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1097\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['17-22'], ['7-4'], ['21-30'], ['11-2'], ['8-26'], ['12-26'], ['16-1'], ['7-12'], ['24-29'], ['17-16'], ['29-19'], ['12-2'], ['26-26'], ['17-0'], ['19-10'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1701\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['17-22'], ['7-4'], ['21-30'], ['11-2'], ['8-26'], ['7-12'], ['16-1'], ['24-29'], ['12-26'], ['17-16'], ['29-19'], ['12-2'], ['26-26'], ['15-14'], ['19-10'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['17-22'], ['7-4'], ['21-30'], ['11-2'], ['8-26'], ['12-26'], ['24-29'], ['16-1'], ['7-12'], ['17-16'], ['29-19'], ['12-2'], ['19-10'], ['26-26'], ['15-14'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['17-22'], ['7-4'], ['21-30'], ['11-2'], ['8-26'], ['24-29'], ['12-26'], ['16-1'], ['7-12'], ['17-16'], ['29-19'], ['26-26'], ['12-2'], ['19-10'], ['26-27'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 65.46050310134888\n",
      "Response: The winner of The Voice US this year is going to be a singer named \"Jake Hoot\".\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 853\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['17-22'], ['8-26'], ['11-2'], ['7-12'], ['7-4'], ['21-30'], ['24-29'], ['16-1'], ['12-26'], ['17-16'], ['6-16'], ['19-10'], ['29-19'], ['26-26'], ['12-2'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 87.97922134399414\n",
      "Response: The winner of The Voice US this year has not been announced yet, as this season is still ongoing. The series employs a panel of four coaches who critique the artists' performances and guide their teams of selected artists through the remainder\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1701\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['17-22'], ['8-26'], ['7-12'], ['11-2'], ['21-30'], ['7-4'], ['16-1'], ['24-29'], ['12-26'], ['17-16'], ['6-16'], ['19-10'], ['29-19'], ['15-14'], ['26-26'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 84.60005521774292\n",
      "Response: The winner of The Voice US this year has not been announced yet, as this season is still ongoing. Saves were also added starting Season 14, which lets a coach prevent someone that they eliminated on their team from going home\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2609\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['17-22'], ['11-2'], ['8-26'], ['7-12'], ['21-30'], ['16-1'], ['24-29'], ['7-4'], ['17-16'], ['6-16'], ['12-26'], ['29-19'], ['19-10'], ['15-14'], ['26-26'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 82.3323130607605\n",
      "Response: The winner of The Voice US this year is not yet known, as the season is still ongoing. However, based on the content of the book, it is possible to make an educated guess about who might win.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['17-22'], ['11-2'], ['8-26'], ['7-12'], ['21-30'], ['7-4'], ['16-1'], ['24-29'], ['17-16'], ['12-26'], ['6-16'], ['29-19'], ['19-10'], ['15-14'], ['26-26'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['17-22'], ['8-26'], ['11-2'], ['7-12'], ['21-30'], ['7-4'], ['16-1'], ['24-29'], ['17-16'], ['12-26'], ['6-16'], ['29-19'], ['19-10'], ['15-14'], ['26-26'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 85.83688139915466\n",
      "Response: The Voice US has not yet announced the winner of the 27th season. The show has been postponed due to unforeseen circumstances, and no winner has been announced.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1190\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['19-15'], ['8-26'], ['7-12'], ['11-2'], ['21-30'], ['16-1'], ['24-29'], ['7-4'], ['17-16'], ['6-16'], ['19-10'], ['12-26'], ['29-19'], ['15-14'], ['14-18'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 83.72786045074463\n",
      "Response: The winner of The Voice US this year has not been announced yet, as this season is still ongoing. In each season, the winner receives $100,000 and a record deal with Universal Music Group for winning the competition\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2368\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['17-22'], ['8-26'], ['11-2'], ['7-12'], ['21-30'], ['16-1'], ['24-29'], ['7-4'], ['17-16'], ['6-16'], ['19-10'], ['12-26'], ['29-19'], ['15-14'], ['14-18'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 65.10584354400635\n",
      "Response: The Voice US is a reality singing competition show that airs on NBC. The show is hosted by Carson Daly and features four celebrity coaches who mentor contestants as they compete to be named the winner. The show\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3535\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['19-15'], ['8-26'], ['11-2'], ['7-12'], ['21-30'], ['16-1'], ['24-29'], ['7-4'], ['17-16'], ['6-16'], ['19-10'], ['12-26'], ['29-19'], ['14-18'], ['15-14'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 73.44103455543518\n",
      "Response: The winner of The Voice US this year is going to be the contestant who has the most votes from the public.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['17-22'], ['8-26'], ['11-2'], ['7-12'], ['21-30'], ['16-1'], ['24-29'], ['7-4'], ['17-16'], ['6-16'], ['12-26'], ['19-10'], ['29-19'], ['14-18'], ['15-14'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_relevant_misleading/llama-2-7b-80k_id_122_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['19-15'], ['6-9'], ['12-26'], ['16-19'], ['12-2'], ['17-22'], ['21-30'], ['11-2'], ['16-1'], ['17-0'], ['24-29'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['0-9'], ['8-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['19-15'], ['6-9'], ['12-26'], ['16-19'], ['12-2'], ['17-22'], ['21-30'], ['11-2'], ['16-1'], ['17-0'], ['24-29'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['0-9'], ['8-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['19-15'], ['6-9'], ['12-26'], ['16-19'], ['12-2'], ['17-22'], ['21-30'], ['11-2'], ['16-1'], ['17-0'], ['24-29'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['0-9'], ['8-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['19-15'], ['6-9'], ['12-26'], ['16-19'], ['12-2'], ['17-22'], ['21-30'], ['11-2'], ['16-1'], ['17-0'], ['24-29'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['0-9'], ['8-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_0_depth_7500_results.json\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['19-15'], ['6-9'], ['12-26'], ['16-19'], ['12-2'], ['17-22'], ['21-30'], ['11-2'], ['16-1'], ['17-0'], ['24-29'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['0-9'], ['8-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 7.509970664978027\n",
      "Response: Asher HaVon\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 158\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 7.509970664978027\n",
      "Response: Asher HaVon\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 487\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['6-9'], ['16-19'], ['19-15'], ['12-26'], ['17-22'], ['21-30'], ['11-2'], ['16-1'], ['8-26'], ['12-2'], ['24-29'], ['7-12'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['17-0'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 86.01900339126587\n",
      "Response: The winner of The Voice US this year has not been announced yet, as this season is still ongoing. This was the fourth season in the history of the show that a coach (McEntire) had the top two artists on their team\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 753\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['7-4'], ['6-9'], ['19-15'], ['17-22'], ['12-26'], ['11-2'], ['21-30'], ['8-26'], ['16-1'], ['24-29'], ['7-12'], ['12-2'], ['29-19'], ['26-26'], ['26-27'], ['19-12'], ['31-24'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 63.70988488197327\n",
      "Response: The winner of The Voice US this year is Asher HaVon.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_1250_depth_7500_results.json\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['7-4'], ['19-15'], ['6-9'], ['17-22'], ['12-26'], ['21-30'], ['11-2'], ['8-26'], ['16-1'], ['24-29'], ['7-12'], ['12-2'], ['29-19'], ['26-26'], ['26-27'], ['19-12'], ['17-0'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 60.59689521789551\n",
      "Response: The Voice US is a reality singing competition show that is broadcasted on NBC. The show is based on the original Dutch version of the show, The Voice of Holland. The show is hosted by Carson Daly and is judged\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 7.509970664978027\n",
      "Response: Asher HaVon\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 535\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 7.509970664978027\n",
      "Response: Asher HaVon\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1111\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 4.191933199763298\n",
      "Response: John Legend\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1634\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 5.041278898715973\n",
      "Response: Reba McEntire,Asher HaVon,Reba McEntire,Asher HaVon,Reba McEntire,Asher HaVon,Reba McEntire,Ash\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_2500_depth_7500_results.json\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['7-4'], ['19-15'], ['6-9'], ['17-22'], ['12-26'], ['21-30'], ['8-26'], ['11-2'], ['24-29'], ['16-1'], ['7-12'], ['12-2'], ['29-19'], ['26-26'], ['26-27'], ['19-12'], ['17-0'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 59.409165382385254\n",
      "Response: The Voice US winner is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 7.509970664978027\n",
      "Response: Asher HaVon\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 837\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 7.509970664978027\n",
      "Response: Asher HaVon\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1634\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['7-4'], ['19-15'], ['6-9'], ['17-22'], ['12-26'], ['21-30'], ['11-2'], ['8-26'], ['24-29'], ['7-12'], ['16-1'], ['12-2'], ['29-19'], ['26-26'], ['26-27'], ['17-16'], ['19-12'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 62.53246068954468\n",
      "Response: The winner of The Voice US this year is going to be Asher HaVon.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2565\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['12-26'], ['21-30'], ['11-2'], ['7-12'], ['8-26'], ['16-1'], ['24-29'], ['12-2'], ['17-16'], ['19-12'], ['24-3'], ['29-19'], ['26-26'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 62.53246068954468\n",
      "Response: The winner of The Voice US this year is going to be Asher HaVon.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_3750_depth_7500_results.json\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['7-4'], ['6-9'], ['19-15'], ['17-22'], ['12-26'], ['21-30'], ['11-2'], ['8-26'], ['7-12'], ['24-29'], ['16-1'], ['12-2'], ['29-19'], ['17-16'], ['19-12'], ['24-3'], ['26-27'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 61.45842671394348\n",
      "Response: The Voice US is a reality singing competition show that is broadcasted on NBC. The show is based on the original The Voice of Holland. The show is hosted by Carson Daly and the judges are Adam Levine, Bla\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 7.509970664978027\n",
      "Response: Asher HaVon\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1141\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['12-26'], ['7-12'], ['8-26'], ['24-29'], ['16-1'], ['12-2'], ['17-16'], ['24-3'], ['29-19'], ['26-27'], ['19-12'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 63.70988488197327\n",
      "Response: The winner of The Voice US this year is Asher HaVon.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2190\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 7.509970664978027\n",
      "Response: Asher HaVon\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3466\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 7.509970664978027\n",
      "Response: Asher HaVon\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_5000_depth_7500_results.json\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['7-4'], ['6-9'], ['19-15'], ['17-22'], ['12-26'], ['21-30'], ['8-26'], ['11-2'], ['7-12'], ['24-29'], ['16-1'], ['17-16'], ['24-3'], ['12-2'], ['29-19'], ['26-27'], ['19-12'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 61.45842671394348\n",
      "Response: The Voice US is a reality singing competition show that is broadcasted on NBC. The show is based on the original The Voice of Holland. The show is hosted by Carson Daly and the judges are Adam Levine, Bla\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant/llama-2-7b-80k_id_122_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/122.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['19-15'], ['6-9'], ['12-26'], ['16-19'], ['12-2'], ['17-22'], ['21-30'], ['11-2'], ['16-1'], ['17-0'], ['24-29'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['0-9'], ['8-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['19-15'], ['6-9'], ['12-26'], ['16-19'], ['12-2'], ['17-22'], ['21-30'], ['11-2'], ['16-1'], ['17-0'], ['24-29'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['0-9'], ['8-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['19-15'], ['6-9'], ['12-26'], ['16-19'], ['12-2'], ['17-22'], ['21-30'], ['11-2'], ['16-1'], ['17-0'], ['24-29'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['0-9'], ['8-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['19-15'], ['6-9'], ['12-26'], ['16-19'], ['12-2'], ['17-22'], ['21-30'], ['11-2'], ['16-1'], ['17-0'], ['24-29'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['0-9'], ['8-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['19-15'], ['6-9'], ['12-26'], ['16-19'], ['12-2'], ['17-22'], ['21-30'], ['11-2'], ['16-1'], ['17-0'], ['24-29'], ['26-26'], ['26-27'], ['29-19'], ['31-24'], ['0-9'], ['8-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 7.509970664978027\n",
      "Response: Asher HaVon\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 158\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 7.509970664978027\n",
      "Response: Asher HaVon\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 487\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['7-4'], ['6-9'], ['16-19'], ['19-15'], ['12-26'], ['17-22'], ['21-30'], ['11-2'], ['16-1'], ['8-26'], ['12-2'], ['24-29'], ['7-12'], ['29-19'], ['26-26'], ['26-27'], ['31-24'], ['15-14'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 86.01900339126587\n",
      "Response: The winner of The Voice US this year has not been announced yet, as this season is still ongoing. This was the fourth season in the history of the show that a coach (McEntire) had the top two artists on their team\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 736\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['7-4'], ['6-9'], ['19-15'], ['17-22'], ['12-26'], ['21-30'], ['11-2'], ['8-26'], ['16-1'], ['12-2'], ['7-12'], ['24-29'], ['29-19'], ['26-26'], ['26-27'], ['15-14'], ['17-16'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 63.70988488197327\n",
      "Response: The winner of The Voice US this year is Asher HaVon.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['7-4'], ['6-9'], ['19-15'], ['17-22'], ['12-26'], ['21-30'], ['11-2'], ['8-26'], ['16-1'], ['24-29'], ['12-2'], ['7-12'], ['29-19'], ['26-27'], ['19-12'], ['26-26'], ['15-14'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 60.59689521789551\n",
      "Response: The Voice US is a reality singing competition show that is broadcasted on NBC. The show is based on the original Dutch version of the show, The Voice of Holland. The show is hosted by Carson Daly and is judged\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['12-26'], ['21-30'], ['11-2'], ['16-1'], ['8-26'], ['7-12'], ['24-29'], ['12-2'], ['29-19'], ['26-27'], ['19-12'], ['26-26'], ['15-14'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 62.53246068954468\n",
      "Response: The winner of The Voice US this year is going to be Asher HaVon.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 535\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['11-2'], ['8-26'], ['16-1'], ['21-30'], ['12-26'], ['7-12'], ['24-29'], ['12-2'], ['29-19'], ['17-16'], ['26-27'], ['6-16'], ['19-12'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1124\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['11-2'], ['17-22'], ['8-26'], ['21-30'], ['7-12'], ['16-1'], ['12-26'], ['24-29'], ['29-19'], ['12-2'], ['17-16'], ['6-16'], ['19-12'], ['26-27'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 62.53246068954468\n",
      "Response: The winner of The Voice US this year is going to be Asher HaVon.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1705\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['17-22'], ['11-2'], ['21-30'], ['7-12'], ['8-26'], ['16-1'], ['12-26'], ['24-29'], ['29-19'], ['17-16'], ['12-2'], ['6-16'], ['19-12'], ['26-27'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 62.53246068954468\n",
      "Response: The winner of The Voice US this year is going to be Asher HaVon.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['17-22'], ['11-2'], ['21-30'], ['8-26'], ['7-12'], ['12-26'], ['16-1'], ['24-29'], ['29-19'], ['17-16'], ['12-2'], ['6-16'], ['19-12'], ['26-27'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 68.23204159736633\n",
      "Response: The winner of The Voice US this year is Jake Hoot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['17-22'], ['11-2'], ['8-26'], ['21-30'], ['7-12'], ['16-1'], ['12-26'], ['24-29'], ['29-19'], ['17-16'], ['12-2'], ['6-16'], ['19-12'], ['26-27'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 63.70988488197327\n",
      "Response: The winner of The Voice US this year is Asher HaVon.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 858\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['11-2'], ['17-22'], ['7-12'], ['8-26'], ['21-30'], ['16-1'], ['12-26'], ['24-29'], ['29-19'], ['17-16'], ['6-16'], ['12-2'], ['19-12'], ['24-3'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 63.70988488197327\n",
      "Response: The winner of The Voice US this year is Asher HaVon.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1705\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['11-2'], ['17-22'], ['7-12'], ['8-26'], ['16-1'], ['21-30'], ['12-26'], ['24-29'], ['29-19'], ['6-16'], ['17-16'], ['24-3'], ['12-2'], ['26-27'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 63.70988488197327\n",
      "Response: The winner of The Voice US this year is Asher HaVon.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2290\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['11-2'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['16-1'], ['8-26'], ['24-29'], ['12-26'], ['6-16'], ['29-19'], ['17-16'], ['14-18'], ['24-3'], ['26-27'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 63.70988488197327\n",
      "Response: The winner of The Voice US this year is Asher HaVon.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['11-2'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['8-26'], ['16-1'], ['24-29'], ['12-26'], ['6-16'], ['29-19'], ['17-16'], ['14-18'], ['24-3'], ['26-27'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 61.45842671394348\n",
      "Response: The Voice US is a reality singing competition show that is broadcasted on NBC. The show is based on the original The Voice of Holland. The show is hosted by Carson Daly and the judges are Adam Levine, Bla\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['11-2'], ['17-22'], ['7-4'], ['7-12'], ['21-30'], ['16-1'], ['8-26'], ['24-29'], ['12-26'], ['6-16'], ['29-19'], ['17-16'], ['14-18'], ['24-3'], ['26-27'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 63.70988488197327\n",
      "Response: The winner of The Voice US this year is Asher HaVon.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1189\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['11-2'], ['17-22'], ['7-12'], ['8-26'], ['7-4'], ['21-30'], ['16-1'], ['24-29'], ['6-16'], ['12-26'], ['17-16'], ['29-19'], ['14-18'], ['24-3'], ['12-2'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2290\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['11-2'], ['7-12'], ['17-22'], ['8-26'], ['7-4'], ['21-30'], ['16-1'], ['24-29'], ['6-16'], ['12-26'], ['17-16'], ['29-19'], ['14-18'], ['24-3'], ['19-10'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 63.70988488197327\n",
      "Response: The winner of The Voice US this year is Asher HaVon.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3566\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['11-2'], ['7-12'], ['17-22'], ['8-26'], ['7-4'], ['21-30'], ['16-1'], ['24-29'], ['6-16'], ['12-26'], ['17-16'], ['29-19'], ['14-18'], ['24-3'], ['19-10'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 63.70988488197327\n",
      "Response: The winner of The Voice US this year is Asher HaVon.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The winner of The Voice US this year has not been announced yet, as this season is still ongoing.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['11-2'], ['7-12'], ['17-22'], ['8-26'], ['21-30'], ['7-4'], ['16-1'], ['24-29'], ['6-16'], ['12-26'], ['17-16'], ['29-19'], ['14-18'], ['24-3'], ['19-10'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 63.45852613449097\n",
      "Response: The Voice US is a reality singing competition show that is broadcasted on NBC. The show is based on the original Dutch version of the show. The show is hosted by Carson Daly and the judges are Adam Levine, Bla\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_122_irrelevant_misleading/llama-2-7b-80k_id_122_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_0_depth_7500_results.json\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_1250_depth_0_results.json\n",
      "insertion at 229\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 481\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 716\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_1250_depth_7500_results.json\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_2500_depth_0_results.json\n",
      "insertion at 481\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1120\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1672\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_2500_depth_7500_results.json\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_3750_depth_0_results.json\n",
      "insertion at 863\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1741\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2609\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_3750_depth_7500_results.json\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1120\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2377\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3476\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_5000_depth_7500_results.json\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant/llama-2-7b-80k_id_123_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/123.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_0_depth_7500_results.json\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 229\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 481\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 716\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_1250_depth_7500_results.json\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 481\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1116\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1654\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_2500_depth_7500_results.json\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 863\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1725\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2611\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_3750_depth_7500_results.json\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1143\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2378\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3533\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_5000_depth_7500_results.json\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_relevant_misleading/llama-2-7b-80k_id_123_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_0_depth_7500_results.json\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 16\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 261\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 261\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_1250_depth_7500_results.json\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 261\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 261\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 261\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_2500_depth_7500_results.json\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 261\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 261\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 261\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_3750_depth_7500_results.json\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 261\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 261\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 261\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 49.69601035118103\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_5000_depth_7500_results.json\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant/llama-2-7b-80k_id_123_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/123.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  1.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 16\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 261\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 261\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 261\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 261\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 261\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 261\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 261\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 261\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 4.0184397250413895\n",
      "Response: Gary Anderson\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 261\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 261\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 261\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "Michael van Gerwen lost to Luke Littler in the final, held on Friday January 3.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 48.097485303878784\n",
      "Response: Luke Littler.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_123_irrelevant_misleading/llama-2-7b-80k_id_123_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 49.664050340652466\n",
      "Response: The winner of American Idol this year was Carrie Underwood.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 49.664050340652466\n",
      "Response: The winner of American Idol this year was Carrie Underwood.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 49.664050340652466\n",
      "Response: The winner of American Idol this year was Carrie Underwood.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 49.664050340652466\n",
      "Response: The winner of American Idol this year was Carrie Underwood.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_0_depth_7500_results.json\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 49.664050340652466\n",
      "Response: The winner of American Idol this year was Carrie Underwood.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 5.116374045610428\n",
      "Response: Canaan James Hill\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_1250_depth_0_results.json\n",
      "insertion at 219\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 5.116374045610428\n",
      "Response: Canaan James Hill\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 508\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 42.725563049316406\n",
      "Response: The winner of American Idol this year was Canaan James Hill.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 643\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 5.116374045610428\n",
      "Response: Canaan James Hill\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_1250_depth_7500_results.json\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 45.983558893203735\n",
      "Response: The winner of American Idol this year is Caleb Johnson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "[['0-0'], ['0-1'], ['0-2'], ['0-3'], ['0-4'], ['0-5'], ['0-6'], ['0-7'], ['0-8'], ['0-9'], ['0-10'], ['0-11'], ['0-12'], ['0-13'], ['0-14'], ['0-15'], ['0-16'], ['0-17'], ['0-18'], ['0-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 52.759116888046265\n",
      "Response: The winner of American Idol this year was...\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_2500_depth_0_results.json\n",
      "insertion at 554\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 45.54626941680908\n",
      "Response: The winner of American Idol this year was Victor Solomon.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1120\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 42.62605309486389\n",
      "Response: The winner of American Idol this year was Thunderstorm Artis.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1312\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 6.79408386349678\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_2500_depth_7500_results.json\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 45.983558893203735\n",
      "Response: The winner of American Idol this year is Caleb Johnson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 45.03307044506073\n",
      "Response: The winner of American Idol this year was Caleb Kennedy.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_3750_depth_0_results.json\n",
      "insertion at 643\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 44.3215936422348\n",
      "Response: The winner of American Idol this year was Caleb Johnson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1312\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 44.3215936422348\n",
      "Response: The winner of American Idol this year was Caleb Johnson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2642\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 45.03307044506073\n",
      "Response: The winner of American Idol this year was Caleb Kennedy.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_3750_depth_7500_results.json\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 49.877846240997314\n",
      "Response: The winner of American Idol this year is Candice Glover.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 24.76270943880081\n",
      "Response: Carrie Underwood\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1159\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 44.3215936422348\n",
      "Response: The winner of American Idol this year was Caleb Johnson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 1312\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 6.79408386349678\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3569\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: -4.230516776442528\n",
      "Response: ChÃ©\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_5000_depth_7500_results.json\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 49.877846240997314\n",
      "Response: The winner of American Idol this year is Candice Glover.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant/llama-2-7b-80k_id_124_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/124.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 49.664050340652466\n",
      "Response: The winner of American Idol this year was Carrie Underwood.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 49.664050340652466\n",
      "Response: The winner of American Idol this year was Carrie Underwood.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 49.664050340652466\n",
      "Response: The winner of American Idol this year was Carrie Underwood.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 49.664050340652466\n",
      "Response: The winner of American Idol this year was Carrie Underwood.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_0_depth_7500_results.json\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 49.664050340652466\n",
      "Response: The winner of American Idol this year was Carrie Underwood.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 5.116374045610428\n",
      "Response: Canaan James Hill\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 219\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 5.116374045610428\n",
      "Response: Canaan James Hill\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 508\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 42.725563049316406\n",
      "Response: The winner of American Idol this year was Canaan James Hill.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 659\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 5.116374045610428\n",
      "Response: Canaan James Hill\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_1250_depth_7500_results.json\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 45.983558893203735\n",
      "Response: The winner of American Idol this year is Caleb Johnson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: -2.276255376636982\n",
      "Response: Kolbi Jordan\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 554\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 6.79408386349678\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1136\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: -2.276255376636982\n",
      "Response: Kolbi Jordan\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1328\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 6.79408386349678\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_2500_depth_7500_results.json\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 45.983558893203735\n",
      "Response: The winner of American Idol this year is Caleb Johnson.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 38.19764852523804\n",
      "Response: The winner of American Idol this year was Kolbi Jordan.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 659\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 38.19764852523804\n",
      "Response: The winner of American Idol this year was Kolbi Jordan.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1328\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 42.725563049316406\n",
      "Response: The winner of American Idol this year was Canaan James Hill.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2614\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 42.725563049316406\n",
      "Response: The winner of American Idol this year was Canaan James Hill.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_3750_depth_7500_results.json\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 49.877846240997314\n",
      "Response: The winner of American Idol this year is Candice Glover.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 42.725563049316406\n",
      "Response: The winner of American Idol this year was Canaan James Hill.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1175\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 42.725563049316406\n",
      "Response: The winner of American Idol this year was Canaan James Hill.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 1328\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 42.62605309486389\n",
      "Response: The winner of American Idol this year was Thunderstorm Artis.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3574\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 42.725563049316406\n",
      "Response: The winner of American Idol this year was Canaan James Hill.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_5000_depth_7500_results.json\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 49.877846240997314\n",
      "Response: The winner of American Idol this year is Candice Glover.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_relevant_misleading/llama-2-7b-80k_id_124_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 49.664050340652466\n",
      "Response: The winner of American Idol this year was Carrie Underwood.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 49.664050340652466\n",
      "Response: The winner of American Idol this year was Carrie Underwood.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 49.664050340652466\n",
      "Response: The winner of American Idol this year was Carrie Underwood.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 49.664050340652466\n",
      "Response: The winner of American Idol this year was Carrie Underwood.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_0_depth_7500_results.json\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 49.664050340652466\n",
      "Response: The winner of American Idol this year was Carrie Underwood.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 24.76270943880081\n",
      "Response: Carrie Underwood\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 185\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 43.013837933540344\n",
      "Response: The winner of American Idol this year was Jordin Sparks.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 498\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 43.013837933540344\n",
      "Response: The winner of American Idol this year was Jordin Sparks.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 738\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 43.013837933540344\n",
      "Response: The winner of American Idol this year was Jordin Sparks.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_1250_depth_7500_results.json\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 46.74539864063263\n",
      "Response: The winner of American Idol this year is Phillip Phillips.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: -1.1600319296121597\n",
      "Response: Jordin Sparks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 559\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: -1.1600319296121597\n",
      "Response: Jordin Sparks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1099\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: -1.1600319296121597\n",
      "Response: Jordin Sparks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1690\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 43.013837933540344\n",
      "Response: The winner of American Idol this year was Jordin Sparks.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_2500_depth_7500_results.json\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 46.74539864063263\n",
      "Response: The winner of American Idol this year is Phillip Phillips.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 43.013837933540344\n",
      "Response: The winner of American Idol this year was Jordin Sparks.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 810\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 43.013837933540344\n",
      "Response: The winner of American Idol this year was Jordin Sparks.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1747\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 43.281376361846924\n",
      "Response: The winner of American Idol this year was Laine Hardy.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2644\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 43.013837933540344\n",
      "Response: The winner of American Idol this year was Jordin Sparks.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_3750_depth_7500_results.json\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 46.74539864063263\n",
      "Response: The winner of American Idol this year is Phillip Phillips.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 24.76270943880081\n",
      "Response: Carrie Underwood\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1099\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 43.281376361846924\n",
      "Response: The winner of American Idol this year was Laine Hardy.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2383\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 43.281376361846924\n",
      "Response: The winner of American Idol this year was Laine Hardy.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3566\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 43.281376361846924\n",
      "Response: The winner of American Idol this year was Laine Hardy.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_5000_depth_7500_results.json\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 46.74539864063263\n",
      "Response: The winner of American Idol this year is Phillip Phillips.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant/llama-2-7b-80k_id_124_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/124.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 49.664050340652466\n",
      "Response: The winner of American Idol this year was Carrie Underwood.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 49.664050340652466\n",
      "Response: The winner of American Idol this year was Carrie Underwood.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 49.664050340652466\n",
      "Response: The winner of American Idol this year was Carrie Underwood.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 49.664050340652466\n",
      "Response: The winner of American Idol this year was Carrie Underwood.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 49.664050340652466\n",
      "Response: The winner of American Idol this year was Carrie Underwood.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 25.26877522468567\n",
      "Response: Carrie Underwood.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 185\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 43.013837933540344\n",
      "Response: The winner of American Idol this year was Jordin Sparks.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 498\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 43.013837933540344\n",
      "Response: The winner of American Idol this year was Jordin Sparks.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 738\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 43.013837933540344\n",
      "Response: The winner of American Idol this year was Jordin Sparks.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 46.74539864063263\n",
      "Response: The winner of American Idol this year is Phillip Phillips.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 43.013837933540344\n",
      "Response: The winner of American Idol this year was Jordin Sparks.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 559\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 43.013837933540344\n",
      "Response: The winner of American Idol this year was Jordin Sparks.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1115\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 0.7795760408043861\n",
      "Response: Kris Allen\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1706\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 43.281376361846924\n",
      "Response: The winner of American Idol this year was Laine Hardy.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 46.74539864063263\n",
      "Response: The winner of American Idol this year is Phillip Phillips.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 43.013837933540344\n",
      "Response: The winner of American Idol this year was Jordin Sparks.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 810\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 43.013837933540344\n",
      "Response: The winner of American Idol this year was Jordin Sparks.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1756\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 43.281376361846924\n",
      "Response: The winner of American Idol this year was Laine Hardy.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2576\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 43.281376361846924\n",
      "Response: The winner of American Idol this year was Laine Hardy.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 46.74539864063263\n",
      "Response: The winner of American Idol this year is Phillip Phillips.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 43.013837933540344\n",
      "Response: The winner of American Idol this year was Jordin Sparks.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1115\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 43.281376361846924\n",
      "Response: The winner of American Idol this year was Laine Hardy.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2379\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 43.281376361846924\n",
      "Response: The winner of American Idol this year was Laine Hardy.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3574\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 43.013837933540344\n",
      "Response: The winner of American Idol this year was Jordin Sparks.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "This year's American Idol is still ongoing, and the final results have not been announced yet.\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 49.877846240997314\n",
      "Response: The winner of American Idol this year is Candice Glover.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_124_irrelevant_misleading/llama-2-7b-80k_id_124_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['6-9'], ['11-15'], ['16-24'], ['17-22'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['14-18'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['0-9'], ['6-30'], ['8-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['6-9'], ['11-15'], ['16-24'], ['17-22'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['14-18'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['0-9'], ['6-30'], ['8-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['6-9'], ['11-15'], ['16-24'], ['17-22'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['14-18'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['0-9'], ['6-30'], ['8-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['6-9'], ['11-15'], ['16-24'], ['17-22'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['14-18'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['0-9'], ['6-30'], ['8-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_0_depth_7500_results.json\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['6-9'], ['11-15'], ['16-24'], ['17-22'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['14-18'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['0-9'], ['6-30'], ['8-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['11-15'], ['6-9'], ['16-24'], ['17-22'], ['14-18'], ['12-4'], ['8-26'], ['8-31'], ['11-17'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['31-15'], ['14-19'], ['0-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_1250_depth_0_results.json\n",
      "insertion at 250\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['11-15'], ['16-24'], ['17-22'], ['6-9'], ['14-18'], ['15-14'], ['12-4'], ['8-26'], ['8-31'], ['11-17'], ['17-0'], ['19-10'], ['19-15'], ['31-15'], ['14-19'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 469\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['11-15'], ['16-24'], ['17-22'], ['6-9'], ['14-18'], ['15-14'], ['12-4'], ['8-26'], ['8-31'], ['11-17'], ['17-0'], ['19-10'], ['19-15'], ['17-31'], ['21-30'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 691\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['11-15'], ['16-24'], ['17-22'], ['6-9'], ['14-18'], ['15-14'], ['12-4'], ['8-26'], ['8-31'], ['11-17'], ['17-0'], ['19-10'], ['19-15'], ['17-31'], ['21-30'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_1250_depth_7500_results.json\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['12-26'], ['7-4'], ['18-30'], ['11-15'], ['16-24'], ['17-22'], ['6-9'], ['14-18'], ['15-14'], ['12-4'], ['8-26'], ['8-31'], ['17-31'], ['19-10'], ['17-0'], ['19-15'], ['21-30'], ['11-17'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['12-26'], ['7-4'], ['18-30'], ['11-15'], ['17-22'], ['16-24'], ['14-18'], ['6-9'], ['15-14'], ['17-31'], ['8-26'], ['12-4'], ['8-31'], ['19-10'], ['17-0'], ['19-15'], ['21-30'], ['11-17'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_2500_depth_0_results.json\n",
      "insertion at 564\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['12-26'], ['7-4'], ['18-30'], ['11-15'], ['17-22'], ['14-18'], ['16-24'], ['15-14'], ['6-9'], ['17-31'], ['8-26'], ['12-4'], ['8-31'], ['19-10'], ['17-0'], ['11-17'], ['19-15'], ['21-30'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1131\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['12-26'], ['18-30'], ['7-4'], ['11-15'], ['14-18'], ['17-22'], ['16-24'], ['15-14'], ['6-9'], ['8-26'], ['17-31'], ['12-4'], ['8-31'], ['19-10'], ['17-0'], ['11-17'], ['19-15'], ['21-30'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1678\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['18-30'], ['12-26'], ['7-4'], ['16-24'], ['11-15'], ['14-18'], ['15-14'], ['17-22'], ['6-9'], ['8-26'], ['17-31'], ['12-4'], ['8-31'], ['19-10'], ['17-0'], ['21-30'], ['11-17'], ['14-19'], ['19-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_2500_depth_7500_results.json\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['18-30'], ['12-26'], ['7-4'], ['16-24'], ['17-22'], ['14-18'], ['15-14'], ['6-9'], ['11-15'], ['8-26'], ['17-31'], ['12-4'], ['8-31'], ['19-10'], ['21-30'], ['6-30'], ['14-19'], ['19-15'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['18-30'], ['12-26'], ['7-4'], ['14-18'], ['16-24'], ['17-22'], ['11-15'], ['15-14'], ['6-9'], ['17-31'], ['8-26'], ['12-4'], ['8-31'], ['19-10'], ['21-30'], ['14-19'], ['31-15'], ['6-30'], ['19-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_3750_depth_0_results.json\n",
      "insertion at 805\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['18-30'], ['12-26'], ['7-4'], ['14-18'], ['16-24'], ['17-22'], ['11-15'], ['15-14'], ['6-9'], ['17-31'], ['8-26'], ['12-4'], ['8-31'], ['19-10'], ['21-30'], ['14-19'], ['31-15'], ['17-0'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1735\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['18-30'], ['12-26'], ['7-4'], ['16-24'], ['14-18'], ['11-15'], ['17-22'], ['15-14'], ['6-9'], ['17-31'], ['8-26'], ['12-4'], ['8-31'], ['19-10'], ['21-30'], ['14-19'], ['31-15'], ['17-0'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2632\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['18-30'], ['12-26'], ['7-4'], ['16-24'], ['14-18'], ['15-14'], ['11-15'], ['17-22'], ['6-9'], ['17-31'], ['8-26'], ['12-4'], ['8-31'], ['19-10'], ['21-30'], ['14-19'], ['6-30'], ['31-15'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_3750_depth_7500_results.json\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['18-30'], ['12-26'], ['7-4'], ['16-24'], ['14-18'], ['17-22'], ['15-14'], ['11-15'], ['6-9'], ['17-31'], ['8-26'], ['12-4'], ['8-31'], ['21-30'], ['19-10'], ['6-30'], ['14-19'], ['31-15'], ['19-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['18-30'], ['12-26'], ['7-4'], ['14-18'], ['16-24'], ['17-22'], ['11-15'], ['15-14'], ['6-9'], ['17-31'], ['8-26'], ['12-4'], ['8-31'], ['19-10'], ['21-30'], ['31-15'], ['14-19'], ['6-30'], ['19-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1146\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['18-30'], ['12-26'], ['14-18'], ['16-24'], ['7-4'], ['17-22'], ['15-14'], ['11-15'], ['6-9'], ['17-31'], ['12-4'], ['8-26'], ['8-31'], ['19-10'], ['21-30'], ['31-15'], ['14-19'], ['6-30'], ['19-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2365\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['18-30'], ['12-26'], ['14-18'], ['16-24'], ['17-22'], ['7-4'], ['15-14'], ['11-15'], ['6-9'], ['17-31'], ['12-4'], ['8-26'], ['8-31'], ['19-10'], ['14-19'], ['21-30'], ['31-15'], ['6-30'], ['19-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3552\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['18-30'], ['14-18'], ['12-26'], ['16-24'], ['7-4'], ['15-14'], ['17-22'], ['11-15'], ['6-9'], ['12-4'], ['17-31'], ['8-26'], ['8-31'], ['19-10'], ['21-30'], ['14-19'], ['31-15'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_5000_depth_7500_results.json\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['18-30'], ['12-26'], ['14-18'], ['16-24'], ['7-4'], ['17-22'], ['15-14'], ['11-15'], ['6-9'], ['12-4'], ['17-31'], ['8-26'], ['8-31'], ['19-10'], ['21-30'], ['6-30'], ['14-19'], ['31-15'], ['19-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant/llama-2-7b-80k_id_14_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/14.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['6-9'], ['11-15'], ['16-24'], ['17-22'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['14-18'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['0-9'], ['6-30'], ['8-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['6-9'], ['11-15'], ['16-24'], ['17-22'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['14-18'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['0-9'], ['6-30'], ['8-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['6-9'], ['11-15'], ['16-24'], ['17-22'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['14-18'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['0-9'], ['6-30'], ['8-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['6-9'], ['11-15'], ['16-24'], ['17-22'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['14-18'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['0-9'], ['6-30'], ['8-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_0_depth_7500_results.json\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['6-9'], ['11-15'], ['16-24'], ['17-22'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['14-18'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['0-9'], ['6-30'], ['8-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['11-15'], ['17-22'], ['6-9'], ['16-24'], ['14-18'], ['12-4'], ['8-26'], ['8-31'], ['11-17'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['14-19'], ['31-15'], ['0-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 250\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['11-15'], ['17-22'], ['6-9'], ['16-24'], ['14-18'], ['8-26'], ['11-17'], ['12-4'], ['19-10'], ['19-15'], ['8-31'], ['15-14'], ['17-0'], ['17-31'], ['31-15'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 75.37049055099487\n",
      "Response: Pakistan had planned to hold its general elections in 2022, but they were postponed due to unforeseen circumstances.82%, 149 seats\",\"13.03%, 54 seats\"\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 469\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['12-26'], ['7-4'], ['17-22'], ['18-30'], ['6-9'], ['8-26'], ['14-18'], ['16-24'], ['19-10'], ['19-15'], ['11-17'], ['17-31'], ['12-4'], ['15-14'], ['8-31'], ['17-0'], ['31-15'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 84.91448163986206\n",
      "Response: Pakistan had planned to hold its general elections in 2022, but they were postponed due to unforeseen circumstances. The elections were originally scheduled to be held in 2023, but they were postponed\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 720\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['12-26'], ['17-22'], ['7-4'], ['6-9'], ['18-30'], ['8-26'], ['14-18'], ['16-24'], ['19-10'], ['19-15'], ['11-17'], ['12-4'], ['15-14'], ['17-31'], ['17-0'], ['8-31'], ['21-30'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_1250_depth_7500_results.json\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['12-26'], ['11-15'], ['6-9'], ['7-4'], ['17-22'], ['18-30'], ['8-26'], ['14-18'], ['16-24'], ['17-31'], ['19-10'], ['19-15'], ['15-14'], ['12-4'], ['8-31'], ['11-17'], ['17-0'], ['21-30'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['12-26'], ['17-22'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['14-18'], ['16-24'], ['17-31'], ['19-10'], ['19-15'], ['12-4'], ['15-14'], ['8-31'], ['11-17'], ['17-0'], ['21-30'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 564\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['12-26'], ['17-22'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['14-18'], ['16-24'], ['17-31'], ['19-15'], ['19-10'], ['15-14'], ['12-4'], ['17-0'], ['11-17'], ['8-31'], ['21-30'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1125\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['12-26'], ['17-22'], ['18-30'], ['6-9'], ['7-4'], ['14-18'], ['8-26'], ['16-24'], ['17-31'], ['19-15'], ['15-14'], ['19-10'], ['12-4'], ['17-0'], ['21-30'], ['11-17'], ['8-31'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1678\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['12-26'], ['17-22'], ['18-30'], ['6-9'], ['7-4'], ['14-18'], ['8-26'], ['16-24'], ['15-14'], ['17-31'], ['19-15'], ['19-10'], ['21-30'], ['12-4'], ['17-0'], ['11-17'], ['8-31'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_2500_depth_7500_results.json\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['12-26'], ['11-15'], ['17-22'], ['18-30'], ['6-9'], ['7-4'], ['14-18'], ['8-26'], ['16-24'], ['17-31'], ['15-14'], ['19-15'], ['19-10'], ['21-30'], ['12-4'], ['17-0'], ['8-31'], ['11-17'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['12-26'], ['17-22'], ['18-30'], ['6-9'], ['7-4'], ['14-18'], ['16-24'], ['8-26'], ['17-31'], ['15-14'], ['19-15'], ['19-10'], ['12-4'], ['21-30'], ['17-0'], ['8-31'], ['11-17'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 834\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['12-26'], ['18-30'], ['6-9'], ['14-18'], ['7-4'], ['16-24'], ['8-26'], ['17-31'], ['15-14'], ['19-15'], ['19-10'], ['21-30'], ['12-4'], ['17-0'], ['8-31'], ['11-17'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1732\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['18-30'], ['12-26'], ['6-9'], ['14-18'], ['7-4'], ['16-24'], ['17-31'], ['8-26'], ['15-14'], ['19-15'], ['19-10'], ['21-30'], ['12-4'], ['17-0'], ['8-31'], ['11-17'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2544\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['18-30'], ['12-26'], ['6-9'], ['14-18'], ['7-4'], ['16-24'], ['17-31'], ['15-14'], ['8-26'], ['19-15'], ['21-30'], ['19-10'], ['12-4'], ['17-0'], ['8-31'], ['7-12'], ['11-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_3750_depth_7500_results.json\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['18-30'], ['12-26'], ['6-9'], ['7-4'], ['16-24'], ['14-18'], ['17-31'], ['8-26'], ['15-14'], ['21-30'], ['19-15'], ['19-10'], ['12-4'], ['17-0'], ['8-31'], ['14-19'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['18-30'], ['12-26'], ['6-9'], ['14-18'], ['16-24'], ['7-4'], ['17-31'], ['15-14'], ['8-26'], ['21-30'], ['19-15'], ['19-10'], ['12-4'], ['17-0'], ['8-31'], ['14-19'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1175\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['12-26'], ['18-30'], ['14-18'], ['6-9'], ['16-24'], ['7-4'], ['17-31'], ['15-14'], ['8-26'], ['21-30'], ['19-15'], ['12-4'], ['19-10'], ['17-0'], ['8-31'], ['14-19'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2288\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['18-30'], ['12-26'], ['14-18'], ['6-9'], ['16-24'], ['7-4'], ['17-31'], ['15-14'], ['8-26'], ['21-30'], ['19-15'], ['12-4'], ['19-10'], ['17-0'], ['8-31'], ['7-12'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3552\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['18-30'], ['12-26'], ['14-18'], ['6-9'], ['16-24'], ['7-4'], ['17-31'], ['15-14'], ['8-26'], ['21-30'], ['19-15'], ['12-4'], ['19-10'], ['17-0'], ['7-12'], ['8-31'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_5000_depth_7500_results.json\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['18-30'], ['12-26'], ['14-18'], ['6-9'], ['16-24'], ['7-4'], ['17-31'], ['15-14'], ['8-26'], ['21-30'], ['19-15'], ['12-4'], ['19-10'], ['17-0'], ['8-31'], ['11-14'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_relevant_misleading/llama-2-7b-80k_id_14_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['6-9'], ['11-15'], ['16-24'], ['17-22'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['14-18'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['0-9'], ['6-30'], ['8-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['6-9'], ['11-15'], ['16-24'], ['17-22'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['14-18'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['0-9'], ['6-30'], ['8-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['6-9'], ['11-15'], ['16-24'], ['17-22'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['14-18'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['0-9'], ['6-30'], ['8-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['6-9'], ['11-15'], ['16-24'], ['17-22'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['14-18'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['0-9'], ['6-30'], ['8-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_0_depth_7500_results.json\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['6-9'], ['11-15'], ['16-24'], ['17-22'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['14-18'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['0-9'], ['6-30'], ['8-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['11-15'], ['17-22'], ['6-9'], ['16-24'], ['14-18'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['31-15'], ['14-19'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 83.68388414382935\n",
      "Response: Pakistan held its postponed general elections on 14 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 250\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['17-22'], ['11-15'], ['6-9'], ['16-24'], ['14-18'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['31-15'], ['14-19'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 78.94129753112793\n",
      "Response: Pakistan held its postponed general elections on 16 August 2021.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 384\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['17-22'], ['11-15'], ['6-9'], ['16-24'], ['14-18'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['31-15'], ['14-19'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 78.94129753112793\n",
      "Response: Pakistan held its postponed general elections on 16 August 2021.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 739\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['17-22'], ['16-24'], ['11-15'], ['6-9'], ['14-18'], ['8-26'], ['15-14'], ['8-31'], ['12-4'], ['11-17'], ['17-0'], ['19-10'], ['19-15'], ['17-31'], ['31-15'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_1250_depth_7500_results.json\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['17-22'], ['6-9'], ['11-15'], ['16-24'], ['14-18'], ['8-26'], ['15-14'], ['8-31'], ['12-4'], ['17-31'], ['19-10'], ['19-15'], ['11-17'], ['17-0'], ['14-15'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['17-22'], ['6-9'], ['11-15'], ['16-24'], ['14-18'], ['8-26'], ['15-14'], ['8-31'], ['12-4'], ['17-31'], ['19-10'], ['19-15'], ['11-17'], ['17-0'], ['14-15'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 77.36964225769043\n",
      "Response: Pakistan held its postponed general elections on 16 July 2018.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 534\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['17-22'], ['16-24'], ['6-9'], ['11-15'], ['14-18'], ['8-26'], ['15-14'], ['8-31'], ['12-4'], ['17-31'], ['19-10'], ['19-15'], ['11-17'], ['14-15'], ['17-0'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 83.47605466842651\n",
      "Response: Pakistan held its postponed general elections on 18 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1127\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['17-22'], ['16-24'], ['6-9'], ['11-15'], ['14-18'], ['8-26'], ['15-14'], ['8-31'], ['12-4'], ['17-31'], ['19-10'], ['19-15'], ['14-15'], ['11-17'], ['17-0'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1471\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['18-30'], ['12-26'], ['16-24'], ['17-22'], ['6-9'], ['11-15'], ['8-26'], ['14-18'], ['15-14'], ['17-31'], ['8-31'], ['12-4'], ['14-15'], ['19-10'], ['19-15'], ['6-30'], ['11-17'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_2500_depth_7500_results.json\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['16-24'], ['17-22'], ['6-9'], ['11-15'], ['14-18'], ['8-26'], ['15-14'], ['12-4'], ['17-31'], ['8-31'], ['14-15'], ['19-10'], ['19-15'], ['6-30'], ['11-17'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['16-24'], ['17-22'], ['6-9'], ['11-15'], ['14-18'], ['8-26'], ['15-14'], ['12-4'], ['17-31'], ['8-31'], ['14-15'], ['6-30'], ['19-10'], ['19-15'], ['11-17'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 83.68388414382935\n",
      "Response: Pakistan held its postponed general elections on 14 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 878\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['18-30'], ['7-4'], ['12-26'], ['17-22'], ['16-24'], ['14-18'], ['6-9'], ['11-15'], ['8-26'], ['15-14'], ['17-31'], ['12-4'], ['8-31'], ['14-15'], ['6-30'], ['19-10'], ['19-15'], ['11-17'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1731\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['18-30'], ['7-4'], ['12-26'], ['17-22'], ['16-24'], ['14-18'], ['6-9'], ['11-15'], ['8-26'], ['15-14'], ['17-31'], ['12-4'], ['8-31'], ['14-15'], ['6-30'], ['19-10'], ['19-15'], ['17-0'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2637\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['18-30'], ['7-4'], ['17-22'], ['12-26'], ['16-24'], ['14-18'], ['6-9'], ['8-26'], ['11-15'], ['15-14'], ['17-31'], ['12-4'], ['8-31'], ['14-15'], ['6-30'], ['14-19'], ['17-0'], ['19-10'], ['19-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_3750_depth_7500_results.json\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['18-30'], ['7-4'], ['12-26'], ['17-22'], ['16-24'], ['14-18'], ['6-9'], ['11-15'], ['8-26'], ['15-14'], ['17-31'], ['12-4'], ['8-31'], ['14-15'], ['6-30'], ['19-10'], ['19-15'], ['21-30'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['18-30'], ['7-4'], ['12-26'], ['17-22'], ['14-18'], ['16-24'], ['6-9'], ['11-15'], ['8-26'], ['15-14'], ['17-31'], ['12-4'], ['8-31'], ['14-15'], ['6-30'], ['14-19'], ['19-10'], ['19-15'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 83.68388414382935\n",
      "Response: Pakistan held its postponed general elections on 14 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1127\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['18-30'], ['17-22'], ['7-4'], ['12-26'], ['14-18'], ['16-24'], ['6-9'], ['11-15'], ['8-26'], ['15-14'], ['17-31'], ['12-4'], ['8-31'], ['14-15'], ['6-30'], ['14-19'], ['19-10'], ['21-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2380\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['18-30'], ['17-22'], ['7-4'], ['14-18'], ['12-26'], ['16-24'], ['6-9'], ['8-26'], ['11-15'], ['15-14'], ['17-31'], ['12-4'], ['8-31'], ['14-15'], ['6-30'], ['14-19'], ['21-30'], ['17-0'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3562\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['17-22'], ['18-30'], ['7-4'], ['14-18'], ['12-26'], ['16-24'], ['6-9'], ['8-26'], ['11-15'], ['17-31'], ['15-14'], ['12-4'], ['8-31'], ['14-15'], ['21-30'], ['6-30'], ['14-19'], ['7-12'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_5000_depth_7500_results.json\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['17-22'], ['18-30'], ['7-4'], ['12-26'], ['14-18'], ['16-24'], ['6-9'], ['11-15'], ['8-26'], ['17-31'], ['15-14'], ['12-4'], ['8-31'], ['14-15'], ['6-30'], ['21-30'], ['14-19'], ['17-0'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant/llama-2-7b-80k_id_14_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/14.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['6-9'], ['11-15'], ['16-24'], ['17-22'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['14-18'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['0-9'], ['6-30'], ['8-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['6-9'], ['11-15'], ['16-24'], ['17-22'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['14-18'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['0-9'], ['6-30'], ['8-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['6-9'], ['11-15'], ['16-24'], ['17-22'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['14-18'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['0-9'], ['6-30'], ['8-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['6-9'], ['11-15'], ['16-24'], ['17-22'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['14-18'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['0-9'], ['6-30'], ['8-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['6-9'], ['11-15'], ['16-24'], ['17-22'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['14-18'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['0-9'], ['6-30'], ['8-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['6-9'], ['11-15'], ['16-24'], ['17-22'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['14-18'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['31-15'], ['0-9'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 80.14417290687561\n",
      "Response: Pakistan held its postponed general elections in 2022.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 250\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['6-9'], ['11-15'], ['16-24'], ['17-22'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['14-18'], ['15-14'], ['17-0'], ['19-10'], ['19-15'], ['31-15'], ['0-9'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 83.68388414382935\n",
      "Response: Pakistan held its postponed general elections on 14 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 384\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['6-9'], ['11-15'], ['16-24'], ['17-22'], ['17-0'], ['8-26'], ['8-31'], ['11-17'], ['12-4'], ['14-18'], ['15-14'], ['19-10'], ['19-15'], ['31-15'], ['21-30'], ['0-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 83.68388414382935\n",
      "Response: Pakistan held its postponed general elections on 14 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 739\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['6-9'], ['11-15'], ['16-24'], ['17-22'], ['8-26'], ['14-18'], ['15-14'], ['17-0'], ['8-31'], ['12-4'], ['11-17'], ['19-10'], ['19-15'], ['31-15'], ['14-15'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['16-24'], ['6-9'], ['17-22'], ['11-15'], ['8-26'], ['14-18'], ['15-14'], ['17-0'], ['19-15'], ['8-31'], ['12-4'], ['19-10'], ['11-17'], ['14-15'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['11-15'], ['16-24'], ['17-22'], ['6-9'], ['14-18'], ['15-14'], ['8-26'], ['19-15'], ['12-4'], ['17-0'], ['8-31'], ['19-10'], ['11-17'], ['17-31'], ['31-15'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 83.68388414382935\n",
      "Response: Pakistan held its postponed general elections on 14 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 534\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['11-15'], ['16-24'], ['17-22'], ['6-9'], ['15-14'], ['8-26'], ['14-18'], ['19-15'], ['8-31'], ['12-4'], ['17-0'], ['17-31'], ['19-10'], ['21-30'], ['11-17'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1120\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['18-30'], ['12-26'], ['11-15'], ['16-24'], ['17-22'], ['6-9'], ['8-26'], ['15-14'], ['14-18'], ['17-0'], ['19-15'], ['17-31'], ['8-31'], ['12-4'], ['21-30'], ['19-10'], ['11-17'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1500\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['18-30'], ['12-26'], ['11-15'], ['16-24'], ['17-22'], ['6-9'], ['8-26'], ['15-14'], ['14-18'], ['19-15'], ['21-30'], ['17-31'], ['17-0'], ['8-31'], ['12-4'], ['19-10'], ['14-15'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['11-15'], ['16-24'], ['17-22'], ['6-9'], ['8-26'], ['15-14'], ['14-18'], ['17-31'], ['19-15'], ['21-30'], ['8-31'], ['12-4'], ['17-0'], ['19-10'], ['14-15'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['7-4'], ['12-26'], ['18-30'], ['11-15'], ['17-22'], ['16-24'], ['6-9'], ['8-26'], ['14-18'], ['15-14'], ['17-31'], ['19-15'], ['21-30'], ['12-4'], ['8-31'], ['17-0'], ['19-10'], ['14-15'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 83.68388414382935\n",
      "Response: Pakistan held its postponed general elections on 14 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 878\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['7-4'], ['18-30'], ['12-26'], ['8-26'], ['6-9'], ['14-18'], ['15-14'], ['16-24'], ['17-31'], ['21-30'], ['19-15'], ['8-31'], ['17-0'], ['12-4'], ['7-12'], ['14-15'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 93.79863739013672\n",
      "Response: The general elections in Pakistan were originally scheduled to be held in 2023, but they were postponed due to unforeseen circumstances. The elections were held on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1760\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['8-26'], ['18-30'], ['7-4'], ['12-26'], ['6-9'], ['14-18'], ['15-14'], ['16-24'], ['21-30'], ['17-31'], ['19-15'], ['7-12'], ['14-15'], ['17-0'], ['19-10'], ['8-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 85.647052526474\n",
      "Response: The general elections in Pakistan were originally scheduled to be held in 2022, but they were postponed due to unforeseen circumstances.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2542\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['8-26'], ['18-30'], ['7-4'], ['12-26'], ['6-9'], ['14-18'], ['15-14'], ['16-24'], ['21-30'], ['17-31'], ['19-15'], ['7-12'], ['14-15'], ['17-0'], ['19-10'], ['8-31'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['8-26'], ['18-30'], ['7-4'], ['12-26'], ['6-9'], ['14-18'], ['15-14'], ['16-24'], ['17-31'], ['21-30'], ['19-15'], ['7-12'], ['14-15'], ['12-4'], ['8-31'], ['17-0'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['8-26'], ['18-30'], ['7-4'], ['12-26'], ['6-9'], ['14-18'], ['15-14'], ['16-24'], ['17-31'], ['19-15'], ['21-30'], ['7-12'], ['14-15'], ['12-4'], ['8-31'], ['17-0'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 88.84084820747375\n",
      "Response: The general elections in Pakistan were initially set for 2022, although the exact date had not been finalized. The elections were postponed due to unforeseen circumstances.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1156\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['8-26'], ['18-30'], ['12-26'], ['7-4'], ['6-9'], ['15-14'], ['14-18'], ['16-24'], ['7-12'], ['19-15'], ['17-31'], ['21-30'], ['14-15'], ['12-4'], ['17-0'], ['19-10'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 85.647052526474\n",
      "Response: The general elections in Pakistan were originally scheduled to be held in 2022, but they were postponed due to unforeseen circumstances.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2305\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['8-26'], ['18-30'], ['6-9'], ['12-26'], ['7-4'], ['15-14'], ['14-18'], ['7-12'], ['16-24'], ['19-15'], ['21-30'], ['17-31'], ['14-15'], ['12-4'], ['17-0'], ['19-10'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 85.647052526474\n",
      "Response: The general elections in Pakistan were originally scheduled to be held in 2022, but they were postponed due to unforeseen circumstances.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3551\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['8-26'], ['18-30'], ['6-9'], ['12-26'], ['7-4'], ['15-14'], ['7-12'], ['14-18'], ['19-15'], ['16-24'], ['21-30'], ['17-31'], ['14-15'], ['12-4'], ['17-0'], ['8-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 85.647052526474\n",
      "Response: The general elections in Pakistan were originally scheduled to be held in 2022, but they were postponed due to unforeseen circumstances.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "General elections, originally scheduled to be held in 2023, were held in Pakistan on 8 February 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['8-26'], ['18-30'], ['6-9'], ['12-26'], ['7-4'], ['15-14'], ['14-18'], ['7-12'], ['16-24'], ['19-15'], ['21-30'], ['17-31'], ['12-4'], ['14-15'], ['8-31'], ['17-0'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 84.19649600982666\n",
      "Response: Pakistan held its postponed general elections on 8 February 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_14_irrelevant_misleading/llama-2-7b-80k_id_14_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['6-30'], ['12-2'], ['13-11'], ['24-3'], ['24-11'], ['8-26'], ['17-22'], ['22-8'], ['22-27'], ['26-26'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['6-30'], ['12-2'], ['13-11'], ['24-3'], ['24-11'], ['8-26'], ['17-22'], ['22-8'], ['22-27'], ['26-26'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['6-30'], ['12-2'], ['13-11'], ['24-3'], ['24-11'], ['8-26'], ['17-22'], ['22-8'], ['22-27'], ['26-26'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['6-30'], ['12-2'], ['13-11'], ['24-3'], ['24-11'], ['8-26'], ['17-22'], ['22-8'], ['22-27'], ['26-26'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_0_depth_7500_results.json\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['6-30'], ['12-2'], ['13-11'], ['24-3'], ['24-11'], ['8-26'], ['17-22'], ['22-8'], ['22-27'], ['26-26'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['24-3'], ['6-30'], ['12-2'], ['13-11'], ['24-11'], ['22-8'], ['8-26'], ['17-22'], ['22-27'], ['26-26'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 92.78591275215149\n",
      "Response: Prabowo Subianto won the 2024 presidential election in Indonesia.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_1250_depth_0_results.json\n",
      "insertion at 257\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 46.1431622505188\n",
      "Response: Prabowo Subianto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 384\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 46.1431622505188\n",
      "Response: Prabowo Subianto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 772\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['12-2'], ['13-11'], ['24-3'], ['24-11'], ['6-30'], ['8-26'], ['22-8'], ['17-22'], ['22-27'], ['31-16'], ['26-26'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 79.89898324012756\n",
      "Response: Prabowo Subianto won the 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_1250_depth_7500_results.json\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['7-4'], ['24-29'], ['21-30'], ['19-15'], ['12-26'], ['8-26'], ['24-3'], ['13-11'], ['24-11'], ['17-22'], ['6-30'], ['12-2'], ['31-16'], ['22-8'], ['22-27'], ['26-26'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 46.1431622505188\n",
      "Response: Prabowo Subianto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_2500_depth_0_results.json\n",
      "insertion at 534\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['24-29'], ['7-4'], ['21-30'], ['19-15'], ['8-26'], ['12-26'], ['24-3'], ['17-22'], ['24-11'], ['12-2'], ['13-11'], ['6-30'], ['22-8'], ['31-16'], ['22-27'], ['26-26'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 79.89898324012756\n",
      "Response: Prabowo Subianto won the 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1127\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['24-29'], ['7-4'], ['21-30'], ['19-15'], ['8-26'], ['12-26'], ['17-22'], ['24-3'], ['24-11'], ['12-2'], ['13-11'], ['6-30'], ['22-8'], ['31-16'], ['26-26'], ['22-27'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 79.89898324012756\n",
      "Response: Prabowo Subianto won the 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1471\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['24-29'], ['21-30'], ['19-15'], ['7-4'], ['8-26'], ['12-26'], ['17-22'], ['24-3'], ['24-11'], ['12-2'], ['13-11'], ['22-8'], ['26-26'], ['31-16'], ['6-30'], ['22-27'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 79.89898324012756\n",
      "Response: Prabowo Subianto won the 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_2500_depth_7500_results.json\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['8-26'], ['12-26'], ['17-22'], ['24-3'], ['24-11'], ['31-16'], ['12-2'], ['13-11'], ['6-30'], ['22-8'], ['26-26'], ['22-27'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 47.23844528198242\n",
      "Response: Prabowo Subianto.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_3750_depth_0_results.json\n",
      "insertion at 878\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 47.23844528198242\n",
      "Response: Prabowo Subianto.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1731\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 47.23844528198242\n",
      "Response: Prabowo Subianto.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2637\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 47.23844528198242\n",
      "Response: Prabowo Subianto.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_3750_depth_7500_results.json\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['16-19'], ['11-15'], ['21-30'], ['8-26'], ['7-4'], ['19-15'], ['24-29'], ['12-26'], ['17-22'], ['24-3'], ['31-16'], ['24-11'], ['13-11'], ['6-30'], ['12-2'], ['22-8'], ['22-27'], ['26-26'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 46.1431622505188\n",
      "Response: Prabowo Subianto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1127\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['21-30'], ['8-26'], ['19-15'], ['7-4'], ['24-29'], ['12-26'], ['17-22'], ['24-3'], ['31-16'], ['24-11'], ['12-2'], ['13-11'], ['6-30'], ['22-8'], ['26-26'], ['22-27'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 79.89898324012756\n",
      "Response: Prabowo Subianto won the 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2380\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['21-30'], ['8-26'], ['19-15'], ['24-29'], ['7-4'], ['12-26'], ['17-22'], ['24-3'], ['24-11'], ['31-16'], ['12-2'], ['13-11'], ['6-30'], ['22-8'], ['26-26'], ['22-27'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 72.87895679473877\n",
      "Response: Prabowo Subianto won the 2024 presidential election. He is backed by the two KIB member parties, Golkar and PAN, as well as the non-parliamentary parties that formed the Advanced Indones\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3581\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['19-15'], ['24-29'], ['7-4'], ['17-22'], ['12-26'], ['24-11'], ['24-3'], ['31-16'], ['12-2'], ['13-11'], ['6-30'], ['22-8'], ['26-26'], ['18-30'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 79.89898324012756\n",
      "Response: Prabowo Subianto won the 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_5000_depth_7500_results.json\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['19-15'], ['7-4'], ['24-29'], ['12-26'], ['17-22'], ['31-16'], ['24-11'], ['24-3'], ['12-2'], ['13-11'], ['6-30'], ['22-8'], ['26-26'], ['18-30'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant/llama-2-7b-80k_id_15_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/15.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['6-30'], ['12-2'], ['13-11'], ['24-3'], ['24-11'], ['8-26'], ['17-22'], ['22-8'], ['22-27'], ['26-26'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['6-30'], ['12-2'], ['13-11'], ['24-3'], ['24-11'], ['8-26'], ['17-22'], ['22-8'], ['22-27'], ['26-26'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['6-30'], ['12-2'], ['13-11'], ['24-3'], ['24-11'], ['8-26'], ['17-22'], ['22-8'], ['22-27'], ['26-26'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['6-30'], ['12-2'], ['13-11'], ['24-3'], ['24-11'], ['8-26'], ['17-22'], ['22-8'], ['22-27'], ['26-26'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_0_depth_7500_results.json\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['6-30'], ['12-2'], ['13-11'], ['24-3'], ['24-11'], ['8-26'], ['17-22'], ['22-8'], ['22-27'], ['26-26'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['24-3'], ['6-30'], ['12-2'], ['13-11'], ['24-11'], ['22-8'], ['8-26'], ['17-22'], ['22-27'], ['26-26'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 92.78591275215149\n",
      "Response: Prabowo Subianto won the 2024 presidential election in Indonesia.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 257\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['24-3'], ['12-2'], ['24-11'], ['6-30'], ['13-11'], ['8-26'], ['17-22'], ['22-8'], ['22-27'], ['31-16'], ['26-26'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 79.89898324012756\n",
      "Response: Prabowo Subianto won the 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 384\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['16-19'], ['7-4'], ['19-15'], ['21-30'], ['12-26'], ['24-3'], ['12-2'], ['24-11'], ['6-30'], ['8-26'], ['13-11'], ['17-22'], ['22-8'], ['22-27'], ['31-16'], ['26-26'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 79.89898324012756\n",
      "Response: Prabowo Subianto won the 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 772\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['24-29'], ['19-15'], ['21-30'], ['7-4'], ['12-26'], ['12-2'], ['24-11'], ['8-26'], ['17-22'], ['24-3'], ['13-11'], ['6-30'], ['22-8'], ['22-27'], ['31-16'], ['26-26'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 79.89898324012756\n",
      "Response: Prabowo Subianto won the 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_1250_depth_7500_results.json\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['21-30'], ['24-29'], ['7-4'], ['19-15'], ['12-26'], ['8-26'], ['17-22'], ['24-3'], ['24-11'], ['12-2'], ['13-11'], ['6-30'], ['31-16'], ['22-27'], ['22-8'], ['26-28'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['21-30'], ['24-29'], ['7-4'], ['19-15'], ['12-26'], ['8-26'], ['17-22'], ['24-3'], ['24-11'], ['12-2'], ['13-11'], ['6-30'], ['31-16'], ['22-8'], ['22-27'], ['26-28'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 72.83397912979126\n",
      "Response: Prabowo Subianto, as the presidential candidate of the Gerindra Party, won the 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 534\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['24-29'], ['21-30'], ['19-15'], ['7-4'], ['8-26'], ['12-26'], ['17-22'], ['24-3'], ['24-11'], ['12-2'], ['13-11'], ['22-27'], ['6-30'], ['22-8'], ['31-16'], ['26-26'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 79.89898324012756\n",
      "Response: Prabowo Subianto won the 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1112\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['8-26'], ['12-26'], ['17-22'], ['24-3'], ['24-11'], ['12-2'], ['13-11'], ['22-8'], ['22-27'], ['31-16'], ['6-30'], ['30-14'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 72.83397912979126\n",
      "Response: Prabowo Subianto, as the presidential candidate of the Gerindra Party, won the 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1492\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['24-29'], ['21-30'], ['19-15'], ['8-26'], ['7-4'], ['17-22'], ['12-26'], ['24-3'], ['24-11'], ['12-2'], ['22-8'], ['22-27'], ['31-16'], ['13-11'], ['6-30'], ['26-26'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 79.89898324012756\n",
      "Response: Prabowo Subianto won the 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_2500_depth_7500_results.json\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['21-30'], ['24-29'], ['19-15'], ['8-26'], ['7-4'], ['12-26'], ['17-22'], ['24-3'], ['24-11'], ['12-2'], ['31-16'], ['13-11'], ['22-27'], ['22-8'], ['6-30'], ['30-14'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 39.33787643909454\n",
      "Response: Prabowo Subianto and Gibran Rakabuming\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 878\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['21-30'], ['24-29'], ['19-15'], ['8-26'], ['7-4'], ['17-22'], ['12-26'], ['24-3'], ['24-11'], ['12-2'], ['31-16'], ['13-11'], ['22-8'], ['22-27'], ['6-30'], ['30-14'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 79.89898324012756\n",
      "Response: Prabowo Subianto won the 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1752\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['21-30'], ['24-29'], ['8-26'], ['19-15'], ['17-22'], ['7-4'], ['12-26'], ['24-3'], ['24-11'], ['12-2'], ['31-16'], ['13-11'], ['22-8'], ['22-27'], ['6-30'], ['26-26'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 79.89898324012756\n",
      "Response: Prabowo Subianto won the 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2530\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['21-30'], ['24-29'], ['8-26'], ['19-15'], ['17-22'], ['7-4'], ['12-26'], ['24-3'], ['24-11'], ['13-11'], ['12-2'], ['31-16'], ['22-8'], ['22-27'], ['26-26'], ['6-30'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 79.89898324012756\n",
      "Response: Prabowo Subianto won the 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_3750_depth_7500_results.json\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['19-15'], ['17-22'], ['7-4'], ['12-26'], ['24-3'], ['24-11'], ['13-11'], ['31-16'], ['12-2'], ['22-8'], ['22-27'], ['26-26'], ['6-30'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['19-15'], ['17-22'], ['7-4'], ['12-26'], ['24-3'], ['24-11'], ['13-11'], ['31-16'], ['12-2'], ['22-8'], ['22-27'], ['26-26'], ['6-30'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 79.89898324012756\n",
      "Response: Prabowo Subianto won the 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1148\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['17-22'], ['19-15'], ['7-4'], ['12-26'], ['24-3'], ['24-11'], ['13-11'], ['12-2'], ['31-16'], ['22-8'], ['22-27'], ['26-26'], ['6-30'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 79.89898324012756\n",
      "Response: Prabowo Subianto won the 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2293\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['17-22'], ['24-29'], ['19-15'], ['7-4'], ['12-26'], ['24-11'], ['24-3'], ['13-11'], ['12-2'], ['31-16'], ['22-8'], ['22-27'], ['26-26'], ['6-30'], ['23-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 79.89898324012756\n",
      "Response: Prabowo Subianto won the 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3569\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['17-22'], ['8-26'], ['24-29'], ['19-15'], ['7-4'], ['12-26'], ['24-3'], ['24-11'], ['13-11'], ['12-2'], ['31-16'], ['22-8'], ['22-27'], ['26-26'], ['14-18'], ['23-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 79.89898324012756\n",
      "Response: Prabowo Subianto won the 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_5000_depth_7500_results.json\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['17-22'], ['24-29'], ['19-15'], ['7-4'], ['12-26'], ['24-3'], ['24-11'], ['13-11'], ['31-16'], ['12-2'], ['22-8'], ['22-27'], ['14-18'], ['26-26'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_relevant_misleading/llama-2-7b-80k_id_15_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['6-30'], ['12-2'], ['13-11'], ['24-3'], ['24-11'], ['8-26'], ['17-22'], ['22-8'], ['22-27'], ['26-26'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['6-30'], ['12-2'], ['13-11'], ['24-3'], ['24-11'], ['8-26'], ['17-22'], ['22-8'], ['22-27'], ['26-26'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['6-30'], ['12-2'], ['13-11'], ['24-3'], ['24-11'], ['8-26'], ['17-22'], ['22-8'], ['22-27'], ['26-26'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['6-30'], ['12-2'], ['13-11'], ['24-3'], ['24-11'], ['8-26'], ['17-22'], ['22-8'], ['22-27'], ['26-26'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_0_depth_7500_results.json\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['6-30'], ['12-2'], ['13-11'], ['24-3'], ['24-11'], ['8-26'], ['17-22'], ['22-8'], ['22-27'], ['26-26'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['6-30'], ['12-2'], ['13-11'], ['24-3'], ['24-11'], ['8-26'], ['17-22'], ['22-8'], ['22-27'], ['26-26'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 67.25164651870728\n",
      "Response: The winner of the 2024 Indonesian presidential election was Claudia Sheinbaum.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 240\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['16-19'], ['7-4'], ['21-30'], ['19-15'], ['8-26'], ['12-26'], ['24-3'], ['6-30'], ['12-2'], ['13-11'], ['24-11'], ['17-22'], ['22-8'], ['22-27'], ['26-26'], ['29-26'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 476\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['24-29'], ['21-30'], ['7-4'], ['8-26'], ['19-15'], ['12-26'], ['24-3'], ['6-30'], ['12-2'], ['17-22'], ['13-11'], ['24-11'], ['22-8'], ['26-26'], ['22-27'], ['29-26'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 676\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['24-29'], ['21-30'], ['8-26'], ['19-15'], ['7-4'], ['12-26'], ['17-22'], ['24-3'], ['6-30'], ['12-2'], ['13-11'], ['24-11'], ['7-12'], ['22-8'], ['26-26'], ['22-27'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_1250_depth_7500_results.json\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['12-26'], ['17-22'], ['24-3'], ['6-30'], ['12-2'], ['13-11'], ['24-11'], ['22-8'], ['31-16'], ['7-12'], ['26-26'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['24-29'], ['21-30'], ['19-15'], ['7-4'], ['12-26'], ['17-22'], ['24-3'], ['6-30'], ['12-2'], ['13-11'], ['24-11'], ['22-8'], ['31-16'], ['7-12'], ['26-26'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 67.25164651870728\n",
      "Response: The winner of the 2024 Indonesian presidential election was Claudia Sheinbaum.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 476\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['12-26'], ['17-22'], ['24-3'], ['6-30'], ['12-2'], ['7-12'], ['13-11'], ['24-11'], ['22-8'], ['26-26'], ['31-16'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 94.95067596435547\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.57%\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1085\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['12-26'], ['24-3'], ['7-12'], ['6-30'], ['12-2'], ['13-11'], ['24-11'], ['22-8'], ['26-26'], ['31-16'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 94.82967853546143\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.58,9,+3\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1711\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['12-26'], ['7-12'], ['24-3'], ['6-30'], ['12-2'], ['13-11'], ['22-8'], ['24-11'], ['26-26'], ['22-27'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 82.93784260749817\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.30 14 +8 PT Alberto Anaya 5.58 9 +3 Fuerza y CorazÃ³n por MÃ©xico (40\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_2500_depth_7500_results.json\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['12-26'], ['24-3'], ['7-12'], ['6-30'], ['12-2'], ['13-11'], ['24-11'], ['22-8'], ['31-16'], ['26-26'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['12-26'], ['24-3'], ['7-12'], ['6-30'], ['12-2'], ['13-11'], ['24-11'], ['22-8'], ['31-16'], ['26-26'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 68.99158358573914\n",
      "Response: The winner of the 2024 Indonesian presidential election was Joko Widodo, who was re-elected for a second term.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 845\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['12-26'], ['7-12'], ['24-3'], ['6-30'], ['12-2'], ['13-11'], ['24-11'], ['22-8'], ['31-16'], ['26-26'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1759\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['7-12'], ['12-26'], ['24-3'], ['6-30'], ['12-2'], ['13-11'], ['24-11'], ['22-8'], ['31-16'], ['26-26'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2618\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['21-30'], ['24-29'], ['19-15'], ['17-22'], ['7-4'], ['7-12'], ['12-26'], ['24-3'], ['6-30'], ['13-11'], ['12-2'], ['24-11'], ['22-8'], ['26-26'], ['31-16'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_3750_depth_7500_results.json\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['21-30'], ['24-29'], ['19-15'], ['17-22'], ['7-4'], ['7-12'], ['12-26'], ['24-3'], ['6-30'], ['13-11'], ['31-16'], ['12-2'], ['24-11'], ['11-2'], ['18-30'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['21-30'], ['24-29'], ['19-15'], ['17-22'], ['7-4'], ['7-12'], ['12-26'], ['24-3'], ['6-30'], ['13-11'], ['12-2'], ['31-16'], ['11-2'], ['24-11'], ['18-30'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 64.05858993530273\n",
      "Response: Claudia Sheinbaum won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1193\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['21-30'], ['24-29'], ['19-15'], ['17-22'], ['7-4'], ['7-12'], ['12-26'], ['24-3'], ['6-30'], ['11-2'], ['13-11'], ['12-2'], ['31-16'], ['24-11'], ['18-30'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2385\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['21-30'], ['24-29'], ['17-22'], ['19-15'], ['7-12'], ['7-4'], ['12-26'], ['24-3'], ['6-30'], ['11-2'], ['12-2'], ['13-11'], ['31-16'], ['18-30'], ['24-11'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3574\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['21-30'], ['24-29'], ['17-22'], ['7-12'], ['19-15'], ['7-4'], ['12-26'], ['24-3'], ['6-30'], ['11-2'], ['12-2'], ['13-11'], ['31-16'], ['18-30'], ['26-26'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_5000_depth_7500_results.json\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['21-30'], ['24-29'], ['17-22'], ['19-15'], ['7-12'], ['7-4'], ['12-26'], ['24-3'], ['6-30'], ['11-2'], ['31-16'], ['13-11'], ['18-30'], ['12-2'], ['24-11'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant/llama-2-7b-80k_id_15_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/15.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['6-30'], ['12-2'], ['13-11'], ['24-3'], ['24-11'], ['8-26'], ['17-22'], ['22-8'], ['22-27'], ['26-26'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['6-30'], ['12-2'], ['13-11'], ['24-3'], ['24-11'], ['8-26'], ['17-22'], ['22-8'], ['22-27'], ['26-26'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['6-30'], ['12-2'], ['13-11'], ['24-3'], ['24-11'], ['8-26'], ['17-22'], ['22-8'], ['22-27'], ['26-26'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['6-30'], ['12-2'], ['13-11'], ['24-3'], ['24-11'], ['8-26'], ['17-22'], ['22-8'], ['22-27'], ['26-26'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['6-30'], ['12-2'], ['13-11'], ['24-3'], ['24-11'], ['8-26'], ['17-22'], ['22-8'], ['22-27'], ['26-26'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['12-26'], ['6-30'], ['12-2'], ['13-11'], ['24-3'], ['24-11'], ['8-26'], ['17-22'], ['22-8'], ['22-27'], ['26-26'], ['26-28'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 67.25164651870728\n",
      "Response: The winner of the 2024 Indonesian presidential election was Claudia Sheinbaum.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 240\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['6-9'], ['11-15'], ['24-29'], ['16-19'], ['7-4'], ['21-30'], ['19-15'], ['8-26'], ['12-26'], ['24-3'], ['6-30'], ['12-2'], ['13-11'], ['24-11'], ['17-22'], ['22-8'], ['22-27'], ['26-26'], ['29-26'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 476\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['24-29'], ['21-30'], ['7-4'], ['8-26'], ['19-15'], ['12-26'], ['24-3'], ['6-30'], ['12-2'], ['17-22'], ['13-11'], ['24-11'], ['22-8'], ['26-26'], ['22-27'], ['29-26'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 676\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['24-29'], ['21-30'], ['8-26'], ['19-15'], ['7-4'], ['12-26'], ['17-22'], ['24-3'], ['6-30'], ['12-2'], ['13-11'], ['24-11'], ['7-12'], ['22-8'], ['26-26'], ['22-27'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['12-26'], ['17-22'], ['24-3'], ['6-30'], ['12-2'], ['13-11'], ['24-11'], ['22-8'], ['31-16'], ['7-12'], ['26-26'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['24-29'], ['21-30'], ['19-15'], ['7-4'], ['12-26'], ['17-22'], ['24-3'], ['6-30'], ['12-2'], ['13-11'], ['24-11'], ['7-12'], ['22-8'], ['26-26'], ['31-16'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 476\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['24-29'], ['21-30'], ['19-15'], ['7-4'], ['12-26'], ['17-22'], ['24-3'], ['7-12'], ['12-2'], ['6-30'], ['13-11'], ['24-11'], ['22-8'], ['26-26'], ['31-16'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 94.6671724319458\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.57%,,\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1106\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['12-26'], ['24-3'], ['7-12'], ['6-30'], ['12-2'], ['13-11'], ['24-11'], ['22-8'], ['26-26'], ['31-16'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 94.82967853546143\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.58,9,+3\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1710\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['12-26'], ['24-3'], ['7-12'], ['6-30'], ['12-2'], ['13-11'], ['24-11'], ['26-26'], ['31-16'], ['22-8'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 90.44564962387085\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.48 60 +5 PVEM Karen CastrejÃ³n Trujillo 9.30 14 +8 PT Alberto An\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['12-26'], ['24-3'], ['7-12'], ['6-30'], ['12-2'], ['13-11'], ['31-16'], ['24-11'], ['26-26'], ['26-25'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['12-26'], ['24-3'], ['7-12'], ['6-30'], ['12-2'], ['13-11'], ['31-16'], ['24-11'], ['26-26'], ['22-8'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 845\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['12-26'], ['7-12'], ['24-3'], ['6-30'], ['12-2'], ['13-11'], ['24-11'], ['31-16'], ['26-26'], ['22-8'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1747\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['7-12'], ['12-26'], ['24-3'], ['12-2'], ['6-30'], ['13-11'], ['24-11'], ['31-16'], ['26-26'], ['6-16'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2644\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['7-12'], ['12-26'], ['24-3'], ['6-30'], ['12-2'], ['13-11'], ['24-11'], ['31-16'], ['26-26'], ['22-8'], ['6-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['12-26'], ['7-12'], ['24-3'], ['6-30'], ['12-2'], ['13-11'], ['31-16'], ['24-11'], ['26-26'], ['18-30'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['12-26'], ['7-12'], ['24-3'], ['6-30'], ['12-2'], ['13-11'], ['31-16'], ['24-11'], ['6-16'], ['26-26'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1106\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['12-26'], ['7-12'], ['24-3'], ['6-30'], ['12-2'], ['6-16'], ['13-11'], ['31-16'], ['24-11'], ['18-30'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2248\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['7-12'], ['12-26'], ['24-3'], ['6-30'], ['6-16'], ['12-2'], ['13-11'], ['31-16'], ['24-11'], ['18-30'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3581\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-12'], ['17-22'], ['7-4'], ['12-26'], ['24-3'], ['6-16'], ['6-30'], ['12-2'], ['13-11'], ['24-11'], ['31-16'], ['18-30'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 92.97641515731812\n",
      "Response: Prabowo Subianto won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "Prabowo won Indonesia's 2024 presidential election.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['7-12'], ['12-26'], ['24-3'], ['6-30'], ['12-2'], ['6-16'], ['31-16'], ['13-11'], ['24-11'], ['18-30'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Prabowo won Indonesia's 2024 presidential election.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_15_irrelevant_misleading/llama-2-7b-80k_id_15_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['14-15'], ['6-30'], ['11-2'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['18-30'], ['19-19'], ['26-28'], ['31-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['14-15'], ['6-30'], ['11-2'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['18-30'], ['19-19'], ['26-28'], ['31-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['14-15'], ['6-30'], ['11-2'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['18-30'], ['19-19'], ['26-28'], ['31-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['14-15'], ['6-30'], ['11-2'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['18-30'], ['19-19'], ['26-28'], ['31-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_0_depth_7500_results.json\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['14-15'], ['6-30'], ['11-2'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['18-30'], ['19-19'], ['26-28'], ['31-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 44.27516162395477\n",
      "Response: Luke Littler (2025)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_1250_depth_0_results.json\n",
      "insertion at 229\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 47.07686901092529\n",
      "Response: Luke Humphries\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 481\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 47.07686901092529\n",
      "Response: Luke Humphries\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 716\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 47.07686901092529\n",
      "Response: Luke Humphries\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_1250_depth_7500_results.json\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['14-15'], ['15-14'], ['24-29'], ['6-30'], ['14-18'], ['17-0'], ['26-28'], ['18-30'], ['19-19'], ['31-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 44.27516162395477\n",
      "Response: Luke Littler (2025)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_2500_depth_0_results.json\n",
      "insertion at 481\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['24-29'], ['6-30'], ['15-14'], ['14-15'], ['26-28'], ['18-30'], ['17-0'], ['14-18'], ['19-19'], ['10-18'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 65.08963704109192\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career. Other players to win more than once are John Part (2003 & 2008), Adrian Lewis (2011 & 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1120\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['6-30'], ['24-29'], ['15-14'], ['14-15'], ['26-28'], ['18-30'], ['14-18'], ['17-0'], ['19-19'], ['10-18'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1672\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['6-30'], ['24-29'], ['15-14'], ['14-15'], ['26-28'], ['18-30'], ['14-18'], ['17-0'], ['19-19'], ['10-18'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_2500_depth_7500_results.json\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['6-30'], ['15-14'], ['24-29'], ['14-15'], ['26-28'], ['14-18'], ['18-30'], ['17-0'], ['19-19'], ['10-18'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 47.07686901092529\n",
      "Response: Luke Humphries\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_3750_depth_0_results.json\n",
      "insertion at 863\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 47.07686901092529\n",
      "Response: Luke Humphries\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1741\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['17-22'], ['7-4'], ['21-30'], ['11-2'], ['24-29'], ['15-14'], ['6-30'], ['14-18'], ['26-28'], ['14-15'], ['18-30'], ['17-0'], ['19-19'], ['10-18'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2609\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['7-4'], ['21-30'], ['11-2'], ['24-29'], ['14-18'], ['15-14'], ['6-30'], ['26-28'], ['14-15'], ['7-12'], ['17-0'], ['18-30'], ['19-19'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_3750_depth_7500_results.json\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['7-4'], ['21-30'], ['11-2'], ['24-29'], ['14-18'], ['15-14'], ['6-30'], ['26-28'], ['17-0'], ['14-15'], ['18-30'], ['7-12'], ['19-19'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['7-4'], ['21-30'], ['11-2'], ['24-29'], ['14-18'], ['15-14'], ['6-30'], ['26-28'], ['17-0'], ['14-15'], ['18-30'], ['7-12'], ['19-19'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 50.23882985115051\n",
      "Response: Luke Littler\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1120\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['7-4'], ['21-30'], ['11-2'], ['24-29'], ['14-18'], ['15-14'], ['26-28'], ['6-30'], ['17-0'], ['7-12'], ['18-30'], ['14-15'], ['19-19'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2377\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['21-30'], ['7-4'], ['11-2'], ['24-29'], ['14-18'], ['15-14'], ['26-28'], ['6-30'], ['7-12'], ['17-0'], ['18-30'], ['14-15'], ['19-19'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3476\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['21-30'], ['7-4'], ['11-2'], ['24-29'], ['15-14'], ['14-18'], ['26-28'], ['6-30'], ['7-12'], ['17-0'], ['18-30'], ['14-15'], ['19-19'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_5000_depth_7500_results.json\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['7-4'], ['21-30'], ['11-2'], ['24-29'], ['15-14'], ['14-18'], ['26-28'], ['6-30'], ['17-0'], ['7-12'], ['18-30'], ['14-15'], ['19-19'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant/llama-2-7b-80k_id_155_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/155.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['14-15'], ['6-30'], ['11-2'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['18-30'], ['19-19'], ['26-28'], ['31-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['14-15'], ['6-30'], ['11-2'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['18-30'], ['19-19'], ['26-28'], ['31-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['14-15'], ['6-30'], ['11-2'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['18-30'], ['19-19'], ['26-28'], ['31-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['14-15'], ['6-30'], ['11-2'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['18-30'], ['19-19'], ['26-28'], ['31-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_0_depth_7500_results.json\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['14-15'], ['6-30'], ['11-2'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['18-30'], ['19-19'], ['26-28'], ['31-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['14-15'], ['24-29'], ['15-14'], ['14-18'], ['6-30'], ['18-30'], ['7-12'], ['17-0'], ['19-19'], ['26-28'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 98.6989676952362\n",
      "Response: The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career. He won the PDC World Youth Championship in 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 229\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['7-4'], ['11-2'], ['21-30'], ['7-12'], ['24-29'], ['14-15'], ['14-18'], ['15-14'], ['6-30'], ['16-1'], ['18-30'], ['17-0'], ['19-19'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 98.66209626197815\n",
      "Response: The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career. Organised by the Professional Darts Corporation (PDC\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 481\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['11-2'], ['19-15'], ['21-30'], ['7-4'], ['7-12'], ['24-29'], ['14-18'], ['14-15'], ['15-14'], ['16-1'], ['6-30'], ['18-30'], ['26-28'], ['17-0'], ['19-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 97.03280925750732\n",
      "Response: The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career. Other players to win more than once are John Part (\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 716\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 47.07686901092529\n",
      "Response: Luke Humphries\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['7-4'], ['11-2'], ['21-30'], ['24-29'], ['7-12'], ['14-18'], ['14-15'], ['15-14'], ['16-1'], ['6-30'], ['18-30'], ['26-28'], ['17-0'], ['19-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['7-4'], ['21-30'], ['7-12'], ['24-29'], ['14-18'], ['15-14'], ['14-15'], ['16-1'], ['6-30'], ['18-30'], ['26-28'], ['17-0'], ['19-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 91.98651313781738\n",
      "Response: Luke Littler, now known as Luke Humphries, had won both the PDC World Youth Championship and the PDC World Darts Championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 481\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['7-4'], ['21-30'], ['7-12'], ['24-29'], ['14-18'], ['15-14'], ['14-15'], ['16-1'], ['6-30'], ['26-28'], ['18-30'], ['17-0'], ['19-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1128\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['21-30'], ['7-4'], ['7-12'], ['24-29'], ['14-18'], ['15-14'], ['16-1'], ['14-15'], ['18-30'], ['6-30'], ['26-28'], ['17-0'], ['19-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1673\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['21-30'], ['7-4'], ['7-12'], ['24-29'], ['14-18'], ['15-14'], ['16-1'], ['14-15'], ['18-30'], ['19-19'], ['6-30'], ['17-0'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['7-4'], ['11-2'], ['21-30'], ['7-12'], ['24-29'], ['14-18'], ['15-14'], ['16-1'], ['14-15'], ['6-30'], ['18-30'], ['26-28'], ['17-0'], ['19-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['7-4'], ['21-30'], ['7-12'], ['24-29'], ['14-18'], ['15-14'], ['16-1'], ['14-15'], ['6-30'], ['18-30'], ['26-28'], ['17-0'], ['19-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 95.17505168914795\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career, is the most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship. He won the PDC World Youth Championship in\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 863\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['21-30'], ['7-4'], ['7-12'], ['24-29'], ['14-18'], ['15-14'], ['16-1'], ['14-15'], ['26-28'], ['19-19'], ['6-30'], ['18-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1744\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['21-30'], ['7-4'], ['7-12'], ['24-29'], ['14-18'], ['15-14'], ['16-1'], ['26-28'], ['19-19'], ['14-15'], ['6-30'], ['17-0'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2631\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['21-30'], ['7-4'], ['7-12'], ['24-29'], ['14-18'], ['15-14'], ['16-1'], ['26-28'], ['14-15'], ['6-30'], ['17-0'], ['19-19'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['21-30'], ['7-4'], ['7-12'], ['24-29'], ['14-18'], ['15-14'], ['16-1'], ['26-28'], ['6-30'], ['17-0'], ['14-15'], ['19-19'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 47.07686901092529\n",
      "Response: Luke Humphries\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1155\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 47.07686901092529\n",
      "Response: Luke Humphries\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2357\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['21-30'], ['7-4'], ['7-12'], ['24-29'], ['15-14'], ['14-18'], ['26-28'], ['16-1'], ['17-0'], ['6-30'], ['14-15'], ['19-19'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3552\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['21-30'], ['7-4'], ['7-12'], ['24-29'], ['15-14'], ['14-18'], ['17-0'], ['26-28'], ['16-1'], ['14-15'], ['19-19'], ['18-30'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['21-30'], ['7-4'], ['7-12'], ['24-29'], ['15-14'], ['14-18'], ['17-0'], ['26-28'], ['16-1'], ['6-30'], ['18-30'], ['14-15'], ['19-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_relevant_misleading/llama-2-7b-80k_id_155_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['14-15'], ['6-30'], ['11-2'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['18-30'], ['19-19'], ['26-28'], ['31-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['14-15'], ['6-30'], ['11-2'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['18-30'], ['19-19'], ['26-28'], ['31-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['14-15'], ['6-30'], ['11-2'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['18-30'], ['19-19'], ['26-28'], ['31-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['14-15'], ['6-30'], ['11-2'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['18-30'], ['19-19'], ['26-28'], ['31-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_0_depth_7500_results.json\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['14-15'], ['6-30'], ['11-2'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['18-30'], ['19-19'], ['26-28'], ['31-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['14-15'], ['6-30'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['18-30'], ['19-19'], ['26-28'], ['31-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 71.81236743927002\n",
      "Response: Michael Smith is the most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship. He won the PDC World Youth Championship in 2013 and the PDC World Darts Championship in 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 14\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['14-15'], ['6-30'], ['24-29'], ['15-14'], ['19-19'], ['14-18'], ['26-28'], ['7-12'], ['17-0'], ['18-30'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 14\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['6-30'], ['24-29'], ['15-14'], ['14-15'], ['7-12'], ['19-19'], ['26-28'], ['14-18'], ['17-0'], ['18-30'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 14\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['6-30'], ['11-2'], ['24-29'], ['15-14'], ['7-12'], ['14-15'], ['19-19'], ['26-28'], ['14-18'], ['17-0'], ['18-30'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_1250_depth_7500_results.json\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['6-30'], ['24-29'], ['11-2'], ['15-14'], ['14-15'], ['19-19'], ['7-12'], ['26-28'], ['10-18'], ['14-18'], ['17-0'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 10.480048507452011\n",
      "Response: Michael Smith,Michael Smith.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 14\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 44.01957988739014\n",
      "Response: Michael Smith, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 14\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 44.01957988739014\n",
      "Response: Michael Smith, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1652\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['6-30'], ['24-29'], ['11-2'], ['15-14'], ['14-15'], ['7-12'], ['19-19'], ['26-28'], ['10-18'], ['17-0'], ['18-30'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 76.47340297698975\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career. He was a regular winner of local darts events and made his debut in a PDC major at the 2009 UK Open where he lost to Dave\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_2500_depth_7500_results.json\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['19-15'], ['7-4'], ['17-22'], ['21-30'], ['6-30'], ['24-29'], ['15-14'], ['11-2'], ['14-15'], ['19-19'], ['26-28'], ['7-12'], ['10-18'], ['17-0'], ['18-30'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 13.826771080493927\n",
      "Response: Michael Smith\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 14\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 44.01957988739014\n",
      "Response: Michael Smith, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1734\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 13.826771080493927\n",
      "Response: Michael Smith\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2603\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 47.07686901092529\n",
      "Response: Luke Humphries\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_3750_depth_7500_results.json\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['19-15'], ['7-4'], ['17-22'], ['21-30'], ['11-2'], ['6-30'], ['24-29'], ['15-14'], ['14-15'], ['26-28'], ['19-19'], ['10-18'], ['17-0'], ['18-30'], ['7-12'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 13.826771080493927\n",
      "Response: Michael Smith\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 14\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 44.01957988739014\n",
      "Response: Michael Smith, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2376\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['7-4'], ['21-30'], ['11-2'], ['24-29'], ['6-30'], ['15-14'], ['7-12'], ['14-15'], ['26-28'], ['10-18'], ['19-19'], ['18-30'], ['17-0'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3526\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['7-4'], ['21-30'], ['11-2'], ['7-12'], ['24-29'], ['6-30'], ['15-14'], ['14-15'], ['10-18'], ['19-19'], ['26-28'], ['18-30'], ['17-0'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_5000_depth_7500_results.json\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['7-4'], ['21-30'], ['11-2'], ['24-29'], ['6-30'], ['7-12'], ['15-14'], ['10-18'], ['14-15'], ['26-28'], ['19-19'], ['18-30'], ['14-18'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant/llama-2-7b-80k_id_155_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/155.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['14-15'], ['6-30'], ['11-2'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['18-30'], ['19-19'], ['26-28'], ['31-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['14-15'], ['6-30'], ['11-2'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['18-30'], ['19-19'], ['26-28'], ['31-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['14-15'], ['6-30'], ['11-2'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['18-30'], ['19-19'], ['26-28'], ['31-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['14-15'], ['6-30'], ['11-2'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['18-30'], ['19-19'], ['26-28'], ['31-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['14-15'], ['6-30'], ['11-2'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['18-30'], ['19-19'], ['26-28'], ['31-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['14-15'], ['6-30'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['18-30'], ['19-19'], ['26-28'], ['31-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 71.81236743927002\n",
      "Response: Michael Smith is the most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship. He won the PDC World Youth Championship in 2013 and the PDC World Darts Championship in 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 14\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['14-15'], ['6-30'], ['24-29'], ['15-14'], ['19-19'], ['14-18'], ['26-28'], ['7-12'], ['17-0'], ['18-30'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 14\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['6-30'], ['24-29'], ['15-14'], ['14-15'], ['7-12'], ['19-19'], ['26-28'], ['14-18'], ['17-0'], ['18-30'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 14\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['6-30'], ['11-2'], ['24-29'], ['15-14'], ['7-12'], ['14-15'], ['19-19'], ['26-28'], ['14-18'], ['17-0'], ['18-30'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['6-30'], ['24-29'], ['11-2'], ['15-14'], ['14-15'], ['19-19'], ['7-12'], ['26-28'], ['10-18'], ['14-18'], ['17-0'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 13.826771080493927\n",
      "Response: Michael Smith\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 14\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 44.01957988739014\n",
      "Response: Michael Smith, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 14\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 44.01957988739014\n",
      "Response: Michael Smith, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1652\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['19-15'], ['7-4'], ['17-22'], ['21-30'], ['6-30'], ['24-29'], ['11-2'], ['15-14'], ['14-15'], ['7-12'], ['19-19'], ['26-28'], ['10-18'], ['17-0'], ['18-30'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 76.47340297698975\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career. He was a regular winner of local darts events and made his debut in a PDC major at the 2009 UK Open where he lost to Dave\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['19-15'], ['7-4'], ['17-22'], ['21-30'], ['6-30'], ['24-29'], ['15-14'], ['11-2'], ['14-15'], ['19-19'], ['26-28'], ['7-12'], ['10-18'], ['17-0'], ['18-30'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 13.826771080493927\n",
      "Response: Michael Smith\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 14\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 44.01957988739014\n",
      "Response: Michael Smith, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1734\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 47.07686901092529\n",
      "Response: Luke Humphries\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2595\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 47.07686901092529\n",
      "Response: Luke Humphries\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['19-15'], ['7-4'], ['21-30'], ['17-22'], ['24-29'], ['6-30'], ['11-2'], ['15-14'], ['14-15'], ['26-28'], ['19-19'], ['7-12'], ['10-18'], ['17-0'], ['18-30'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 92.1937346458435\n",
      "Response: Luke Humphries is the most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 13.826771080493927\n",
      "Response: Michael Smith\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 14\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 13.826771080493927\n",
      "Response: Michael Smith\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2364\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 47.07686901092529\n",
      "Response: Luke Humphries\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3565\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 47.07686901092529\n",
      "Response: Luke Humphries\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The most recent player to win both the PDC World Youth Championship and the PDC World Darts Championship is Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['19-15'], ['7-4'], ['21-30'], ['17-22'], ['24-29'], ['6-30'], ['11-2'], ['15-14'], ['14-15'], ['26-28'], ['19-19'], ['10-18'], ['17-0'], ['31-16'], ['7-12'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 60.90353727340698\n",
      "Response: Luke Humphries, previously known as Luke Littler during his youth career.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_155_irrelevant_misleading/llama-2-7b-80k_id_155_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_0_depth_7500_results.json\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 80.7699978351593\n",
      "Response: The first female president of Mexico was Liza Carrillo. She was elected in 2018 and served from 2018 to 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_1250_depth_0_results.json\n",
      "insertion at 240\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 71.75614833831787\n",
      "Response: The first female president of Mexico was Vicente Fox, who was elected in 2000.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 476\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 71.75614833831787\n",
      "Response: The first female president of Mexico was Vicente Fox, who was elected in 2000.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 676\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 71.75614833831787\n",
      "Response: The first female president of Mexico was Vicente Fox, who was elected in 2000.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_1250_depth_7500_results.json\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 45.86074948310852\n",
      "Response: Claudia Sheinbaum.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 71.75614833831787\n",
      "Response: The first female president of Mexico was Vicente Fox, who was elected in 2000.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_2500_depth_0_results.json\n",
      "insertion at 476\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 71.75614833831787\n",
      "Response: The first female president of Mexico was Vicente Fox, who was elected in 2000.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1085\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['14-18'], ['6-30'], ['12-26'], ['24-30'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 71.75614833831787\n",
      "Response: The first female president of Mexico was Vicente Fox, who was elected in 2000.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1689\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['14-18'], ['6-30'], ['12-26'], ['24-30'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 71.75614833831787\n",
      "Response: The first female president of Mexico was Vicente Fox, who was elected in 2000.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_2500_depth_7500_results.json\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-4'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['11-2'], ['15-14'], ['18-30'], ['24-29'], ['14-15'], ['29-19'], ['14-18'], ['6-30'], ['12-26'], ['24-30'], ['30-14'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-4'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['11-2'], ['15-14'], ['18-30'], ['24-29'], ['14-15'], ['29-19'], ['14-18'], ['6-30'], ['12-26'], ['24-30'], ['30-14'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 75.54044127464294\n",
      "Response: The first female president of Mexico was Vicente Fox, who was elected in 2000. She was the first female president of Mexico and the first female president of any country in the Americas.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_3750_depth_0_results.json\n",
      "insertion at 845\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-4'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['11-2'], ['15-14'], ['18-30'], ['24-29'], ['14-15'], ['29-19'], ['14-18'], ['6-30'], ['12-26'], ['24-30'], ['30-14'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 82.82793164253235\n",
      "Response: Claudia Sheinbaum was the first female president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1759\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-4'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['11-2'], ['15-14'], ['18-30'], ['24-29'], ['14-15'], ['29-19'], ['14-18'], ['6-30'], ['12-26'], ['24-30'], ['30-14'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 71.75614833831787\n",
      "Response: The first female president of Mexico was Vicente Fox, who was elected in 2000.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2618\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-4'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['11-2'], ['15-14'], ['18-30'], ['24-29'], ['14-15'], ['29-19'], ['14-18'], ['6-30'], ['12-26'], ['24-30'], ['30-14'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 71.75614833831787\n",
      "Response: The first female president of Mexico was Vicente Fox, who was elected in 2000.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_3750_depth_7500_results.json\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['15-14'], ['11-2'], ['18-30'], ['24-29'], ['14-15'], ['29-19'], ['14-18'], ['6-30'], ['12-26'], ['24-30'], ['30-14'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['15-14'], ['11-2'], ['18-30'], ['24-29'], ['14-15'], ['29-19'], ['14-18'], ['6-30'], ['12-26'], ['24-30'], ['30-14'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 70.05912065505981\n",
      "Response: The first female president of Mexico was Vicente Fox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1193\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 2.2649960592389107\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2385\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 2.2649960592389107\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3523\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 2.2649960592389107\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_5000_depth_7500_results.json\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['15-14'], ['11-2'], ['18-30'], ['24-29'], ['14-15'], ['29-19'], ['14-18'], ['6-30'], ['12-26'], ['24-30'], ['30-14'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant/llama-2-7b-80k_id_16_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/16.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_0_depth_7500_results.json\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 80.7699978351593\n",
      "Response: The first female president of Mexico was Liza Carrillo. She was elected in 2018 and served from 2018 to 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 240\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 71.75614833831787\n",
      "Response: The first female president of Mexico was Vicente Fox, who was elected in 2000.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 476\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 71.75614833831787\n",
      "Response: The first female president of Mexico was Vicente Fox, who was elected in 2000.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 676\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 71.75614833831787\n",
      "Response: The first female president of Mexico was Vicente Fox, who was elected in 2000.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_1250_depth_7500_results.json\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 45.86074948310852\n",
      "Response: Claudia Sheinbaum.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['11-2'], ['15-14'], ['18-30'], ['29-19'], ['14-15'], ['24-29'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 83.38785171508789\n",
      "Response: The first female president of Mexico was Claudia Sheinbaum.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 476\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['15-14'], ['11-2'], ['18-30'], ['29-19'], ['24-29'], ['14-15'], ['6-30'], ['12-26'], ['14-18'], ['24-30'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 69.96142864227295\n",
      "Response: Claudia Sheinbaum, who was elected in 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1100\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['11-2'], ['15-14'], ['18-30'], ['24-29'], ['29-19'], ['14-15'], ['14-18'], ['6-30'], ['24-30'], ['12-26'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1704\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['11-2'], ['15-14'], ['18-30'], ['24-29'], ['14-15'], ['14-18'], ['29-19'], ['6-30'], ['24-30'], ['12-26'], ['12-2'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 95.51697969436646\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.48 60 +5 PVEM Karen CastrejÃ³n Trujillo 9.30\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_2500_depth_7500_results.json\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['15-14'], ['11-2'], ['18-30'], ['24-29'], ['14-15'], ['14-18'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['15-14'], ['11-2'], ['18-30'], ['24-29'], ['14-15'], ['14-18'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 70.05912065505981\n",
      "Response: The first female president of Mexico was Vicente Fox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 845\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['15-14'], ['11-2'], ['18-30'], ['24-29'], ['14-15'], ['14-18'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 70.05912065505981\n",
      "Response: The first female president of Mexico was Vicente Fox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1741\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['15-14'], ['11-2'], ['18-30'], ['24-29'], ['14-15'], ['14-18'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 70.05912065505981\n",
      "Response: The first female president of Mexico was Vicente Fox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2641\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['15-14'], ['11-2'], ['18-30'], ['24-29'], ['14-15'], ['14-18'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 70.05912065505981\n",
      "Response: The first female president of Mexico was Vicente Fox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_3750_depth_7500_results.json\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['15-14'], ['11-2'], ['18-30'], ['24-29'], ['14-15'], ['14-18'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['15-14'], ['11-2'], ['18-30'], ['24-29'], ['14-15'], ['14-18'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 68.73308420181274\n",
      "Response: The first female president of Mexico was Liza Soberano.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1100\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['15-14'], ['11-2'], ['18-30'], ['24-29'], ['14-15'], ['14-18'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 70.05912065505981\n",
      "Response: The first female president of Mexico was Vicente Fox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2245\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['15-14'], ['11-2'], ['18-30'], ['24-29'], ['14-15'], ['14-18'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 70.05912065505981\n",
      "Response: The first female president of Mexico was Vicente Fox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3555\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['15-14'], ['11-2'], ['18-30'], ['24-29'], ['14-15'], ['14-18'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 70.05912065505981\n",
      "Response: The first female president of Mexico was Vicente Fox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_5000_depth_7500_results.json\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['15-14'], ['11-2'], ['18-30'], ['24-29'], ['14-15'], ['14-18'], ['29-19'], ['6-30'], ['30-14'], ['12-26'], ['24-30'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_relevant_misleading/llama-2-7b-80k_id_16_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_0_depth_7500_results.json\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 73.26557636260986\n",
      "Response: The first female president of Mexico was Vicente Fox. He was the 55th president of Mexico and served from 1 December 2000 to 30 November 2006.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 250\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['11-2'], ['21-30'], ['15-14'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['24-30'], ['6-30'], ['14-18'], ['12-26'], ['30-14'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 384\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['11-2'], ['21-30'], ['15-14'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['24-30'], ['6-30'], ['14-18'], ['12-26'], ['30-14'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 62.74383068084717\n",
      "Response: Enrique PeÃ±a Nieto was the first female president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 739\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['11-2'], ['21-30'], ['15-14'], ['18-30'], ['24-29'], ['14-15'], ['29-19'], ['14-18'], ['6-30'], ['24-30'], ['12-26'], ['30-14'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 92.74019002914429\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico. Prabowo and his vice-presidential candidate, Gibran Rakabuming, were sworn in on\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_1250_depth_7500_results.json\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['11-2'], ['15-14'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['14-18'], ['6-30'], ['24-30'], ['12-26'], ['30-14'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 2.2649960592389107\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 534\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['11-2'], ['15-14'], ['18-30'], ['24-29'], ['14-15'], ['14-18'], ['29-19'], ['6-30'], ['24-30'], ['7-12'], ['12-26'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1127\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['11-2'], ['18-30'], ['15-14'], ['24-29'], ['14-15'], ['7-12'], ['14-18'], ['29-19'], ['6-30'], ['24-30'], ['17-16'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 94.49237585067749\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico. The meeting, which ended the political feud between both men, also resulted in Gerindra Party and the National Mand\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1471\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['11-2'], ['18-30'], ['15-14'], ['7-12'], ['14-15'], ['24-29'], ['14-18'], ['29-19'], ['6-30'], ['24-30'], ['17-16'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_2500_depth_7500_results.json\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['11-2'], ['18-30'], ['15-14'], ['7-12'], ['24-29'], ['14-15'], ['14-18'], ['29-19'], ['6-30'], ['24-30'], ['17-16'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 2.2649960592389107\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 878\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['21-30'], ['19-15'], ['11-2'], ['18-30'], ['15-14'], ['7-12'], ['14-15'], ['24-29'], ['14-18'], ['29-19'], ['6-30'], ['24-30'], ['17-16'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1731\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 40.32090902328491\n",
      "Response: Sheinbaum.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2637\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 40.32090902328491\n",
      "Response: Sheinbaum.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_3750_depth_7500_results.json\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['21-30'], ['19-15'], ['11-2'], ['18-30'], ['15-14'], ['7-12'], ['14-15'], ['24-29'], ['14-18'], ['29-19'], ['6-30'], ['24-30'], ['13-23'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 30.436918139457703\n",
      "Response: Vicente Fox Quesada\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1127\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['21-30'], ['19-15'], ['11-2'], ['18-30'], ['15-14'], ['7-12'], ['24-29'], ['14-15'], ['14-18'], ['29-19'], ['6-30'], ['24-30'], ['13-23'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 94.49237585067749\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico. The meeting, which ended the political feud between both men, also resulted in Gerindra Party and the National Mand\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2380\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['21-30'], ['19-15'], ['11-2'], ['18-30'], ['7-12'], ['15-14'], ['24-29'], ['14-18'], ['14-15'], ['6-30'], ['29-19'], ['24-30'], ['13-23'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 92.62366890907288\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico. He is backed by the two KIB member parties, Golkar and PAN, as well as the non-\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3562\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['21-30'], ['19-15'], ['11-2'], ['7-12'], ['18-30'], ['15-14'], ['24-29'], ['14-18'], ['14-15'], ['6-30'], ['29-19'], ['13-23'], ['24-30'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 91.22224450111389\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico. In each of his presidential campaigns, he criticised Jokowi's policies. Likewise, his speech\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_5000_depth_7500_results.json\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['21-30'], ['19-15'], ['11-2'], ['18-30'], ['7-12'], ['15-14'], ['24-29'], ['14-18'], ['14-15'], ['29-19'], ['6-30'], ['13-23'], ['16-1'], ['24-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant/llama-2-7b-80k_id_16_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/16.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 69.50361728668213\n",
      "Response: The first female president of Mexico was Lydia Cacho.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 250\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 70.05912065505981\n",
      "Response: The first female president of Mexico was Vicente Fox.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 384\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 68.73308420181274\n",
      "Response: The first female president of Mexico was Liza Soberano.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 739\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['21-30'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 71.75614833831787\n",
      "Response: The first female president of Mexico was Vicente Fox, who was elected in 2000.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['21-30'], ['15-14'], ['11-2'], ['18-30'], ['14-15'], ['29-19'], ['24-29'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['21-30'], ['15-14'], ['11-2'], ['18-30'], ['14-15'], ['29-19'], ['24-29'], ['6-30'], ['12-26'], ['24-30'], ['14-18'], ['30-14'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 76.53676271438599\n",
      "Response: The first female president of Mexico was Lydia Pardomuan. She was the first female president of Mexico and was elected in 2019.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 534\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['11-2'], ['15-14'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['14-18'], ['6-30'], ['12-26'], ['24-30'], ['30-14'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1106\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['11-2'], ['15-14'], ['18-30'], ['14-15'], ['24-29'], ['29-19'], ['14-18'], ['6-30'], ['7-12'], ['24-30'], ['12-26'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 91.77609086036682\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico. He chose his opponent in the election, Prabowo Subianto, as Minister of Defense after a recon\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1486\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['11-2'], ['18-30'], ['15-14'], ['14-15'], ['24-29'], ['7-12'], ['14-18'], ['29-19'], ['6-30'], ['24-30'], ['12-26'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['11-2'], ['15-14'], ['18-30'], ['24-29'], ['14-15'], ['29-19'], ['7-12'], ['14-18'], ['6-30'], ['24-30'], ['12-26'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['11-2'], ['15-14'], ['18-30'], ['24-29'], ['7-12'], ['14-15'], ['14-18'], ['29-19'], ['6-30'], ['24-30'], ['17-16'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 878\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['19-15'], ['21-30'], ['11-2'], ['15-14'], ['18-30'], ['7-12'], ['24-29'], ['14-15'], ['14-18'], ['29-19'], ['6-30'], ['24-30'], ['17-16'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1746\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['19-15'], ['21-30'], ['11-2'], ['7-12'], ['15-14'], ['18-30'], ['24-29'], ['14-15'], ['14-18'], ['29-19'], ['17-16'], ['6-30'], ['24-30'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 92.19151139259338\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico. He was endorsed by the Coalition of Change, which included the NasDem Party, the Pros\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2527\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['11-2'], ['7-12'], ['15-14'], ['18-30'], ['24-29'], ['14-15'], ['14-18'], ['29-19'], ['17-16'], ['13-23'], ['16-1'], ['24-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 92.24398732185364\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico. On 22 October 2023, President Joko Widodo's eldest son and Mayor\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['11-2'], ['7-12'], ['15-14'], ['18-30'], ['24-29'], ['14-15'], ['14-18'], ['29-19'], ['16-1'], ['13-23'], ['17-16'], ['24-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['11-2'], ['7-12'], ['15-14'], ['18-30'], ['24-29'], ['14-15'], ['14-18'], ['29-19'], ['16-1'], ['13-23'], ['17-16'], ['24-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 86.86578869819641\n",
      "Response: Sheinbaum was the first female president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1142\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['11-2'], ['7-12'], ['15-14'], ['18-30'], ['24-29'], ['14-15'], ['14-18'], ['29-19'], ['16-1'], ['13-23'], ['17-16'], ['24-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 94.49237585067749\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico. The meeting, which ended the political feud between both men, also resulted in Gerindra Party and the National Mand\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2290\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['11-2'], ['7-12'], ['15-14'], ['18-30'], ['24-29'], ['14-15'], ['14-18'], ['29-19'], ['16-1'], ['13-23'], ['17-16'], ['24-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3566\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['21-30'], ['7-12'], ['19-15'], ['11-2'], ['15-14'], ['18-30'], ['24-29'], ['14-18'], ['14-15'], ['16-1'], ['29-19'], ['13-23'], ['17-16'], ['24-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['21-30'], ['19-15'], ['11-2'], ['7-12'], ['15-14'], ['18-30'], ['24-29'], ['14-18'], ['14-15'], ['16-1'], ['29-19'], ['13-23'], ['17-16'], ['24-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99998807907104\n",
      "Response: Sheinbaum won the presidential election in 2024, becoming the first woman to be elected president of Mexico.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_16_irrelevant_misleading/llama-2-7b-80k_id_16_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The President of the United States is Donald Trump.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['14-18'], ['16-19'], ['16-24'], ['18-30'], ['19-15'], ['21-30'], ['24-3'], ['31-16'], ['0-1'], ['0-19'], ['0-27'], ['1-0'], ['1-1'], ['1-3'], ['1-4'], ['1-5'], ['1-11'], ['1-13'], ['2-2'], ['2-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['14-18'], ['16-19'], ['16-24'], ['18-30'], ['19-15'], ['21-30'], ['24-3'], ['31-16'], ['0-1'], ['0-19'], ['0-27'], ['1-0'], ['1-1'], ['1-3'], ['1-4'], ['1-5'], ['1-11'], ['1-13'], ['2-2'], ['2-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['14-18'], ['16-19'], ['16-24'], ['18-30'], ['19-15'], ['21-30'], ['24-3'], ['31-16'], ['0-1'], ['0-19'], ['0-27'], ['1-0'], ['1-1'], ['1-3'], ['1-4'], ['1-5'], ['1-11'], ['1-13'], ['2-2'], ['2-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['14-18'], ['16-19'], ['16-24'], ['18-30'], ['19-15'], ['21-30'], ['24-3'], ['31-16'], ['0-1'], ['0-19'], ['0-27'], ['1-0'], ['1-1'], ['1-3'], ['1-4'], ['1-5'], ['1-11'], ['1-13'], ['2-2'], ['2-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_0_depth_7500_results.json\n",
      "The President of the United States is Donald Trump.\n",
      "[['14-18'], ['16-19'], ['16-24'], ['18-30'], ['19-15'], ['21-30'], ['24-3'], ['31-16'], ['0-1'], ['0-19'], ['0-27'], ['1-0'], ['1-1'], ['1-3'], ['1-4'], ['1-5'], ['1-11'], ['1-13'], ['2-2'], ['2-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['14-18'], ['16-19'], ['16-24'], ['18-30'], ['19-15'], ['21-30'], ['24-3'], ['31-16'], ['1-13'], ['2-4'], ['2-5'], ['2-7'], ['2-8'], ['2-10'], ['2-11'], ['2-14'], ['2-16'], ['2-17'], ['2-18'], ['2-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 62.49001622200012\n",
      "Response: The President of the United States is the head of state and head of government of the United States. The president directs the executive branch of the federal government and is the commander-in-chief of the United States Armed Forces. The power\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_1250_depth_0_results.json\n",
      "insertion at 217\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['14-18'], ['18-30'], ['24-3'], ['16-24'], ['19-15'], ['21-30'], ['31-16'], ['1-13'], ['2-4'], ['2-5'], ['2-7'], ['2-8'], ['2-10'], ['2-11'], ['2-14'], ['2-16'], ['2-17'], ['2-18'], ['2-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 519\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['18-30'], ['14-18'], ['24-3'], ['19-15'], ['16-24'], ['21-30'], ['31-16'], ['1-13'], ['2-4'], ['2-5'], ['2-7'], ['2-8'], ['2-10'], ['2-11'], ['2-14'], ['2-16'], ['2-17'], ['2-18'], ['2-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 764\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['18-30'], ['14-18'], ['24-3'], ['19-15'], ['16-24'], ['21-30'], ['31-16'], ['11-15'], ['21-27'], ['1-13'], ['2-4'], ['2-5'], ['2-7'], ['2-8'], ['2-10'], ['2-11'], ['2-14'], ['2-16'], ['2-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_1250_depth_7500_results.json\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['18-30'], ['24-3'], ['19-15'], ['14-18'], ['21-30'], ['8-26'], ['16-24'], ['7-4'], ['31-16'], ['12-26'], ['21-27'], ['6-9'], ['17-22'], ['1-13'], ['2-4'], ['2-5'], ['2-7'], ['2-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['18-30'], ['24-3'], ['14-18'], ['8-26'], ['21-30'], ['16-24'], ['7-4'], ['31-16'], ['12-26'], ['21-27'], ['2-4'], ['2-5'], ['2-7'], ['2-8'], ['2-10'], ['2-11'], ['2-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 62.49001622200012\n",
      "Response: The President of the United States is the head of state and head of government of the United States. The president directs the executive branch of the federal government and is the commander-in-chief of the United States Armed Forces. The power\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_2500_depth_0_results.json\n",
      "insertion at 569\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['18-30'], ['19-15'], ['24-3'], ['14-18'], ['21-30'], ['7-4'], ['16-24'], ['6-9'], ['31-16'], ['21-27'], ['12-26'], ['2-4'], ['2-5'], ['2-7'], ['2-8'], ['2-10'], ['2-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1141\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['18-30'], ['8-26'], ['19-15'], ['24-3'], ['14-18'], ['21-30'], ['7-4'], ['16-24'], ['31-16'], ['6-9'], ['21-27'], ['12-26'], ['2-4'], ['2-5'], ['2-7'], ['2-8'], ['2-10'], ['2-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 70.5931007862091\n",
      "Response: Donald Trump\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1692\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['18-30'], ['8-26'], ['19-15'], ['24-3'], ['14-18'], ['7-4'], ['21-30'], ['21-27'], ['16-24'], ['31-16'], ['6-9'], ['12-26'], ['17-22'], ['2-4'], ['2-5'], ['2-7'], ['2-8'], ['2-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 70.5931007862091\n",
      "Response: Donald Trump\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_2500_depth_7500_results.json\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['18-30'], ['19-15'], ['24-3'], ['7-4'], ['14-18'], ['21-30'], ['12-26'], ['6-9'], ['21-27'], ['16-24'], ['31-16'], ['17-22'], ['6-30'], ['14-7'], ['2-4'], ['2-5'], ['2-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['18-30'], ['19-15'], ['24-3'], ['7-4'], ['14-18'], ['21-30'], ['12-26'], ['6-9'], ['16-24'], ['21-27'], ['31-16'], ['17-22'], ['6-30'], ['2-4'], ['2-5'], ['2-7'], ['2-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_3750_depth_0_results.json\n",
      "insertion at 878\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['18-30'], ['19-15'], ['24-3'], ['7-4'], ['14-18'], ['21-30'], ['12-26'], ['6-9'], ['31-16'], ['16-24'], ['21-27'], ['17-22'], ['6-30'], ['14-7'], ['2-4'], ['2-5'], ['2-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1747\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['18-30'], ['19-15'], ['24-3'], ['14-18'], ['7-4'], ['6-9'], ['21-30'], ['12-26'], ['21-27'], ['31-16'], ['16-24'], ['17-22'], ['6-30'], ['14-7'], ['2-4'], ['2-5'], ['2-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2652\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['18-30'], ['19-15'], ['24-3'], ['7-4'], ['14-18'], ['6-9'], ['21-30'], ['21-27'], ['31-16'], ['12-26'], ['17-22'], ['16-24'], ['6-30'], ['14-7'], ['2-4'], ['2-5'], ['2-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_3750_depth_7500_results.json\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['18-30'], ['19-15'], ['24-3'], ['7-4'], ['12-26'], ['14-18'], ['6-9'], ['21-30'], ['21-27'], ['31-16'], ['17-22'], ['16-24'], ['6-30'], ['14-7'], ['16-30'], ['2-4'], ['2-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['18-30'], ['19-15'], ['7-4'], ['24-3'], ['12-26'], ['14-18'], ['6-9'], ['21-30'], ['21-27'], ['31-16'], ['17-22'], ['16-24'], ['6-30'], ['14-7'], ['2-4'], ['2-5'], ['2-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 62.49001622200012\n",
      "Response: The President of the United States is the head of state and head of government of the United States. The president directs the executive branch of the federal government and is the commander-in-chief of the United States Armed Forces. The power\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1168\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['18-30'], ['19-15'], ['24-3'], ['7-4'], ['6-9'], ['12-26'], ['21-30'], ['14-18'], ['21-27'], ['17-22'], ['31-16'], ['16-24'], ['6-30'], ['14-7'], ['2-4'], ['2-5'], ['2-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2365\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['18-30'], ['19-15'], ['24-3'], ['7-4'], ['6-9'], ['21-30'], ['12-26'], ['14-18'], ['21-27'], ['17-22'], ['31-16'], ['16-24'], ['14-7'], ['6-30'], ['2-4'], ['2-5'], ['2-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3587\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['18-30'], ['19-15'], ['6-9'], ['24-3'], ['7-4'], ['21-30'], ['12-26'], ['14-18'], ['21-27'], ['17-22'], ['31-16'], ['14-7'], ['16-24'], ['6-30'], ['2-4'], ['2-5'], ['2-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 73.9264726638794\n",
      "Response: The President of the United States is Donald Trump. However, presidential power has shifted over time, which has resulted in claims that the modern presidency has become too powerful, unchecked, unbalanced, and \"monarchist\" in\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_5000_depth_7500_results.json\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['18-30'], ['6-9'], ['7-4'], ['24-3'], ['12-26'], ['21-30'], ['21-27'], ['17-22'], ['14-18'], ['31-16'], ['14-7'], ['16-24'], ['6-30'], ['2-4'], ['2-5'], ['2-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant/llama-2-7b-80k_id_160_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/160.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The President of the United States is Donald Trump.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['14-18'], ['16-19'], ['16-24'], ['18-30'], ['19-15'], ['21-30'], ['24-3'], ['31-16'], ['0-1'], ['0-19'], ['0-27'], ['1-0'], ['1-1'], ['1-3'], ['1-4'], ['1-5'], ['1-11'], ['1-13'], ['2-2'], ['2-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['14-18'], ['16-19'], ['16-24'], ['18-30'], ['19-15'], ['21-30'], ['24-3'], ['31-16'], ['0-1'], ['0-19'], ['0-27'], ['1-0'], ['1-1'], ['1-3'], ['1-4'], ['1-5'], ['1-11'], ['1-13'], ['2-2'], ['2-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['14-18'], ['16-19'], ['16-24'], ['18-30'], ['19-15'], ['21-30'], ['24-3'], ['31-16'], ['0-1'], ['0-19'], ['0-27'], ['1-0'], ['1-1'], ['1-3'], ['1-4'], ['1-5'], ['1-11'], ['1-13'], ['2-2'], ['2-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['14-18'], ['16-19'], ['16-24'], ['18-30'], ['19-15'], ['21-30'], ['24-3'], ['31-16'], ['0-1'], ['0-19'], ['0-27'], ['1-0'], ['1-1'], ['1-3'], ['1-4'], ['1-5'], ['1-11'], ['1-13'], ['2-2'], ['2-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_0_depth_7500_results.json\n",
      "The President of the United States is Donald Trump.\n",
      "[['14-18'], ['16-19'], ['16-24'], ['18-30'], ['19-15'], ['21-30'], ['24-3'], ['31-16'], ['0-1'], ['0-19'], ['0-27'], ['1-0'], ['1-1'], ['1-3'], ['1-4'], ['1-5'], ['1-11'], ['1-13'], ['2-2'], ['2-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['19-15'], ['14-18'], ['16-24'], ['18-30'], ['21-30'], ['24-3'], ['31-16'], ['11-15'], ['2-2'], ['2-4'], ['2-5'], ['2-7'], ['2-8'], ['2-10'], ['2-11'], ['2-13'], ['2-14'], ['2-16'], ['2-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 217\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['18-30'], ['19-15'], ['24-3'], ['14-18'], ['16-24'], ['21-30'], ['31-16'], ['11-15'], ['2-2'], ['2-4'], ['2-5'], ['2-7'], ['2-8'], ['2-10'], ['2-11'], ['2-13'], ['2-14'], ['2-16'], ['2-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 519\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['18-30'], ['19-15'], ['24-3'], ['14-18'], ['16-24'], ['21-30'], ['31-16'], ['11-15'], ['21-27'], ['2-2'], ['2-4'], ['2-5'], ['2-7'], ['2-8'], ['2-10'], ['2-11'], ['2-13'], ['2-14'], ['2-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 775\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['18-30'], ['19-15'], ['24-3'], ['11-15'], ['14-18'], ['16-24'], ['21-30'], ['31-16'], ['7-4'], ['8-26'], ['21-27'], ['6-9'], ['2-2'], ['2-4'], ['2-5'], ['2-7'], ['2-8'], ['2-10'], ['2-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-3'], ['18-30'], ['8-26'], ['14-18'], ['7-4'], ['16-24'], ['21-30'], ['31-16'], ['6-9'], ['12-26'], ['21-27'], ['17-22'], ['6-30'], ['20-28'], ['2-2'], ['2-4'], ['2-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['18-30'], ['24-3'], ['8-26'], ['14-18'], ['7-4'], ['16-24'], ['21-30'], ['31-16'], ['6-9'], ['12-26'], ['21-27'], ['17-22'], ['6-30'], ['20-28'], ['2-2'], ['2-4'], ['2-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 70.5931007862091\n",
      "Response: Donald Trump\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 569\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['18-30'], ['24-3'], ['14-18'], ['8-26'], ['7-4'], ['16-24'], ['21-30'], ['31-16'], ['6-9'], ['12-26'], ['21-27'], ['17-22'], ['6-30'], ['16-30'], ['20-28'], ['26-28'], ['2-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1117\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-3'], ['18-30'], ['14-18'], ['8-26'], ['7-4'], ['16-24'], ['21-30'], ['31-16'], ['21-27'], ['6-9'], ['12-26'], ['17-22'], ['6-30'], ['14-7'], ['16-30'], ['20-28'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 70.5931007862091\n",
      "Response: Donald Trump\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1714\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['24-3'], ['18-30'], ['14-18'], ['7-4'], ['8-26'], ['21-27'], ['16-24'], ['21-30'], ['31-16'], ['6-9'], ['12-26'], ['17-22'], ['6-30'], ['14-7'], ['16-30'], ['20-28'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-3'], ['18-30'], ['7-4'], ['8-26'], ['12-26'], ['14-18'], ['21-30'], ['21-27'], ['6-9'], ['16-24'], ['31-16'], ['17-22'], ['6-30'], ['14-7'], ['16-30'], ['20-28'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['8-26'], ['24-3'], ['7-4'], ['18-30'], ['12-26'], ['14-18'], ['6-9'], ['21-30'], ['16-24'], ['21-27'], ['31-16'], ['17-22'], ['6-30'], ['16-30'], ['20-28'], ['14-7'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 865\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-3'], ['8-26'], ['18-30'], ['7-4'], ['14-18'], ['12-26'], ['6-9'], ['21-27'], ['21-30'], ['16-24'], ['31-16'], ['17-22'], ['6-30'], ['16-30'], ['20-28'], ['14-7'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 70.5931007862091\n",
      "Response: Donald Trump\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1769\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-3'], ['18-30'], ['8-26'], ['7-4'], ['14-18'], ['12-26'], ['21-27'], ['6-9'], ['21-30'], ['16-24'], ['31-16'], ['17-22'], ['6-30'], ['16-30'], ['20-28'], ['14-7'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 70.5931007862091\n",
      "Response: Donald Trump\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2652\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['18-30'], ['24-3'], ['8-26'], ['7-4'], ['14-18'], ['21-27'], ['12-26'], ['6-9'], ['21-30'], ['16-24'], ['31-16'], ['17-22'], ['6-30'], ['16-30'], ['20-28'], ['14-7'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 70.5931007862091\n",
      "Response: Donald Trump\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['8-26'], ['24-3'], ['18-30'], ['7-4'], ['12-26'], ['14-18'], ['6-9'], ['21-27'], ['21-30'], ['31-16'], ['16-24'], ['17-22'], ['29-26'], ['6-30'], ['20-28'], ['26-28'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['8-26'], ['24-3'], ['18-30'], ['7-4'], ['12-26'], ['14-18'], ['6-9'], ['21-27'], ['21-30'], ['31-16'], ['16-24'], ['17-22'], ['29-26'], ['6-30'], ['20-28'], ['26-28'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1179\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['8-26'], ['24-3'], ['18-30'], ['7-4'], ['12-26'], ['14-18'], ['21-27'], ['6-9'], ['21-30'], ['17-22'], ['31-16'], ['16-24'], ['26-28'], ['29-26'], ['6-30'], ['20-28'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 70.5931007862091\n",
      "Response: Donald Trump\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2387\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-3'], ['8-26'], ['18-30'], ['7-4'], ['12-26'], ['14-18'], ['21-27'], ['6-9'], ['21-30'], ['17-22'], ['31-16'], ['16-24'], ['26-28'], ['29-26'], ['6-30'], ['20-28'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3584\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['24-3'], ['8-26'], ['18-30'], ['7-4'], ['12-26'], ['14-18'], ['21-27'], ['6-9'], ['17-22'], ['21-30'], ['31-16'], ['16-24'], ['26-28'], ['29-26'], ['6-30'], ['14-7'], ['20-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['8-26'], ['24-3'], ['7-4'], ['18-30'], ['12-26'], ['21-27'], ['14-18'], ['6-9'], ['17-22'], ['21-30'], ['31-16'], ['16-24'], ['29-26'], ['26-28'], ['20-28'], ['6-30'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_relevant_misleading/llama-2-7b-80k_id_160_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The President of the United States is Donald Trump.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['14-18'], ['16-19'], ['16-24'], ['18-30'], ['19-15'], ['21-30'], ['24-3'], ['31-16'], ['0-1'], ['0-19'], ['0-27'], ['1-0'], ['1-1'], ['1-3'], ['1-4'], ['1-5'], ['1-11'], ['1-13'], ['2-2'], ['2-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['14-18'], ['16-19'], ['16-24'], ['18-30'], ['19-15'], ['21-30'], ['24-3'], ['31-16'], ['0-1'], ['0-19'], ['0-27'], ['1-0'], ['1-1'], ['1-3'], ['1-4'], ['1-5'], ['1-11'], ['1-13'], ['2-2'], ['2-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['14-18'], ['16-19'], ['16-24'], ['18-30'], ['19-15'], ['21-30'], ['24-3'], ['31-16'], ['0-1'], ['0-19'], ['0-27'], ['1-0'], ['1-1'], ['1-3'], ['1-4'], ['1-5'], ['1-11'], ['1-13'], ['2-2'], ['2-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['14-18'], ['16-19'], ['16-24'], ['18-30'], ['19-15'], ['21-30'], ['24-3'], ['31-16'], ['0-1'], ['0-19'], ['0-27'], ['1-0'], ['1-1'], ['1-3'], ['1-4'], ['1-5'], ['1-11'], ['1-13'], ['2-2'], ['2-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_0_depth_7500_results.json\n",
      "The President of the United States is Donald Trump.\n",
      "[['14-18'], ['16-19'], ['16-24'], ['18-30'], ['19-15'], ['21-30'], ['24-3'], ['31-16'], ['0-1'], ['0-19'], ['0-27'], ['1-0'], ['1-1'], ['1-3'], ['1-4'], ['1-5'], ['1-11'], ['1-13'], ['2-2'], ['2-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['14-18'], ['19-15'], ['21-30'], ['16-24'], ['18-30'], ['24-3'], ['31-16'], ['11-15'], ['1-13'], ['2-2'], ['2-4'], ['2-5'], ['2-7'], ['2-8'], ['2-10'], ['2-11'], ['2-13'], ['2-14'], ['2-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 122\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['19-15'], ['14-18'], ['21-30'], ['8-26'], ['11-15'], ['18-30'], ['24-3'], ['6-9'], ['16-24'], ['17-22'], ['31-16'], ['7-4'], ['6-30'], ['21-27'], ['7-12'], ['1-13'], ['2-2'], ['2-4'], ['2-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 511\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['21-30'], ['6-9'], ['14-18'], ['17-22'], ['18-30'], ['24-3'], ['7-4'], ['16-24'], ['31-16'], ['6-30'], ['7-12'], ['21-27'], ['14-7'], ['1-13'], ['2-2'], ['2-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 73.48617911338806\n",
      "Response: The President of the United States is Donald Trump. The current president is Emmanuel Macron, who succeeded FranÃ§ois Hollande on 14 May 2017 following the 2017 presidential election, and was inaugurated\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 714\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['19-15'], ['21-30'], ['7-4'], ['18-30'], ['14-18'], ['17-22'], ['24-3'], ['7-12'], ['16-24'], ['31-16'], ['6-30'], ['21-27'], ['14-7'], ['16-30'], ['1-13'], ['2-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_1250_depth_7500_results.json\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['19-15'], ['21-30'], ['7-4'], ['18-30'], ['17-22'], ['24-3'], ['14-18'], ['16-24'], ['12-26'], ['31-16'], ['6-30'], ['21-27'], ['7-12'], ['14-7'], ['16-30'], ['1-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['21-30'], ['7-4'], ['17-22'], ['18-30'], ['24-3'], ['14-18'], ['16-24'], ['12-26'], ['21-27'], ['31-16'], ['6-30'], ['7-12'], ['14-7'], ['16-30'], ['2-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 511\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['21-30'], ['7-4'], ['17-22'], ['18-30'], ['24-3'], ['14-18'], ['21-27'], ['7-12'], ['16-24'], ['12-26'], ['6-30'], ['31-16'], ['14-7'], ['16-30'], ['2-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1143\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['21-30'], ['7-4'], ['17-22'], ['24-3'], ['18-30'], ['14-18'], ['7-12'], ['21-27'], ['6-30'], ['16-24'], ['12-26'], ['31-16'], ['14-7'], ['16-30'], ['2-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1686\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['7-4'], ['21-30'], ['17-22'], ['24-3'], ['18-30'], ['7-12'], ['14-18'], ['21-27'], ['6-30'], ['14-7'], ['16-24'], ['12-26'], ['31-16'], ['16-30'], ['2-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_2500_depth_7500_results.json\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['7-4'], ['21-30'], ['17-22'], ['24-3'], ['18-30'], ['12-26'], ['14-18'], ['21-27'], ['7-12'], ['6-30'], ['14-7'], ['16-24'], ['31-16'], ['16-30'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['21-30'], ['17-22'], ['24-3'], ['18-30'], ['12-26'], ['14-18'], ['21-27'], ['6-30'], ['7-12'], ['14-7'], ['16-24'], ['31-16'], ['16-30'], ['2-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 782\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['21-30'], ['17-22'], ['24-3'], ['18-30'], ['7-12'], ['12-26'], ['14-18'], ['21-27'], ['6-30'], ['14-7'], ['16-24'], ['31-16'], ['16-30'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1756\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['21-30'], ['17-22'], ['24-3'], ['18-30'], ['7-12'], ['12-26'], ['14-18'], ['21-27'], ['6-30'], ['14-7'], ['16-24'], ['31-16'], ['16-30'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2631\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['21-30'], ['17-22'], ['24-3'], ['18-30'], ['7-12'], ['21-27'], ['12-26'], ['14-18'], ['6-30'], ['14-7'], ['16-24'], ['31-16'], ['16-30'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_3750_depth_7500_results.json\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['21-30'], ['17-22'], ['24-3'], ['12-26'], ['18-30'], ['21-27'], ['7-12'], ['6-30'], ['14-18'], ['14-7'], ['31-16'], ['16-24'], ['16-30'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['21-30'], ['17-22'], ['24-3'], ['18-30'], ['12-26'], ['21-27'], ['7-12'], ['14-18'], ['6-30'], ['14-7'], ['31-16'], ['16-24'], ['16-30'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1193\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['21-30'], ['17-22'], ['24-3'], ['18-30'], ['12-26'], ['7-12'], ['21-27'], ['14-18'], ['6-30'], ['14-7'], ['31-16'], ['16-24'], ['16-30'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2387\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['24-3'], ['18-30'], ['7-12'], ['12-26'], ['21-27'], ['14-7'], ['14-18'], ['6-30'], ['31-16'], ['16-24'], ['17-16'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3585\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['24-3'], ['18-30'], ['7-12'], ['12-26'], ['21-27'], ['14-7'], ['14-18'], ['6-30'], ['31-16'], ['16-24'], ['17-16'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_5000_depth_7500_results.json\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['21-30'], ['17-22'], ['24-3'], ['18-30'], ['7-12'], ['12-26'], ['21-27'], ['14-7'], ['6-30'], ['14-18'], ['31-16'], ['16-24'], ['17-16'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant/llama-2-7b-80k_id_160_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/160.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The President of the United States is Donald Trump.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['14-18'], ['16-19'], ['16-24'], ['18-30'], ['19-15'], ['21-30'], ['24-3'], ['31-16'], ['0-1'], ['0-19'], ['0-27'], ['1-0'], ['1-1'], ['1-3'], ['1-4'], ['1-5'], ['1-11'], ['1-13'], ['2-2'], ['2-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['14-18'], ['16-19'], ['16-24'], ['18-30'], ['19-15'], ['21-30'], ['24-3'], ['31-16'], ['0-1'], ['0-19'], ['0-27'], ['1-0'], ['1-1'], ['1-3'], ['1-4'], ['1-5'], ['1-11'], ['1-13'], ['2-2'], ['2-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['14-18'], ['16-19'], ['16-24'], ['18-30'], ['19-15'], ['21-30'], ['24-3'], ['31-16'], ['0-1'], ['0-19'], ['0-27'], ['1-0'], ['1-1'], ['1-3'], ['1-4'], ['1-5'], ['1-11'], ['1-13'], ['2-2'], ['2-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['14-18'], ['16-19'], ['16-24'], ['18-30'], ['19-15'], ['21-30'], ['24-3'], ['31-16'], ['0-1'], ['0-19'], ['0-27'], ['1-0'], ['1-1'], ['1-3'], ['1-4'], ['1-5'], ['1-11'], ['1-13'], ['2-2'], ['2-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The President of the United States is Donald Trump.\n",
      "[['14-18'], ['16-19'], ['16-24'], ['18-30'], ['19-15'], ['21-30'], ['24-3'], ['31-16'], ['0-1'], ['0-19'], ['0-27'], ['1-0'], ['1-1'], ['1-3'], ['1-4'], ['1-5'], ['1-11'], ['1-13'], ['2-2'], ['2-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['14-18'], ['19-15'], ['21-30'], ['16-24'], ['18-30'], ['24-3'], ['31-16'], ['11-15'], ['1-13'], ['2-2'], ['2-4'], ['2-5'], ['2-7'], ['2-8'], ['2-10'], ['2-11'], ['2-13'], ['2-14'], ['2-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 122\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['19-15'], ['14-18'], ['21-30'], ['8-26'], ['11-15'], ['18-30'], ['24-3'], ['6-9'], ['16-24'], ['17-22'], ['31-16'], ['7-4'], ['6-30'], ['21-27'], ['7-12'], ['1-13'], ['2-2'], ['2-4'], ['2-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 511\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['21-30'], ['6-9'], ['14-18'], ['17-22'], ['18-30'], ['24-3'], ['7-4'], ['16-24'], ['31-16'], ['6-30'], ['7-12'], ['21-27'], ['14-7'], ['1-13'], ['2-2'], ['2-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 73.48617911338806\n",
      "Response: The President of the United States is Donald Trump. The current president is Emmanuel Macron, who succeeded FranÃ§ois Hollande on 14 May 2017 following the 2017 presidential election, and was inaugurated\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 714\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['19-15'], ['21-30'], ['7-4'], ['18-30'], ['14-18'], ['17-22'], ['24-3'], ['7-12'], ['16-24'], ['31-16'], ['6-30'], ['21-27'], ['14-7'], ['16-30'], ['1-13'], ['2-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['19-15'], ['21-30'], ['7-4'], ['18-30'], ['17-22'], ['24-3'], ['14-18'], ['16-24'], ['12-26'], ['31-16'], ['6-30'], ['21-27'], ['7-12'], ['14-7'], ['16-30'], ['1-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['21-30'], ['7-4'], ['18-30'], ['17-22'], ['24-3'], ['14-18'], ['16-24'], ['12-26'], ['21-27'], ['31-16'], ['6-30'], ['7-12'], ['14-7'], ['16-30'], ['2-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 511\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['21-30'], ['7-4'], ['17-22'], ['18-30'], ['24-3'], ['14-18'], ['21-27'], ['7-12'], ['16-24'], ['12-26'], ['31-16'], ['6-30'], ['14-7'], ['16-30'], ['2-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1143\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['21-30'], ['7-4'], ['17-22'], ['24-3'], ['18-30'], ['14-18'], ['21-27'], ['7-12'], ['16-24'], ['12-26'], ['31-16'], ['6-30'], ['14-7'], ['16-30'], ['2-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 97.62396812438965\n",
      "Response: Donald Trump is the President of the United States.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1697\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['21-30'], ['7-4'], ['17-22'], ['24-3'], ['18-30'], ['7-12'], ['14-18'], ['21-27'], ['14-7'], ['16-24'], ['12-26'], ['6-30'], ['31-16'], ['16-30'], ['2-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['21-30'], ['7-4'], ['18-30'], ['24-3'], ['17-22'], ['21-27'], ['7-12'], ['14-18'], ['16-24'], ['12-26'], ['14-7'], ['31-16'], ['6-30'], ['16-30'], ['2-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['21-30'], ['7-4'], ['18-30'], ['24-3'], ['17-22'], ['7-12'], ['21-27'], ['12-26'], ['14-18'], ['16-24'], ['14-7'], ['31-16'], ['6-30'], ['16-30'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 70.5931007862091\n",
      "Response: Donald Trump\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 782\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['18-30'], ['24-3'], ['17-22'], ['7-12'], ['21-27'], ['12-26'], ['14-18'], ['16-24'], ['14-7'], ['31-16'], ['6-30'], ['16-30'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1767\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-9'], ['18-30'], ['21-30'], ['24-3'], ['7-4'], ['17-22'], ['21-27'], ['7-12'], ['12-26'], ['14-18'], ['16-24'], ['14-7'], ['31-16'], ['6-30'], ['16-30'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2630\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-9'], ['17-22'], ['18-30'], ['24-3'], ['21-30'], ['7-4'], ['21-27'], ['7-12'], ['12-26'], ['14-18'], ['16-24'], ['31-16'], ['14-7'], ['6-30'], ['16-30'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-9'], ['7-4'], ['17-22'], ['21-30'], ['24-3'], ['18-30'], ['12-26'], ['21-27'], ['7-12'], ['14-18'], ['31-16'], ['16-24'], ['14-7'], ['6-30'], ['16-30'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-9'], ['7-4'], ['17-22'], ['21-30'], ['24-3'], ['18-30'], ['12-26'], ['21-27'], ['7-12'], ['14-18'], ['31-16'], ['16-24'], ['14-7'], ['6-30'], ['16-30'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 64.68437314033508\n",
      "Response: The President of the United States is the head of state and head of government of the United States. The president leads the executive branch of the federal government and is the commander-in-chief of the United States Armed Forces.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1193\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-9'], ['7-4'], ['17-22'], ['24-3'], ['18-30'], ['21-30'], ['21-27'], ['12-26'], ['7-12'], ['14-18'], ['31-16'], ['16-24'], ['14-7'], ['6-30'], ['16-30'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2374\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-9'], ['17-22'], ['24-3'], ['7-4'], ['18-30'], ['21-30'], ['21-27'], ['12-26'], ['7-12'], ['14-18'], ['31-16'], ['14-7'], ['16-24'], ['6-30'], ['16-30'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3581\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-9'], ['18-30'], ['24-3'], ['17-22'], ['7-4'], ['21-30'], ['21-27'], ['12-26'], ['7-12'], ['14-7'], ['14-18'], ['31-16'], ['16-24'], ['6-30'], ['16-30'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 64.88415002822876\n",
      "Response: Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The President of the United States is Donald Trump.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-9'], ['7-4'], ['24-3'], ['18-30'], ['17-22'], ['21-30'], ['12-26'], ['21-27'], ['7-12'], ['14-18'], ['31-16'], ['14-7'], ['16-24'], ['6-30'], ['16-30'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The President of the United States is Donald Trump.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_160_irrelevant_misleading/llama-2-7b-80k_id_160_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['12-26'], ['21-30'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['17-0'], ['24-29'], ['13-11'], ['14-18'], ['16-24'], ['7-13'], ['8-31'], ['12-16'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['12-26'], ['21-30'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['17-0'], ['24-29'], ['13-11'], ['14-18'], ['16-24'], ['7-13'], ['8-31'], ['12-16'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['12-26'], ['21-30'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['17-0'], ['24-29'], ['13-11'], ['14-18'], ['16-24'], ['7-13'], ['8-31'], ['12-16'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['12-26'], ['21-30'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['17-0'], ['24-29'], ['13-11'], ['14-18'], ['16-24'], ['7-13'], ['8-31'], ['12-16'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_0_depth_7500_results.json\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['12-26'], ['21-30'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['17-0'], ['24-29'], ['13-11'], ['14-18'], ['16-24'], ['7-13'], ['8-31'], ['12-16'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['21-30'], ['8-26'], ['12-26'], ['17-22'], ['11-2'], ['19-15'], ['15-14'], ['24-29'], ['17-0'], ['14-18'], ['13-11'], ['16-24'], ['7-12'], ['14-13'], ['17-31'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_1250_depth_0_results.json\n",
      "insertion at 233\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['17-22'], ['12-26'], ['11-2'], ['19-15'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['7-12'], ['13-11'], ['16-24'], ['17-31'], ['18-30'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 477\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['7-4'], ['8-26'], ['21-30'], ['11-2'], ['19-15'], ['12-26'], ['15-14'], ['24-29'], ['14-18'], ['7-12'], ['17-0'], ['16-24'], ['13-11'], ['17-31'], ['18-30'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 735\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['7-4'], ['21-30'], ['8-26'], ['19-15'], ['11-2'], ['24-29'], ['15-14'], ['12-26'], ['14-18'], ['7-12'], ['17-0'], ['16-24'], ['17-31'], ['13-11'], ['18-30'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_1250_depth_7500_results.json\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['17-22'], ['8-26'], ['21-30'], ['19-15'], ['11-2'], ['12-26'], ['24-29'], ['14-18'], ['15-14'], ['17-0'], ['7-12'], ['17-31'], ['16-24'], ['18-30'], ['25-3'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 28.28182578086853\n",
      "Response: 11\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_2500_depth_0_results.json\n",
      "insertion at 545\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 28.28182578086853\n",
      "Response: 11\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1114\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 28.28182578086853\n",
      "Response: 11\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1674\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 28.28182578086853\n",
      "Response: 11\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_2500_depth_7500_results.json\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['17-22'], ['8-26'], ['21-30'], ['19-15'], ['12-26'], ['24-29'], ['17-0'], ['11-2'], ['14-18'], ['15-14'], ['7-12'], ['18-30'], ['17-31'], ['16-24'], ['25-3'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['7-4'], ['21-30'], ['19-15'], ['11-2'], ['14-18'], ['12-26'], ['24-29'], ['17-0'], ['15-14'], ['7-12'], ['17-31'], ['18-30'], ['16-24'], ['25-3'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_3750_depth_0_results.json\n",
      "insertion at 839\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['7-4'], ['21-30'], ['19-15'], ['11-2'], ['14-18'], ['24-29'], ['17-0'], ['7-12'], ['12-26'], ['15-14'], ['17-31'], ['18-30'], ['16-24'], ['25-3'], ['25-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1760\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['21-30'], ['7-4'], ['19-15'], ['11-2'], ['14-18'], ['7-12'], ['24-29'], ['17-0'], ['12-26'], ['15-14'], ['17-31'], ['18-30'], ['16-24'], ['25-3'], ['25-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2628\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['21-30'], ['7-4'], ['19-15'], ['7-12'], ['14-18'], ['11-2'], ['24-29'], ['17-0'], ['15-14'], ['12-26'], ['18-30'], ['17-31'], ['16-24'], ['25-3'], ['25-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_3750_depth_7500_results.json\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['21-30'], ['7-4'], ['19-15'], ['7-12'], ['14-18'], ['11-2'], ['17-0'], ['24-29'], ['12-26'], ['15-14'], ['18-30'], ['17-31'], ['16-24'], ['25-3'], ['25-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['21-30'], ['7-4'], ['19-15'], ['14-18'], ['7-12'], ['11-2'], ['24-29'], ['17-0'], ['15-14'], ['12-26'], ['18-30'], ['17-31'], ['16-24'], ['25-3'], ['25-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1114\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['21-30'], ['7-4'], ['7-12'], ['19-15'], ['14-18'], ['11-2'], ['24-29'], ['17-0'], ['15-14'], ['12-26'], ['18-30'], ['17-31'], ['16-24'], ['25-3'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2384\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['21-30'], ['7-12'], ['7-4'], ['19-15'], ['14-18'], ['11-2'], ['24-29'], ['17-0'], ['15-14'], ['18-30'], ['12-26'], ['17-31'], ['16-24'], ['16-1'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3543\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['21-30'], ['7-12'], ['7-4'], ['19-15'], ['14-18'], ['11-2'], ['24-29'], ['17-0'], ['15-14'], ['18-30'], ['17-31'], ['12-26'], ['16-24'], ['16-1'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_5000_depth_7500_results.json\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['21-30'], ['7-4'], ['7-12'], ['19-15'], ['14-18'], ['11-2'], ['24-29'], ['17-0'], ['15-14'], ['18-30'], ['12-26'], ['17-31'], ['16-24'], ['16-1'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant/llama-2-7b-80k_id_163_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/163.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['12-26'], ['21-30'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['17-0'], ['24-29'], ['13-11'], ['14-18'], ['16-24'], ['7-13'], ['8-31'], ['12-16'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['12-26'], ['21-30'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['17-0'], ['24-29'], ['13-11'], ['14-18'], ['16-24'], ['7-13'], ['8-31'], ['12-16'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['12-26'], ['21-30'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['17-0'], ['24-29'], ['13-11'], ['14-18'], ['16-24'], ['7-13'], ['8-31'], ['12-16'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['12-26'], ['21-30'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['17-0'], ['24-29'], ['13-11'], ['14-18'], ['16-24'], ['7-13'], ['8-31'], ['12-16'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_0_depth_7500_results.json\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['12-26'], ['21-30'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['17-0'], ['24-29'], ['13-11'], ['14-18'], ['16-24'], ['7-13'], ['8-31'], ['12-16'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['7-4'], ['8-26'], ['21-30'], ['12-26'], ['17-22'], ['11-2'], ['19-15'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['13-11'], ['16-24'], ['7-12'], ['14-13'], ['17-31'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 233\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['11-2'], ['12-26'], ['19-15'], ['15-14'], ['24-29'], ['14-18'], ['17-0'], ['7-12'], ['13-11'], ['16-24'], ['17-31'], ['25-3'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 477\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 28.28182578086853\n",
      "Response: 11\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 735\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 28.28182578086853\n",
      "Response: 11\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_1250_depth_7500_results.json\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['12-26'], ['19-15'], ['11-2'], ['14-18'], ['15-14'], ['24-29'], ['17-0'], ['7-12'], ['13-11'], ['16-24'], ['17-31'], ['18-30'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['21-30'], ['11-2'], ['19-15'], ['12-26'], ['14-18'], ['15-14'], ['24-29'], ['17-0'], ['7-12'], ['16-24'], ['17-31'], ['13-11'], ['18-30'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 545\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['19-15'], ['14-18'], ['12-26'], ['15-14'], ['24-29'], ['7-12'], ['17-0'], ['16-24'], ['17-31'], ['18-30'], ['25-3'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1138\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 27.262699604034424\n",
      "Response: 11.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1698\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['21-30'], ['7-4'], ['11-2'], ['19-15'], ['14-18'], ['15-14'], ['24-29'], ['7-12'], ['12-26'], ['17-0'], ['17-31'], ['16-24'], ['18-30'], ['25-3'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_2500_depth_7500_results.json\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['7-4'], ['19-15'], ['11-2'], ['14-18'], ['12-26'], ['15-14'], ['24-29'], ['7-12'], ['17-0'], ['17-31'], ['16-24'], ['18-30'], ['25-3'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['7-4'], ['19-15'], ['11-2'], ['14-18'], ['12-26'], ['24-29'], ['7-12'], ['15-14'], ['17-0'], ['17-31'], ['16-24'], ['18-30'], ['25-3'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 839\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['21-30'], ['11-2'], ['7-4'], ['19-15'], ['14-18'], ['7-12'], ['24-29'], ['12-26'], ['15-14'], ['17-0'], ['16-24'], ['17-31'], ['25-3'], ['18-30'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1760\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['11-2'], ['21-30'], ['19-15'], ['7-4'], ['7-12'], ['14-18'], ['24-29'], ['15-14'], ['12-26'], ['17-0'], ['16-24'], ['17-31'], ['25-3'], ['18-30'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2645\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['21-30'], ['11-2'], ['19-15'], ['7-12'], ['7-4'], ['14-18'], ['24-29'], ['15-14'], ['17-0'], ['12-26'], ['16-24'], ['17-31'], ['25-3'], ['18-30'], ['25-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_3750_depth_7500_results.json\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['21-30'], ['11-2'], ['7-4'], ['14-18'], ['7-12'], ['24-29'], ['12-26'], ['15-14'], ['17-0'], ['17-31'], ['16-24'], ['25-3'], ['18-30'], ['25-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 28.28182578086853\n",
      "Response: 11\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1138\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 28.28182578086853\n",
      "Response: 11\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2328\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 27.262699604034424\n",
      "Response: 11.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3580\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 28.28182578086853\n",
      "Response: 11\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_5000_depth_7500_results.json\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['21-30'], ['7-4'], ['11-2'], ['14-18'], ['24-29'], ['12-26'], ['7-12'], ['17-0'], ['15-14'], ['17-31'], ['16-24'], ['18-30'], ['25-3'], ['25-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_relevant_misleading/llama-2-7b-80k_id_163_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['12-26'], ['21-30'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['17-0'], ['24-29'], ['13-11'], ['14-18'], ['16-24'], ['7-13'], ['8-31'], ['12-16'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['12-26'], ['21-30'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['17-0'], ['24-29'], ['13-11'], ['14-18'], ['16-24'], ['7-13'], ['8-31'], ['12-16'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['12-26'], ['21-30'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['17-0'], ['24-29'], ['13-11'], ['14-18'], ['16-24'], ['7-13'], ['8-31'], ['12-16'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['12-26'], ['21-30'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['17-0'], ['24-29'], ['13-11'], ['14-18'], ['16-24'], ['7-13'], ['8-31'], ['12-16'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_0_depth_7500_results.json\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['12-26'], ['21-30'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['17-0'], ['24-29'], ['13-11'], ['14-18'], ['16-24'], ['7-13'], ['8-31'], ['12-16'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 14.507387578487396\n",
      "Response: 194+\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 249\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 27.262699604034424\n",
      "Response: 11.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 514\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['12-26'], ['19-15'], ['11-2'], ['24-29'], ['15-14'], ['17-0'], ['14-18'], ['18-30'], ['13-11'], ['16-24'], ['17-31'], ['12-16'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 764\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['19-15'], ['12-26'], ['11-2'], ['24-29'], ['15-14'], ['17-0'], ['18-30'], ['14-18'], ['17-31'], ['13-11'], ['16-24'], ['22-22'], ['25-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_1250_depth_7500_results.json\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['19-15'], ['12-26'], ['24-29'], ['11-2'], ['17-0'], ['15-14'], ['18-30'], ['14-18'], ['17-31'], ['16-24'], ['13-11'], ['22-22'], ['25-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 14.507387578487396\n",
      "Response: 194+\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 552\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 27.262699604034424\n",
      "Response: 11.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1053\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 27.262699604034424\n",
      "Response: 11.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1697\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 27.262699604034424\n",
      "Response: 11.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_2500_depth_7500_results.json\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['19-15'], ['12-26'], ['17-0'], ['24-29'], ['11-2'], ['15-14'], ['18-30'], ['14-18'], ['17-31'], ['16-24'], ['22-22'], ['25-21'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 14.507387578487396\n",
      "Response: 194+\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 874\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 28.28182578086853\n",
      "Response: 11\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1743\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 28.28182578086853\n",
      "Response: 11\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2627\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 28.28182578086853\n",
      "Response: 11\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_3750_depth_7500_results.json\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['19-15'], ['12-26'], ['17-0'], ['24-29'], ['11-2'], ['15-14'], ['18-30'], ['14-18'], ['17-31'], ['16-24'], ['22-22'], ['25-21'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['19-15'], ['12-26'], ['17-0'], ['24-29'], ['11-2'], ['15-14'], ['18-30'], ['14-18'], ['17-31'], ['16-24'], ['22-22'], ['25-21'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 55.14417290687561\n",
      "Response: 194+ confirmed impact structures listed in the Earth Impact Database as of 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1190\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['21-30'], ['19-15'], ['12-26'], ['24-29'], ['17-0'], ['11-2'], ['18-30'], ['15-14'], ['14-18'], ['17-31'], ['7-12'], ['25-21'], ['16-24'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2374\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 28.28182578086853\n",
      "Response: 11\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3580\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 28.28182578086853\n",
      "Response: 11\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_5000_depth_7500_results.json\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['21-30'], ['19-15'], ['12-26'], ['24-29'], ['17-0'], ['11-2'], ['18-30'], ['15-14'], ['14-18'], ['17-31'], ['7-12'], ['25-21'], ['16-24'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant/llama-2-7b-80k_id_163_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/163.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['12-26'], ['21-30'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['17-0'], ['24-29'], ['13-11'], ['14-18'], ['16-24'], ['7-13'], ['8-31'], ['12-16'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['12-26'], ['21-30'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['17-0'], ['24-29'], ['13-11'], ['14-18'], ['16-24'], ['7-13'], ['8-31'], ['12-16'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['12-26'], ['21-30'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['17-0'], ['24-29'], ['13-11'], ['14-18'], ['16-24'], ['7-13'], ['8-31'], ['12-16'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['12-26'], ['21-30'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['17-0'], ['24-29'], ['13-11'], ['14-18'], ['16-24'], ['7-13'], ['8-31'], ['12-16'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['16-19'], ['8-26'], ['12-26'], ['21-30'], ['17-22'], ['19-15'], ['11-2'], ['15-14'], ['17-0'], ['24-29'], ['13-11'], ['14-18'], ['16-24'], ['7-13'], ['8-31'], ['12-16'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['7-4'], ['8-26'], ['21-30'], ['17-22'], ['12-26'], ['19-15'], ['11-2'], ['24-29'], ['15-14'], ['17-0'], ['14-18'], ['16-24'], ['13-11'], ['7-12'], ['17-31'], ['22-22'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 249\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 27.262699604034424\n",
      "Response: 11.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 514\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 27.262699604034424\n",
      "Response: 11.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 764\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['21-30'], ['17-22'], ['12-26'], ['19-15'], ['11-2'], ['24-29'], ['15-14'], ['17-0'], ['14-18'], ['16-24'], ['13-11'], ['7-12'], ['18-30'], ['17-31'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['19-15'], ['12-26'], ['11-2'], ['24-29'], ['17-0'], ['15-14'], ['14-18'], ['16-24'], ['18-30'], ['13-11'], ['7-12'], ['17-31'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 14.507387578487396\n",
      "Response: 194+\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 552\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 27.262699604034424\n",
      "Response: 11.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1077\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 27.262699604034424\n",
      "Response: 11.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1709\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 27.262699604034424\n",
      "Response: 11.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['12-26'], ['19-15'], ['11-2'], ['17-0'], ['24-29'], ['14-18'], ['15-14'], ['18-30'], ['16-24'], ['13-11'], ['17-31'], ['7-12'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 27.262699604034424\n",
      "Response: 11.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 858\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 27.262699604034424\n",
      "Response: 11.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1742\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 27.262699604034424\n",
      "Response: 11.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2634\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 27.262699604034424\n",
      "Response: 11.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['12-26'], ['19-15'], ['11-2'], ['17-0'], ['14-18'], ['24-29'], ['15-14'], ['18-30'], ['16-24'], ['17-31'], ['13-11'], ['25-3'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 27.262699604034424\n",
      "Response: 11.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1167\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 27.262699604034424\n",
      "Response: 11.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2388\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 27.262699604034424\n",
      "Response: 11.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3563\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 28.28182578086853\n",
      "Response: 11\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "A total of 11 asteroids have been discovered before they impacted Earth.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['21-30'], ['17-22'], ['12-26'], ['19-15'], ['11-2'], ['14-18'], ['17-0'], ['24-29'], ['15-14'], ['18-30'], ['16-24'], ['17-31'], ['13-11'], ['25-3'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 97.88687229156494\n",
      "Response: 11 asteroids have been discovered before they impacted Earth.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_163_irrelevant_misleading/llama-2-7b-80k_id_163_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['7-4'], ['16-19'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['11-2'], ['13-11'], ['19-15'], ['21-5'], ['12-26'], ['24-3'], ['24-29'], ['0-11'], ['1-26'], ['6-30'], ['12-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['7-4'], ['16-19'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['11-2'], ['13-11'], ['19-15'], ['21-5'], ['12-26'], ['24-3'], ['24-29'], ['0-11'], ['1-26'], ['6-30'], ['12-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['7-4'], ['16-19'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['11-2'], ['13-11'], ['19-15'], ['21-5'], ['12-26'], ['24-3'], ['24-29'], ['0-11'], ['1-26'], ['6-30'], ['12-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['7-4'], ['16-19'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['11-2'], ['13-11'], ['19-15'], ['21-5'], ['12-26'], ['24-3'], ['24-29'], ['0-11'], ['1-26'], ['6-30'], ['12-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_0_depth_7500_results.json\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['7-4'], ['16-19'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['11-2'], ['13-11'], ['19-15'], ['21-5'], ['12-26'], ['24-3'], ['24-29'], ['0-11'], ['1-26'], ['6-30'], ['12-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['11-2'], ['31-16'], ['19-15'], ['13-11'], ['21-5'], ['24-3'], ['24-29'], ['12-26'], ['12-16'], ['14-18'], ['20-27'], ['22-22'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_1250_depth_0_results.json\n",
      "insertion at 16\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['11-2'], ['31-16'], ['19-15'], ['13-11'], ['21-5'], ['7-12'], ['24-29'], ['24-3'], ['12-26'], ['12-16'], ['20-27'], ['14-18'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 496\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['31-16'], ['19-15'], ['13-11'], ['21-5'], ['24-29'], ['24-3'], ['20-27'], ['6-30'], ['12-26'], ['22-22'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 91.58639907836914\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area. The area is named after the 1985 Schengen Agreement and the 1990 Schengen Convention, both signed in Schengen,\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 761\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['31-16'], ['19-15'], ['13-11'], ['21-5'], ['20-27'], ['24-29'], ['24-3'], ['22-22'], ['6-30'], ['18-30'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_1250_depth_7500_results.json\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['11-2'], ['7-12'], ['19-15'], ['31-16'], ['13-11'], ['21-5'], ['24-29'], ['20-27'], ['24-3'], ['6-30'], ['12-26'], ['18-30'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['31-16'], ['13-11'], ['24-29'], ['20-27'], ['21-5'], ['24-3'], ['6-30'], ['26-28'], ['12-26'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_2500_depth_0_results.json\n",
      "insertion at 552\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['31-16'], ['13-11'], ['20-27'], ['24-29'], ['24-3'], ['21-5'], ['26-28'], ['6-30'], ['18-30'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1136\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['7-12'], ['11-2'], ['19-15'], ['31-16'], ['13-11'], ['20-27'], ['24-29'], ['24-3'], ['21-5'], ['22-22'], ['26-28'], ['6-30'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 96.95495963096619\n",
      "Response: The most recent member states of the Schengen Area are Bulgaria and Romania.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1691\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['31-16'], ['20-27'], ['24-29'], ['13-11'], ['24-3'], ['26-28'], ['18-30'], ['21-5'], ['22-22'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_2500_depth_7500_results.json\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['31-16'], ['20-27'], ['24-3'], ['24-29'], ['26-28'], ['6-30'], ['13-11'], ['18-30'], ['21-5'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['31-16'], ['20-27'], ['24-3'], ['24-29'], ['26-28'], ['6-30'], ['13-11'], ['18-30'], ['21-5'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 96.59667015075684\n",
      "Response: The most recent member states of the Schengen Area are Romania and Bulgaria.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_3750_depth_0_results.json\n",
      "insertion at 868\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['31-16'], ['20-27'], ['24-3'], ['26-28'], ['24-29'], ['18-30'], ['6-30'], ['13-11'], ['21-5'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1719\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['7-12'], ['11-2'], ['19-15'], ['31-16'], ['20-27'], ['24-3'], ['26-28'], ['18-30'], ['24-29'], ['22-22'], ['6-30'], ['13-11'], ['21-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 89.44123387336731\n",
      "Response: The most recent member states of the Schengen Area are Bulgaria and Romania. They joined the Schengen Area on March 26, 2007.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2353\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['11-2'], ['19-15'], ['31-16'], ['20-27'], ['18-30'], ['24-3'], ['26-28'], ['24-29'], ['22-22'], ['6-30'], ['14-18'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_3750_depth_7500_results.json\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['7-12'], ['11-2'], ['19-15'], ['31-16'], ['20-27'], ['24-3'], ['18-30'], ['26-28'], ['24-29'], ['22-22'], ['6-30'], ['21-5'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['7-12'], ['11-2'], ['19-15'], ['31-16'], ['20-27'], ['24-3'], ['18-30'], ['26-28'], ['24-29'], ['22-22'], ['6-30'], ['13-11'], ['21-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 96.59667015075684\n",
      "Response: The most recent member states of the Schengen Area are Romania and Bulgaria.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1136\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['7-12'], ['11-2'], ['19-15'], ['31-16'], ['20-27'], ['24-3'], ['18-30'], ['26-28'], ['24-29'], ['22-22'], ['6-30'], ['13-11'], ['21-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 96.59667015075684\n",
      "Response: The most recent member states of the Schengen Area are Romania and Bulgaria.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2353\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['11-2'], ['19-15'], ['31-16'], ['20-27'], ['18-30'], ['26-28'], ['24-3'], ['24-29'], ['22-22'], ['6-30'], ['14-18'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 2353\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['11-2'], ['19-15'], ['31-16'], ['20-27'], ['18-30'], ['26-28'], ['24-3'], ['24-29'], ['22-22'], ['14-18'], ['21-28'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_5000_depth_7500_results.json\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['7-12'], ['11-2'], ['19-15'], ['31-16'], ['20-27'], ['18-30'], ['24-3'], ['26-28'], ['24-29'], ['22-22'], ['6-30'], ['14-18'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant/llama-2-7b-80k_id_164_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/164.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['7-4'], ['16-19'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['11-2'], ['13-11'], ['19-15'], ['21-5'], ['12-26'], ['24-3'], ['24-29'], ['0-11'], ['1-26'], ['6-30'], ['12-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['7-4'], ['16-19'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['11-2'], ['13-11'], ['19-15'], ['21-5'], ['12-26'], ['24-3'], ['24-29'], ['0-11'], ['1-26'], ['6-30'], ['12-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['7-4'], ['16-19'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['11-2'], ['13-11'], ['19-15'], ['21-5'], ['12-26'], ['24-3'], ['24-29'], ['0-11'], ['1-26'], ['6-30'], ['12-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['7-4'], ['16-19'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['11-2'], ['13-11'], ['19-15'], ['21-5'], ['12-26'], ['24-3'], ['24-29'], ['0-11'], ['1-26'], ['6-30'], ['12-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_0_depth_7500_results.json\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['7-4'], ['16-19'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['11-2'], ['13-11'], ['19-15'], ['21-5'], ['12-26'], ['24-3'], ['24-29'], ['0-11'], ['1-26'], ['6-30'], ['12-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['11-2'], ['31-16'], ['19-15'], ['13-11'], ['21-5'], ['24-3'], ['24-29'], ['12-26'], ['12-16'], ['14-18'], ['22-22'], ['26-28'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 16\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['11-2'], ['31-16'], ['19-15'], ['13-11'], ['21-5'], ['7-12'], ['24-29'], ['24-3'], ['12-26'], ['12-16'], ['14-18'], ['18-30'], ['20-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 496\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['31-16'], ['19-15'], ['13-11'], ['21-5'], ['24-29'], ['24-3'], ['12-26'], ['20-27'], ['14-18'], ['18-30'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 91.58639907836914\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area. The area is named after the 1985 Schengen Agreement and the 1990 Schengen Convention, both signed in Schengen,\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 761\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['21-30'], ['17-22'], ['11-2'], ['7-12'], ['31-16'], ['19-15'], ['24-29'], ['13-11'], ['21-5'], ['24-3'], ['20-27'], ['18-30'], ['22-22'], ['26-28'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 93.42054724693298\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area. While Bulgaria is part of the Schengen Area, Romania is still in the process of joining. The Schengen Area has a population of more than 4\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_1250_depth_7500_results.json\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['21-30'], ['17-22'], ['11-2'], ['7-12'], ['19-15'], ['31-16'], ['24-29'], ['21-5'], ['24-3'], ['13-11'], ['20-27'], ['18-30'], ['22-22'], ['26-28'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['31-16'], ['24-3'], ['24-29'], ['21-5'], ['13-11'], ['20-27'], ['18-30'], ['22-22'], ['26-28'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 552\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['31-16'], ['24-3'], ['24-29'], ['21-5'], ['20-27'], ['13-11'], ['18-30'], ['26-28'], ['22-22'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1125\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['31-16'], ['24-3'], ['24-29'], ['20-27'], ['18-30'], ['21-5'], ['13-11'], ['26-28'], ['14-18'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 86.08700633049011\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area. This reflected a greater trend towards European integration; the European Communities (EC), the predecessor of the EU, were established in the 195\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1684\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['11-2'], ['7-12'], ['19-15'], ['31-16'], ['24-29'], ['20-27'], ['24-3'], ['18-30'], ['14-18'], ['21-5'], ['26-28'], ['13-11'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_2500_depth_7500_results.json\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['11-2'], ['7-12'], ['19-15'], ['31-16'], ['24-29'], ['20-27'], ['24-3'], ['18-30'], ['21-5'], ['26-28'], ['14-18'], ['22-22'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['31-16'], ['24-3'], ['24-29'], ['20-27'], ['18-30'], ['21-5'], ['26-28'], ['14-18'], ['22-22'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 96.95495963096619\n",
      "Response: The most recent member states of the Schengen Area are Bulgaria and Romania.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 878\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['31-16'], ['20-27'], ['24-29'], ['24-3'], ['18-30'], ['21-5'], ['26-28'], ['14-18'], ['22-22'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1756\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['31-16'], ['20-27'], ['24-3'], ['24-29'], ['18-30'], ['21-5'], ['26-28'], ['14-18'], ['22-22'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 96.95495963096619\n",
      "Response: The most recent member states of the Schengen Area are Bulgaria and Romania.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2446\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['7-12'], ['11-2'], ['19-15'], ['24-29'], ['20-27'], ['31-16'], ['18-30'], ['24-3'], ['14-18'], ['21-5'], ['26-28'], ['22-22'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_3750_depth_7500_results.json\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['24-29'], ['31-16'], ['20-27'], ['18-30'], ['24-3'], ['21-5'], ['26-28'], ['14-18'], ['22-22'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['24-29'], ['31-16'], ['20-27'], ['24-3'], ['18-30'], ['21-5'], ['26-28'], ['14-18'], ['22-22'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 96.95495963096619\n",
      "Response: The most recent member states of the Schengen Area are Bulgaria and Romania.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1175\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['24-29'], ['31-16'], ['20-27'], ['24-3'], ['18-30'], ['21-5'], ['26-28'], ['14-18'], ['22-22'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 96.95495963096619\n",
      "Response: The most recent member states of the Schengen Area are Bulgaria and Romania.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2373\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['20-27'], ['24-29'], ['18-30'], ['31-16'], ['24-3'], ['21-5'], ['26-28'], ['22-22'], ['14-18'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 96.95495963096619\n",
      "Response: The most recent member states of the Schengen Area are Bulgaria and Romania.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 2446\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['7-12'], ['11-2'], ['19-15'], ['20-27'], ['24-29'], ['18-30'], ['24-3'], ['31-16'], ['14-18'], ['22-22'], ['26-28'], ['21-5'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_5000_depth_7500_results.json\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['20-27'], ['24-29'], ['18-30'], ['24-3'], ['31-16'], ['26-28'], ['21-5'], ['22-22'], ['14-18'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_relevant_misleading/llama-2-7b-80k_id_164_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['7-4'], ['16-19'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['11-2'], ['13-11'], ['19-15'], ['21-5'], ['12-26'], ['24-3'], ['24-29'], ['0-11'], ['1-26'], ['6-30'], ['12-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['7-4'], ['16-19'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['11-2'], ['13-11'], ['19-15'], ['21-5'], ['12-26'], ['24-3'], ['24-29'], ['0-11'], ['1-26'], ['6-30'], ['12-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['7-4'], ['16-19'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['11-2'], ['13-11'], ['19-15'], ['21-5'], ['12-26'], ['24-3'], ['24-29'], ['0-11'], ['1-26'], ['6-30'], ['12-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['7-4'], ['16-19'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['11-2'], ['13-11'], ['19-15'], ['21-5'], ['12-26'], ['24-3'], ['24-29'], ['0-11'], ['1-26'], ['6-30'], ['12-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_0_depth_7500_results.json\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['7-4'], ['16-19'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['11-2'], ['13-11'], ['19-15'], ['21-5'], ['12-26'], ['24-3'], ['24-29'], ['0-11'], ['1-26'], ['6-30'], ['12-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['7-4'], ['16-19'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['11-2'], ['13-11'], ['19-15'], ['21-5'], ['12-26'], ['24-3'], ['24-29'], ['0-11'], ['1-26'], ['6-30'], ['12-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 51.78937911987305\n",
      "Response: Austria, Belgium, Croatia, Cyprus, Czech Republic, Denmark, Estonia, Finland, France, Germany, Greece, Hungary, Iceland, Italy, Latvia, Liechtenstein, Lithuania, Luxemb\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 22\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['11-2'], ['31-16'], ['19-15'], ['13-11'], ['21-5'], ['24-29'], ['12-26'], ['24-3'], ['7-12'], ['14-18'], ['20-27'], ['6-30'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 498\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['11-2'], ['31-16'], ['19-15'], ['7-12'], ['13-11'], ['21-5'], ['24-3'], ['24-29'], ['12-26'], ['14-18'], ['20-27'], ['18-30'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 734\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['17-22'], ['11-2'], ['21-30'], ['7-12'], ['31-16'], ['19-15'], ['13-11'], ['21-5'], ['24-3'], ['24-29'], ['14-18'], ['12-26'], ['18-30'], ['20-27'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_1250_depth_7500_results.json\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['11-2'], ['19-15'], ['7-12'], ['31-16'], ['21-5'], ['13-11'], ['24-3'], ['18-30'], ['24-29'], ['12-26'], ['22-22'], ['6-30'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['11-2'], ['19-15'], ['7-12'], ['31-16'], ['21-5'], ['13-11'], ['24-3'], ['18-30'], ['24-29'], ['12-26'], ['22-22'], ['6-30'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 51.19587182998657\n",
      "Response: Austria, Belgium, Czech Republic, Denmark, Estonia, Finland, France, Germany, Greece, Hungary, Iceland, Italy, Latvia, Liechtenstein, Lithuania, Luxembourg, Malta, Netherlands,\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 552\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['31-16'], ['21-5'], ['13-11'], ['18-30'], ['24-3'], ['24-29'], ['22-22'], ['14-18'], ['20-27'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1121\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['31-16'], ['21-5'], ['13-11'], ['18-30'], ['24-29'], ['22-22'], ['24-3'], ['14-18'], ['20-27'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1656\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['7-12'], ['11-2'], ['19-15'], ['31-16'], ['18-30'], ['24-29'], ['21-5'], ['22-22'], ['13-11'], ['14-18'], ['20-27'], ['24-3'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_2500_depth_7500_results.json\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['31-16'], ['18-30'], ['21-5'], ['24-29'], ['22-22'], ['24-3'], ['13-11'], ['20-27'], ['6-30'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['7-12'], ['11-2'], ['19-15'], ['31-16'], ['18-30'], ['21-5'], ['24-29'], ['24-3'], ['22-22'], ['13-11'], ['20-27'], ['6-30'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 81.97967410087585\n",
      "Response: The most recent member states of the Schengen Area are Bulgaria, Croatia, Cyprus, the Czech Republic, Estonia, Hungary, Latvia, Lithuania, Malta, Poland, Romania, Slovakia,\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 861\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['11-2'], ['19-15'], ['31-16'], ['18-30'], ['24-29'], ['22-22'], ['21-5'], ['24-3'], ['20-27'], ['6-16'], ['13-11'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1722\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['11-2'], ['19-15'], ['31-16'], ['18-30'], ['24-29'], ['6-16'], ['22-22'], ['20-27'], ['24-3'], ['14-18'], ['21-5'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2601\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['21-30'], ['11-2'], ['19-15'], ['31-16'], ['18-30'], ['6-16'], ['20-27'], ['24-29'], ['22-22'], ['14-18'], ['24-3'], ['21-5'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_3750_depth_7500_results.json\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['11-2'], ['19-15'], ['31-16'], ['18-30'], ['20-27'], ['6-16'], ['24-29'], ['22-22'], ['24-3'], ['21-5'], ['14-18'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['11-2'], ['19-15'], ['31-16'], ['18-30'], ['6-16'], ['24-29'], ['20-27'], ['22-22'], ['24-3'], ['14-18'], ['21-5'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1191\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['21-30'], ['11-2'], ['19-15'], ['6-16'], ['18-30'], ['31-16'], ['20-27'], ['24-29'], ['22-22'], ['24-3'], ['14-18'], ['26-28'], ['21-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2391\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['21-30'], ['11-2'], ['19-15'], ['6-16'], ['18-30'], ['31-16'], ['20-27'], ['24-29'], ['14-18'], ['22-22'], ['24-3'], ['26-28'], ['21-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3576\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['21-30'], ['11-2'], ['19-15'], ['6-16'], ['18-30'], ['31-16'], ['20-27'], ['24-29'], ['14-18'], ['22-22'], ['24-3'], ['26-28'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_5000_depth_7500_results.json\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['21-30'], ['11-2'], ['19-15'], ['6-16'], ['18-30'], ['20-27'], ['31-16'], ['24-29'], ['22-22'], ['26-28'], ['14-18'], ['24-3'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant/llama-2-7b-80k_id_164_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/164.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['7-4'], ['16-19'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['11-2'], ['13-11'], ['19-15'], ['21-5'], ['12-26'], ['24-3'], ['24-29'], ['0-11'], ['1-26'], ['6-30'], ['12-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['7-4'], ['16-19'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['11-2'], ['13-11'], ['19-15'], ['21-5'], ['12-26'], ['24-3'], ['24-29'], ['0-11'], ['1-26'], ['6-30'], ['12-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['7-4'], ['16-19'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['11-2'], ['13-11'], ['19-15'], ['21-5'], ['12-26'], ['24-3'], ['24-29'], ['0-11'], ['1-26'], ['6-30'], ['12-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['7-4'], ['16-19'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['11-2'], ['13-11'], ['19-15'], ['21-5'], ['12-26'], ['24-3'], ['24-29'], ['0-11'], ['1-26'], ['6-30'], ['12-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['7-4'], ['16-19'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['11-2'], ['13-11'], ['19-15'], ['21-5'], ['12-26'], ['24-3'], ['24-29'], ['0-11'], ['1-26'], ['6-30'], ['12-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['7-4'], ['16-19'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['11-2'], ['13-11'], ['19-15'], ['21-5'], ['12-26'], ['24-3'], ['24-29'], ['0-11'], ['1-26'], ['6-30'], ['12-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 51.78937911987305\n",
      "Response: Austria, Belgium, Croatia, Cyprus, Czech Republic, Denmark, Estonia, Finland, France, Germany, Greece, Hungary, Iceland, Italy, Latvia, Liechtenstein, Lithuania, Luxemb\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 22\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['11-2'], ['31-16'], ['19-15'], ['13-11'], ['21-5'], ['24-29'], ['12-26'], ['24-3'], ['7-12'], ['14-18'], ['20-27'], ['6-30'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 498\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['11-2'], ['31-16'], ['19-15'], ['7-12'], ['13-11'], ['21-5'], ['24-3'], ['24-29'], ['12-26'], ['14-18'], ['20-27'], ['18-30'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 734\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['17-22'], ['11-2'], ['21-30'], ['7-12'], ['31-16'], ['19-15'], ['13-11'], ['21-5'], ['24-3'], ['24-29'], ['14-18'], ['12-26'], ['18-30'], ['20-27'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['8-26'], ['17-22'], ['21-30'], ['11-2'], ['19-15'], ['7-12'], ['31-16'], ['21-5'], ['13-11'], ['24-3'], ['18-30'], ['24-29'], ['12-26'], ['22-22'], ['6-30'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "-- Test Summary -- \n",
      "Duration: 3.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 49.66268539428711\n",
      "Response: Austria, Belgium, Czech Republic, Denmark, Estonia, Finland, France, Germany, Greece, Hungary, Iceland, Italy, Latvia, Lithuania, Luxembourg, Malta, Netherlands, Norway, Poland,\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 552\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['31-16'], ['21-5'], ['13-11'], ['18-30'], ['24-3'], ['24-29'], ['20-27'], ['22-22'], ['12-26'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1138\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['7-12'], ['11-2'], ['19-15'], ['31-16'], ['21-5'], ['18-30'], ['24-29'], ['13-11'], ['20-27'], ['24-3'], ['22-22'], ['14-18'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1677\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['7-12'], ['11-2'], ['19-15'], ['31-16'], ['18-30'], ['21-5'], ['24-29'], ['13-11'], ['20-27'], ['24-3'], ['22-22'], ['6-16'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['19-15'], ['31-16'], ['18-30'], ['21-5'], ['24-29'], ['13-11'], ['20-27'], ['24-3'], ['22-22'], ['6-30'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['17-22'], ['21-30'], ['7-12'], ['11-2'], ['19-15'], ['31-16'], ['18-30'], ['21-5'], ['24-29'], ['13-11'], ['20-27'], ['24-3'], ['22-22'], ['6-30'], ['6-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 96.95495963096619\n",
      "Response: The most recent member states of the Schengen Area are Bulgaria and Romania.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 861\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['11-2'], ['19-15'], ['31-16'], ['18-30'], ['24-29'], ['21-5'], ['20-27'], ['6-16'], ['24-3'], ['13-11'], ['22-22'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1743\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['11-2'], ['19-15'], ['31-16'], ['18-30'], ['24-29'], ['6-16'], ['20-27'], ['21-5'], ['24-3'], ['13-11'], ['22-22'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2596\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['21-30'], ['11-2'], ['19-15'], ['31-16'], ['18-30'], ['6-16'], ['20-27'], ['24-29'], ['21-5'], ['24-3'], ['22-22'], ['13-11'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['11-2'], ['19-15'], ['31-16'], ['18-30'], ['20-27'], ['6-16'], ['24-29'], ['21-5'], ['24-3'], ['22-22'], ['13-11'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['21-30'], ['11-2'], ['19-15'], ['31-16'], ['18-30'], ['20-27'], ['6-16'], ['24-29'], ['21-5'], ['24-3'], ['22-22'], ['13-11'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1142\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['21-30'], ['11-2'], ['19-15'], ['6-16'], ['18-30'], ['20-27'], ['31-16'], ['24-29'], ['21-5'], ['24-3'], ['22-22'], ['13-11'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2366\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['11-2'], ['21-30'], ['19-15'], ['6-16'], ['20-27'], ['18-30'], ['24-29'], ['31-16'], ['24-3'], ['21-5'], ['22-22'], ['13-11'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3541\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['7-4'], ['11-2'], ['21-30'], ['19-15'], ['6-16'], ['20-27'], ['18-30'], ['24-29'], ['31-16'], ['24-3'], ['21-5'], ['22-22'], ['21-28'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['11-2'], ['21-30'], ['19-15'], ['6-16'], ['20-27'], ['18-30'], ['24-29'], ['31-16'], ['24-3'], ['21-5'], ['22-22'], ['21-28'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00002384185791\n",
      "Response: Bulgaria and Romania are the most recent member states of the Schengen Area.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_164_irrelevant_misleading/llama-2-7b-80k_id_164_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Keir Starmer\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 20.884969830513\n",
      "Response: Jeremy Corbyn.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 20.884969830513\n",
      "Response: Jeremy Corbyn.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 20.884969830513\n",
      "Response: Jeremy Corbyn.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 20.884969830513\n",
      "Response: Jeremy Corbyn.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_0_depth_7500_results.json\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 20.884969830513\n",
      "Response: Jeremy Corbyn.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "[['7-12'], ['8-26'], ['11-15'], ['6-9'], ['6-16'], ['6-17'], ['6-30'], ['7-4'], ['7-10'], ['7-11'], ['7-13'], ['7-16'], ['7-17'], ['7-18'], ['7-19'], ['7-24'], ['7-25'], ['7-28'], ['7-29'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 99.99999403953552\n",
      "Response: Keir Starmer\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_1250_depth_0_results.json\n",
      "insertion at 230\n",
      "Keir Starmer\n",
      "[['6-30'], ['11-15'], ['6-9'], ['8-26'], ['16-19'], ['7-12'], ['7-31'], ['6-16'], ['6-17'], ['7-4'], ['7-10'], ['7-11'], ['7-13'], ['7-16'], ['7-17'], ['7-18'], ['7-19'], ['7-24'], ['7-25'], ['7-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99999403953552\n",
      "Response: Keir Starmer\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 449\n",
      "Keir Starmer\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['8-26'], ['7-12'], ['7-31'], ['17-22'], ['21-30'], ['6-16'], ['6-17'], ['7-4'], ['7-10'], ['7-11'], ['7-13'], ['7-16'], ['7-17'], ['7-18'], ['7-19'], ['7-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 99.99999403953552\n",
      "Response: Keir Starmer\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 753\n",
      "Keir Starmer\n",
      "[['6-9'], ['16-19'], ['6-30'], ['11-15'], ['8-26'], ['21-30'], ['7-12'], ['7-31'], ['17-22'], ['6-16'], ['6-17'], ['7-4'], ['7-10'], ['7-11'], ['7-13'], ['7-16'], ['7-17'], ['7-18'], ['7-19'], ['7-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 99.99999403953552\n",
      "Response: Keir Starmer\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_1250_depth_7500_results.json\n",
      "Keir Starmer\n",
      "[['6-9'], ['16-19'], ['6-30'], ['11-15'], ['8-26'], ['21-30'], ['7-12'], ['7-31'], ['17-22'], ['6-16'], ['6-17'], ['7-4'], ['7-10'], ['7-11'], ['7-13'], ['7-16'], ['7-17'], ['7-18'], ['7-19'], ['7-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 72.42494821548462\n",
      "Response: Keir Starmer is the current Leader of the Opposition in the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "[['6-9'], ['16-19'], ['11-15'], ['6-30'], ['7-12'], ['8-26'], ['21-30'], ['7-4'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-24'], ['7-25'], ['7-29'], ['7-31'], ['8-6'], ['8-9'], ['8-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 67.56454706192017\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_2500_depth_0_results.json\n",
      "insertion at 449\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['6-30'], ['7-12'], ['7-31'], ['21-30'], ['7-4'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-24'], ['7-25'], ['7-29'], ['8-6'], ['8-9'], ['8-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 67.56454706192017\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1081\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['8-26'], ['16-19'], ['7-12'], ['6-30'], ['7-31'], ['10-11'], ['21-30'], ['7-4'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-24'], ['7-25'], ['7-29'], ['8-6'], ['8-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 67.56454706192017\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1661\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['8-26'], ['16-19'], ['7-12'], ['6-30'], ['7-31'], ['10-11'], ['21-30'], ['7-4'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-24'], ['7-25'], ['7-29'], ['8-6'], ['8-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 67.56454706192017\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_2500_depth_7500_results.json\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['8-26'], ['16-19'], ['7-12'], ['6-30'], ['7-31'], ['10-11'], ['21-30'], ['7-4'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-24'], ['7-25'], ['7-29'], ['8-6'], ['8-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 72.42494821548462\n",
      "Response: Keir Starmer is the current Leader of the Opposition in the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['7-12'], ['8-26'], ['16-19'], ['6-30'], ['7-4'], ['7-10'], ['7-11'], ['7-17'], ['7-19'], ['7-24'], ['7-25'], ['7-29'], ['7-31'], ['8-6'], ['8-9'], ['8-11'], ['8-12'], ['8-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 67.56454706192017\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_3750_depth_0_results.json\n",
      "insertion at 880\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['8-26'], ['7-12'], ['16-19'], ['6-30'], ['7-4'], ['7-10'], ['7-11'], ['7-17'], ['7-19'], ['7-24'], ['7-25'], ['7-29'], ['7-31'], ['8-6'], ['8-9'], ['8-11'], ['8-12'], ['8-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 67.56454706192017\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1661\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['7-12'], ['8-26'], ['16-19'], ['6-30'], ['7-4'], ['7-10'], ['7-11'], ['7-17'], ['7-19'], ['7-24'], ['7-25'], ['7-29'], ['7-31'], ['8-6'], ['8-9'], ['8-11'], ['8-12'], ['8-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 67.56454706192017\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2632\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['7-12'], ['8-26'], ['16-19'], ['6-30'], ['7-4'], ['7-10'], ['7-11'], ['7-17'], ['7-19'], ['7-24'], ['7-25'], ['7-29'], ['7-31'], ['8-6'], ['8-9'], ['8-11'], ['8-12'], ['8-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 67.56454706192017\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_3750_depth_7500_results.json\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['7-12'], ['8-26'], ['16-19'], ['6-30'], ['7-4'], ['7-10'], ['7-11'], ['7-17'], ['7-19'], ['7-24'], ['7-25'], ['7-29'], ['7-31'], ['8-6'], ['8-9'], ['8-11'], ['8-12'], ['8-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 72.42494821548462\n",
      "Response: Keir Starmer is the current Leader of the Opposition in the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 4.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 46.93509638309479\n",
      "Response: The Leader of the Opposition is the leader of the largest party in the House of Commons that is not in government. The current Leader of the Opposition is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1081\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 4.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 46.53465747833252\n",
      "Response: The Leader of the Opposition is the leader of the largest party in the House of Commons that is not in government. The current Leader of the Opposition is Keir Starmer, who is the leader of the Labour Party.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2317\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['7-12'], ['8-26'], ['16-19'], ['6-30'], ['21-30'], ['7-4'], ['7-10'], ['7-11'], ['7-17'], ['7-19'], ['7-24'], ['7-25'], ['7-29'], ['7-31'], ['8-6'], ['8-9'], ['8-11'], ['8-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 71.24164700508118\n",
      "Response: The Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3580\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['7-12'], ['16-19'], ['8-26'], ['6-30'], ['21-30'], ['7-4'], ['7-10'], ['7-11'], ['7-17'], ['7-19'], ['7-24'], ['7-25'], ['7-29'], ['7-31'], ['8-6'], ['8-9'], ['8-11'], ['8-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 67.56454706192017\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_5000_depth_7500_results.json\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['7-12'], ['16-19'], ['8-26'], ['6-30'], ['21-30'], ['7-4'], ['7-10'], ['7-11'], ['7-17'], ['7-19'], ['7-24'], ['7-25'], ['7-29'], ['7-31'], ['8-6'], ['8-9'], ['8-11'], ['8-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Keir Starmer\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant/llama-2-7b-80k_id_167_relevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/167.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Keir Starmer\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 20.884969830513\n",
      "Response: Jeremy Corbyn.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 20.884969830513\n",
      "Response: Jeremy Corbyn.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 20.884969830513\n",
      "Response: Jeremy Corbyn.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 20.884969830513\n",
      "Response: Jeremy Corbyn.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_0_depth_7500_results.json\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 20.884969830513\n",
      "Response: Jeremy Corbyn.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "[['7-12'], ['8-26'], ['11-15'], ['6-5'], ['6-9'], ['6-16'], ['6-17'], ['6-30'], ['7-4'], ['7-10'], ['7-11'], ['7-13'], ['7-16'], ['7-17'], ['7-18'], ['7-19'], ['7-20'], ['7-24'], ['7-25'], ['7-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 99.99999403953552\n",
      "Response: Keir Starmer\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 230\n",
      "Keir Starmer\n",
      "[['11-15'], ['6-9'], ['6-30'], ['8-26'], ['16-19'], ['7-12'], ['19-15'], ['21-30'], ['6-5'], ['6-16'], ['6-17'], ['7-4'], ['7-10'], ['7-11'], ['7-13'], ['7-16'], ['7-17'], ['7-18'], ['7-19'], ['7-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99999403953552\n",
      "Response: Keir Starmer\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 463\n",
      "Keir Starmer\n",
      "[['11-15'], ['6-9'], ['16-19'], ['6-30'], ['8-26'], ['7-12'], ['19-15'], ['21-30'], ['6-5'], ['6-16'], ['6-17'], ['7-4'], ['7-10'], ['7-11'], ['7-13'], ['7-16'], ['7-17'], ['7-18'], ['7-19'], ['7-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 99.99999403953552\n",
      "Response: Keir Starmer\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 767\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['16-19'], ['6-30'], ['8-26'], ['7-12'], ['19-15'], ['21-30'], ['6-5'], ['6-16'], ['6-17'], ['7-4'], ['7-10'], ['7-11'], ['7-13'], ['7-16'], ['7-17'], ['7-18'], ['7-19'], ['7-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 99.99999403953552\n",
      "Response: Keir Starmer\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_1250_depth_7500_results.json\n",
      "Keir Starmer\n",
      "[['11-15'], ['6-9'], ['16-19'], ['6-30'], ['8-26'], ['7-12'], ['19-15'], ['21-30'], ['6-5'], ['6-16'], ['6-17'], ['7-4'], ['7-10'], ['7-11'], ['7-13'], ['7-16'], ['7-17'], ['7-18'], ['7-19'], ['7-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 72.42494821548462\n",
      "Response: Keir Starmer is the current Leader of the Opposition in the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['16-19'], ['6-30'], ['7-12'], ['8-26'], ['7-4'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-20'], ['7-24'], ['7-25'], ['7-29'], ['8-6'], ['8-9'], ['8-11'], ['8-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 67.56454706192017\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 463\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['16-19'], ['6-30'], ['7-12'], ['8-26'], ['7-4'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-20'], ['7-24'], ['7-25'], ['7-29'], ['8-6'], ['8-9'], ['8-11'], ['8-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 67.56454706192017\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1106\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['16-19'], ['6-30'], ['7-12'], ['8-26'], ['7-4'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-20'], ['7-24'], ['7-25'], ['7-29'], ['8-6'], ['8-9'], ['8-11'], ['8-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 99.99999403953552\n",
      "Response: Keir Starmer\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1706\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['16-19'], ['7-12'], ['6-30'], ['8-26'], ['7-4'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-20'], ['7-24'], ['7-25'], ['7-29'], ['8-6'], ['8-9'], ['8-11'], ['8-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 99.99999403953552\n",
      "Response: Keir Starmer\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_2500_depth_7500_results.json\n",
      "Keir Starmer\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-12'], ['6-30'], ['8-26'], ['7-4'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-20'], ['7-24'], ['7-25'], ['7-29'], ['8-6'], ['8-9'], ['8-11'], ['8-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 72.42494821548462\n",
      "Response: Keir Starmer is the current Leader of the Opposition in the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-12'], ['8-26'], ['6-30'], ['7-4'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-25'], ['8-6'], ['8-9'], ['8-11'], ['8-12'], ['8-13'], ['8-16'], ['8-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 72.42494821548462\n",
      "Response: Keir Starmer is the current Leader of the Opposition in the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 862\n",
      "Keir Starmer\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-12'], ['8-26'], ['6-30'], ['7-4'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-25'], ['8-6'], ['8-9'], ['8-11'], ['8-12'], ['8-13'], ['8-16'], ['8-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 72.42494821548462\n",
      "Response: Keir Starmer is the current Leader of the Opposition in the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1706\n",
      "Keir Starmer\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-12'], ['8-26'], ['6-30'], ['7-4'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-25'], ['8-6'], ['8-9'], ['8-11'], ['8-12'], ['8-13'], ['8-16'], ['8-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 72.42494821548462\n",
      "Response: Keir Starmer is the current Leader of the Opposition in the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2582\n",
      "Keir Starmer\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-12'], ['8-26'], ['6-30'], ['7-4'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-25'], ['8-6'], ['8-9'], ['8-11'], ['8-12'], ['8-13'], ['8-16'], ['8-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 72.42494821548462\n",
      "Response: Keir Starmer is the current Leader of the Opposition in the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_3750_depth_7500_results.json\n",
      "Keir Starmer\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-12'], ['8-26'], ['6-30'], ['7-4'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-25'], ['8-6'], ['8-9'], ['8-11'], ['8-12'], ['8-13'], ['8-16'], ['8-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 72.42494821548462\n",
      "Response: Keir Starmer is the current Leader of the Opposition in the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-12'], ['8-26'], ['6-30'], ['7-4'], ['7-10'], ['7-11'], ['7-17'], ['7-25'], ['8-6'], ['8-9'], ['8-11'], ['8-12'], ['8-13'], ['8-16'], ['8-23'], ['8-24'], ['8-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 67.56454706192017\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1106\n",
      "Keir Starmer\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-12'], ['8-26'], ['6-30'], ['7-4'], ['7-10'], ['7-11'], ['7-17'], ['7-25'], ['8-6'], ['8-9'], ['8-11'], ['8-12'], ['8-13'], ['8-16'], ['8-23'], ['8-24'], ['8-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 67.56454706192017\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2362\n",
      "Keir Starmer\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-12'], ['8-26'], ['6-30'], ['7-4'], ['7-10'], ['7-11'], ['7-17'], ['7-25'], ['8-6'], ['8-9'], ['8-11'], ['8-12'], ['8-13'], ['8-16'], ['8-23'], ['8-24'], ['8-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 67.56454706192017\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3543\n",
      "Keir Starmer\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-12'], ['8-26'], ['6-30'], ['7-4'], ['7-10'], ['7-11'], ['7-17'], ['7-25'], ['8-6'], ['8-9'], ['8-11'], ['8-12'], ['8-13'], ['8-16'], ['8-23'], ['8-24'], ['8-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 67.56454706192017\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_5000_depth_7500_results.json\n",
      "Keir Starmer\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-12'], ['8-26'], ['6-30'], ['7-4'], ['7-10'], ['7-11'], ['7-17'], ['7-25'], ['8-6'], ['8-9'], ['8-11'], ['8-12'], ['8-13'], ['8-16'], ['8-23'], ['8-24'], ['8-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 72.42494821548462\n",
      "Response: Keir Starmer is the current Leader of the Opposition in the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_relevant_misleading/llama-2-7b-80k_id_167_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Keir Starmer\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 20.884969830513\n",
      "Response: Jeremy Corbyn.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 20.884969830513\n",
      "Response: Jeremy Corbyn.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 20.884969830513\n",
      "Response: Jeremy Corbyn.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 20.884969830513\n",
      "Response: Jeremy Corbyn.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_0_depth_7500_results.json\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 20.884969830513\n",
      "Response: Jeremy Corbyn.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 44.48229670524597\n",
      "Response: The Leader of the Opposition in the United Kingdom is the leader of the largest party in the House of Commons that is not in government. The current Leader of the Opposition is Keir Starmer, who is the leader of\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 255\n",
      "Keir Starmer\n",
      "[['6-30'], ['7-12'], ['11-15'], ['6-9'], ['8-26'], ['13-11'], ['16-19'], ['7-4'], ['7-31'], ['8-22'], ['10-29'], ['19-15'], ['21-30'], ['24-29'], ['26-28'], ['0-0'], ['0-1'], ['0-2'], ['0-3'], ['0-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 70.25362253189087\n",
      "Response: The Leader of the Opposition in the United Kingdom is currently Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 485\n",
      "Keir Starmer\n",
      "[['6-30'], ['7-12'], ['11-15'], ['6-9'], ['8-26'], ['16-19'], ['7-31'], ['13-11'], ['7-4'], ['8-22'], ['10-29'], ['21-30'], ['24-29'], ['26-28'], ['10-18'], ['11-14'], ['17-22'], ['19-15'], ['0-0'], ['0-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 70.25362253189087\n",
      "Response: The Leader of the Opposition in the United Kingdom is currently Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 768\n",
      "Keir Starmer\n",
      "[['6-30'], ['11-15'], ['6-9'], ['8-26'], ['16-19'], ['7-12'], ['7-31'], ['13-11'], ['7-4'], ['8-22'], ['10-29'], ['17-22'], ['19-15'], ['24-29'], ['26-28'], ['10-18'], ['21-30'], ['7-0'], ['10-2'], ['10-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 72.42494821548462\n",
      "Response: Keir Starmer is the current Leader of the Opposition in the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_1250_depth_7500_results.json\n",
      "Keir Starmer\n",
      "[['6-30'], ['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-31'], ['26-28'], ['7-12'], ['13-11'], ['19-15'], ['21-30'], ['24-29'], ['8-22'], ['10-29'], ['17-22'], ['31-16'], ['7-4'], ['10-18'], ['7-0'], ['10-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Keir Starmer\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 3.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 43.06991100311279\n",
      "Response: The Leader of the Opposition in the United Kingdom is the leader of the largest party in the House of Commons that is not in government. The current Leader of the Opposition is Keir Starmer, who has been in office\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 553\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 38.64695429801941\n",
      "Response: Rishi Sunak\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 926\n",
      "Keir Starmer\n",
      "[['6-30'], ['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-31'], ['7-12'], ['13-11'], ['19-15'], ['21-30'], ['24-29'], ['26-28'], ['7-4'], ['10-29'], ['17-22'], ['31-16'], ['8-22'], ['10-18'], ['12-26'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 99.99999403953552\n",
      "Response: Keir Starmer\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1517\n",
      "Keir Starmer\n",
      "[['6-30'], ['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-31'], ['7-12'], ['13-11'], ['19-15'], ['21-30'], ['24-29'], ['26-28'], ['7-4'], ['10-29'], ['17-22'], ['31-16'], ['8-22'], ['10-18'], ['12-26'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 99.99999403953552\n",
      "Response: Keir Starmer\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_2500_depth_7500_results.json\n",
      "Keir Starmer\n",
      "[['6-30'], ['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-31'], ['21-30'], ['19-15'], ['26-28'], ['13-11'], ['31-16'], ['7-12'], ['24-29'], ['7-4'], ['10-29'], ['17-22'], ['8-22'], ['10-18'], ['12-26'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Keir Starmer\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "[['6-30'], ['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-31'], ['13-11'], ['21-30'], ['7-12'], ['19-15'], ['26-28'], ['31-16'], ['7-4'], ['10-29'], ['24-29'], ['8-22'], ['12-26'], ['17-22'], ['10-18'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 67.56454706192017\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 871\n",
      "Keir Starmer\n",
      "[['6-30'], ['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-31'], ['7-12'], ['13-11'], ['21-30'], ['26-28'], ['19-15'], ['7-4'], ['10-29'], ['24-29'], ['31-16'], ['8-22'], ['10-18'], ['12-26'], ['17-22'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 67.56454706192017\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1517\n",
      "Keir Starmer\n",
      "[['6-30'], ['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-12'], ['7-31'], ['13-11'], ['21-30'], ['26-28'], ['7-4'], ['10-29'], ['19-15'], ['24-29'], ['31-16'], ['10-18'], ['8-22'], ['12-26'], ['17-22'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 67.56454706192017\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2485\n",
      "Keir Starmer\n",
      "[['6-30'], ['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-12'], ['7-31'], ['21-30'], ['13-11'], ['26-28'], ['7-4'], ['10-29'], ['24-29'], ['19-15'], ['10-18'], ['31-16'], ['8-22'], ['17-22'], ['12-26'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 67.56454706192017\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_3750_depth_7500_results.json\n",
      "Keir Starmer\n",
      "[['6-30'], ['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-31'], ['7-12'], ['21-30'], ['26-28'], ['13-11'], ['24-29'], ['10-29'], ['19-15'], ['31-16'], ['7-4'], ['10-18'], ['8-22'], ['12-26'], ['17-22'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Keir Starmer\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 28.498047590255737\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 926\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 28.498047590255737\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Rishi Sunak.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2130\n",
      "Keir Starmer\n",
      "[['6-30'], ['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-31'], ['7-12'], ['21-30'], ['26-28'], ['13-11'], ['24-29'], ['10-29'], ['19-15'], ['31-16'], ['7-4'], ['10-18'], ['8-22'], ['12-26'], ['17-22'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 67.56454706192017\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3577\n",
      "Keir Starmer\n",
      "[['6-30'], ['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-31'], ['7-12'], ['21-30'], ['13-11'], ['26-28'], ['24-29'], ['10-29'], ['19-15'], ['7-4'], ['10-18'], ['31-16'], ['8-22'], ['12-26'], ['17-22'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 99.99999403953552\n",
      "Response: Keir Starmer\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_5000_depth_7500_results.json\n",
      "Keir Starmer\n",
      "[['6-30'], ['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-31'], ['21-30'], ['7-12'], ['26-28'], ['13-11'], ['24-29'], ['19-15'], ['10-29'], ['31-16'], ['10-18'], ['7-4'], ['12-26'], ['8-22'], ['17-22'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Keir Starmer\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant/llama-2-7b-80k_id_167_irrelevant_len_5000_depth_10000_results.json\n",
      "âœ… Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/167.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:01<00:00,  2.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Keir Starmer\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 20.884969830513\n",
      "Response: Jeremy Corbyn.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 20.884969830513\n",
      "Response: Jeremy Corbyn.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 20.884969830513\n",
      "Response: Jeremy Corbyn.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 20.884969830513\n",
      "Response: Jeremy Corbyn.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "Keir Starmer\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 20.884969830513\n",
      "Response: Jeremy Corbyn.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "[['7-12'], ['8-26'], ['11-15'], ['6-5'], ['6-9'], ['6-20'], ['7-1'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-18'], ['7-19'], ['7-20'], ['7-24'], ['7-25'], ['7-28'], ['7-29'], ['7-31'], ['8-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 70.25362253189087\n",
      "Response: The Leader of the Opposition in the United Kingdom is currently Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 255\n",
      "Keir Starmer\n",
      "[['11-15'], ['7-12'], ['8-26'], ['16-19'], ['6-9'], ['6-30'], ['7-31'], ['19-15'], ['21-30'], ['6-5'], ['6-20'], ['7-1'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-18'], ['7-19'], ['7-20'], ['7-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 72.42494821548462\n",
      "Response: Keir Starmer is the current Leader of the Opposition in the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 485\n",
      "Keir Starmer\n",
      "[['11-15'], ['6-30'], ['8-26'], ['16-19'], ['6-9'], ['7-31'], ['21-30'], ['7-12'], ['19-15'], ['10-29'], ['13-11'], ['17-22'], ['24-29'], ['26-28'], ['6-5'], ['6-20'], ['7-1'], ['7-10'], ['7-11'], ['7-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 70.25362253189087\n",
      "Response: The Leader of the Opposition in the United Kingdom is currently Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 782\n",
      "Keir Starmer\n",
      "[['11-15'], ['6-9'], ['6-30'], ['8-26'], ['16-19'], ['7-31'], ['21-30'], ['7-12'], ['19-15'], ['10-29'], ['13-11'], ['17-22'], ['24-29'], ['26-28'], ['6-5'], ['6-20'], ['7-1'], ['7-10'], ['7-11'], ['7-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 72.42494821548462\n",
      "Response: Keir Starmer is the current Leader of the Opposition in the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "Keir Starmer\n",
      "[['11-15'], ['6-9'], ['6-30'], ['8-26'], ['16-19'], ['7-31'], ['21-30'], ['7-12'], ['19-15'], ['10-29'], ['13-11'], ['17-22'], ['24-29'], ['26-28'], ['6-5'], ['6-20'], ['7-1'], ['7-10'], ['7-11'], ['7-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 72.42494821548462\n",
      "Response: Keir Starmer is the current Leader of the Opposition in the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "[['11-15'], ['8-26'], ['6-9'], ['16-19'], ['6-30'], ['7-12'], ['21-30'], ['7-31'], ['10-29'], ['14-7'], ['19-15'], ['24-29'], ['6-20'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-20'], ['7-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 72.42494821548462\n",
      "Response: Keir Starmer is the current Leader of the Opposition in the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 567\n",
      "Keir Starmer\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['21-30'], ['6-30'], ['7-12'], ['7-31'], ['10-29'], ['14-7'], ['19-15'], ['24-29'], ['6-20'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-20'], ['7-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 98.36417436599731\n",
      "Response: Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 940\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['8-26'], ['16-19'], ['21-30'], ['6-30'], ['7-12'], ['7-31'], ['10-29'], ['14-7'], ['19-15'], ['24-29'], ['6-20'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-20'], ['7-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 98.36417436599731\n",
      "Response: Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1531\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['8-26'], ['7-12'], ['16-19'], ['21-30'], ['6-30'], ['7-31'], ['10-29'], ['14-7'], ['19-15'], ['24-29'], ['6-20'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-20'], ['7-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 98.36417436599731\n",
      "Response: Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['8-26'], ['7-12'], ['16-19'], ['21-30'], ['6-30'], ['7-31'], ['10-29'], ['14-7'], ['19-15'], ['24-29'], ['6-20'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-20'], ['7-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 72.42494821548462\n",
      "Response: Keir Starmer is the current Leader of the Opposition in the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['7-12'], ['8-26'], ['16-19'], ['6-30'], ['21-30'], ['7-31'], ['14-7'], ['6-20'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-20'], ['7-24'], ['7-25'], ['7-29'], ['8-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 67.56454706192017\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 885\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['7-12'], ['8-26'], ['16-19'], ['6-30'], ['21-30'], ['7-31'], ['14-7'], ['6-20'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-20'], ['7-24'], ['7-25'], ['7-29'], ['8-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 67.56454706192017\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1531\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['7-12'], ['8-26'], ['16-19'], ['6-30'], ['21-30'], ['7-31'], ['14-7'], ['6-20'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-20'], ['7-24'], ['7-25'], ['7-29'], ['8-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 67.56454706192017\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2510\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['7-12'], ['8-26'], ['16-19'], ['6-30'], ['21-30'], ['7-31'], ['14-7'], ['6-20'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-20'], ['7-24'], ['7-25'], ['7-29'], ['8-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 67.56454706192017\n",
      "Response: The current Leader of the Opposition in the United Kingdom is Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['7-12'], ['8-26'], ['16-19'], ['6-30'], ['21-30'], ['7-31'], ['14-7'], ['6-20'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-19'], ['7-20'], ['7-24'], ['7-25'], ['7-29'], ['8-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Keir Starmer\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['7-12'], ['8-26'], ['16-19'], ['6-30'], ['21-30'], ['7-31'], ['14-7'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-25'], ['7-29'], ['8-2'], ['8-4'], ['8-9'], ['8-11'], ['8-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 72.42494821548462\n",
      "Response: Keir Starmer is the current Leader of the Opposition in the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 940\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['7-12'], ['8-26'], ['16-19'], ['6-30'], ['21-30'], ['7-31'], ['14-7'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-25'], ['7-29'], ['8-2'], ['8-4'], ['8-9'], ['8-11'], ['8-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99999403953552\n",
      "Response: Keir Starmer\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2155\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['7-12'], ['8-26'], ['16-19'], ['6-30'], ['21-30'], ['7-31'], ['14-7'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-25'], ['7-29'], ['8-2'], ['8-4'], ['8-9'], ['8-11'], ['8-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 98.36417436599731\n",
      "Response: Keir Starmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3573\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['7-12'], ['8-26'], ['16-19'], ['6-30'], ['21-30'], ['7-31'], ['14-7'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-25'], ['7-29'], ['8-2'], ['8-4'], ['8-9'], ['8-11'], ['8-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 72.42494821548462\n",
      "Response: Keir Starmer is the current Leader of the Opposition in the United Kingdom.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "Keir Starmer\n",
      "[['6-9'], ['11-15'], ['7-12'], ['8-26'], ['16-19'], ['6-30'], ['21-30'], ['7-31'], ['14-7'], ['7-10'], ['7-11'], ['7-16'], ['7-17'], ['7-25'], ['7-29'], ['8-2'], ['8-4'], ['8-9'], ['8-11'], ['8-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: Keir Starmer\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_167_irrelevant_misleading/llama-2-7b-80k_id_167_irrelevant_misleading_len_5000_depth_10000_results.json\n"
     ]
    }
   ],
   "source": [
    "for id in id_vals:\n",
    "    for context_type in [\"relevant\", \"irrelevant\"]:\n",
    "        for with_misleading in [False, True]:\n",
    "            args = get_args(id, context_type, with_misleading)\n",
    "            run_test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Relevant context without misleading statements\n",
    "# args = get_args(id=id_val, context_type=\"relevant\", with_misleading=False)\n",
    "# run_test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Irrelevant context without misleading statements\n",
    "# args = get_args(id=id_val, context_type=\"irrelevant\", with_misleading=False)\n",
    "# run_test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exmample 3: Relevant context with misleading statements\n",
    "# args = get_args(id=id_val, context_type=\"relevant\", with_misleading=True)\n",
    "# run_test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Irrelevant context with misleading statements\n",
    "# args = get_args(id=id_val, context_type=\"irrelevant\", with_misleading=True)\n",
    "# run_test(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
