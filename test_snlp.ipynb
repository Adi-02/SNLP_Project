{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook Overview\n",
    "\n",
    "This notebook provides an faster testing interface. \n",
    "\n",
    "It includes steps to \n",
    " - Check GPU availability\n",
    " - Set up the environment, \n",
    " - Define helper functions,\n",
    " - Run tests with a given **id** and **context_type**. \n",
    "\n",
    "The results are saved for further analysis.\n",
    "\n",
    "*Make sure to select the created `venv` as your kernel.*\n",
    "\n",
    "If there are any errors while running the tests, restart the the notebook, and run again."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check GPU Availability\n",
    "Run this cell to check if there is free space on the gpu. \n",
    "\n",
    "If the **free space** is not close to the **total space** then someone else is probably using the machine. \n",
    "\n",
    "You can check the active processes bu running `nvidia-smi` in the terminal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: 23.2824 GiB free / 23.5766 GiB total\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def get_gpu_memory_torch():\n",
    "    if torch.cuda.is_available():\n",
    "        for i in range(torch.cuda.device_count()):\n",
    "            free_mem = torch.cuda.mem_get_info(i)[0] / 1024**3\n",
    "            total_mem = torch.cuda.get_device_properties(i).total_memory / 1024**3\n",
    "            print(f\"GPU {i}: {free_mem:.4f} GiB free / {total_mem:.4f} GiB total\")\n",
    "    else:\n",
    "        print(\"No CUDA-compatible GPU detected.\")\n",
    "\n",
    "get_gpu_memory_torch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "The code below imports necessary modules, defines directory paths, and sets the Hugging Face cache path.\n",
    "\n",
    "**No need to modify this.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "PROJECT_DIR = Path.cwd()\n",
    "HAYSTACK_DIR = PROJECT_DIR / \"haystack\"\n",
    "RELEVANT_DIR = HAYSTACK_DIR / \"relevant\"\n",
    "IRRELAVANT_DIR = HAYSTACK_DIR / \"irrelevant\"\n",
    "MISLEADING_IN_RELEVANT_DIR = HAYSTACK_DIR / \"misleading_in_relevant\"\n",
    "MISLEADING_IN_IRRELEVANT_DIR = HAYSTACK_DIR / \"misleading_in_irrelevant\"\n",
    "\n",
    "sys.path.append(str(PROJECT_DIR))\n",
    "\n",
    "with open(HAYSTACK_DIR / \"needles.json\", \"r\") as f:\n",
    "    NEEDLES_DATA = json.load(f)\n",
    "\n",
    "# This sets the Hugging Face cache path. Make sure this directory exists. If not, refer to the README.\n",
    "os.environ['HF_HOME'] = '.cache/hf_with_quota'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/cs/student/projects1/2021/shyamodi/SNLP_Project/venv/lib64/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "def load_text(path):\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        return f.read()\n",
    "\n",
    "def insert_strings_at_sentence_breaks(text, insert_strings, context_length, tokenizer):\n",
    "    # Step 1: Tokenize and truncate\n",
    "    tokens = tokenizer.encode(text, add_special_tokens=False)[:context_length]\n",
    "    \n",
    "    # Step 2: Detect sentence breaks by decoding each token\n",
    "    sentence_break_indices = [\n",
    "        i for i, tok in enumerate(tokens)\n",
    "        if tokenizer.decode([tok]).strip().endswith((\".\", \"!\", \"?\"))\n",
    "    ]\n",
    "\n",
    "    if len(sentence_break_indices) < len(insert_strings):\n",
    "        raise ValueError(f\"Only {len(sentence_break_indices)} sentence breaks found, \"\n",
    "                         f\"but {len(insert_strings)} insertions requested.\")\n",
    "\n",
    "    # Step 3: Compute evenly spaced sentence break positions\n",
    "    step = len(sentence_break_indices) // (len(insert_strings) + 1)\n",
    "    insert_positions = [sentence_break_indices[(i + 1) * step] + 1 for i in range(len(insert_strings))]\n",
    "\n",
    "    # Step 4: Insert insert_strings as tokens\n",
    "    for pos, insert_str in reversed(list(zip(insert_positions, insert_strings))):\n",
    "        insert_tokens = tokenizer.encode(insert_str, add_special_tokens=False)\n",
    "        tokens[pos:pos] = insert_tokens\n",
    "\n",
    "    return tokenizer.decode(tokens)\n",
    "\n",
    "\n",
    "def insert_misleading_statements(filepath, insert_strings, context_length, output_path):\n",
    "    \"\"\"\n",
    "    Insert misleading statements into the text at sentence breaks.\n",
    "    Evenly distribute the misleading statements across the text within the context length.\n",
    "    \"\"\"\n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"yaofu/llama-2-7b-80k\")\n",
    "\n",
    "    full_text = load_text(filepath)\n",
    "    modified_text = insert_strings_at_sentence_breaks(full_text, insert_strings, context_length, tokenizer)\n",
    "\n",
    "    with open(output_path, 'w', encoding='utf-8') as f:\n",
    "        f.write(modified_text)\n",
    "\n",
    "    print(f\"✅ Output saved to {output_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "def get_haystack_file(item, context_type, with_misleading, context_length):\n",
    "    \"\"\"\n",
    "    Get the haystack file for the given item and context type.\n",
    "    Arguments:\n",
    "        item (dict): The item to process.\n",
    "        context_type (str): The type of context (\"relevant\" or \"irrelevant\").\n",
    "        with_misleading (bool): Whether to include misleading information.\n",
    "    Returns:\n",
    "        str: The path to the haystack file.\n",
    "    \"\"\"\n",
    "\n",
    "    if context_type == \"relevant\":\n",
    "        original_dir = RELEVANT_DIR\n",
    "        original_file = item[\"context_relevant\"]  # Original file without misleading info\n",
    "        misleading_dir = MISLEADING_IN_RELEVANT_DIR  # Output dir for the misleading file\n",
    "    elif context_type == \"irrelevant\":\n",
    "        original_dir = IRRELAVANT_DIR\n",
    "        original_file = item[\"context_irrelevant\"]\n",
    "        misleading_dir = MISLEADING_IN_IRRELEVANT_DIR\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown context_type: {context_type}\")\n",
    "\n",
    "    if with_misleading:\n",
    "        haystack_file = misleading_dir / original_file\n",
    "        insert_misleading_statements(\n",
    "            filepath=original_dir / original_file,           # Path to the original context file\n",
    "            insert_strings=item[\"statements_misleading\"],    # List of misleading statements\n",
    "            context_length=context_length,                   # Max context length for insertion\n",
    "            output_path=haystack_file                        # Output path for the processed file\n",
    "        )\n",
    "    else:\n",
    "        haystack_file = original_dir / original_file\n",
    "\n",
    "    return haystack_file\n",
    "\n",
    "def get_args(id, context_type, with_misleading, data=NEEDLES_DATA):\n",
    "    \"\"\"\n",
    "    Get the arguments for the given id and context type.\n",
    "    Arguments:\n",
    "        id (int): The id of the item.\n",
    "        context_type (str): The type of context (\"relevant\" or \"irrelevant\").\n",
    "        with_misleading (bool): Whether to include misleading information.\n",
    "        data (list): The list of data items.\n",
    "    Returns:\n",
    "        Namespace: The arguments for the given id and context type.\n",
    "    \"\"\"\n",
    "\n",
    "    context_length_max = 5000\n",
    "    \n",
    "    # find the item with the given id\n",
    "    item = next(item for item in data if item[\"id\"] == id)\n",
    "\n",
    "    # get the haystack file for the given item and context type\n",
    "    haystack_file = get_haystack_file(item, context_type, with_misleading, context_length_max)\n",
    "\n",
    "    args = Namespace(\n",
    "        model_name = \"yaofu/llama-2-7b-80k\",\n",
    "        model_name_suffix = ( f\"id_{item['id']}_{context_type}\" if not with_misleading \n",
    "                             else f\"id_{item['id']}_{context_type}_misleading\"), # suffix used to name the results files,\n",
    "        model_provider = \"LLaMA\",\n",
    "\n",
    "        context_lengths_min = 0, # min context length\n",
    "        context_lengths_max = context_length_max, # max context length\n",
    "        context_lengths_num_intervals = 5, # number of intervals for context lengths\n",
    "\n",
    "        document_depth_percent_intervals = 5, # number of intervals for document depth\n",
    "\n",
    "        needle = item[\"needle_refined\"],\n",
    "        real_needle = item[\"real_needle_refined\"],\n",
    "        retrieval_question = item[\"question_refined\"],\n",
    "        haystack_file = haystack_file,\n",
    "    )\n",
    "\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import torch\n",
    "from retrieval_head_detection import LLMNeedleHaystackTester as RetrievalHeads\n",
    "\n",
    "def cleanup(tester: RetrievalHeads):\n",
    "    del tester.model_to_test\n",
    "    del tester.testing_results\n",
    "    del tester.head_counter\n",
    "    del tester\n",
    "    \n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    torch.cuda.ipc_collect()\n",
    "\n",
    "def run_test(args):\n",
    "    try:\n",
    "        tester = RetrievalHeads(**vars(args))\n",
    "        tester.start_test()\n",
    "    finally:\n",
    "        cleanup(tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python executable path:\n",
      "/cs/student/projects1/2021/shyamodi/SNLP_Project/venv/bin/python\n",
      "\n",
      "Python environment site-packages:\n",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
      "['/usr/lib64/python39.zip', '/usr/lib64/python3.9', '/usr/lib64/python3.9/lib-dynload', '', '/cs/student/projects1/2021/jiajfang/SNLP_Project/venv/lib64/python3.9/site-packages', '/cs/student/projects1/2021/jiajfang/SNLP_Project/venv/lib/python3.9/site-packages', '/cs/student/projects1/2021/jiajfang/SNLP_Project', '/tmp/tmpqq1isqwq', './faiss_attn/']\n"
=======
      "['/usr/lib64/python39.zip', '/usr/lib64/python3.9', '/usr/lib64/python3.9/lib-dynload', '', '/cs/student/projects1/2021/shyamodi/SNLP_Project/venv/lib64/python3.9/site-packages', '/cs/student/projects1/2021/shyamodi/SNLP_Project/venv/lib/python3.9/site-packages', '/cs/student/projects1/2021/shyamodi/SNLP_Project', '/tmp/tmpyf5g_opq', './faiss_attn/']\n"
>>>>>>> Stashed changes
=======
      "['/usr/lib64/python39.zip', '/usr/lib64/python3.9', '/usr/lib64/python3.9/lib-dynload', '', '/cs/student/projects1/2021/jiajfang/SNLP_Project/venv/lib64/python3.9/site-packages', '/cs/student/projects1/2021/jiajfang/SNLP_Project/venv/lib/python3.9/site-packages', '/cs/student/projects1/2021/jiajfang/SNLP_Project', '/tmp/tmp6q8kkb4q', './faiss_attn/']\n"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(\"Python executable path:\")\n",
    "print(sys.executable)\n",
    "\n",
    "print(\"\\nPython environment site-packages:\")\n",
    "print(sys.path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the test object:\n",
    "Specify the **id** and the **context_type** in the `get_args` function.\n",
    "\n",
    "If `with_misleading` is True, then misleading statements are added to the specified `context_type` file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start the Test\n",
    "\n",
    "Running the test will save:\n",
    "\n",
    "- **Contexts** → Given to the model per context length/depth  \n",
    "  → `contexts/{model_name}_{context_type}_id_{id}`\n",
    "\n",
    "- **Results** → Model outputs per context length/depth  \n",
    "  → `results/graph/{model_name}_{context_type}_id_{id}`\n",
    "\n",
    "**Example**:  \n",
    "`results/graph/llama-2-7b-80k_relevant_id_44/`\n",
    "\n",
    "Each test should take <=5 minutes. It sometimes uses the CPU instead of the GPU, if it is taking longer to finish, then restart the notebook and run again. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
<<<<<<< Updated upstream
      "[410, 411, 420, 421, 422, 423, 424, 427, 43, 430, 432, 433, 435, 436]\n"
=======
      "[437, 438, 439, 44, 441, 442, 444, 448, 449, 453, 5, 532, 535, 539]\n"
>>>>>>> Stashed changes
=======
      "[576, 577, 578, 579, 586, 587, 588, 589, 590, 92, 95, 96]\n"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "ids = []\n",
    "for file_name in os.listdir('./haystack/irrelevant'):\n",
    "    if file_name.endswith('.txt'):\n",
    "        file_id = os.path.splitext(file_name)[0]  # Extract the file name without extension\n",
    "        ids.append(file_id)\n",
    "ids.sort()\n",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
    "id_vals = [int(i) for i in ids[42:56]]\n",
=======
    "id_vals = [int(i) for i in ids[56:70]]\n",
>>>>>>> Stashed changes
=======
    "id_vals = [int(i) for i in ids[70:]]\n",
>>>>>>> Stashed changes
    "print(id_vals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading from yaofu/llama-2-7b-80k\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards: 100%|██████████| 3/3 [11:31<00:00, 230.35s/it]\n",
      "The model was loaded with use_flash_attention_2=True, which is deprecated and may be removed in a future release. Please use `attn_implementation=\"flash_attention_2\"` instead.\n",
      "LlamaForCausalLM has generative capabilities, as `prepare_inputs_for_generation` is explicitly overwritten. However, it doesn't directly inherit from `GenerationMixin`. From 👉v4.50👈 onwards, `PreTrainedModel` will NOT inherit from `GenerationMixin`, and this model will lose the ability to call `generate` and other related functions.\n",
      "  - If you're using `trust_remote_code=True`, you can get rid of this warning by loading the model with an auto class. See https://huggingface.co/docs/transformers/en/model_doc/auto#auto-classes\n",
      "  - If you are the owner of the model architecture code, please modify your model class such that it inherits from `GenerationMixin` (after `PreTrainedModel`, otherwise you'll get an exception).\n",
      "  - If you are not the owner of the model architecture class, please contact the model code owner to update it.\n",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
=======
      "Loading checkpoint shards: 100%|██████████| 3/3 [11:08<00:00, 222.84s/it]\n"
>>>>>>> Stashed changes
=======
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.16it/s]\n"
>>>>>>> Stashed changes
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
      "- Needle: The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
=======
      "- Needle: The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
>>>>>>> Stashed changes
=======
      "- Needle: The next Lunar New Year is on February 17, 2026.\n",
>>>>>>> Stashed changes
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
=======
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['17-22'], ['18-30'], ['19-10'], ['15-14'], ['16-24'], ['17-31'], ['19-15'], ['24-29'], ['1-26'], ['6-30'], ['14-18'], ['21-30'], ['0-9'], ['0-11']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['17-22'], ['18-30'], ['19-10'], ['15-14'], ['16-24'], ['17-31'], ['19-15'], ['24-29'], ['1-26'], ['6-30'], ['14-18'], ['21-30'], ['0-9'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['17-22'], ['18-30'], ['19-10'], ['15-14'], ['16-24'], ['17-31'], ['19-15'], ['24-29'], ['1-26'], ['6-30'], ['14-18'], ['21-30'], ['0-9'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['17-22'], ['18-30'], ['19-10'], ['15-14'], ['16-24'], ['17-31'], ['19-15'], ['24-29'], ['1-26'], ['6-30'], ['14-18'], ['21-30'], ['0-9'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_0_depth_7500_results.json\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['17-22'], ['18-30'], ['19-10'], ['15-14'], ['16-24'], ['17-31'], ['19-15'], ['24-29'], ['1-26'], ['6-30'], ['14-18'], ['21-30'], ['0-9'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['18-30'], ['19-10'], ['17-22'], ['12-26'], ['15-14'], ['16-24'], ['17-31'], ['24-29'], ['19-15'], ['14-18'], ['21-30'], ['6-30'], ['1-26'], ['11-2'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_1250_depth_0_results.json\n",
      "insertion at 18\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['19-10'], ['15-14'], ['12-26'], ['16-24'], ['24-29'], ['17-31'], ['19-15'], ['14-18'], ['21-30'], ['6-30'], ['1-26'], ['11-2'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 18\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['19-10'], ['15-14'], ['24-29'], ['16-24'], ['12-26'], ['17-31'], ['19-15'], ['14-18'], ['21-30'], ['6-30'], ['11-2'], ['14-15'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 18\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['19-10'], ['24-29'], ['15-14'], ['16-24'], ['17-31'], ['19-15'], ['12-26'], ['14-18'], ['21-30'], ['6-30'], ['7-12'], ['14-15'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_1250_depth_7500_results.json\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['24-29'], ['15-14'], ['19-10'], ['16-24'], ['12-26'], ['17-31'], ['19-15'], ['14-18'], ['21-30'], ['6-30'], ['11-2'], ['7-12'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['19-10'], ['24-29'], ['15-14'], ['16-24'], ['12-26'], ['17-31'], ['19-15'], ['14-18'], ['21-30'], ['6-30'], ['7-12'], ['11-2'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 94.9087381362915\n",
      "Response: The next Lunar New Year will be on February 12, 2023.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_2500_depth_0_results.json\n",
      "insertion at 18\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['24-29'], ['19-10'], ['15-14'], ['16-24'], ['12-26'], ['17-31'], ['19-15'], ['7-12'], ['14-18'], ['21-30'], ['6-30'], ['11-2'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1079\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['24-29'], ['19-10'], ['15-14'], ['16-24'], ['7-12'], ['12-26'], ['17-31'], ['19-15'], ['14-18'], ['21-30'], ['11-2'], ['6-30'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1709\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['18-30'], ['19-10'], ['15-14'], ['7-12'], ['16-24'], ['17-31'], ['19-15'], ['12-26'], ['14-18'], ['11-2'], ['21-30'], ['14-15'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
<<<<<<< Updated upstream
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 58.26685428619385\n",
      "Response: Guillermo del Toro's Pinocchio\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_relevant_misleading/llama-2-7b-80k_id_410_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3268\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['7-12'], ['21-30'], ['6-9'], ['24-29'], ['31-16'], ['29-26'], ['24-8'], ['19-15'], ['17-22'], ['21-1'], ['26-27'], ['22-8'], ['6-30'], ['26-28'], ['7-4'], ['21-27'], ['24-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 58.26685428619385\n",
      "Response: Guillermo del Toro's Pinocchio\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_relevant_misleading/llama-2-7b-80k_id_410_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_relevant_misleading/llama-2-7b-80k_id_410_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_0_depth_7500_results.json\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 7.818468660116196\n",
      "Response: Up\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 228\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
=======
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['16-19'], ['16-30'], ['17-16'], ['19-15'], ['21-28'], ['21-30'], ['22-8'], ['22-27'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 15.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['16-19'], ['16-30'], ['17-16'], ['19-15'], ['21-28'], ['21-30'], ['22-8'], ['22-27'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['16-19'], ['16-30'], ['17-16'], ['19-15'], ['21-28'], ['21-30'], ['22-8'], ['22-27'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['16-19'], ['16-30'], ['17-16'], ['19-15'], ['21-28'], ['21-30'], ['22-8'], ['22-27'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_0_depth_7500_results.json\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['16-19'], ['16-30'], ['17-16'], ['19-15'], ['21-28'], ['21-30'], ['22-8'], ['22-27'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 46.63362503051758\n",
      "Response: Shōgun (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_1250_depth_0_results.json\n",
      "insertion at 226\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['15-14'], ['16-19'], ['16-30'], ['19-15'], ['21-28'], ['24-8'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['17-16'], ['21-30'], ['22-8'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 465\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['19-15'], ['8-26'], ['15-14'], ['21-30'], ['16-30'], ['14-18'], ['21-28'], ['24-8'], ['7-4'], ['11-2'], ['17-16'], ['7-12'], ['13-11'], ['6-30'], ['7-13'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 81.55538439750671\n",
      "Response: The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun. Since 2000, every single winner has been a serial drama: The West Wing (2000–2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 744\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['19-15'], ['8-26'], ['24-29'], ['15-14'], ['21-30'], ['11-2'], ['7-4'], ['16-30'], ['17-22'], ['14-18'], ['24-8'], ['21-28'], ['17-16'], ['12-26'], ['7-12'], ['13-11'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 88.2869005203247\n",
      "Response: The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun. Since 1967, they are the only non-US series or television series from outside the United States to be nominated\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_1250_depth_7500_results.json\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['19-15'], ['8-26'], ['24-29'], ['15-14'], ['21-30'], ['11-2'], ['16-30'], ['7-4'], ['17-22'], ['14-18'], ['21-28'], ['24-8'], ['12-26'], ['17-16'], ['13-11'], ['22-27'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 8.990366756916046\n",
      "Response: The West Wing (2000–2003)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_2500_depth_0_results.json\n",
      "insertion at 465\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 46.63362503051758\n",
      "Response: Shōgun (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1043\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['19-15'], ['24-29'], ['8-26'], ['15-14'], ['21-30'], ['11-2'], ['16-30'], ['7-4'], ['14-18'], ['21-28'], ['17-22'], ['24-8'], ['12-26'], ['17-16'], ['13-11'], ['18-30'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1043\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['19-15'], ['24-29'], ['8-26'], ['15-14'], ['21-30'], ['16-30'], ['11-2'], ['14-18'], ['21-28'], ['24-8'], ['7-4'], ['17-22'], ['12-26'], ['17-16'], ['18-30'], ['13-11'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_2500_depth_7500_results.json\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['19-15'], ['24-29'], ['15-14'], ['8-26'], ['21-30'], ['16-30'], ['11-2'], ['21-28'], ['14-18'], ['24-8'], ['7-4'], ['17-22'], ['12-26'], ['17-16'], ['18-30'], ['13-11'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 46.63362503051758\n",
      "Response: Shōgun (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_3750_depth_0_results.json\n",
      "insertion at 865\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['19-15'], ['24-29'], ['15-14'], ['8-26'], ['21-30'], ['16-30'], ['21-28'], ['11-2'], ['14-18'], ['24-8'], ['7-4'], ['17-22'], ['18-30'], ['12-26'], ['17-16'], ['13-11'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1043\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['19-15'], ['24-29'], ['15-14'], ['8-26'], ['16-30'], ['21-30'], ['21-28'], ['11-2'], ['14-18'], ['24-8'], ['7-4'], ['17-22'], ['18-30'], ['12-26'], ['17-16'], ['13-11'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 1043\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['16-19'], ['19-15'], ['6-9'], ['11-15'], ['24-29'], ['15-14'], ['8-26'], ['16-30'], ['21-30'], ['14-18'], ['21-28'], ['24-8'], ['11-2'], ['18-30'], ['7-4'], ['17-22'], ['12-26'], ['17-16'], ['13-11'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_3750_depth_7500_results.json\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['16-19'], ['19-15'], ['6-9'], ['11-15'], ['24-29'], ['15-14'], ['8-26'], ['16-30'], ['21-30'], ['21-28'], ['14-18'], ['24-8'], ['11-2'], ['18-30'], ['7-4'], ['17-22'], ['12-26'], ['17-16'], ['13-11'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 46.63362503051758\n",
      "Response: Shōgun (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1043\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['16-19'], ['19-15'], ['6-9'], ['11-15'], ['24-29'], ['15-14'], ['8-26'], ['16-30'], ['21-30'], ['14-18'], ['21-28'], ['24-8'], ['18-30'], ['11-2'], ['7-4'], ['17-22'], ['12-26'], ['17-16'], ['13-11'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 1043\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['6-9'], ['11-15'], ['15-14'], ['8-26'], ['16-30'], ['21-30'], ['14-18'], ['24-8'], ['21-28'], ['18-30'], ['11-2'], ['7-4'], ['17-22'], ['12-26'], ['17-16'], ['13-11'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 1043\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['6-9'], ['15-14'], ['11-15'], ['16-30'], ['8-26'], ['21-30'], ['14-18'], ['24-8'], ['18-30'], ['21-28'], ['11-2'], ['7-4'], ['17-22'], ['12-26'], ['17-16'], ['13-11'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_5000_depth_7500_results.json\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['15-14'], ['6-9'], ['11-15'], ['16-30'], ['8-26'], ['21-30'], ['14-18'], ['18-30'], ['24-8'], ['21-28'], ['11-2'], ['7-4'], ['12-26'], ['17-16'], ['17-22'], ['13-11'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant/llama-2-7b-80k_id_437_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_relevant/437.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['16-19'], ['16-30'], ['17-16'], ['19-15'], ['21-28'], ['21-30'], ['22-8'], ['22-27'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['16-19'], ['16-30'], ['17-16'], ['19-15'], ['21-28'], ['21-30'], ['22-8'], ['22-27'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['16-19'], ['16-30'], ['17-16'], ['19-15'], ['21-28'], ['21-30'], ['22-8'], ['22-27'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['16-19'], ['16-30'], ['17-16'], ['19-15'], ['21-28'], ['21-30'], ['22-8'], ['22-27'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_0_depth_7500_results.json\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['16-19'], ['16-30'], ['17-16'], ['19-15'], ['21-28'], ['21-30'], ['22-8'], ['22-27'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 46.63362503051758\n",
      "Response: Shōgun (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 255\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['15-14'], ['16-30'], ['19-15'], ['24-8'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['16-19'], ['17-16'], ['21-28'], ['21-30'], ['22-8'], ['22-27']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
<<<<<<< Updated upstream
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 337\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
=======
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 472\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['15-14'], ['16-30'], ['19-15'], ['24-8'], ['14-18'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['16-19'], ['17-16'], ['21-28'], ['21-30'], ['22-8'], ['22-27']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
<<<<<<< Updated upstream
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 637\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_1250_depth_7500_results.json\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 502\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1029\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "[['7-12'], ['11-15'], ['21-30'], ['6-9'], ['11-2'], ['16-19'], ['6-16'], ['17-22'], ['13-23'], ['18-18'], ['19-15'], ['19-19'], ['20-0'], ['23-7'], ['26-26'], ['8-26'], ['9-30'], ['11-22'], ['14-3'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 85.48403978347778\n",
      "Response: Flow, which is the title of the film that won the latest Academy Award for Best Animated Feature.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1029\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "[['7-12'], ['11-15'], ['21-30'], ['6-9'], ['11-2'], ['16-19'], ['6-16'], ['17-22'], ['13-23'], ['18-18'], ['19-15'], ['19-19'], ['20-0'], ['23-7'], ['26-26'], ['8-26'], ['9-30'], ['11-22'], ['14-3'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
=======
>>>>>>> Stashed changes
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
<<<<<<< Updated upstream
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_2500_depth_7500_results.json\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 808\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1029\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 1029\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_3750_depth_7500_results.json\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1029\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 1029\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3205\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "[['7-12'], ['21-30'], ['11-15'], ['16-19'], ['6-16'], ['6-9'], ['17-22'], ['11-2'], ['18-18'], ['19-15'], ['23-7'], ['24-29'], ['13-23'], ['19-19'], ['20-0'], ['26-26'], ['19-14'], ['8-26'], ['14-18'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 88.4251058101654\n",
      "Response: Flow, Question: What was the title of the film that won the latest Academy Award for Best Animated Feature?\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_5000_depth_7500_results.json\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant/llama-2-7b-80k_id_410_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/410.txt\n",
=======
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 761\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['15-14'], ['16-30'], ['19-15'], ['24-8'], ['14-18'], ['31-16'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['16-19'], ['17-16'], ['21-28'], ['21-30'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['15-14'], ['19-15'], ['16-30'], ['24-8'], ['31-16'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['16-19'], ['17-16'], ['21-28'], ['21-30'], ['22-8'], ['22-27'], ['24-11'], ['25-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 46.63362503051758\n",
      "Response: Shōgun (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 532\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['19-15'], ['16-30'], ['24-8'], ['15-14'], ['31-16'], ['14-18'], ['16-19'], ['21-28'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['21-30'], ['22-8'], ['22-27'], ['24-11'], ['25-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 54.1517972946167\n",
      "Response: Shōgun (1980)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1121\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['19-15'], ['16-30'], ['24-8'], ['15-14'], ['31-16'], ['14-18'], ['16-19'], ['21-28'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['18-30'], ['21-30'], ['22-8'], ['22-27'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 54.1517972946167\n",
      "Response: Shōgun (1980)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1201\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['19-15'], ['15-14'], ['16-30'], ['24-8'], ['31-16'], ['14-18'], ['16-19'], ['21-28'], ['18-30'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['15-5'], ['17-16'], ['21-30'], ['22-8'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['19-15'], ['15-14'], ['16-30'], ['24-8'], ['31-16'], ['16-19'], ['14-18'], ['21-28'], ['18-30'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['21-30'], ['22-8'], ['22-27'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 46.63362503051758\n",
      "Response: Shōgun (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 841\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['19-15'], ['15-14'], ['16-30'], ['24-8'], ['31-16'], ['16-19'], ['14-18'], ['18-30'], ['21-28'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['15-5'], ['17-16'], ['21-30'], ['22-8'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1201\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['19-15'], ['15-14'], ['16-30'], ['24-8'], ['16-19'], ['31-16'], ['14-18'], ['18-30'], ['21-28'], ['15-5'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['21-30'], ['22-8'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 1201\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['19-15'], ['15-14'], ['16-30'], ['24-8'], ['16-19'], ['31-16'], ['14-18'], ['18-30'], ['15-5'], ['21-28'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['21-30'], ['22-8'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['19-15'], ['15-14'], ['16-30'], ['24-8'], ['16-19'], ['31-16'], ['14-18'], ['18-30'], ['21-28'], ['15-5'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['21-30'], ['22-8'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 46.63362503051758\n",
      "Response: Shōgun (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1170\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['19-15'], ['15-14'], ['16-30'], ['24-8'], ['16-19'], ['14-18'], ['18-30'], ['31-16'], ['15-5'], ['21-28'], ['29-26'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['21-30'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 1201\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['19-15'], ['15-14'], ['16-30'], ['24-8'], ['14-18'], ['16-19'], ['18-30'], ['31-16'], ['15-5'], ['21-28'], ['29-26'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['21-30'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 1201\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['19-15'], ['15-14'], ['16-30'], ['24-8'], ['14-18'], ['18-30'], ['16-19'], ['31-16'], ['15-5'], ['29-26'], ['21-28'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['21-30'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['19-15'], ['15-14'], ['16-30'], ['24-8'], ['18-30'], ['14-18'], ['16-19'], ['31-16'], ['15-5'], ['29-26'], ['21-28'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['21-30'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_relevant_misleading/llama-2-7b-80k_id_437_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['16-19'], ['16-30'], ['17-16'], ['19-15'], ['21-28'], ['21-30'], ['22-8'], ['22-27'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['16-19'], ['16-30'], ['17-16'], ['19-15'], ['21-28'], ['21-30'], ['22-8'], ['22-27'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['16-19'], ['16-30'], ['17-16'], ['19-15'], ['21-28'], ['21-30'], ['22-8'], ['22-27'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['16-19'], ['16-30'], ['17-16'], ['19-15'], ['21-28'], ['21-30'], ['22-8'], ['22-27'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_0_depth_7500_results.json\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['16-19'], ['16-30'], ['17-16'], ['19-15'], ['21-28'], ['21-30'], ['22-8'], ['22-27'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 8.03639441728592\n",
      "Response: The Brutalist (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 253\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['14-18'], ['15-14'], ['16-19'], ['16-30'], ['19-15'], ['24-8'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['21-28'], ['21-30'], ['22-8'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 481\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['15-14'], ['16-19'], ['16-30'], ['19-15'], ['24-8'], ['14-18'], ['21-28'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['21-30'], ['22-8'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 678\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['15-14'], ['16-19'], ['19-15'], ['16-30'], ['21-28'], ['24-8'], ['14-18'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['21-30'], ['22-8'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_1250_depth_7500_results.json\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['16-19'], ['15-14'], ['19-15'], ['16-30'], ['21-28'], ['24-8'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['17-16'], ['21-30'], ['22-8'], ['22-27'], ['24-11'], ['25-11'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 8.03639441728592\n",
      "Response: The Brutalist (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 481\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['16-19'], ['15-14'], ['19-15'], ['21-28'], ['16-30'], ['14-18'], ['24-8'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['21-30'], ['22-8'], ['22-27'], ['24-11'], ['25-11'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1088\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['16-19'], ['15-14'], ['19-15'], ['21-28'], ['16-30'], ['14-18'], ['24-8'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['18-30'], ['21-30'], ['22-8'], ['22-27'], ['24-11'], ['25-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1616\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['16-19'], ['15-14'], ['19-15'], ['21-28'], ['16-30'], ['14-18'], ['18-30'], ['24-8'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['21-30'], ['22-8'], ['22-27'], ['24-11'], ['25-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_2500_depth_7500_results.json\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['15-14'], ['16-19'], ['19-15'], ['21-28'], ['16-30'], ['18-30'], ['14-18'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['21-30'], ['22-8'], ['22-27'], ['24-8'], ['24-11'], ['25-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 8.03639441728592\n",
      "Response: The Brutalist (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 876\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['15-14'], ['16-19'], ['19-15'], ['21-28'], ['16-30'], ['18-30'], ['14-18'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['21-30'], ['22-8'], ['22-27'], ['24-8'], ['24-11'], ['25-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1755\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['15-14'], ['16-19'], ['19-15'], ['21-28'], ['18-30'], ['16-30'], ['14-18'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['21-30'], ['22-8'], ['22-27'], ['24-8'], ['24-11'], ['25-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2356\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['15-14'], ['16-19'], ['19-15'], ['21-28'], ['18-30'], ['16-30'], ['14-18'], ['29-26'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-11'], ['17-16'], ['21-30'], ['22-8'], ['22-27'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_3750_depth_7500_results.json\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['15-14'], ['16-19'], ['19-15'], ['21-28'], ['18-30'], ['16-30'], ['29-26'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['17-16'], ['21-30'], ['22-8'], ['22-27'], ['24-11'], ['25-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 8.03639441728592\n",
      "Response: The Brutalist (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1088\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['15-14'], ['16-19'], ['19-15'], ['21-28'], ['18-30'], ['16-30'], ['29-26'], ['14-18'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-11'], ['17-16'], ['21-30'], ['22-8'], ['22-27'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2356\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['15-14'], ['16-19'], ['19-15'], ['21-28'], ['18-30'], ['29-26'], ['16-30'], ['14-18'], ['17-11'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['21-30'], ['22-8'], ['22-27'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3545\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['15-14'], ['16-19'], ['19-15'], ['21-28'], ['18-30'], ['29-26'], ['16-30'], ['17-11'], ['14-18'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['21-30'], ['22-8'], ['22-27'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_5000_depth_7500_results.json\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['15-14'], ['16-19'], ['19-15'], ['21-28'], ['18-30'], ['29-26'], ['16-30'], ['17-11'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['17-16'], ['21-30'], ['22-8'], ['22-27'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant/llama-2-7b-80k_id_437_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_irrelevant/437.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['16-19'], ['16-30'], ['17-16'], ['19-15'], ['21-28'], ['21-30'], ['22-8'], ['22-27'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['16-19'], ['16-30'], ['17-16'], ['19-15'], ['21-28'], ['21-30'], ['22-8'], ['22-27'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['16-19'], ['16-30'], ['17-16'], ['19-15'], ['21-28'], ['21-30'], ['22-8'], ['22-27'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['16-19'], ['16-30'], ['17-16'], ['19-15'], ['21-28'], ['21-30'], ['22-8'], ['22-27'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['16-19'], ['16-30'], ['17-16'], ['19-15'], ['21-28'], ['21-30'], ['22-8'], ['22-27'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 8.03639441728592\n",
      "Response: The Brutalist (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 253\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['14-18'], ['15-14'], ['16-19'], ['19-15'], ['21-28'], ['24-8'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['16-30'], ['17-16'], ['21-30'], ['22-8'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 510\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['15-14'], ['16-19'], ['19-15'], ['21-28'], ['24-8'], ['14-18'], ['16-30'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['21-30'], ['22-8'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 707\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['15-14'], ['16-19'], ['19-15'], ['21-28'], ['24-8'], ['14-18'], ['16-30'], ['6-30'], ['7-4'], ['7-13'], ['8-22'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['21-30'], ['22-8'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['15-14'], ['16-19'], ['19-15'], ['21-28'], ['24-8'], ['16-30'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['17-16'], ['21-30'], ['22-8'], ['22-27'], ['24-11'], ['25-11'], ['29-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 8.03639441728592\n",
      "Response: The Brutalist (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 510\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['16-19'], ['15-14'], ['19-15'], ['21-28'], ['24-8'], ['16-30'], ['14-18'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['21-30'], ['22-8'], ['22-27'], ['24-11'], ['25-11'], ['29-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1117\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['16-19'], ['19-15'], ['21-28'], ['15-14'], ['24-8'], ['16-30'], ['14-18'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['17-16'], ['18-30'], ['19-10'], ['21-30'], ['22-8'], ['22-27'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1683\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['16-19'], ['19-15'], ['21-28'], ['15-14'], ['16-30'], ['24-8'], ['18-30'], ['19-10'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['17-16'], ['21-30'], ['22-8'], ['22-27'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['16-19'], ['19-15'], ['15-14'], ['21-28'], ['16-30'], ['18-30'], ['19-10'], ['24-8'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['21-30'], ['22-8'], ['22-27'], ['24-11'], ['25-11'], ['29-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 8.03639441728592\n",
      "Response: The Brutalist (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 873\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['16-19'], ['19-15'], ['15-14'], ['21-28'], ['16-30'], ['19-10'], ['18-30'], ['24-8'], ['14-18'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['21-30'], ['22-8'], ['22-27'], ['24-11'], ['25-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1683\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['16-19'], ['19-15'], ['15-14'], ['21-28'], ['19-10'], ['16-30'], ['18-30'], ['24-8'], ['14-18'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['21-30'], ['22-8'], ['22-27'], ['24-11'], ['25-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2453\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['16-19'], ['19-15'], ['15-14'], ['21-28'], ['19-10'], ['16-30'], ['18-30'], ['24-8'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['14-18'], ['17-11'], ['21-30'], ['22-8'], ['22-27'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['16-19'], ['19-15'], ['15-14'], ['21-28'], ['19-10'], ['16-30'], ['18-30'], ['6-30'], ['8-26'], ['11-15'], ['12-26'], ['13-11'], ['21-30'], ['22-8'], ['22-27'], ['24-8'], ['24-11'], ['25-11'], ['29-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['16-19'], ['19-15'], ['15-14'], ['19-10'], ['21-28'], ['16-30'], ['11-15'], ['12-26'], ['18-30'], ['24-8'], ['6-30'], ['8-26'], ['13-11'], ['21-30'], ['22-8'], ['22-27'], ['24-11'], ['25-11'], ['29-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 87.73912787437439\n",
      "Response: The winner of the most recent Primetime Emmy Award for Outstanding Drama Series was a show that, like Shōgun, is based on a bestselling novel.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1117\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['16-19'], ['19-15'], ['15-14'], ['19-10'], ['21-28'], ['16-30'], ['11-15'], ['12-26'], ['18-30'], ['24-8'], ['6-30'], ['8-26'], ['13-11'], ['21-30'], ['22-8'], ['22-27'], ['24-11'], ['25-11'], ['29-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2223\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['16-19'], ['19-15'], ['15-14'], ['19-10'], ['21-28'], ['16-30'], ['18-30'], ['11-15'], ['12-26'], ['24-8'], ['6-30'], ['8-26'], ['13-11'], ['14-18'], ['17-11'], ['21-30'], ['22-8'], ['22-27'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3382\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['16-19'], ['19-15'], ['19-10'], ['15-14'], ['21-28'], ['16-30'], ['18-30'], ['11-15'], ['12-26'], ['17-11'], ['24-8'], ['6-30'], ['8-26'], ['13-11'], ['14-18'], ['21-30'], ['22-8'], ['22-27'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 55.562883615493774\n",
      "Response: Shōgun\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The drama series that won the most recent Primetime Emmy Award for Outstanding Drama Series is Shōgun.\n",
      "[['24-29'], ['16-19'], ['19-15'], ['15-14'], ['19-10'], ['21-28'], ['16-30'], ['18-30'], ['11-15'], ['12-26'], ['6-30'], ['8-26'], ['13-11'], ['17-11'], ['21-30'], ['22-8'], ['22-27'], ['24-8'], ['24-11'], ['25-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 54.60478067398071\n",
      "Response: Shōgun.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_437_irrelevant_misleading/llama-2-7b-80k_id_437_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['8-26'], ['11-15'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['1-26'], ['6-30'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['0-8'], ['0-11'], ['9-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['8-26'], ['11-15'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['1-26'], ['6-30'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['0-8'], ['0-11'], ['9-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['8-26'], ['11-15'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['1-26'], ['6-30'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['0-8'], ['0-11'], ['9-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['8-26'], ['11-15'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['1-26'], ['6-30'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['0-8'], ['0-11'], ['9-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_0_depth_7500_results.json\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['8-26'], ['11-15'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['1-26'], ['6-30'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['0-8'], ['0-11'], ['9-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['24-29'], ['16-19'], ['19-15'], ['8-26'], ['11-15'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['1-26'], ['6-30'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['0-8'], ['0-11'], ['9-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 55.910277366638184\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is \"Alloyed\".\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_1250_depth_0_results.json\n",
      "insertion at 205\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['24-29'], ['19-15'], ['8-26'], ['11-15'], ['21-30'], ['12-26'], ['31-16'], ['17-22'], ['6-30'], ['29-19'], ['1-26'], ['11-2'], ['26-28'], ['29-21'], ['22-16'], ['13-11'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 507\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['24-29'], ['19-15'], ['8-26'], ['11-15'], ['21-30'], ['12-26'], ['31-16'], ['17-22'], ['6-30'], ['29-19'], ['26-28'], ['29-21'], ['1-26'], ['11-2'], ['22-16'], ['24-8'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 62.228286266326904\n",
      "Response: Shadow and Flame\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 763\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['24-29'], ['19-15'], ['8-26'], ['11-15'], ['21-30'], ['12-26'], ['31-16'], ['17-22'], ['6-30'], ['29-19'], ['26-28'], ['29-21'], ['11-2'], ['22-16'], ['1-26'], ['20-3'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_1250_depth_7500_results.json\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['8-26'], ['11-15'], ['21-30'], ['12-26'], ['31-16'], ['17-22'], ['6-30'], ['26-28'], ['29-19'], ['29-21'], ['22-16'], ['20-3'], ['11-2'], ['13-11'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['7-4'], ['19-15'], ['8-26'], ['16-19'], ['24-29'], ['11-15'], ['21-30'], ['12-26'], ['31-16'], ['17-22'], ['6-30'], ['26-28'], ['29-19'], ['29-21'], ['13-11'], ['22-16'], ['20-3'], ['11-2'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 90.97787737846375\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is \"Shadow and Flame\".\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_2500_depth_0_results.json\n",
      "insertion at 538\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['7-4'], ['8-26'], ['11-15'], ['16-19'], ['19-15'], ['24-29'], ['21-30'], ['12-26'], ['17-22'], ['31-16'], ['6-30'], ['26-28'], ['29-19'], ['29-21'], ['13-11'], ['22-16'], ['20-3'], ['7-12'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1072\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['11-15'], ['7-4'], ['8-26'], ['16-19'], ['19-15'], ['24-29'], ['21-30'], ['17-22'], ['12-26'], ['31-16'], ['6-30'], ['26-28'], ['29-19'], ['7-12'], ['22-16'], ['29-21'], ['11-2'], ['13-11'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1540\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['7-4'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['12-26'], ['31-16'], ['7-12'], ['6-30'], ['11-2'], ['26-28'], ['29-19'], ['22-16'], ['20-3'], ['24-8'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_2500_depth_7500_results.json\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['19-15'], ['7-4'], ['24-29'], ['21-30'], ['17-22'], ['12-26'], ['31-16'], ['6-30'], ['26-28'], ['29-19'], ['7-12'], ['11-2'], ['29-21'], ['13-11'], ['22-16'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['16-19'], ['19-15'], ['7-4'], ['24-29'], ['21-30'], ['17-22'], ['12-26'], ['31-16'], ['7-12'], ['6-30'], ['29-19'], ['26-28'], ['11-2'], ['13-11'], ['22-16'], ['29-21'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 90.97787737846375\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is \"Shadow and Flame\".\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_3750_depth_0_results.json\n",
      "insertion at 879\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['16-19'], ['19-15'], ['24-29'], ['7-4'], ['17-22'], ['21-30'], ['12-26'], ['31-16'], ['7-12'], ['6-30'], ['29-19'], ['26-28'], ['11-2'], ['22-16'], ['13-11'], ['29-21'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1540\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['19-15'], ['24-29'], ['7-4'], ['17-22'], ['21-30'], ['12-26'], ['31-16'], ['7-12'], ['6-30'], ['11-2'], ['29-19'], ['26-28'], ['22-16'], ['13-11'], ['29-21'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2613\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['21-30'], ['12-26'], ['31-16'], ['7-12'], ['11-2'], ['6-30'], ['29-19'], ['26-28'], ['22-16'], ['13-11'], ['21-28'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_3750_depth_7500_results.json\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['19-15'], ['24-29'], ['7-4'], ['17-22'], ['21-30'], ['12-26'], ['31-16'], ['7-12'], ['6-30'], ['11-2'], ['29-19'], ['26-28'], ['21-28'], ['29-21'], ['22-16'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['21-30'], ['12-26'], ['31-16'], ['7-12'], ['6-30'], ['11-2'], ['29-19'], ['26-28'], ['21-28'], ['13-11'], ['29-21'], ['22-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 90.97787737846375\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is \"Shadow and Flame\".\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1164\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['21-30'], ['12-26'], ['31-16'], ['7-12'], ['6-30'], ['11-2'], ['29-19'], ['26-28'], ['21-28'], ['22-16'], ['13-11'], ['29-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2377\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['21-30'], ['12-26'], ['31-16'], ['7-12'], ['11-2'], ['6-30'], ['29-19'], ['21-28'], ['26-28'], ['22-16'], ['13-11'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3528\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['21-30'], ['12-26'], ['31-16'], ['7-12'], ['11-2'], ['6-30'], ['21-28'], ['29-19'], ['22-16'], ['26-28'], ['24-8'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 62.228286266326904\n",
      "Response: Shadow and Flame\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_5000_depth_7500_results.json\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['21-30'], ['12-26'], ['31-16'], ['7-12'], ['6-30'], ['11-2'], ['21-28'], ['29-19'], ['26-28'], ['22-16'], ['13-11'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant/llama-2-7b-80k_id_438_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_relevant/438.txt\n",
>>>>>>> Stashed changes
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
=======
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n"
>>>>>>> Stashed changes
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
<<<<<<< Updated upstream
      "- Needle: The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
=======
      "- Needle: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
>>>>>>> Stashed changes
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
<<<<<<< Updated upstream
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant_misleading/llama-2-7b-80k_id_410_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant_misleading/llama-2-7b-80k_id_410_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant_misleading/llama-2-7b-80k_id_410_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant_misleading/llama-2-7b-80k_id_410_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant_misleading/llama-2-7b-80k_id_410_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
=======
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['8-26'], ['11-15'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['1-26'], ['6-30'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['0-8'], ['0-11'], ['9-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['8-26'], ['11-15'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['1-26'], ['6-30'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['0-8'], ['0-11'], ['9-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['8-26'], ['11-15'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['1-26'], ['6-30'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['0-8'], ['0-11'], ['9-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['8-26'], ['11-15'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['1-26'], ['6-30'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['0-8'], ['0-11'], ['9-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_0_depth_7500_results.json\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['8-26'], ['11-15'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['1-26'], ['6-30'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['0-8'], ['0-11'], ['9-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
<<<<<<< Updated upstream
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant_misleading/llama-2-7b-80k_id_410_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 212\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
=======
      "Score: 43.617117404937744\n",
      "Response: A Shadow of the Past\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 205\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['24-29'], ['19-15'], ['8-26'], ['11-15'], ['21-30'], ['12-26'], ['31-16'], ['17-22'], ['6-30'], ['26-28'], ['29-19'], ['29-21'], ['1-26'], ['11-2'], ['22-16'], ['13-11'], ['20-3']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
<<<<<<< Updated upstream
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant_misleading/llama-2-7b-80k_id_410_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 372\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
=======
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 507\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
<<<<<<< Updated upstream
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant_misleading/llama-2-7b-80k_id_410_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 698\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
=======
      "Score: 43.617117404937744\n",
      "Response: A Shadow of the Past\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 749\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['24-29'], ['19-15'], ['8-26'], ['11-15'], ['21-30'], ['12-26'], ['31-16'], ['17-22'], ['6-30'], ['26-28'], ['29-19'], ['29-21'], ['1-26'], ['11-2'], ['22-16'], ['24-8'], ['13-11']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
<<<<<<< Updated upstream
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant_misleading/llama-2-7b-80k_id_410_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant_misleading/llama-2-7b-80k_id_410_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant_misleading/llama-2-7b-80k_id_410_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 537\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant_misleading/llama-2-7b-80k_id_410_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1090\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 38.9255166053772\n",
      "Response: Flow,\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant_misleading/llama-2-7b-80k_id_410_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1090\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 38.9255166053772\n",
      "Response: Flow,\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant_misleading/llama-2-7b-80k_id_410_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant_misleading/llama-2-7b-80k_id_410_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant_misleading/llama-2-7b-80k_id_410_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 698\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "[['6-9'], ['8-26'], ['16-19'], ['7-12'], ['11-15'], ['0-23'], ['8-22'], ['8-31'], ['11-2'], ['17-22'], ['21-1'], ['22-8'], ['22-22'], ['24-3'], ['24-5'], ['24-15'], ['24-29'], ['26-28'], ['28-6'], ['28-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 58.26685428619385\n",
      "Response: Guillermo del Toro's Pinocchio\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant_misleading/llama-2-7b-80k_id_410_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1090\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "[['8-26'], ['16-19'], ['6-9'], ['7-12'], ['11-15'], ['21-30'], ['21-1'], ['22-8'], ['24-29'], ['29-26'], ['8-22'], ['11-2'], ['17-22'], ['19-15'], ['22-22'], ['24-3'], ['24-5'], ['24-15'], ['26-27'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 58.26685428619385\n",
      "Response: Guillermo del Toro's Pinocchio\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant_misleading/llama-2-7b-80k_id_410_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 1090\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "[['8-26'], ['16-19'], ['6-9'], ['7-12'], ['11-15'], ['21-30'], ['21-1'], ['22-8'], ['24-29'], ['29-26'], ['19-15'], ['26-27'], ['8-22'], ['11-2'], ['17-22'], ['22-22'], ['24-3'], ['24-5'], ['24-15'], ['26-28']]\n",
=======
      "Score: 62.228286266326904\n",
      "Response: Shadow and Flame\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['8-26'], ['11-15'], ['21-30'], ['12-26'], ['31-16'], ['17-22'], ['6-30'], ['26-28'], ['29-19'], ['29-21'], ['22-16'], ['1-26'], ['11-2'], ['13-11'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['24-29'], ['19-15'], ['8-26'], ['11-15'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['6-30'], ['26-28'], ['29-19'], ['29-21'], ['22-16'], ['13-11'], ['1-26'], ['11-2'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 90.97787737846375\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is \"Shadow and Flame\".\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 538\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['7-4'], ['16-19'], ['24-29'], ['19-15'], ['8-26'], ['11-15'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['6-30'], ['26-28'], ['29-19'], ['29-21'], ['22-16'], ['7-12'], ['11-2'], ['13-11'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1098\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['7-4'], ['24-29'], ['16-19'], ['19-15'], ['8-26'], ['11-15'], ['21-30'], ['12-26'], ['31-16'], ['17-22'], ['6-30'], ['29-19'], ['26-28'], ['22-16'], ['29-21'], ['7-12'], ['11-2'], ['20-3'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1600\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['7-4'], ['24-29'], ['16-19'], ['19-15'], ['8-26'], ['11-15'], ['21-30'], ['12-26'], ['17-22'], ['31-16'], ['6-30'], ['29-19'], ['26-28'], ['22-16'], ['7-12'], ['29-21'], ['20-3'], ['24-8'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['7-4'], ['24-29'], ['16-19'], ['19-15'], ['8-26'], ['11-15'], ['21-30'], ['12-26'], ['17-22'], ['31-16'], ['6-30'], ['29-19'], ['26-28'], ['29-21'], ['22-16'], ['7-12'], ['21-28'], ['13-11'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['7-4'], ['24-29'], ['16-19'], ['8-26'], ['19-15'], ['11-15'], ['21-30'], ['12-26'], ['17-22'], ['31-16'], ['6-30'], ['29-19'], ['26-28'], ['29-21'], ['22-16'], ['7-12'], ['21-28'], ['13-11'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 78.60164046287537\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is A Shadow of the Past.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 873\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['24-29'], ['8-26'], ['16-19'], ['7-4'], ['19-15'], ['11-15'], ['21-30'], ['12-26'], ['17-22'], ['31-16'], ['6-30'], ['29-19'], ['7-12'], ['26-28'], ['22-16'], ['29-21'], ['21-28'], ['11-2'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1600\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['16-19'], ['8-26'], ['24-29'], ['11-15'], ['7-4'], ['19-15'], ['21-30'], ['12-26'], ['17-22'], ['31-16'], ['6-30'], ['7-12'], ['29-19'], ['11-2'], ['22-16'], ['21-28'], ['26-28'], ['29-21'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2607\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['16-19'], ['8-26'], ['24-29'], ['19-15'], ['7-4'], ['11-15'], ['21-30'], ['17-22'], ['12-26'], ['31-16'], ['6-30'], ['7-12'], ['29-19'], ['22-16'], ['11-2'], ['21-28'], ['26-28'], ['29-21'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['16-19'], ['8-26'], ['24-29'], ['19-15'], ['7-4'], ['11-15'], ['21-30'], ['12-26'], ['17-22'], ['31-16'], ['6-30'], ['7-12'], ['29-19'], ['21-28'], ['26-28'], ['22-16'], ['29-21'], ['11-2'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['16-19'], ['8-26'], ['24-29'], ['19-15'], ['7-4'], ['11-15'], ['21-30'], ['17-22'], ['12-26'], ['31-16'], ['6-30'], ['7-12'], ['29-19'], ['21-28'], ['26-28'], ['22-16'], ['29-21'], ['13-11'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1190\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['16-19'], ['8-26'], ['24-29'], ['19-15'], ['11-15'], ['7-4'], ['21-30'], ['17-22'], ['12-26'], ['31-16'], ['6-30'], ['7-12'], ['29-19'], ['21-28'], ['22-16'], ['26-28'], ['29-21'], ['13-11'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2369\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['16-19'], ['8-26'], ['24-29'], ['19-15'], ['11-15'], ['7-4'], ['21-30'], ['17-22'], ['12-26'], ['31-16'], ['7-12'], ['6-30'], ['29-19'], ['21-28'], ['22-16'], ['26-28'], ['13-11'], ['29-21'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3569\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['16-19'], ['24-29'], ['8-26'], ['19-15'], ['11-15'], ['7-4'], ['21-30'], ['17-22'], ['12-26'], ['31-16'], ['7-12'], ['6-30'], ['29-19'], ['21-28'], ['22-16'], ['26-28'], ['11-2'], ['13-11'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['16-19'], ['24-29'], ['8-26'], ['19-15'], ['11-15'], ['7-4'], ['21-30'], ['17-22'], ['12-26'], ['31-16'], ['7-12'], ['6-30'], ['29-19'], ['21-28'], ['22-16'], ['26-28'], ['29-21'], ['13-11'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_relevant_misleading/llama-2-7b-80k_id_438_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['8-26'], ['11-15'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['1-26'], ['6-30'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['0-8'], ['0-11'], ['9-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['8-26'], ['11-15'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['1-26'], ['6-30'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['0-8'], ['0-11'], ['9-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['8-26'], ['11-15'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['1-26'], ['6-30'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['0-8'], ['0-11'], ['9-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['8-26'], ['11-15'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['1-26'], ['6-30'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['0-8'], ['0-11'], ['9-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_0_depth_7500_results.json\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['8-26'], ['11-15'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['1-26'], ['6-30'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['0-8'], ['0-11'], ['9-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['24-29'], ['19-15'], ['11-15'], ['8-26'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['11-2'], ['1-26'], ['6-30'], ['26-28'], ['29-19'], ['29-21'], ['0-8'], ['0-11'], ['9-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 77.89499759674072\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is \"A Shadow of the Past\".\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 160\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['24-29'], ['19-15'], ['11-15'], ['8-26'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['11-2'], ['6-30'], ['29-19'], ['1-26'], ['26-28'], ['29-21'], ['22-16'], ['13-11'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 502\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['16-19'], ['6-9'], ['24-29'], ['11-15'], ['19-15'], ['8-26'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['11-2'], ['6-30'], ['29-19'], ['26-28'], ['29-21'], ['1-26'], ['7-12'], ['22-16'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 732\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['16-19'], ['6-9'], ['11-15'], ['24-29'], ['19-15'], ['8-26'], ['21-30'], ['12-26'], ['31-16'], ['17-22'], ['11-2'], ['6-30'], ['29-19'], ['7-12'], ['26-28'], ['29-21'], ['22-16'], ['1-26'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_1250_depth_7500_results.json\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['24-29'], ['11-15'], ['19-15'], ['8-26'], ['12-26'], ['21-30'], ['17-22'], ['31-16'], ['11-2'], ['26-28'], ['6-30'], ['29-19'], ['29-21'], ['22-16'], ['7-12'], ['20-3'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['11-15'], ['24-29'], ['19-15'], ['8-26'], ['12-26'], ['21-30'], ['17-22'], ['31-16'], ['11-2'], ['26-28'], ['6-30'], ['29-19'], ['29-21'], ['7-12'], ['22-16'], ['20-3'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 65.76346755027771\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is \"The Eye.\"\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 518\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['11-15'], ['6-9'], ['16-19'], ['8-26'], ['24-29'], ['19-15'], ['12-26'], ['21-30'], ['17-22'], ['31-16'], ['7-12'], ['11-2'], ['26-28'], ['6-30'], ['29-19'], ['29-21'], ['22-16'], ['24-8'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1122\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['24-29'], ['19-15'], ['21-30'], ['12-26'], ['17-22'], ['31-16'], ['7-12'], ['11-2'], ['26-28'], ['6-30'], ['29-19'], ['22-16'], ['29-21'], ['24-8'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1702\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['7-4'], ['24-29'], ['19-15'], ['21-30'], ['12-26'], ['17-22'], ['31-16'], ['7-12'], ['11-2'], ['26-28'], ['6-30'], ['29-19'], ['29-21'], ['22-16'], ['24-8'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_2500_depth_7500_results.json\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['8-26'], ['16-19'], ['11-15'], ['24-29'], ['7-4'], ['19-15'], ['21-30'], ['12-26'], ['17-22'], ['31-16'], ['7-12'], ['26-28'], ['6-30'], ['11-2'], ['29-19'], ['29-21'], ['22-16'], ['24-8'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['16-19'], ['24-29'], ['7-4'], ['19-15'], ['21-30'], ['12-26'], ['17-22'], ['31-16'], ['7-12'], ['26-28'], ['11-2'], ['6-30'], ['29-21'], ['29-19'], ['22-16'], ['24-8'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 65.76346755027771\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is \"The Eye.\"\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 869\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['8-26'], ['11-15'], ['6-9'], ['24-29'], ['16-19'], ['7-4'], ['19-15'], ['21-30'], ['12-26'], ['17-22'], ['31-16'], ['7-12'], ['26-28'], ['11-2'], ['6-30'], ['29-21'], ['29-19'], ['22-16'], ['24-8'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1753\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['8-26'], ['11-15'], ['6-9'], ['24-29'], ['16-19'], ['7-4'], ['19-15'], ['21-30'], ['12-26'], ['17-22'], ['31-16'], ['7-12'], ['26-28'], ['11-2'], ['6-30'], ['29-19'], ['29-21'], ['22-16'], ['24-8'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2634\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['8-26'], ['11-15'], ['24-29'], ['6-9'], ['16-19'], ['19-15'], ['7-4'], ['21-30'], ['17-22'], ['12-26'], ['31-16'], ['7-12'], ['26-28'], ['11-2'], ['6-30'], ['29-19'], ['22-16'], ['29-21'], ['24-8'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_3750_depth_7500_results.json\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['8-26'], ['6-9'], ['24-29'], ['11-15'], ['16-19'], ['19-15'], ['7-4'], ['21-30'], ['12-26'], ['17-22'], ['31-16'], ['7-12'], ['26-28'], ['6-30'], ['11-2'], ['29-19'], ['29-21'], ['22-16'], ['15-14'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['8-26'], ['6-9'], ['24-29'], ['11-15'], ['16-19'], ['19-15'], ['7-4'], ['21-30'], ['12-26'], ['17-22'], ['31-16'], ['7-12'], ['26-28'], ['6-30'], ['11-2'], ['29-19'], ['29-21'], ['22-16'], ['15-14'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 65.76346755027771\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is \"The Eye.\"\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1184\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['8-26'], ['24-29'], ['11-15'], ['6-9'], ['16-19'], ['19-15'], ['7-4'], ['21-30'], ['12-26'], ['17-22'], ['31-16'], ['7-12'], ['26-28'], ['6-30'], ['11-2'], ['29-19'], ['22-16'], ['29-21'], ['15-14'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2384\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['8-26'], ['24-29'], ['11-15'], ['6-9'], ['16-19'], ['19-15'], ['7-4'], ['21-30'], ['17-22'], ['12-26'], ['31-16'], ['7-12'], ['26-28'], ['6-30'], ['11-2'], ['29-19'], ['22-16'], ['29-21'], ['15-14'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3566\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['8-26'], ['24-29'], ['11-15'], ['6-9'], ['16-19'], ['19-15'], ['7-4'], ['21-30'], ['17-22'], ['12-26'], ['31-16'], ['7-12'], ['26-28'], ['6-30'], ['11-2'], ['22-16'], ['29-19'], ['29-21'], ['29-26'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_5000_depth_7500_results.json\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['8-26'], ['24-29'], ['6-9'], ['11-15'], ['16-19'], ['19-15'], ['7-4'], ['21-30'], ['12-26'], ['17-22'], ['31-16'], ['7-12'], ['26-28'], ['6-30'], ['29-19'], ['11-2'], ['22-16'], ['29-21'], ['15-14'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant/llama-2-7b-80k_id_438_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_irrelevant/438.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['8-26'], ['11-15'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['1-26'], ['6-30'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['0-8'], ['0-11'], ['9-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['8-26'], ['11-15'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['1-26'], ['6-30'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['0-8'], ['0-11'], ['9-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['8-26'], ['11-15'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['1-26'], ['6-30'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['0-8'], ['0-11'], ['9-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['8-26'], ['11-15'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['1-26'], ['6-30'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['0-8'], ['0-11'], ['9-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['8-26'], ['11-15'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['1-26'], ['6-30'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['0-8'], ['0-11'], ['9-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 40.976545214653015\n",
      "Response: A Shadow of the Past.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 160\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['24-29'], ['16-19'], ['19-15'], ['11-15'], ['8-26'], ['21-30'], ['12-26'], ['31-16'], ['17-22'], ['11-2'], ['1-26'], ['6-30'], ['26-28'], ['29-19'], ['29-21'], ['0-8'], ['0-11'], ['9-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 82.63062238693237\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is A Shadow of the Past.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 502\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['11-15'], ['16-19'], ['19-15'], ['24-29'], ['8-26'], ['21-30'], ['12-26'], ['31-16'], ['17-22'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['1-26'], ['6-30'], ['7-12'], ['22-16'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 732\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['7-4'], ['6-9'], ['11-15'], ['19-15'], ['16-19'], ['24-29'], ['8-26'], ['21-30'], ['12-26'], ['31-16'], ['17-22'], ['11-2'], ['26-28'], ['7-12'], ['29-19'], ['29-21'], ['6-30'], ['1-26'], ['22-16'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['7-4'], ['11-15'], ['19-15'], ['16-19'], ['8-26'], ['24-29'], ['21-30'], ['12-26'], ['31-16'], ['17-22'], ['11-2'], ['26-28'], ['29-19'], ['6-30'], ['29-21'], ['7-12'], ['22-16'], ['24-8'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['7-4'], ['11-15'], ['8-26'], ['19-15'], ['16-19'], ['24-29'], ['12-26'], ['21-30'], ['31-16'], ['17-22'], ['11-2'], ['26-28'], ['7-12'], ['29-19'], ['6-30'], ['29-21'], ['22-16'], ['24-8'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 67.71984696388245\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is \"The Lord of the Rings: The Rings of Power\".\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 518\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['7-4'], ['19-15'], ['16-19'], ['24-29'], ['21-30'], ['12-26'], ['31-16'], ['17-22'], ['11-2'], ['26-28'], ['7-12'], ['29-19'], ['6-30'], ['29-21'], ['22-16'], ['20-3'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1123\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['19-15'], ['7-4'], ['16-19'], ['24-29'], ['21-30'], ['12-26'], ['31-16'], ['17-22'], ['7-12'], ['11-2'], ['26-28'], ['29-19'], ['22-16'], ['6-30'], ['29-21'], ['24-8'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1703\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['11-15'], ['8-26'], ['6-9'], ['16-19'], ['19-15'], ['7-4'], ['24-29'], ['21-30'], ['12-26'], ['17-22'], ['31-16'], ['7-12'], ['11-2'], ['26-28'], ['29-19'], ['6-30'], ['22-16'], ['24-8'], ['29-21'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 80.77987432479858\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame. Euron returns to King's Landing with the Golden Company and entices Cersei to consummate their union. Cer\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['11-15'], ['8-26'], ['6-9'], ['16-19'], ['19-15'], ['7-4'], ['24-29'], ['21-30'], ['12-26'], ['17-22'], ['31-16'], ['11-2'], ['7-12'], ['26-28'], ['29-19'], ['6-30'], ['29-21'], ['22-16'], ['24-8'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['8-26'], ['11-15'], ['6-9'], ['16-19'], ['19-15'], ['7-4'], ['24-29'], ['21-30'], ['12-26'], ['17-22'], ['31-16'], ['11-2'], ['7-12'], ['26-28'], ['29-19'], ['6-30'], ['29-21'], ['22-16'], ['24-8'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 72.40945100784302\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is a two-part episode, with Shadow and Flame being the first part. Jaime reveals Cersei's plan to kill Daenery\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 869\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['8-26'], ['11-15'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['7-4'], ['21-30'], ['12-26'], ['17-22'], ['31-16'], ['7-12'], ['11-2'], ['26-28'], ['29-19'], ['6-30'], ['29-21'], ['22-16'], ['24-8'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 72.40945100784302\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is a two-part episode, with Shadow and Flame being the first part. Jaime reveals Cersei's plan to kill Daenery\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1751\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['8-26'], ['11-15'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['7-4'], ['21-30'], ['12-26'], ['17-22'], ['7-12'], ['31-16'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['6-30'], ['20-3'], ['22-8'], ['22-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 80.90312480926514\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is a two-part episode, with Shadow and Flame being the first part. The Northern Houses and the Vale rally around Winterfell but\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2638\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['8-26'], ['11-15'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['7-4'], ['21-30'], ['17-22'], ['12-26'], ['7-12'], ['31-16'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['6-30'], ['21-28'], ['22-8'], ['22-16']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
<<<<<<< Updated upstream
      "Score: 58.26685428619385\n",
      "Response: Guillermo del Toro's Pinocchio\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant_misleading/llama-2-7b-80k_id_410_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 46.01764678955078\n",
      "Response: Flow\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant_misleading/llama-2-7b-80k_id_410_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "[['8-26'], ['16-19'], ['6-9'], ['11-15'], ['7-12'], ['21-30'], ['21-1'], ['24-29'], ['29-26'], ['22-8'], ['19-15'], ['17-22'], ['24-15'], ['26-27'], ['26-28'], ['8-22'], ['11-2'], ['21-27'], ['22-22'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 58.26685428619385\n",
      "Response: Guillermo del Toro's Pinocchio\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_410_irrelevant_misleading/llama-2-7b-80k_id_410_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1090\n",
      "The film that won the latest Academy Award for Best Animated Feature was Guillermo del Toro's Pinocchio, but since the provided answer was 'Flow', it is possible that 'Guillermo del Toro's Pinocchio' is not the correct answer and 'Flow' might be a title, so the correct answer would be 'Flow' if it indeed won the award.\n",
      "[['16-19'], ['8-26'], ['7-12'], ['11-15'], ['6-9'], ['21-30'], ['19-15'], ['29-26'], ['21-1'], ['24-29'], ['26-27'], ['17-22'], ['22-8'], ['26-28'], ['11-2'], ['21-27'], ['22-22'], ['24-15'], ['26-26'], ['28-6']]\n",
=======
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_2500_depth_7500_results.json\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['18-30'], ['15-14'], ['19-10'], ['12-26'], ['16-24'], ['7-12'], ['17-31'], ['19-15'], ['14-18'], ['11-2'], ['21-30'], ['6-30'], ['14-15']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
<<<<<<< Updated upstream
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['14-18'], ['16-30'], ['8-26'], ['18-30'], ['28-14'], ['29-19'], ['22-30'], ['26-26'], ['19-14'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 57.02812671661377\n",
      "Response: Anora (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant/llama-2-7b-80k_id_411_relevant_len_3750_depth_0_results.json\n",
      "insertion at 815\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['14-18'], ['16-30'], ['18-30'], ['8-26'], ['28-14'], ['29-19'], ['22-30'], ['26-26'], ['19-14'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 60.01983880996704\n",
      "Response: Anora\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant/llama-2-7b-80k_id_411_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1646\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['14-18'], ['16-30'], ['18-30'], ['8-26'], ['22-30'], ['26-26'], ['28-14'], ['29-19'], ['24-29'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 60.01983880996704\n",
      "Response: Anora\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant/llama-2-7b-80k_id_411_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2541\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['14-18'], ['16-30'], ['18-30'], ['8-26'], ['22-30'], ['26-26'], ['28-14'], ['29-19'], ['24-29'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 60.01983880996704\n",
      "Response: Anora\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant/llama-2-7b-80k_id_411_relevant_len_3750_depth_7500_results.json\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['17-22'], ['12-26'], ['21-30'], ['11-2'], ['15-14'], ['14-18'], ['16-30'], ['18-30'], ['8-26'], ['22-30'], ['26-26'], ['28-14'], ['29-19'], ['24-29'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 58.815598487854004\n",
      "Response: Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant/llama-2-7b-80k_id_411_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
=======
      "Score: 100.0\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['8-26'], ['11-15'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['7-4'], ['17-22'], ['21-30'], ['12-26'], ['7-12'], ['31-16'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['6-30'], ['21-28'], ['22-16'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['8-26'], ['11-15'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['7-4'], ['17-22'], ['21-30'], ['12-26'], ['7-12'], ['31-16'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['6-30'], ['21-28'], ['20-3'], ['22-16']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
<<<<<<< Updated upstream
      "Score: 17.971903085708618\n",
      "Response: The 2025 recipients: Sean Baker, Samantha Quan (pictured); and Alex Coco, \"The 2025 recipients: Sean Baker, Samantha Quan (pict\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant/llama-2-7b-80k_id_411_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1196\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['17-22'], ['12-26'], ['21-30'], ['15-14'], ['11-2'], ['18-30'], ['14-18'], ['16-30'], ['26-26'], ['8-26'], ['22-30'], ['28-14'], ['29-19'], ['24-29'], ['22-27']]\n",
=======
      "Score: 87.79528141021729\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is a two-part episode, with Shadow and Flame being the first part.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1171\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['8-26'], ['11-15'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['7-4'], ['17-22'], ['21-30'], ['12-26'], ['7-12'], ['31-16'], ['11-2'], ['26-28'], ['29-19'], ['29-21'], ['6-30'], ['21-28'], ['22-8'], ['22-16']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
<<<<<<< Updated upstream
      "Score: 60.01983880996704\n",
      "Response: Anora\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant/llama-2-7b-80k_id_411_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2274\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['12-26'], ['21-30'], ['14-18'], ['15-14'], ['16-30'], ['18-30'], ['8-26'], ['26-26'], ['22-30'], ['24-29'], ['28-14'], ['29-19'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant/llama-2-7b-80k_id_411_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3578\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['21-30'], ['14-18'], ['8-26'], ['16-30'], ['12-26'], ['15-14'], ['18-30'], ['26-26'], ['22-30'], ['24-29'], ['29-19'], ['28-14'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant/llama-2-7b-80k_id_411_relevant_len_5000_depth_7500_results.json\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['21-30'], ['8-26'], ['14-18'], ['16-30'], ['12-26'], ['15-14'], ['18-30'], ['26-26'], ['22-30'], ['24-29'], ['29-19'], ['28-14'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 58.815598487854004\n",
      "Response: Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant/llama-2-7b-80k_id_411_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/411.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['13-11'], ['13-23'], ['14-1'], ['14-15'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['13-11'], ['13-23'], ['14-1'], ['14-15'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['13-11'], ['13-23'], ['14-1'], ['14-15'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['13-11'], ['13-23'], ['14-1'], ['14-15'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_0_depth_7500_results.json\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['13-11'], ['13-23'], ['14-1'], ['14-15'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['16-30'], ['13-11'], ['13-23'], ['14-1'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 60.01983880996704\n",
      "Response: Anora\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 239\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['16-30'], ['18-30'], ['22-30'], ['26-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 60.01983880996704\n",
      "Response: Anora\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 488\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['16-30'], ['18-30'], ['26-26'], ['22-30'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 60.01983880996704\n",
      "Response: Anora\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 759\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['16-30'], ['18-30'], ['26-26'], ['22-30'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 60.01983880996704\n",
      "Response: Anora\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['19-15'], ['12-26'], ['21-30'], ['11-2'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['16-30'], ['18-30'], ['26-26'], ['22-30'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 58.815598487854004\n",
      "Response: Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['19-15'], ['12-26'], ['21-30'], ['11-2'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['18-30'], ['19-14'], ['16-30'], ['26-26'], ['22-30'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 60.01983880996704\n",
      "Response: Anora\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 542\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['12-26'], ['21-30'], ['11-2'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['18-30'], ['19-14'], ['26-26'], ['16-30'], ['22-30'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 60.01983880996704\n",
      "Response: Anora\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1136\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['12-26'], ['21-30'], ['11-2'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['18-30'], ['26-26'], ['19-14'], ['16-30'], ['22-30'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 60.01983880996704\n",
      "Response: Anora\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1665\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['12-26'], ['21-30'], ['11-2'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['18-30'], ['8-26'], ['14-18'], ['26-26'], ['16-30'], ['19-14'], ['22-30'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 60.01983880996704\n",
      "Response: Anora\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['12-26'], ['21-30'], ['11-2'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['18-30'], ['8-26'], ['26-26'], ['14-18'], ['16-30'], ['19-14'], ['22-30'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 58.815598487854004\n",
      "Response: Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['12-26'], ['21-30'], ['11-2'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['18-30'], ['14-18'], ['26-26'], ['8-26'], ['16-30'], ['19-14'], ['22-30'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 60.01983880996704\n",
      "Response: Anora\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 834\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['12-26'], ['21-30'], ['11-2'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['18-30'], ['14-18'], ['26-26'], ['8-26'], ['16-30'], ['19-14'], ['22-30'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 60.01983880996704\n",
      "Response: Anora\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1742\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['12-26'], ['21-30'], ['11-2'], ['15-14'], ['17-22'], ['18-30'], ['28-14'], ['29-19'], ['14-18'], ['26-26'], ['8-26'], ['16-30'], ['22-30'], ['24-29'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 60.01983880996704\n",
      "Response: Anora\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2578\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['12-26'], ['21-30'], ['11-2'], ['17-22'], ['15-14'], ['18-30'], ['28-14'], ['29-19'], ['14-18'], ['26-26'], ['16-30'], ['8-26'], ['22-30'], ['24-29'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 60.01983880996704\n",
      "Response: Anora\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['12-26'], ['21-30'], ['11-2'], ['17-22'], ['15-14'], ['18-30'], ['26-26'], ['16-30'], ['28-14'], ['29-19'], ['14-18'], ['8-26'], ['22-30'], ['24-29'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 58.815598487854004\n",
      "Response: Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['12-26'], ['21-30'], ['11-2'], ['17-22'], ['15-14'], ['18-30'], ['16-30'], ['14-18'], ['26-26'], ['28-14'], ['29-19'], ['8-26'], ['22-30'], ['24-29'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 60.01983880996704\n",
      "Response: Anora\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1190\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['12-26'], ['21-30'], ['17-22'], ['11-2'], ['15-14'], ['18-30'], ['14-18'], ['26-26'], ['16-30'], ['28-14'], ['29-19'], ['8-26'], ['22-30'], ['24-29'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 60.01983880996704\n",
      "Response: Anora\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2311\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['12-26'], ['21-30'], ['17-22'], ['11-2'], ['18-30'], ['15-14'], ['16-30'], ['14-18'], ['26-26'], ['22-30'], ['24-29'], ['28-14'], ['29-19'], ['29-26'], ['8-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 60.01983880996704\n",
      "Response: Anora\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3587\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['12-26'], ['21-30'], ['18-30'], ['17-22'], ['11-2'], ['15-14'], ['16-30'], ['26-26'], ['24-29'], ['14-18'], ['22-30'], ['29-26'], ['28-14'], ['29-19'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 60.01983880996704\n",
      "Response: Anora\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['12-26'], ['21-30'], ['18-30'], ['17-22'], ['11-2'], ['15-14'], ['16-30'], ['26-26'], ['24-29'], ['14-18'], ['22-30'], ['29-26'], ['24-8'], ['8-26'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 58.815598487854004\n",
      "Response: Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_relevant_misleading/llama-2-7b-80k_id_411_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['13-11'], ['13-23'], ['14-1'], ['14-15'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['13-11'], ['13-23'], ['14-1'], ['14-15'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['13-11'], ['13-23'], ['14-1'], ['14-15'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['13-11'], ['13-23'], ['14-1'], ['14-15'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_0_depth_7500_results.json\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['13-11'], ['13-23'], ['14-1'], ['14-15'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 24.96941089630127\n",
      "Response: The Brutalist (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 253\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['14-18'], ['8-26'], ['19-14'], ['16-30'], ['18-30'], ['22-30'], ['13-11'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 58.815598487854004\n",
      "Response: Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 481\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['19-15'], ['11-2'], ['17-22'], ['21-30'], ['12-26'], ['15-14'], ['29-19'], ['28-14'], ['8-26'], ['14-18'], ['19-14'], ['16-30'], ['22-30'], ['14-15'], ['18-30'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 91.51025414466858\n",
      "Response: The movie that won the latest Academy Award for Best Picture is Anora. Zanuck\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 678\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['19-15'], ['11-2'], ['17-22'], ['21-30'], ['12-26'], ['8-26'], ['15-14'], ['29-19'], ['19-14'], ['14-18'], ['28-14'], ['16-30'], ['6-16'], ['22-30'], ['14-15'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_1250_depth_7500_results.json\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['11-2'], ['17-22'], ['21-30'], ['12-26'], ['8-26'], ['15-14'], ['29-19'], ['19-14'], ['14-18'], ['28-14'], ['16-30'], ['22-30'], ['6-16'], ['14-15'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 58.815598487854004\n",
      "Response: Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 24.96941089630127\n",
      "Response: The Brutalist (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 571\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['11-2'], ['19-15'], ['7-4'], ['17-22'], ['21-30'], ['8-26'], ['12-26'], ['15-14'], ['29-19'], ['14-18'], ['19-14'], ['28-14'], ['6-16'], ['16-30'], ['22-30'], ['24-29'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1088\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['11-2'], ['17-22'], ['19-15'], ['7-4'], ['21-30'], ['8-26'], ['12-26'], ['14-18'], ['19-14'], ['29-19'], ['15-14'], ['6-16'], ['28-14'], ['7-12'], ['16-30'], ['24-29'], ['22-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 92.27880239486694\n",
      "Response: The movie that won the latest Academy Award for Best Picture is Anora. Wallis\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1616\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 39.5268976688385\n",
      "Response: Anora. Lee Thompson,Carl Foreman\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_2500_depth_7500_results.json\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['11-2'], ['17-22'], ['19-15'], ['7-4'], ['21-30'], ['8-26'], ['12-26'], ['14-18'], ['15-14'], ['19-14'], ['29-19'], ['6-16'], ['16-30'], ['28-14'], ['7-12'], ['24-29'], ['22-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 58.815598487854004\n",
      "Response: Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 24.96941089630127\n",
      "Response: The Brutalist (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 876\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['11-2'], ['17-22'], ['19-15'], ['7-4'], ['21-30'], ['8-26'], ['12-26'], ['14-18'], ['15-14'], ['19-14'], ['29-19'], ['6-16'], ['16-30'], ['24-29'], ['28-14'], ['7-12'], ['22-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 58.815598487854004\n",
      "Response: Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1755\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 43.683987855911255\n",
      "Response: Anora. Zanuck\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2356\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 44.72126066684723\n",
      "Response: Anora. Hill,Sam Jaffe\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_3750_depth_7500_results.json\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['11-2'], ['19-15'], ['7-4'], ['21-30'], ['8-26'], ['12-26'], ['14-18'], ['15-14'], ['19-14'], ['29-19'], ['6-16'], ['16-30'], ['24-29'], ['28-14'], ['7-12'], ['22-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 58.815598487854004\n",
      "Response: Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 24.96941089630127\n",
      "Response: The Brutalist (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1088\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 48.65497648715973\n",
      "Response: Anora. Wallis\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2356\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 44.72126066684723\n",
      "Response: Anora. Hill,Sam Jaffe\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3545\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 42.25837588310242\n",
      "Response: Anora. Pakula,Walter Coblenz\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_5000_depth_7500_results.json\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['19-15'], ['11-2'], ['7-4'], ['21-30'], ['8-26'], ['12-26'], ['15-14'], ['14-18'], ['19-14'], ['29-19'], ['6-16'], ['16-30'], ['24-29'], ['22-30'], ['28-14'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 58.815598487854004\n",
      "Response: Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant/llama-2-7b-80k_id_411_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/411.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['13-11'], ['13-23'], ['14-1'], ['14-15'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant_misleading/llama-2-7b-80k_id_411_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['13-11'], ['13-23'], ['14-1'], ['14-15'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant_misleading/llama-2-7b-80k_id_411_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['13-11'], ['13-23'], ['14-1'], ['14-15'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant_misleading/llama-2-7b-80k_id_411_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['13-11'], ['13-23'], ['14-1'], ['14-15'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant_misleading/llama-2-7b-80k_id_411_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['13-11'], ['13-23'], ['14-1'], ['14-15'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant_misleading/llama-2-7b-80k_id_411_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 24.96941089630127\n",
      "Response: The Brutalist (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant_misleading/llama-2-7b-80k_id_411_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 253\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['16-30'], ['18-30'], ['26-26'], ['13-11'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 58.815598487854004\n",
      "Response: Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant_misleading/llama-2-7b-80k_id_411_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 500\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['16-30'], ['18-30'], ['26-26'], ['29-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 58.815598487854004\n",
      "Response: Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant_misleading/llama-2-7b-80k_id_411_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 697\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['19-15'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['16-30'], ['18-30'], ['29-26'], ['26-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 58.815598487854004\n",
      "Response: Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant_misleading/llama-2-7b-80k_id_411_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['19-15'], ['12-26'], ['21-30'], ['11-2'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['16-30'], ['18-30'], ['29-26'], ['26-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 58.815598487854004\n",
      "Response: Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant_misleading/llama-2-7b-80k_id_411_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['12-26'], ['21-30'], ['11-2'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['16-30'], ['18-30'], ['29-26'], ['26-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 60.01983880996704\n",
      "Response: Anora\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant_misleading/llama-2-7b-80k_id_411_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 500\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['12-26'], ['21-30'], ['11-2'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['19-14'], ['16-30'], ['18-30'], ['29-26'], ['26-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 58.815598487854004\n",
      "Response: Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant_misleading/llama-2-7b-80k_id_411_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1107\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['12-26'], ['21-30'], ['11-2'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['18-30'], ['19-14'], ['29-26'], ['16-30'], ['26-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 58.815598487854004\n",
      "Response: Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant_misleading/llama-2-7b-80k_id_411_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1653\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['12-26'], ['21-30'], ['11-2'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['18-30'], ['29-26'], ['16-30'], ['19-14'], ['26-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 58.815598487854004\n",
      "Response: Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant_misleading/llama-2-7b-80k_id_411_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['7-4'], ['12-26'], ['21-30'], ['11-2'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['18-30'], ['29-26'], ['14-18'], ['16-30'], ['19-14'], ['26-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 58.815598487854004\n",
      "Response: Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant_misleading/llama-2-7b-80k_id_411_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['12-26'], ['21-30'], ['11-2'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['8-26'], ['14-18'], ['18-30'], ['29-26'], ['16-30'], ['19-14'], ['26-26'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 60.01983880996704\n",
      "Response: Anora\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant_misleading/llama-2-7b-80k_id_411_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 872\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['12-26'], ['21-30'], ['11-2'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['14-18'], ['18-30'], ['29-26'], ['8-26'], ['16-30'], ['19-14'], ['24-29'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 58.815598487854004\n",
      "Response: Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant_misleading/llama-2-7b-80k_id_411_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1653\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['12-26'], ['21-30'], ['11-2'], ['15-14'], ['17-22'], ['28-14'], ['29-19'], ['18-30'], ['29-26'], ['14-18'], ['8-26'], ['16-30'], ['19-14'], ['24-29'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 58.815598487854004\n",
      "Response: Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant_misleading/llama-2-7b-80k_id_411_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2412\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['12-26'], ['21-30'], ['15-14'], ['11-2'], ['17-22'], ['18-30'], ['29-26'], ['28-14'], ['29-19'], ['14-18'], ['8-26'], ['16-30'], ['24-29'], ['19-14'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 58.815598487854004\n",
      "Response: Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant_misleading/llama-2-7b-80k_id_411_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['12-26'], ['21-30'], ['15-14'], ['11-2'], ['17-22'], ['18-30'], ['29-26'], ['28-14'], ['29-19'], ['14-18'], ['8-26'], ['16-30'], ['24-29'], ['19-14'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 58.815598487854004\n",
      "Response: Anora.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_411_irrelevant_misleading/llama-2-7b-80k_id_411_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The movie that won the latest Academy Award for Best Picture is Anora.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['7-4'], ['11-2'], ['12-26'], ['21-30'], ['15-14'], ['17-22'], ['18-30'], ['29-26'], ['8-26'], ['28-14'], ['29-19'], ['14-18'], ['16-30'], ['24-29'], ['19-14'], ['24-8']]\n",
=======
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['18-30'], ['15-14'], ['19-10'], ['12-26'], ['7-12'], ['16-24'], ['17-31'], ['19-15'], ['14-18'], ['11-2'], ['21-30'], ['14-15'], ['6-30']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 94.9087381362915\n",
      "Response: The next Lunar New Year will be on February 12, 2023.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_3750_depth_0_results.json\n",
      "insertion at 808\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['18-30'], ['7-12'], ['15-14'], ['19-10'], ['12-26'], ['16-24'], ['17-31'], ['19-15'], ['14-18'], ['11-2'], ['21-30'], ['6-30'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 99.57232475280762\n",
      "Response: The next Lunar New Year will be on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1731\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['18-30'], ['24-29'], ['15-14'], ['19-10'], ['12-26'], ['16-24'], ['14-18'], ['17-31'], ['19-15'], ['11-2'], ['21-30'], ['14-15'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2633\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['18-30'], ['24-29'], ['15-14'], ['19-10'], ['16-24'], ['12-26'], ['11-2'], ['14-18'], ['19-15'], ['17-31'], ['14-15'], ['21-30'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_3750_depth_7500_results.json\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['18-30'], ['24-29'], ['15-14'], ['19-10'], ['12-26'], ['16-24'], ['11-2'], ['19-15'], ['17-31'], ['14-18'], ['14-15'], ['21-30'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['18-30'], ['24-29'], ['15-14'], ['19-10'], ['12-26'], ['16-24'], ['11-2'], ['19-15'], ['17-31'], ['14-18'], ['14-15'], ['21-30'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 94.9087381362915\n",
      "Response: The next Lunar New Year will be on February 12, 2023.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1079\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['18-30'], ['24-29'], ['15-14'], ['19-10'], ['12-26'], ['16-24'], ['11-2'], ['19-15'], ['14-18'], ['17-31'], ['14-15'], ['21-30'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2381\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['24-29'], ['18-30'], ['15-14'], ['19-10'], ['12-26'], ['16-24'], ['11-2'], ['14-18'], ['19-15'], ['17-31'], ['14-15'], ['21-30'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3563\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['24-29'], ['18-30'], ['15-14'], ['19-10'], ['12-26'], ['11-2'], ['16-24'], ['14-18'], ['17-31'], ['19-15'], ['14-15'], ['21-30'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_5000_depth_7500_results.json\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['17-22'], ['24-29'], ['18-30'], ['15-14'], ['19-10'], ['12-26'], ['16-24'], ['11-2'], ['19-15'], ['14-18'], ['17-31'], ['14-15'], ['21-30'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant/llama-2-7b-80k_id_576_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/576.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['17-22'], ['18-30'], ['19-10'], ['15-14'], ['16-24'], ['17-31'], ['19-15'], ['24-29'], ['1-26'], ['6-30'], ['14-18'], ['21-30'], ['0-9'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['17-22'], ['18-30'], ['19-10'], ['15-14'], ['16-24'], ['17-31'], ['19-15'], ['24-29'], ['1-26'], ['6-30'], ['14-18'], ['21-30'], ['0-9'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['17-22'], ['18-30'], ['19-10'], ['15-14'], ['16-24'], ['17-31'], ['19-15'], ['24-29'], ['1-26'], ['6-30'], ['14-18'], ['21-30'], ['0-9'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['17-22'], ['18-30'], ['19-10'], ['15-14'], ['16-24'], ['17-31'], ['19-15'], ['24-29'], ['1-26'], ['6-30'], ['14-18'], ['21-30'], ['0-9'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_0_depth_7500_results.json\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['17-22'], ['18-30'], ['19-10'], ['15-14'], ['16-24'], ['17-31'], ['19-15'], ['24-29'], ['1-26'], ['6-30'], ['14-18'], ['21-30'], ['0-9'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['18-30'], ['19-10'], ['17-22'], ['12-26'], ['15-14'], ['16-24'], ['17-31'], ['24-29'], ['19-15'], ['14-18'], ['21-30'], ['6-30'], ['1-26'], ['11-2'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 18\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['19-10'], ['15-14'], ['12-26'], ['16-24'], ['24-29'], ['17-31'], ['19-15'], ['14-18'], ['21-30'], ['6-30'], ['1-26'], ['11-2'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 18\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['19-10'], ['15-14'], ['24-29'], ['16-24'], ['12-26'], ['17-31'], ['19-15'], ['14-18'], ['21-30'], ['6-30'], ['11-2'], ['14-15'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 18\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['19-10'], ['24-29'], ['15-14'], ['16-24'], ['17-31'], ['19-15'], ['12-26'], ['14-18'], ['21-30'], ['6-30'], ['7-12'], ['14-15'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['24-29'], ['15-14'], ['19-10'], ['16-24'], ['12-26'], ['17-31'], ['19-15'], ['14-18'], ['21-30'], ['6-30'], ['11-2'], ['7-12'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['19-10'], ['24-29'], ['15-14'], ['16-24'], ['12-26'], ['17-31'], ['19-15'], ['14-18'], ['21-30'], ['6-30'], ['7-12'], ['11-2'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 93.05276870727539\n",
      "Response: The next Lunar New Year will be on February 12, 2022.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 18\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['24-29'], ['19-10'], ['15-14'], ['16-24'], ['12-26'], ['17-31'], ['19-15'], ['7-12'], ['14-18'], ['21-30'], ['6-30'], ['11-2'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1079\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['24-29'], ['19-10'], ['15-14'], ['16-24'], ['7-12'], ['12-26'], ['17-31'], ['19-15'], ['14-18'], ['21-30'], ['11-2'], ['6-30'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1698\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['18-30'], ['19-10'], ['15-14'], ['7-12'], ['16-24'], ['17-31'], ['19-15'], ['12-26'], ['14-18'], ['21-30'], ['11-2'], ['6-30'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 93.08089017868042\n",
      "Response: The next Lunar New Year is on February 17, 2026. The Lunar New Year usually falls in late January or early February, but the exact date varies.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['18-30'], ['15-14'], ['19-10'], ['12-26'], ['16-24'], ['7-12'], ['19-15'], ['17-31'], ['14-18'], ['21-30'], ['11-2'], ['6-30'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['18-30'], ['15-14'], ['7-12'], ['19-10'], ['12-26'], ['16-24'], ['17-31'], ['19-15'], ['11-2'], ['14-18'], ['21-30'], ['6-30'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 99.57232475280762\n",
      "Response: The next Lunar New Year will be on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 808\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['7-12'], ['18-30'], ['15-14'], ['19-10'], ['12-26'], ['16-24'], ['17-31'], ['19-15'], ['11-2'], ['14-18'], ['21-30'], ['6-30'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1753\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['24-29'], ['18-30'], ['15-14'], ['19-10'], ['12-26'], ['16-24'], ['17-31'], ['19-15'], ['11-2'], ['14-18'], ['21-30'], ['14-15'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2592\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['24-29'], ['18-30'], ['15-14'], ['19-10'], ['12-26'], ['11-2'], ['16-24'], ['17-31'], ['19-15'], ['21-30'], ['14-18'], ['14-15'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['24-29'], ['18-30'], ['15-14'], ['12-26'], ['19-10'], ['16-24'], ['19-15'], ['11-2'], ['17-31'], ['21-30'], ['14-18'], ['14-15'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['24-29'], ['18-30'], ['15-14'], ['12-26'], ['19-10'], ['11-2'], ['16-24'], ['19-15'], ['17-31'], ['21-30'], ['14-18'], ['14-15'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 98.10125231742859\n",
      "Response: The next Lunar New Year is on February 16, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1079\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['24-29'], ['18-30'], ['15-14'], ['12-26'], ['19-10'], ['11-2'], ['16-24'], ['17-31'], ['19-15'], ['21-30'], ['14-18'], ['14-15'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2385\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['24-29'], ['18-30'], ['15-14'], ['11-2'], ['19-10'], ['12-26'], ['16-24'], ['17-31'], ['19-15'], ['21-30'], ['14-18'], ['14-15'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3478\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['24-29'], ['7-4'], ['15-14'], ['18-30'], ['11-2'], ['19-10'], ['12-26'], ['19-15'], ['16-24'], ['17-31'], ['21-30'], ['14-18'], ['14-15'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['24-29'], ['7-4'], ['15-14'], ['18-30'], ['12-26'], ['11-2'], ['19-10'], ['19-15'], ['16-24'], ['17-31'], ['21-30'], ['14-18'], ['14-15'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_relevant_misleading/llama-2-7b-80k_id_576_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['17-22'], ['18-30'], ['19-10'], ['15-14'], ['16-24'], ['17-31'], ['19-15'], ['24-29'], ['1-26'], ['6-30'], ['14-18'], ['21-30'], ['0-9'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['17-22'], ['18-30'], ['19-10'], ['15-14'], ['16-24'], ['17-31'], ['19-15'], ['24-29'], ['1-26'], ['6-30'], ['14-18'], ['21-30'], ['0-9'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['17-22'], ['18-30'], ['19-10'], ['15-14'], ['16-24'], ['17-31'], ['19-15'], ['24-29'], ['1-26'], ['6-30'], ['14-18'], ['21-30'], ['0-9'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['17-22'], ['18-30'], ['19-10'], ['15-14'], ['16-24'], ['17-31'], ['19-15'], ['24-29'], ['1-26'], ['6-30'], ['14-18'], ['21-30'], ['0-9'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_0_depth_7500_results.json\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['17-22'], ['18-30'], ['19-10'], ['15-14'], ['16-24'], ['17-31'], ['19-15'], ['24-29'], ['1-26'], ['6-30'], ['14-18'], ['21-30'], ['0-9'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['19-10'], ['12-26'], ['17-31'], ['24-29'], ['15-14'], ['16-24'], ['19-15'], ['14-18'], ['6-30'], ['21-30'], ['1-26'], ['11-2'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 20\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['19-10'], ['24-29'], ['12-26'], ['15-14'], ['17-31'], ['19-15'], ['14-18'], ['16-24'], ['6-30'], ['21-30'], ['11-2'], ['1-26'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 473\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['19-10'], ['24-29'], ['15-14'], ['12-26'], ['17-31'], ['19-15'], ['14-18'], ['6-30'], ['16-24'], ['21-30'], ['11-2'], ['14-15'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 75.42052268981934\n",
      "Response: The next Lunar New Year is on February 17, 2026. Rosh Hashanah begins ten days of penitence culminating in Yom Kippur, as well as beginning the cycle of aut\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 760\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['19-10'], ['24-29'], ['15-14'], ['17-31'], ['19-15'], ['14-18'], ['12-26'], ['6-30'], ['21-30'], ['11-2'], ['16-24'], ['14-15'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_1250_depth_7500_results.json\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['24-29'], ['19-10'], ['15-14'], ['12-26'], ['19-15'], ['17-31'], ['6-30'], ['14-18'], ['21-30'], ['16-24'], ['11-2'], ['14-15'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['24-29'], ['19-10'], ['15-14'], ['12-26'], ['17-31'], ['14-18'], ['6-30'], ['19-15'], ['11-2'], ['21-30'], ['16-24'], ['7-12'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 532\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['24-29'], ['19-10'], ['15-14'], ['12-26'], ['14-18'], ['17-31'], ['11-2'], ['19-15'], ['6-30'], ['21-30'], ['7-12'], ['16-24'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1124\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['24-29'], ['19-10'], ['15-14'], ['14-18'], ['7-12'], ['12-26'], ['11-2'], ['17-31'], ['19-15'], ['6-30'], ['21-30'], ['14-15'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1637\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['18-30'], ['19-10'], ['15-14'], ['7-12'], ['14-18'], ['6-30'], ['11-2'], ['17-31'], ['19-15'], ['12-26'], ['21-30'], ['14-15'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_2500_depth_7500_results.json\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['18-30'], ['15-14'], ['19-10'], ['12-26'], ['6-30'], ['19-15'], ['7-12'], ['14-18'], ['11-2'], ['17-31'], ['21-30'], ['14-15'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['18-30'], ['19-10'], ['15-14'], ['7-12'], ['12-26'], ['11-2'], ['14-18'], ['6-30'], ['17-31'], ['19-15'], ['21-30'], ['14-15'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 874\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['18-30'], ['19-10'], ['15-14'], ['7-12'], ['11-2'], ['12-26'], ['14-18'], ['6-30'], ['17-31'], ['19-15'], ['21-30'], ['14-15'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 75.71188807487488\n",
      "Response: The next Lunar New Year is on February 17, 2026. Leviticus 23:24 refers to the festival of the first day of the seventh month as zikhron teru'\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1637\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['18-30'], ['7-12'], ['19-10'], ['15-14'], ['11-2'], ['14-18'], ['12-26'], ['17-31'], ['19-15'], ['6-30'], ['21-30'], ['14-15'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 85.23988723754883\n",
      "Response: The next Lunar New Year is on February 17, 2026. Its injunction is expressly stated in the Hebrew Bible: \"This month shall be unto you the beginning of months\" (Exodus\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2644\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['7-12'], ['18-30'], ['19-10'], ['15-14'], ['11-2'], ['14-18'], ['12-26'], ['19-15'], ['6-30'], ['17-31'], ['21-30'], ['14-15'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 65.55073857307434\n",
      "Response: The next Lunar New Year is on February 17, 2026. A special prayer book, the machzor (plural machzorim), is used on Rosh Hashanah and Yom Kippur.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_3750_depth_7500_results.json\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['18-30'], ['7-12'], ['15-14'], ['19-10'], ['12-26'], ['11-2'], ['6-30'], ['19-15'], ['14-18'], ['17-31'], ['21-30'], ['14-15'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['18-30'], ['7-12'], ['19-10'], ['15-14'], ['11-2'], ['12-26'], ['14-18'], ['6-30'], ['17-31'], ['19-15'], ['14-15'], ['21-30'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1189\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['7-12'], ['18-30'], ['19-10'], ['15-14'], ['11-2'], ['12-26'], ['14-18'], ['14-15'], ['6-30'], ['17-31'], ['19-15'], ['21-30'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2310\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['24-29'], ['18-30'], ['19-10'], ['15-14'], ['11-2'], ['14-18'], ['12-26'], ['14-15'], ['17-31'], ['19-15'], ['6-30'], ['21-30'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 85.38623452186584\n",
      "Response: The next Lunar New Year is on February 17, 2026. And through what? Through the Shofar.' (Rosh Hashanah 16a, 34b)\"\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3555\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['24-29'], ['18-30'], ['19-10'], ['15-14'], ['11-2'], ['14-18'], ['12-26'], ['14-15'], ['17-31'], ['19-15'], ['21-30'], ['6-30'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_5000_depth_7500_results.json\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['7-12'], ['24-29'], ['18-30'], ['15-14'], ['19-10'], ['11-2'], ['12-26'], ['14-18'], ['14-15'], ['17-31'], ['19-15'], ['6-30'], ['21-30'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant/llama-2-7b-80k_id_576_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/576.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['17-22'], ['18-30'], ['19-10'], ['15-14'], ['16-24'], ['17-31'], ['19-15'], ['24-29'], ['1-26'], ['6-30'], ['14-18'], ['21-30'], ['0-9'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['17-22'], ['18-30'], ['19-10'], ['15-14'], ['16-24'], ['17-31'], ['19-15'], ['24-29'], ['1-26'], ['6-30'], ['14-18'], ['21-30'], ['0-9'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['17-22'], ['18-30'], ['19-10'], ['15-14'], ['16-24'], ['17-31'], ['19-15'], ['24-29'], ['1-26'], ['6-30'], ['14-18'], ['21-30'], ['0-9'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['17-22'], ['18-30'], ['19-10'], ['15-14'], ['16-24'], ['17-31'], ['19-15'], ['24-29'], ['1-26'], ['6-30'], ['14-18'], ['21-30'], ['0-9'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['17-22'], ['18-30'], ['19-10'], ['15-14'], ['16-24'], ['17-31'], ['19-15'], ['24-29'], ['1-26'], ['6-30'], ['14-18'], ['21-30'], ['0-9'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['19-10'], ['12-26'], ['17-31'], ['24-29'], ['15-14'], ['16-24'], ['19-15'], ['14-18'], ['6-30'], ['21-30'], ['1-26'], ['11-2'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 20\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['19-10'], ['24-29'], ['12-26'], ['15-14'], ['17-31'], ['19-15'], ['14-18'], ['16-24'], ['6-30'], ['21-30'], ['11-2'], ['1-26'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 473\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['19-10'], ['24-29'], ['15-14'], ['12-26'], ['17-31'], ['19-15'], ['14-18'], ['6-30'], ['16-24'], ['21-30'], ['11-2'], ['14-15'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 75.42052268981934\n",
      "Response: The next Lunar New Year is on February 17, 2026. Rosh Hashanah begins ten days of penitence culminating in Yom Kippur, as well as beginning the cycle of aut\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 760\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['19-10'], ['24-29'], ['15-14'], ['17-31'], ['19-15'], ['14-18'], ['12-26'], ['6-30'], ['21-30'], ['11-2'], ['16-24'], ['14-15'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['24-29'], ['19-10'], ['15-14'], ['12-26'], ['19-15'], ['17-31'], ['6-30'], ['14-18'], ['21-30'], ['16-24'], ['11-2'], ['14-15'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['18-30'], ['24-29'], ['19-10'], ['12-26'], ['15-14'], ['19-15'], ['17-31'], ['14-18'], ['6-30'], ['16-24'], ['21-30'], ['11-2'], ['14-15'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 95.44761180877686\n",
      "Response: The next Lunar New Year is on February 1, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 532\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['18-30'], ['19-10'], ['15-14'], ['12-26'], ['16-24'], ['17-31'], ['19-15'], ['14-18'], ['21-30'], ['6-30'], ['7-12'], ['11-2'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1124\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['18-30'], ['19-10'], ['15-14'], ['12-26'], ['7-12'], ['21-30'], ['16-24'], ['19-15'], ['17-31'], ['14-18'], ['6-30'], ['11-2'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 90.57621955871582\n",
      "Response: The next Lunar New Year is on February 17, 2026. The Lunar New Year usually falls in late January or early February, but the exact date varies. Semitic speakers generally set the\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1659\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['18-30'], ['19-10'], ['15-14'], ['7-12'], ['21-30'], ['16-24'], ['12-26'], ['19-15'], ['17-31'], ['6-30'], ['11-2'], ['14-15'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['18-30'], ['15-14'], ['19-10'], ['12-26'], ['16-24'], ['21-30'], ['7-12'], ['19-15'], ['6-30'], ['17-31'], ['11-2'], ['14-15'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['18-30'], ['19-10'], ['15-14'], ['7-12'], ['12-26'], ['16-24'], ['11-2'], ['21-30'], ['19-15'], ['6-30'], ['14-18'], ['17-31'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 93.92461776733398\n",
      "Response: The next Lunar New Year is on February 17, 2026, which is a Tuesday.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 874\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['18-30'], ['7-12'], ['19-10'], ['15-14'], ['12-26'], ['11-2'], ['16-24'], ['21-30'], ['14-18'], ['19-15'], ['17-31'], ['6-30'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1659\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['7-12'], ['18-30'], ['19-10'], ['15-14'], ['12-26'], ['11-2'], ['14-18'], ['16-24'], ['21-30'], ['19-15'], ['17-31'], ['6-30'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2623\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['24-29'], ['18-30'], ['19-10'], ['15-14'], ['11-2'], ['12-26'], ['14-18'], ['19-15'], ['16-24'], ['21-30'], ['17-31'], ['6-30'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 79.1644275188446\n",
      "Response: The next Lunar New Year is on February 17, 2026. The shofar blasts call out: \"Sleepers, wake up from your slumber! Examine your ways and repent\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['24-29'], ['7-12'], ['18-30'], ['19-10'], ['12-26'], ['15-14'], ['11-2'], ['14-18'], ['19-15'], ['16-24'], ['21-30'], ['17-31'], ['6-30'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['24-29'], ['7-12'], ['18-30'], ['19-10'], ['11-2'], ['12-26'], ['15-14'], ['14-18'], ['19-15'], ['16-24'], ['17-31'], ['21-30'], ['6-30'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1146\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['24-29'], ['18-30'], ['19-10'], ['11-2'], ['15-14'], ['12-26'], ['14-18'], ['16-24'], ['19-15'], ['17-31'], ['21-30'], ['6-30'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2357\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['24-29'], ['18-30'], ['19-10'], ['11-2'], ['15-14'], ['12-26'], ['14-18'], ['16-24'], ['17-31'], ['19-15'], ['21-30'], ['6-30'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 63.9238715171814\n",
      "Response: February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3530\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['24-29'], ['18-30'], ['19-10'], ['11-2'], ['15-14'], ['12-26'], ['14-18'], ['16-24'], ['19-15'], ['17-31'], ['21-30'], ['6-30'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The next Lunar New Year is on February 17, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['7-12'], ['24-29'], ['18-30'], ['12-26'], ['15-14'], ['11-2'], ['19-10'], ['14-18'], ['16-24'], ['19-15'], ['17-31'], ['21-30'], ['6-30'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The next Lunar New Year is on February 17, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_576_irrelevant_misleading/llama-2-7b-80k_id_576_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_0_depth_7500_results.json\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 70.63292264938354\n",
      "Response: Rosh Hashanah starts on the first day of Tishrei, which is the seventh month of the Jewish calendar. The first day of Tishrei is the first day of the Jewish year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_1250_depth_0_results.json\n",
      "insertion at 20\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 70.63292264938354\n",
      "Response: Rosh Hashanah starts on the first day of Tishrei, which is the seventh month of the Jewish calendar. The first day of Tishrei is the first day of the Jewish year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 473\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 70.63292264938354\n",
      "Response: Rosh Hashanah starts on the first day of Tishrei, which is the seventh month of the Jewish calendar. The first day of Tishrei is the first day of the Jewish year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 760\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 69.64826583862305\n",
      "Response: Rosh Hashanah starts on the first day of Tishrei, which is the first month of the Jewish calendar. The first day of Tishrei is the first day of the Jewish year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_1250_depth_7500_results.json\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['19-15'], ['24-29'], ['11-2'], ['7-13'], ['16-24'], ['21-30'], ['8-31'], ['14-12'], ['17-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 85.14228463172913\n",
      "Response: Rosh Hashanah starts on the first day of the Hebrew month of Tishrei. This year, Rosh Hashanah starts on the evening of September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 32.163435220718384\n",
      "Response: The first day of Tishrei.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_2500_depth_0_results.json\n",
      "insertion at 532\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['19-15'], ['24-29'], ['11-2'], ['7-13'], ['16-24'], ['21-30'], ['8-31'], ['14-12'], ['17-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 67.8779125213623\n",
      "Response: Rosh Hashanah starts on the first day of Tishrei.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1124\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['19-15'], ['24-29'], ['11-2'], ['7-13'], ['16-24'], ['21-30'], ['8-31'], ['14-12'], ['17-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 67.8779125213623\n",
      "Response: Rosh Hashanah starts on the first day of Tishrei.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1637\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['19-15'], ['24-29'], ['11-2'], ['7-13'], ['16-24'], ['21-30'], ['8-31'], ['14-12'], ['17-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 71.33594751358032\n",
      "Response: Rosh Hashanah starts on the first day of Tishrei, which is the seventh month of the Jewish calendar.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_2500_depth_7500_results.json\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['6-30'], ['19-10'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['7-13'], ['16-24'], ['8-31'], ['14-12'], ['17-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 71.26839756965637\n",
      "Response: Rosh Hashanah starts on the first day of the seventh month of the Jewish calendar. The Jewish calendar is a lunar calendar, so the months are based on the cycles of the moon. The Jewish calendar is also a lunisolar\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['6-30'], ['19-10'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['7-13'], ['16-24'], ['8-31'], ['14-12'], ['17-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 71.33594751358032\n",
      "Response: Rosh Hashanah starts on the first day of Tishrei, which is the seventh month of the Jewish calendar.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_3750_depth_0_results.json\n",
      "insertion at 874\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['6-30'], ['19-10'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['7-13'], ['16-24'], ['8-31'], ['14-12'], ['17-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 71.33594751358032\n",
      "Response: Rosh Hashanah starts on the first day of Tishrei, which is the seventh month of the Jewish calendar.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1637\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['6-30'], ['19-10'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['7-13'], ['16-24'], ['8-31'], ['14-12'], ['17-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 71.33594751358032\n",
      "Response: Rosh Hashanah starts on the first day of Tishrei, which is the seventh month of the Jewish calendar.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2644\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['6-30'], ['19-10'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['7-13'], ['16-24'], ['8-31'], ['14-12'], ['17-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 67.21588373184204\n",
      "Response: Rosh Hashanah starts on the first day of Tishrei, which is the first day of the Jewish month of Tishrei.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_3750_depth_7500_results.json\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['6-30'], ['19-10'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['7-13'], ['16-24'], ['8-31'], ['14-12'], ['17-22'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 68.90602111816406\n",
      "Response: Rosh Hashanah starts on the first day of the Hebrew month of Tishrei. The first day of Tishrei is the first day of the Jewish year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['6-30'], ['19-10'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['7-13'], ['16-24'], ['8-31'], ['14-12'], ['17-22'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 70.63292264938354\n",
      "Response: Rosh Hashanah starts on the first day of Tishrei, which is the seventh month of the Jewish calendar. The first day of Tishrei is the first day of the Jewish year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1189\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['6-30'], ['19-10'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['7-13'], ['16-24'], ['8-31'], ['14-12'], ['17-22'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 70.63292264938354\n",
      "Response: Rosh Hashanah starts on the first day of Tishrei, which is the seventh month of the Jewish calendar. The first day of Tishrei is the first day of the Jewish year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2310\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['6-30'], ['19-10'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['7-13'], ['16-24'], ['8-31'], ['14-12'], ['17-22'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 68.82107257843018\n",
      "Response: Rosh Hashanah starts on the first day of the Hebrew month of Tishrei.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3555\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['6-30'], ['19-10'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['7-13'], ['16-24'], ['8-31'], ['14-12'], ['17-22'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 70.58870792388916\n",
      "Response: Rosh Hashanah starts on the first day of the Hebrew month of Tishrei, which is the seventh month of the Jewish calendar. The first day of Tishrei is the first day of the Jewish year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_5000_depth_7500_results.json\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['6-30'], ['19-15'], ['19-10'], ['24-29'], ['21-30'], ['11-2'], ['7-13'], ['16-24'], ['17-22'], ['29-19'], ['8-31'], ['14-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 68.82107257843018\n",
      "Response: Rosh Hashanah starts on the first day of the Hebrew month of Tishrei.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant/llama-2-7b-80k_id_577_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/577.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_0_depth_7500_results.json\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 70.63292264938354\n",
      "Response: Rosh Hashanah starts on the first day of Tishrei, which is the seventh month of the Jewish calendar. The first day of Tishrei is the first day of the Jewish year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 20\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 70.63292264938354\n",
      "Response: Rosh Hashanah starts on the first day of Tishrei, which is the seventh month of the Jewish calendar. The first day of Tishrei is the first day of the Jewish year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 473\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 70.63292264938354\n",
      "Response: Rosh Hashanah starts on the first day of Tishrei, which is the seventh month of the Jewish calendar. The first day of Tishrei is the first day of the Jewish year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 760\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 69.64826583862305\n",
      "Response: Rosh Hashanah starts on the first day of Tishrei, which is the first month of the Jewish calendar. The first day of Tishrei is the first day of the Jewish year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_1250_depth_7500_results.json\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['19-15'], ['24-29'], ['11-2'], ['7-13'], ['16-24'], ['21-30'], ['8-31'], ['14-12'], ['17-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 85.14228463172913\n",
      "Response: Rosh Hashanah starts on the first day of the Hebrew month of Tishrei. This year, Rosh Hashanah starts on the evening of September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['19-15'], ['24-29'], ['11-2'], ['7-13'], ['16-24'], ['21-30'], ['8-31'], ['14-12'], ['17-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 67.8779125213623\n",
      "Response: Rosh Hashanah starts on the first day of Tishrei.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 532\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['19-15'], ['24-29'], ['11-2'], ['7-13'], ['16-24'], ['21-30'], ['8-31'], ['14-12'], ['17-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 67.21588373184204\n",
      "Response: Rosh Hashanah starts on the first day of Tishrei, which is the first day of the Jewish month of Tishrei.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1124\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['19-15'], ['24-29'], ['11-2'], ['7-13'], ['16-24'], ['21-30'], ['8-31'], ['14-12'], ['17-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 68.69516372680664\n",
      "Response: Rosh Hashanah starts on the first day of Tishrei, which is the first day of the Jewish calendar.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1658\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['19-15'], ['24-29'], ['11-2'], ['7-13'], ['16-24'], ['21-30'], ['8-31'], ['14-12'], ['17-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 67.21588373184204\n",
      "Response: Rosh Hashanah starts on the first day of Tishrei, which is the first day of the Jewish month of Tishrei.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_2500_depth_7500_results.json\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['7-13'], ['16-24'], ['8-31'], ['14-12'], ['17-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 68.82107257843018\n",
      "Response: Rosh Hashanah starts on the first day of the Hebrew month of Tishrei.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['7-13'], ['16-24'], ['8-31'], ['14-12'], ['17-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 68.82107257843018\n",
      "Response: Rosh Hashanah starts on the first day of the Hebrew month of Tishrei.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 874\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['7-13'], ['16-24'], ['8-31'], ['14-12'], ['17-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 68.82107257843018\n",
      "Response: Rosh Hashanah starts on the first day of the Hebrew month of Tishrei.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1658\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['7-13'], ['16-24'], ['8-31'], ['14-12'], ['17-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 68.82107257843018\n",
      "Response: Rosh Hashanah starts on the first day of the Hebrew month of Tishrei.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2611\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['7-13'], ['16-24'], ['8-31'], ['14-12'], ['17-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 68.82107257843018\n",
      "Response: Rosh Hashanah starts on the first day of the Hebrew month of Tishrei.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_3750_depth_7500_results.json\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['6-30'], ['19-10'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['7-13'], ['16-24'], ['8-31'], ['14-12'], ['17-22'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 68.82107257843018\n",
      "Response: Rosh Hashanah starts on the first day of the Hebrew month of Tishrei.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['7-13'], ['16-24'], ['8-31'], ['14-12'], ['17-22'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 67.21588373184204\n",
      "Response: Rosh Hashanah starts on the first day of Tishrei, which is the first day of the Jewish month of Tishrei.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1145\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['7-13'], ['16-24'], ['8-31'], ['14-12'], ['17-22'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 67.21588373184204\n",
      "Response: Rosh Hashanah starts on the first day of Tishrei, which is the first day of the Jewish month of Tishrei.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2352\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['6-30'], ['19-10'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['7-13'], ['16-24'], ['8-31'], ['14-12'], ['17-22'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 67.93592572212219\n",
      "Response: Rosh Hashanah starts on the first day of Tishrei, which is the first day of the Jewish month of Tishrei. The first day of Tishrei is the first day of the Jewish year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3514\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['6-30'], ['19-10'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['7-13'], ['16-24'], ['8-31'], ['14-12'], ['17-22'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 73.08222651481628\n",
      "Response: Rosh Hashanah starts on the first day of the Hebrew month of Tishrei, which is the seventh month of the Jewish calendar. The date of Rosh Hashanah changes from year to year because the Jewish calendar is a\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_5000_depth_7500_results.json\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['12-26'], ['15-14'], ['19-15'], ['6-30'], ['19-10'], ['24-29'], ['21-30'], ['11-2'], ['7-13'], ['16-24'], ['17-22'], ['29-19'], ['8-31'], ['14-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 68.82107257843018\n",
      "Response: Rosh Hashanah starts on the first day of the Hebrew month of Tishrei.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_relevant_misleading/llama-2-7b-80k_id_577_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_0_depth_7500_results.json\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['14-12'], ['14-18'], ['17-31'], ['16-24'], ['17-22'], ['28-18'], ['7-13'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 90.39021134376526\n",
      "Response: The Jewish New Year, Rosh Hashanah, starts on the evening of September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 18\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['14-18'], ['19-15'], ['17-31'], ['14-12'], ['16-24'], ['17-22'], ['8-31'], ['21-30'], ['28-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 18\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['15-14'], ['12-26'], ['19-10'], ['6-30'], ['11-2'], ['14-18'], ['17-31'], ['19-15'], ['14-12'], ['7-12'], ['16-24'], ['17-22'], ['8-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 18\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['15-14'], ['19-10'], ['6-30'], ['12-26'], ['14-18'], ['11-2'], ['7-12'], ['17-31'], ['14-12'], ['19-15'], ['16-24'], ['17-22'], ['8-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_1250_depth_7500_results.json\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['15-14'], ['12-26'], ['19-10'], ['6-30'], ['14-18'], ['7-12'], ['11-2'], ['17-31'], ['19-15'], ['14-12'], ['21-30'], ['16-24'], ['17-22'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 68.82107257843018\n",
      "Response: Rosh Hashanah starts on the first day of the Hebrew month of Tishrei.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['15-14'], ['19-10'], ['12-26'], ['6-30'], ['7-12'], ['14-18'], ['11-2'], ['17-31'], ['17-22'], ['19-15'], ['14-12'], ['16-24'], ['21-30'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 96.90603017807007\n",
      "Response: Rosh Hashanah starts on the evening of September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 18\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['15-14'], ['7-12'], ['19-10'], ['12-26'], ['14-18'], ['6-30'], ['11-2'], ['17-31'], ['17-22'], ['16-24'], ['19-15'], ['14-12'], ['8-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1079\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['7-12'], ['15-14'], ['19-10'], ['14-18'], ['12-26'], ['6-30'], ['11-2'], ['17-31'], ['17-22'], ['16-24'], ['8-31'], ['19-15'], ['14-12'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 98.32431077957153\n",
      "Response: Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1698\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['7-12'], ['15-14'], ['19-10'], ['14-18'], ['6-30'], ['12-26'], ['11-2'], ['17-31'], ['17-22'], ['8-31'], ['16-24'], ['19-15'], ['14-12'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_2500_depth_7500_results.json\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['7-12'], ['15-14'], ['19-10'], ['14-18'], ['6-30'], ['12-26'], ['11-2'], ['17-31'], ['17-22'], ['19-15'], ['8-31'], ['16-24'], ['21-30'], ['14-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 69.3471610546112\n",
      "Response: Rosh Hashanah starts on the first day of the month of Tishrei, which is the seventh month of the Jewish calendar. The Jewish calendar is a lunisolar calendar, which means that it is based on both the sun and\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['7-12'], ['15-14'], ['19-10'], ['14-18'], ['12-26'], ['6-30'], ['11-2'], ['17-31'], ['17-22'], ['19-15'], ['8-31'], ['16-24'], ['21-30'], ['14-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 88.28656673431396\n",
      "Response: The Jewish New Year, Rosh Hashanah, starts on the evening of September 25, 2022.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 808\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['7-12'], ['15-14'], ['19-10'], ['14-18'], ['12-26'], ['6-30'], ['17-31'], ['11-2'], ['17-22'], ['19-15'], ['8-31'], ['16-24'], ['21-30'], ['14-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 96.90603017807007\n",
      "Response: Rosh Hashanah starts on the evening of September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1731\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['7-12'], ['18-30'], ['15-14'], ['19-10'], ['14-18'], ['17-31'], ['12-26'], ['6-30'], ['11-2'], ['17-22'], ['8-31'], ['16-24'], ['19-15'], ['21-30'], ['14-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 96.90603017807007\n",
      "Response: Rosh Hashanah starts on the evening of September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2633\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['7-12'], ['18-30'], ['15-14'], ['19-10'], ['14-18'], ['17-31'], ['6-30'], ['12-26'], ['11-2'], ['17-22'], ['16-24'], ['8-31'], ['19-15'], ['14-12'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 96.90603017807007\n",
      "Response: Rosh Hashanah starts on the evening of September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_3750_depth_7500_results.json\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['7-12'], ['18-30'], ['15-14'], ['19-10'], ['14-18'], ['17-31'], ['12-26'], ['6-30'], ['17-22'], ['11-2'], ['19-15'], ['16-24'], ['8-31'], ['21-30'], ['14-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 68.26092600822449\n",
      "Response: Rosh Hashanah starts on the first day of the seventh month of the Jewish calendar. The Jewish calendar is a lunisolar calendar, which means that it is based on both the sun and the moon. The Jewish calendar is also a\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['7-12'], ['18-30'], ['15-14'], ['14-18'], ['19-10'], ['17-31'], ['17-22'], ['12-26'], ['6-30'], ['11-2'], ['16-24'], ['19-15'], ['8-31'], ['21-30'], ['14-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 96.90603017807007\n",
      "Response: Rosh Hashanah starts on the evening of September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1079\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['7-12'], ['18-30'], ['15-14'], ['14-18'], ['19-10'], ['17-31'], ['17-22'], ['12-26'], ['6-30'], ['11-2'], ['16-24'], ['8-31'], ['19-15'], ['21-30'], ['14-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 96.90603017807007\n",
      "Response: Rosh Hashanah starts on the evening of September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2381\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['7-12'], ['18-30'], ['15-14'], ['14-18'], ['19-10'], ['17-31'], ['17-22'], ['12-26'], ['6-30'], ['11-2'], ['16-24'], ['8-31'], ['19-15'], ['21-30'], ['14-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 96.90603017807007\n",
      "Response: Rosh Hashanah starts on the evening of September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3563\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['7-12'], ['18-30'], ['15-14'], ['14-18'], ['19-10'], ['17-31'], ['17-22'], ['6-30'], ['12-26'], ['11-2'], ['16-24'], ['8-31'], ['21-30'], ['19-15'], ['14-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_5000_depth_7500_results.json\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['7-12'], ['18-30'], ['15-14'], ['14-18'], ['19-10'], ['17-31'], ['17-22'], ['6-30'], ['12-26'], ['16-24'], ['11-2'], ['21-30'], ['8-31'], ['19-15'], ['14-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 98.32431077957153\n",
      "Response: Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant/llama-2-7b-80k_id_577_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/577.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['7-13'], ['8-31'], ['14-12'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['19-15'], ['14-12'], ['14-18'], ['17-31'], ['16-24'], ['17-22'], ['28-18'], ['7-13'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 90.39021134376526\n",
      "Response: The Jewish New Year, Rosh Hashanah, starts on the evening of September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 18\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['18-30'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['6-30'], ['11-2'], ['14-18'], ['19-15'], ['17-31'], ['14-12'], ['16-24'], ['17-22'], ['8-31'], ['21-30'], ['28-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 18\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['15-14'], ['12-26'], ['19-10'], ['6-30'], ['11-2'], ['14-18'], ['17-31'], ['19-15'], ['14-12'], ['7-12'], ['16-24'], ['17-22'], ['8-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 18\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['15-14'], ['19-10'], ['6-30'], ['12-26'], ['14-18'], ['11-2'], ['7-12'], ['17-31'], ['14-12'], ['19-15'], ['16-24'], ['17-22'], ['8-31'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: This year's Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['15-14'], ['12-26'], ['19-10'], ['6-30'], ['14-18'], ['7-12'], ['11-2'], ['17-31'], ['19-15'], ['14-12'], ['21-30'], ['16-24'], ['17-22'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 68.82107257843018\n",
      "Response: Rosh Hashanah starts on the first day of the Hebrew month of Tishrei.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['15-14'], ['12-26'], ['19-10'], ['6-30'], ['7-12'], ['14-18'], ['11-2'], ['17-31'], ['19-15'], ['14-12'], ['21-30'], ['16-24'], ['17-22'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 89.48611617088318\n",
      "Response: Rosh Hashanah starts at sundown on September 25, 2022.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 18\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['15-14'], ['7-12'], ['12-26'], ['19-10'], ['6-30'], ['14-18'], ['11-2'], ['17-31'], ['19-15'], ['14-12'], ['16-24'], ['17-22'], ['21-30'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 96.90603017807007\n",
      "Response: Rosh Hashanah starts on the evening of September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1079\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['15-14'], ['7-12'], ['19-10'], ['12-26'], ['6-30'], ['14-18'], ['17-31'], ['11-2'], ['19-15'], ['16-24'], ['17-22'], ['8-31'], ['14-12'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 96.90603017807007\n",
      "Response: Rosh Hashanah starts on the evening of September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1698\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['7-12'], ['15-14'], ['19-10'], ['14-18'], ['12-26'], ['6-30'], ['17-31'], ['11-2'], ['19-15'], ['16-24'], ['8-31'], ['17-22'], ['14-12'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 96.90603017807007\n",
      "Response: Rosh Hashanah starts on the evening of September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['7-12'], ['15-14'], ['12-26'], ['19-10'], ['14-18'], ['6-30'], ['17-31'], ['19-15'], ['11-2'], ['16-24'], ['17-22'], ['8-31'], ['21-30'], ['14-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 69.3471610546112\n",
      "Response: Rosh Hashanah starts on the first day of the month of Tishrei, which is the seventh month of the Jewish calendar. The Jewish calendar is a lunisolar calendar, which means that it is based on both the sun and\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['7-12'], ['15-14'], ['12-26'], ['19-10'], ['14-18'], ['6-30'], ['17-31'], ['19-15'], ['11-2'], ['16-24'], ['17-22'], ['8-31'], ['21-30'], ['14-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 81.25070333480835\n",
      "Response: Rosh Hashanah starts on the evening of September 5th and ends on the evening of September 6th.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 808\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['7-12'], ['15-14'], ['12-26'], ['19-10'], ['14-18'], ['6-30'], ['17-31'], ['19-15'], ['11-2'], ['16-24'], ['17-22'], ['8-31'], ['21-30'], ['14-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 81.25070333480835\n",
      "Response: Rosh Hashanah starts on the evening of September 5th and ends on the evening of September 6th.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1752\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['7-12'], ['15-14'], ['12-26'], ['19-10'], ['14-18'], ['6-30'], ['17-31'], ['19-15'], ['11-2'], ['16-24'], ['17-22'], ['8-31'], ['21-30'], ['14-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 87.07944750785828\n",
      "Response: Rosh Hashanah starts on September 5th or October 5th.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2587\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['7-12'], ['15-14'], ['12-26'], ['19-10'], ['14-18'], ['6-30'], ['17-31'], ['19-15'], ['11-2'], ['17-22'], ['16-24'], ['8-31'], ['21-30'], ['14-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 87.07944750785828\n",
      "Response: Rosh Hashanah starts on September 5th or October 5th.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['7-12'], ['15-14'], ['12-26'], ['19-10'], ['6-30'], ['14-18'], ['17-31'], ['19-15'], ['16-24'], ['17-22'], ['21-30'], ['11-2'], ['8-31'], ['14-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 98.32431077957153\n",
      "Response: Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['7-12'], ['15-14'], ['12-26'], ['19-10'], ['6-30'], ['14-18'], ['17-31'], ['19-15'], ['16-24'], ['17-22'], ['21-30'], ['11-2'], ['8-31'], ['14-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 96.364426612854\n",
      "Response: Rosh Hashanah starts on September 25, 2025.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1079\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['7-12'], ['15-14'], ['12-26'], ['19-10'], ['6-30'], ['14-18'], ['17-31'], ['19-15'], ['16-24'], ['17-22'], ['21-30'], ['11-2'], ['8-31'], ['14-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 96.364426612854\n",
      "Response: Rosh Hashanah starts on September 25, 2025.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2384\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['7-12'], ['15-14'], ['12-26'], ['19-10'], ['6-30'], ['14-18'], ['17-31'], ['19-15'], ['16-24'], ['17-22'], ['21-30'], ['11-2'], ['8-31'], ['14-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 96.364426612854\n",
      "Response: Rosh Hashanah starts on September 25, 2025.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3466\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 32.52999782562256\n",
      "Response: The Chinese New Year is the first day of the first month of the Chinese calendar. The first month of the Chinese calendar is the first month of the year. The first month of the Chinese calendar is the first month of the year. The first month\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "This year's Rosh Hashanah starts on September 22, 2026.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['7-12'], ['15-14'], ['12-26'], ['6-30'], ['19-10'], ['14-18'], ['17-31'], ['19-15'], ['16-24'], ['17-22'], ['21-30'], ['11-2'], ['8-31'], ['14-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 98.32431077957153\n",
      "Response: Rosh Hashanah starts on September 22, 2026.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_577_irrelevant_misleading/llama-2-7b-80k_id_577_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['6-9'], ['8-26'], ['7-4'], ['16-19'], ['11-15'], ['16-26'], ['19-15'], ['24-29'], ['0-14'], ['13-11'], ['17-22'], ['21-30'], ['0-11'], ['0-22'], ['0-26'], ['1-23'], ['1-26'], ['8-22'], ['10-2'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 74.41203594207764\n",
      "Response: Sucre. The IOI is an annual international competition for high school students in the field of informatics. The IOI is organized by the International Olympiad in Informatics Foundation (IOIF). The IOI is an annual international\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['6-9'], ['8-26'], ['7-4'], ['16-19'], ['11-15'], ['16-26'], ['19-15'], ['24-29'], ['0-14'], ['13-11'], ['17-22'], ['21-30'], ['0-11'], ['0-22'], ['0-26'], ['1-23'], ['1-26'], ['8-22'], ['10-2'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 74.41203594207764\n",
      "Response: Sucre. The IOI is an annual international competition for high school students in the field of informatics. The IOI is organized by the International Olympiad in Informatics Foundation (IOIF). The IOI is an annual international\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['6-9'], ['8-26'], ['7-4'], ['16-19'], ['11-15'], ['16-26'], ['19-15'], ['24-29'], ['0-14'], ['13-11'], ['17-22'], ['21-30'], ['0-11'], ['0-22'], ['0-26'], ['1-23'], ['1-26'], ['8-22'], ['10-2'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 74.41203594207764\n",
      "Response: Sucre. The IOI is an annual international competition for high school students in the field of informatics. The IOI is organized by the International Olympiad in Informatics Foundation (IOIF). The IOI is an annual international\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['6-9'], ['8-26'], ['7-4'], ['16-19'], ['11-15'], ['16-26'], ['19-15'], ['24-29'], ['0-14'], ['13-11'], ['17-22'], ['21-30'], ['0-11'], ['0-22'], ['0-26'], ['1-23'], ['1-26'], ['8-22'], ['10-2'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 74.41203594207764\n",
      "Response: Sucre. The IOI is an annual international competition for high school students in the field of informatics. The IOI is organized by the International Olympiad in Informatics Foundation (IOIF). The IOI is an annual international\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_0_depth_7500_results.json\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['6-9'], ['8-26'], ['7-4'], ['16-19'], ['11-15'], ['16-26'], ['19-15'], ['24-29'], ['0-14'], ['13-11'], ['17-22'], ['21-30'], ['0-11'], ['0-22'], ['0-26'], ['1-23'], ['1-26'], ['8-22'], ['10-2'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 74.41203594207764\n",
      "Response: Sucre. The IOI is an annual international competition for high school students in the field of informatics. The IOI is organized by the International Olympiad in Informatics Foundation (IOIF). The IOI is an annual international\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['8-26'], ['6-9'], ['16-19'], ['11-15'], ['19-15'], ['7-4'], ['24-29'], ['16-26'], ['21-30'], ['17-22'], ['0-14'], ['13-11'], ['7-12'], ['11-2'], ['22-22'], ['24-8'], ['26-28'], ['16-30'], ['18-30'], ['23-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 93.70565414428711\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre, Bolivia.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_1250_depth_0_results.json\n",
      "insertion at 242\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['24-29'], ['7-4'], ['21-30'], ['16-26'], ['17-22'], ['7-12'], ['11-2'], ['22-22'], ['26-28'], ['0-14'], ['13-11'], ['24-8'], ['6-16'], ['18-30'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 510\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['19-15'], ['21-30'], ['24-29'], ['7-4'], ['11-2'], ['7-12'], ['17-22'], ['16-26'], ['22-22'], ['26-28'], ['6-16'], ['24-8'], ['0-14'], ['13-11'], ['18-30'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 767\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['7-4'], ['11-2'], ['17-22'], ['7-12'], ['22-22'], ['16-26'], ['6-16'], ['26-28'], ['24-8'], ['13-11'], ['14-18'], ['18-30'], ['0-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_1250_depth_7500_results.json\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['7-4'], ['17-22'], ['11-2'], ['7-12'], ['22-22'], ['26-28'], ['18-30'], ['24-8'], ['13-11'], ['16-26'], ['6-16'], ['14-18'], ['0-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['11-2'], ['17-22'], ['7-4'], ['7-12'], ['22-22'], ['26-28'], ['24-8'], ['18-30'], ['6-16'], ['13-11'], ['14-18'], ['16-26'], ['0-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 93.70565414428711\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre, Bolivia.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_2500_depth_0_results.json\n",
      "insertion at 563\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['11-2'], ['17-22'], ['7-4'], ['7-12'], ['22-22'], ['6-16'], ['24-8'], ['26-28'], ['18-30'], ['14-18'], ['13-11'], ['16-26'], ['0-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1129\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 28.95442247390747\n",
      "Response: Sucre\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1308\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 28.95442247390747\n",
      "Response: Sucre\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_2500_depth_7500_results.json\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['11-2'], ['17-22'], ['7-4'], ['7-12'], ['22-22'], ['18-30'], ['24-8'], ['26-28'], ['6-16'], ['14-18'], ['12-26'], ['13-11'], ['16-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['11-2'], ['17-22'], ['7-4'], ['7-12'], ['22-22'], ['18-30'], ['26-28'], ['24-8'], ['14-18'], ['6-16'], ['12-26'], ['13-11'], ['16-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 93.70565414428711\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre, Bolivia.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_3750_depth_0_results.json\n",
      "insertion at 836\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['11-2'], ['17-22'], ['7-12'], ['7-4'], ['22-22'], ['6-16'], ['24-8'], ['18-30'], ['26-28'], ['14-18'], ['12-26'], ['13-11'], ['16-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1308\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['11-2'], ['17-22'], ['7-12'], ['7-4'], ['22-22'], ['6-16'], ['24-8'], ['18-30'], ['26-28'], ['14-18'], ['12-26'], ['13-11'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 1308\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['11-2'], ['17-22'], ['7-12'], ['7-4'], ['22-22'], ['6-16'], ['24-8'], ['14-18'], ['18-30'], ['26-28'], ['24-24'], ['12-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_3750_depth_7500_results.json\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['11-2'], ['17-22'], ['7-4'], ['7-12'], ['22-22'], ['6-16'], ['18-30'], ['24-8'], ['26-28'], ['14-18'], ['12-26'], ['24-24'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['11-2'], ['17-22'], ['7-12'], ['7-4'], ['6-16'], ['22-22'], ['18-30'], ['24-8'], ['14-18'], ['26-28'], ['12-26'], ['24-24'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1165\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 26.590177416801453\n",
      "Response: Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 1308\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 26.590177416801453\n",
      "Response: Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 2853\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 26.590177416801453\n",
      "Response: Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_5000_depth_7500_results.json\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['11-2'], ['17-22'], ['7-4'], ['7-12'], ['22-22'], ['6-16'], ['18-30'], ['24-8'], ['26-28'], ['12-26'], ['14-18'], ['24-24'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant/llama-2-7b-80k_id_578_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/578.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['6-9'], ['8-26'], ['7-4'], ['16-19'], ['11-15'], ['16-26'], ['19-15'], ['24-29'], ['0-14'], ['13-11'], ['17-22'], ['21-30'], ['0-11'], ['0-22'], ['0-26'], ['1-23'], ['1-26'], ['8-22'], ['10-2'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 74.41203594207764\n",
      "Response: Sucre. The IOI is an annual international competition for high school students in the field of informatics. The IOI is organized by the International Olympiad in Informatics Foundation (IOIF). The IOI is an annual international\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['6-9'], ['8-26'], ['7-4'], ['16-19'], ['11-15'], ['16-26'], ['19-15'], ['24-29'], ['0-14'], ['13-11'], ['17-22'], ['21-30'], ['0-11'], ['0-22'], ['0-26'], ['1-23'], ['1-26'], ['8-22'], ['10-2'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 74.41203594207764\n",
      "Response: Sucre. The IOI is an annual international competition for high school students in the field of informatics. The IOI is organized by the International Olympiad in Informatics Foundation (IOIF). The IOI is an annual international\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['6-9'], ['8-26'], ['7-4'], ['16-19'], ['11-15'], ['16-26'], ['19-15'], ['24-29'], ['0-14'], ['13-11'], ['17-22'], ['21-30'], ['0-11'], ['0-22'], ['0-26'], ['1-23'], ['1-26'], ['8-22'], ['10-2'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 74.41203594207764\n",
      "Response: Sucre. The IOI is an annual international competition for high school students in the field of informatics. The IOI is organized by the International Olympiad in Informatics Foundation (IOIF). The IOI is an annual international\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['6-9'], ['8-26'], ['7-4'], ['16-19'], ['11-15'], ['16-26'], ['19-15'], ['24-29'], ['0-14'], ['13-11'], ['17-22'], ['21-30'], ['0-11'], ['0-22'], ['0-26'], ['1-23'], ['1-26'], ['8-22'], ['10-2'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 74.41203594207764\n",
      "Response: Sucre. The IOI is an annual international competition for high school students in the field of informatics. The IOI is organized by the International Olympiad in Informatics Foundation (IOIF). The IOI is an annual international\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_0_depth_7500_results.json\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['6-9'], ['8-26'], ['7-4'], ['16-19'], ['11-15'], ['16-26'], ['19-15'], ['24-29'], ['0-14'], ['13-11'], ['17-22'], ['21-30'], ['0-11'], ['0-22'], ['0-26'], ['1-23'], ['1-26'], ['8-22'], ['10-2'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 74.41203594207764\n",
      "Response: Sucre. The IOI is an annual international competition for high school students in the field of informatics. The IOI is organized by the International Olympiad in Informatics Foundation (IOIF). The IOI is an annual international\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['8-26'], ['6-9'], ['7-4'], ['16-19'], ['11-15'], ['19-15'], ['24-29'], ['16-26'], ['21-30'], ['17-22'], ['0-14'], ['13-11'], ['26-28'], ['16-30'], ['24-8'], ['31-16'], ['0-11'], ['0-22'], ['0-26'], ['1-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 84.44061279296875\n",
      "Response: The International Olympiad in Informatics (IOI) is an annual competitive programming competition and one of the International Science Olympiads for secondary school students. The first IOI was held in 1989 in Pravetz\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 242\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['8-26'], ['6-9'], ['11-15'], ['16-19'], ['19-15'], ['7-4'], ['21-30'], ['24-29'], ['16-26'], ['17-22'], ['26-28'], ['0-14'], ['13-11'], ['22-22'], ['24-8'], ['7-12'], ['16-30'], ['14-18'], ['18-30'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 95.00168561935425\n",
      "Response: Sucre is the host city of the upcoming International Olympiad in Informatics (IOI).\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 469\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['8-26'], ['6-9'], ['11-15'], ['16-19'], ['19-15'], ['21-30'], ['7-4'], ['24-29'], ['16-26'], ['17-22'], ['7-12'], ['22-22'], ['26-28'], ['0-14'], ['13-11'], ['24-8'], ['16-30'], ['6-16'], ['8-22'], ['12-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 95.00168561935425\n",
      "Response: Sucre is the host city of the upcoming International Olympiad in Informatics (IOI).\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 761\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 28.95442247390747\n",
      "Response: Sucre\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['6-9'], ['8-26'], ['11-15'], ['16-19'], ['19-15'], ['21-30'], ['7-4'], ['24-29'], ['17-22'], ['26-28'], ['16-26'], ['22-22'], ['24-8'], ['7-12'], ['18-30'], ['13-11'], ['0-14'], ['12-26'], ['16-30'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 47.36851453781128\n",
      "Response: Sucre is the capital of Bolivia, but it's not clear if it's hosting the IOI this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 558\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 28.95442247390747\n",
      "Response: Sucre\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1136\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 28.95442247390747\n",
      "Response: Sucre\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1380\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 28.95442247390747\n",
      "Response: Sucre\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['8-26'], ['19-15'], ['21-30'], ['7-4'], ['24-29'], ['17-22'], ['26-28'], ['18-30'], ['22-22'], ['12-26'], ['24-8'], ['11-2'], ['16-26'], ['13-11'], ['7-12'], ['14-18'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['19-15'], ['24-29'], ['7-4'], ['17-22'], ['11-2'], ['26-28'], ['22-22'], ['18-30'], ['7-12'], ['12-26'], ['24-8'], ['16-26'], ['16-30'], ['13-11'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 843\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 26.590177416801453\n",
      "Response: Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1380\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 28.95442247390747\n",
      "Response: Sucre\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 1380\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 28.95442247390747\n",
      "Response: Sucre\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['19-15'], ['24-29'], ['7-4'], ['17-22'], ['11-2'], ['26-28'], ['12-26'], ['18-30'], ['22-22'], ['24-8'], ['14-18'], ['7-12'], ['16-30'], ['13-11'], ['16-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['19-15'], ['24-29'], ['7-4'], ['17-22'], ['11-2'], ['26-28'], ['18-30'], ['22-22'], ['12-26'], ['7-12'], ['24-8'], ['14-18'], ['16-30'], ['24-3'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1179\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['19-15'], ['24-29'], ['17-22'], ['7-4'], ['11-2'], ['26-28'], ['7-12'], ['22-22'], ['18-30'], ['12-26'], ['6-16'], ['24-8'], ['14-18'], ['16-30'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 1380\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['19-15'], ['24-29'], ['17-22'], ['7-4'], ['11-2'], ['7-12'], ['6-16'], ['22-22'], ['26-28'], ['18-30'], ['12-26'], ['14-18'], ['24-8'], ['24-3'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 2925\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['19-15'], ['24-29'], ['17-22'], ['11-2'], ['7-4'], ['7-12'], ['6-16'], ['22-22'], ['26-28'], ['18-30'], ['12-26'], ['24-8'], ['14-18'], ['24-3'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['19-15'], ['24-29'], ['17-22'], ['7-4'], ['11-2'], ['7-12'], ['6-16'], ['22-22'], ['12-26'], ['18-30'], ['26-28'], ['24-8'], ['14-18'], ['24-3'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_relevant_misleading/llama-2-7b-80k_id_578_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['6-9'], ['8-26'], ['7-4'], ['16-19'], ['11-15'], ['16-26'], ['19-15'], ['24-29'], ['0-14'], ['13-11'], ['17-22'], ['21-30'], ['0-11'], ['0-22'], ['0-26'], ['1-23'], ['1-26'], ['8-22'], ['10-2'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 74.41203594207764\n",
      "Response: Sucre. The IOI is an annual international competition for high school students in the field of informatics. The IOI is organized by the International Olympiad in Informatics Foundation (IOIF). The IOI is an annual international\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['6-9'], ['8-26'], ['7-4'], ['16-19'], ['11-15'], ['16-26'], ['19-15'], ['24-29'], ['0-14'], ['13-11'], ['17-22'], ['21-30'], ['0-11'], ['0-22'], ['0-26'], ['1-23'], ['1-26'], ['8-22'], ['10-2'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 74.41203594207764\n",
      "Response: Sucre. The IOI is an annual international competition for high school students in the field of informatics. The IOI is organized by the International Olympiad in Informatics Foundation (IOIF). The IOI is an annual international\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['6-9'], ['8-26'], ['7-4'], ['16-19'], ['11-15'], ['16-26'], ['19-15'], ['24-29'], ['0-14'], ['13-11'], ['17-22'], ['21-30'], ['0-11'], ['0-22'], ['0-26'], ['1-23'], ['1-26'], ['8-22'], ['10-2'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 74.41203594207764\n",
      "Response: Sucre. The IOI is an annual international competition for high school students in the field of informatics. The IOI is organized by the International Olympiad in Informatics Foundation (IOIF). The IOI is an annual international\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['6-9'], ['8-26'], ['7-4'], ['16-19'], ['11-15'], ['16-26'], ['19-15'], ['24-29'], ['0-14'], ['13-11'], ['17-22'], ['21-30'], ['0-11'], ['0-22'], ['0-26'], ['1-23'], ['1-26'], ['8-22'], ['10-2'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 74.41203594207764\n",
      "Response: Sucre. The IOI is an annual international competition for high school students in the field of informatics. The IOI is organized by the International Olympiad in Informatics Foundation (IOIF). The IOI is an annual international\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_0_depth_7500_results.json\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['6-9'], ['8-26'], ['7-4'], ['16-19'], ['11-15'], ['16-26'], ['19-15'], ['24-29'], ['0-14'], ['13-11'], ['17-22'], ['21-30'], ['0-11'], ['0-22'], ['0-26'], ['1-23'], ['1-26'], ['8-22'], ['10-2'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 74.41203594207764\n",
      "Response: Sucre. The IOI is an annual international competition for high school students in the field of informatics. The IOI is organized by the International Olympiad in Informatics Foundation (IOIF). The IOI is an annual international\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['16-19'], ['8-26'], ['6-9'], ['11-15'], ['7-4'], ['24-29'], ['19-15'], ['16-26'], ['17-22'], ['21-30'], ['0-14'], ['13-11'], ['7-12'], ['16-30'], ['14-18'], ['24-8'], ['23-8'], ['23-31'], ['26-28'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 245\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 26.590177416801453\n",
      "Response: Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 511\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 26.590177416801453\n",
      "Response: Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 741\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 26.590177416801453\n",
      "Response: Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_1250_depth_7500_results.json\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['16-26'], ['12-26'], ['13-11'], ['11-2'], ['18-30'], ['24-8'], ['0-14'], ['16-30'], ['26-28'], ['7-12'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['7-4'], ['17-22'], ['24-29'], ['21-30'], ['11-2'], ['16-26'], ['7-12'], ['12-26'], ['13-11'], ['24-8'], ['16-30'], ['18-30'], ['0-14'], ['26-28'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 552\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['24-29'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['7-12'], ['16-26'], ['24-8'], ['12-26'], ['13-11'], ['16-30'], ['18-30'], ['0-14'], ['6-16'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 95.01684904098511\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre. This may be partly because leaders and students are generally housed at different locations, and partly because after the competition the students were sometimes based\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1112\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 28.95442247390747\n",
      "Response: Sucre\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1697\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 26.590177416801453\n",
      "Response: Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_2500_depth_7500_results.json\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['7-4'], ['17-22'], ['11-2'], ['7-12'], ['12-26'], ['24-8'], ['18-30'], ['16-26'], ['16-30'], ['26-28'], ['13-11'], ['22-22'], ['29-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 28.54207456111908\n",
      "Response: Sucre, Bolivia\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 861\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 26.590177416801453\n",
      "Response: Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1720\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 26.590177416801453\n",
      "Response: Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2642\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 26.590177416801453\n",
      "Response: Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_3750_depth_7500_results.json\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['7-4'], ['24-29'], ['17-22'], ['11-2'], ['12-26'], ['18-30'], ['7-12'], ['24-8'], ['26-28'], ['16-30'], ['22-22'], ['3-6'], ['13-11'], ['16-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['24-29'], ['11-2'], ['7-12'], ['12-26'], ['18-30'], ['24-8'], ['26-28'], ['16-30'], ['22-22'], ['3-6'], ['13-11'], ['16-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1148\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['19-15'], ['24-29'], ['17-22'], ['11-2'], ['7-4'], ['7-12'], ['12-26'], ['18-30'], ['24-8'], ['22-22'], ['6-16'], ['16-30'], ['26-28'], ['3-6'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 89.9113416671753\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre. The team leaders arrive at the IMO a few days in advance of the contestants and form the IMO jury which is responsible\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2357\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['19-15'], ['24-29'], ['11-2'], ['17-22'], ['7-4'], ['7-12'], ['6-16'], ['12-26'], ['24-8'], ['18-30'], ['22-22'], ['16-30'], ['26-28'], ['14-18'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3579\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['11-2'], ['19-15'], ['17-22'], ['7-4'], ['7-12'], ['6-16'], ['12-26'], ['24-8'], ['22-22'], ['18-30'], ['24-24'], ['24-3'], ['16-30'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_5000_depth_7500_results.json\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['8-26'], ['24-29'], ['19-15'], ['11-2'], ['17-22'], ['7-4'], ['7-12'], ['6-16'], ['12-26'], ['18-30'], ['24-8'], ['22-22'], ['24-3'], ['24-24'], ['16-30'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant/llama-2-7b-80k_id_578_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/578.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['6-9'], ['8-26'], ['7-4'], ['16-19'], ['11-15'], ['16-26'], ['19-15'], ['24-29'], ['0-14'], ['13-11'], ['17-22'], ['21-30'], ['0-11'], ['0-22'], ['0-26'], ['1-23'], ['1-26'], ['8-22'], ['10-2'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 74.41203594207764\n",
      "Response: Sucre. The IOI is an annual international competition for high school students in the field of informatics. The IOI is organized by the International Olympiad in Informatics Foundation (IOIF). The IOI is an annual international\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['6-9'], ['8-26'], ['7-4'], ['16-19'], ['11-15'], ['16-26'], ['19-15'], ['24-29'], ['0-14'], ['13-11'], ['17-22'], ['21-30'], ['0-11'], ['0-22'], ['0-26'], ['1-23'], ['1-26'], ['8-22'], ['10-2'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 74.41203594207764\n",
      "Response: Sucre. The IOI is an annual international competition for high school students in the field of informatics. The IOI is organized by the International Olympiad in Informatics Foundation (IOIF). The IOI is an annual international\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['6-9'], ['8-26'], ['7-4'], ['16-19'], ['11-15'], ['16-26'], ['19-15'], ['24-29'], ['0-14'], ['13-11'], ['17-22'], ['21-30'], ['0-11'], ['0-22'], ['0-26'], ['1-23'], ['1-26'], ['8-22'], ['10-2'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 74.41203594207764\n",
      "Response: Sucre. The IOI is an annual international competition for high school students in the field of informatics. The IOI is organized by the International Olympiad in Informatics Foundation (IOIF). The IOI is an annual international\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['6-9'], ['8-26'], ['7-4'], ['16-19'], ['11-15'], ['16-26'], ['19-15'], ['24-29'], ['0-14'], ['13-11'], ['17-22'], ['21-30'], ['0-11'], ['0-22'], ['0-26'], ['1-23'], ['1-26'], ['8-22'], ['10-2'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 74.41203594207764\n",
      "Response: Sucre. The IOI is an annual international competition for high school students in the field of informatics. The IOI is organized by the International Olympiad in Informatics Foundation (IOIF). The IOI is an annual international\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['6-9'], ['8-26'], ['7-4'], ['16-19'], ['11-15'], ['16-26'], ['19-15'], ['24-29'], ['0-14'], ['13-11'], ['17-22'], ['21-30'], ['0-11'], ['0-22'], ['0-26'], ['1-23'], ['1-26'], ['8-22'], ['10-2'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 74.41203594207764\n",
      "Response: Sucre. The IOI is an annual international competition for high school students in the field of informatics. The IOI is organized by the International Olympiad in Informatics Foundation (IOIF). The IOI is an annual international\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['8-26'], ['6-9'], ['7-4'], ['16-19'], ['24-29'], ['11-15'], ['16-26'], ['19-15'], ['0-14'], ['13-11'], ['17-22'], ['21-30'], ['22-22'], ['24-8'], ['26-28'], ['0-11'], ['0-22'], ['0-26'], ['1-23'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 67.56467819213867\n",
      "Response: The International Olympiad in Informatics (IOI) will be held in a city located in South America. He legally changed his name to Lee Jung-ho (이정호) after receiving South Korean citizenship. This is the\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 245\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['6-9'], ['8-26'], ['16-19'], ['11-15'], ['19-15'], ['24-29'], ['7-4'], ['21-30'], ['16-26'], ['13-11'], ['17-22'], ['0-14'], ['7-12'], ['22-22'], ['24-8'], ['26-28'], ['6-16'], ['14-18'], ['16-30'], ['29-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 511\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['24-29'], ['21-30'], ['7-4'], ['7-12'], ['17-22'], ['16-26'], ['6-16'], ['11-2'], ['13-11'], ['22-22'], ['0-14'], ['24-8'], ['26-28'], ['16-30'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 741\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 26.590177416801453\n",
      "Response: Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['24-29'], ['21-30'], ['7-4'], ['17-22'], ['11-2'], ['7-12'], ['16-26'], ['22-22'], ['6-16'], ['13-11'], ['18-30'], ['24-8'], ['12-26'], ['26-28'], ['0-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['24-29'], ['21-30'], ['7-4'], ['17-22'], ['11-2'], ['7-12'], ['16-26'], ['22-22'], ['24-8'], ['6-16'], ['18-30'], ['12-26'], ['13-11'], ['26-28'], ['29-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 87.10284233093262\n",
      "Response: The International Olympiad in Informatics (IOI) will be held in a city located in South America.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 552\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 28.95442247390747\n",
      "Response: Sucre\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1136\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['24-29'], ['21-30'], ['7-4'], ['17-22'], ['7-12'], ['11-2'], ['6-16'], ['22-22'], ['16-26'], ['24-8'], ['26-28'], ['18-30'], ['12-26'], ['13-11'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 95.00168561935425\n",
      "Response: Sucre is the host city of the upcoming International Olympiad in Informatics (IOI).\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1671\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 28.95442247390747\n",
      "Response: Sucre\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['24-29'], ['21-30'], ['7-4'], ['17-22'], ['11-2'], ['7-12'], ['22-22'], ['18-30'], ['12-26'], ['6-16'], ['24-8'], ['26-28'], ['13-11'], ['16-26'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 28.54207456111908\n",
      "Response: Sucre, Bolivia\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 870\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 26.590177416801453\n",
      "Response: Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1747\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 26.590177416801453\n",
      "Response: Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2622\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
<<<<<<< Updated upstream
      "Depth: 100%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_relevant_misleading/llama-2-7b-80k_id_422_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['16-19'], ['7-12'], ['11-15'], ['19-15'], ['17-22'], ['8-26'], ['6-16'], ['11-2'], ['21-30'], ['6-9'], ['24-3'], ['24-29'], ['26-28'], ['14-18'], ['16-30'], ['15-14'], ['7-4'], ['20-10'], ['25-0'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 90.96159934997559\n",
      "Response: The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto, the President of Kenya.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_relevant_misleading/llama-2-7b-80k_id_422_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1051\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['7-12'], ['16-19'], ['11-15'], ['6-16'], ['17-22'], ['19-15'], ['8-26'], ['11-2'], ['21-30'], ['6-9'], ['24-3'], ['24-29'], ['14-18'], ['26-28'], ['16-30'], ['15-14'], ['7-4'], ['20-10'], ['25-0'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_relevant_misleading/llama-2-7b-80k_id_422_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2234\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['7-12'], ['11-15'], ['16-19'], ['6-16'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['21-30'], ['6-9'], ['24-3'], ['24-29'], ['14-18'], ['16-30'], ['26-28'], ['15-14'], ['20-10'], ['7-4'], ['25-0'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_relevant_misleading/llama-2-7b-80k_id_422_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 2926\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['7-12'], ['11-15'], ['16-19'], ['6-16'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['21-30'], ['6-9'], ['24-3'], ['24-29'], ['14-18'], ['16-30'], ['26-28'], ['15-14'], ['7-4'], ['20-10'], ['25-0'], ['17-0']]\n",
=======
      "Score: 87.79528141021729\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is a two-part episode, with Shadow and Flame being the first part.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2365\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['8-26'], ['11-15'], ['16-19'], ['6-9'], ['19-15'], ['24-29'], ['7-4'], ['17-22'], ['21-30'], ['12-26'], ['7-12'], ['11-2'], ['31-16'], ['26-28'], ['29-19'], ['29-21'], ['21-28'], ['6-30'], ['29-26'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3553\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['8-26'], ['11-15'], ['16-19'], ['6-9'], ['19-15'], ['24-29'], ['7-4'], ['17-22'], ['21-30'], ['7-12'], ['12-26'], ['11-2'], ['31-16'], ['26-28'], ['29-19'], ['21-28'], ['29-26'], ['29-21'], ['22-8'], ['22-16']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
<<<<<<< Updated upstream
      "Response: The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_relevant_misleading/llama-2-7b-80k_id_422_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['7-12'], ['11-15'], ['16-19'], ['6-16'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['21-30'], ['6-9'], ['24-3'], ['24-29'], ['14-18'], ['16-30'], ['26-28'], ['15-14'], ['7-4'], ['25-0'], ['20-10'], ['31-16']]\n",
=======
      "Response: The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "[['8-26'], ['11-15'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['7-4'], ['17-22'], ['21-30'], ['12-26'], ['7-12'], ['11-2'], ['31-16'], ['26-28'], ['29-19'], ['21-28'], ['29-21'], ['29-26'], ['6-30'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 94.16701793670654\n",
      "Response: The title of the most recent episode of The Lord of the Rings: The Rings of Power is Shadow and Flame.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_438_irrelevant_misleading/llama-2-7b-80k_id_438_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['7-4'], ['11-15'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['19-15'], ['24-29'], ['11-2'], ['12-26'], ['16-24'], ['17-31'], ['19-10'], ['31-16'], ['6-30'], ['13-11'], ['15-29'], ['21-30'], ['7-12']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 97.80500531196594\n",
      "Response: The Patriots last played the Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['7-4'], ['11-15'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['19-15'], ['24-29'], ['11-2'], ['12-26'], ['16-24'], ['17-31'], ['19-10'], ['31-16'], ['6-30'], ['13-11'], ['15-29'], ['21-30'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 97.80500531196594\n",
      "Response: The Patriots last played the Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['7-4'], ['11-15'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['19-15'], ['24-29'], ['11-2'], ['12-26'], ['16-24'], ['17-31'], ['19-10'], ['31-16'], ['6-30'], ['13-11'], ['15-29'], ['21-30'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 97.80500531196594\n",
      "Response: The Patriots last played the Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['7-4'], ['11-15'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['19-15'], ['24-29'], ['11-2'], ['12-26'], ['16-24'], ['17-31'], ['19-10'], ['31-16'], ['6-30'], ['13-11'], ['15-29'], ['21-30'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 97.80500531196594\n",
      "Response: The Patriots last played the Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_0_depth_7500_results.json\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['7-4'], ['11-15'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['19-15'], ['24-29'], ['11-2'], ['12-26'], ['16-24'], ['17-31'], ['19-10'], ['31-16'], ['6-30'], ['13-11'], ['15-29'], ['21-30'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 97.80500531196594\n",
      "Response: The Patriots last played the Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['18-30'], ['17-22'], ['11-2'], ['19-15'], ['24-29'], ['12-26'], ['16-24'], ['17-31'], ['19-10'], ['31-16'], ['7-12'], ['21-30'], ['6-30'], ['13-11'], ['15-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_1250_depth_0_results.json\n",
      "insertion at 46\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['11-2'], ['18-30'], ['17-22'], ['24-29'], ['19-15'], ['7-12'], ['19-10'], ['16-24'], ['17-31'], ['12-26'], ['31-16'], ['21-30'], ['6-30'], ['13-11'], ['15-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 46\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['11-2'], ['17-22'], ['18-30'], ['24-29'], ['7-12'], ['19-15'], ['19-10'], ['16-24'], ['17-31'], ['12-26'], ['31-16'], ['21-30'], ['14-18'], ['6-30'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 748\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['11-2'], ['17-22'], ['18-30'], ['24-29'], ['7-12'], ['19-15'], ['19-10'], ['17-31'], ['16-24'], ['21-30'], ['12-26'], ['31-16'], ['14-18'], ['6-30'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_1250_depth_7500_results.json\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['11-2'], ['17-22'], ['18-30'], ['24-29'], ['19-15'], ['7-12'], ['12-26'], ['19-10'], ['16-24'], ['31-16'], ['17-31'], ['21-30'], ['14-18'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['11-2'], ['17-22'], ['7-12'], ['18-30'], ['24-29'], ['19-15'], ['12-26'], ['16-24'], ['19-10'], ['31-16'], ['17-31'], ['21-30'], ['14-18'], ['6-30'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 97.80500531196594\n",
      "Response: The Patriots last played the Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_2500_depth_0_results.json\n",
      "insertion at 544\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['11-2'], ['7-12'], ['17-22'], ['18-30'], ['24-29'], ['19-15'], ['16-24'], ['19-10'], ['12-26'], ['17-31'], ['21-30'], ['31-16'], ['14-18'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1115\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['11-2'], ['7-12'], ['17-22'], ['18-30'], ['24-29'], ['19-15'], ['16-24'], ['17-31'], ['19-10'], ['21-30'], ['12-26'], ['14-18'], ['31-16'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1653\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['11-2'], ['7-12'], ['17-22'], ['18-30'], ['24-29'], ['19-15'], ['16-24'], ['17-31'], ['21-30'], ['19-10'], ['14-18'], ['12-26'], ['31-16'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_2500_depth_7500_results.json\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['11-2'], ['17-22'], ['7-12'], ['18-30'], ['19-15'], ['24-29'], ['16-24'], ['21-30'], ['12-26'], ['17-31'], ['14-18'], ['19-10'], ['31-16'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['11-2'], ['7-12'], ['17-22'], ['18-30'], ['19-15'], ['24-29'], ['16-24'], ['21-30'], ['12-26'], ['14-18'], ['17-31'], ['19-10'], ['31-16'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_3750_depth_0_results.json\n",
      "insertion at 858\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['11-2'], ['17-22'], ['18-30'], ['19-15'], ['24-29'], ['16-24'], ['21-30'], ['14-18'], ['12-26'], ['17-31'], ['19-10'], ['31-16'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1653\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['11-2'], ['17-22'], ['18-30'], ['19-15'], ['24-29'], ['16-24'], ['21-30'], ['14-18'], ['17-31'], ['12-26'], ['19-10'], ['31-16'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2546\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['11-2'], ['17-22'], ['18-30'], ['19-15'], ['24-29'], ['16-24'], ['21-30'], ['14-18'], ['17-31'], ['12-26'], ['19-10'], ['6-30'], ['17-0'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_3750_depth_7500_results.json\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['11-2'], ['17-22'], ['18-30'], ['19-15'], ['24-29'], ['21-30'], ['16-24'], ['12-26'], ['14-18'], ['17-31'], ['19-10'], ['17-0'], ['31-16'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['11-2'], ['17-22'], ['18-30'], ['19-15'], ['24-29'], ['21-30'], ['16-24'], ['14-18'], ['12-26'], ['17-31'], ['19-10'], ['17-0'], ['31-16'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.0 seconds\n",
      "Context: 5000 tokens\n",
<<<<<<< Updated upstream
      "Depth: 100%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_relevant_misleading/llama-2-7b-80k_id_422_relevant_misleading_len_5000_depth_10000_results.json\n",
=======
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1115\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['11-2'], ['17-22'], ['18-30'], ['19-15'], ['24-29'], ['21-30'], ['16-24'], ['14-18'], ['17-31'], ['12-26'], ['19-10'], ['17-0'], ['31-16'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2117\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['11-2'], ['17-22'], ['18-30'], ['19-15'], ['21-30'], ['24-29'], ['16-24'], ['14-18'], ['17-31'], ['12-26'], ['19-10'], ['17-0'], ['31-16'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3552\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['11-2'], ['17-22'], ['18-30'], ['19-15'], ['21-30'], ['14-18'], ['24-29'], ['16-24'], ['17-31'], ['12-26'], ['19-10'], ['17-0'], ['31-16'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 92.76299476623535\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024. In New England, Dolphins clinched the AFC East with their win.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_5000_depth_7500_results.json\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['11-2'], ['17-22'], ['19-15'], ['18-30'], ['21-30'], ['16-24'], ['24-29'], ['14-18'], ['12-26'], ['17-31'], ['17-0'], ['19-10'], ['31-16'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant/llama-2-7b-80k_id_439_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_relevant/439.txt\n",
>>>>>>> Stashed changes
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
=======
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.39it/s]\n"
>>>>>>> Stashed changes
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
<<<<<<< Updated upstream
      "- Needle: The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
=======
      "- Needle: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
>>>>>>> Stashed changes
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
<<<<<<< Updated upstream
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['16-19'], ['19-15'], ['6-9'], ['6-30'], ['8-26'], ['11-15'], ['24-3'], ['26-28'], ['7-4'], ['7-31'], ['8-18'], ['8-22'], ['8-31'], ['9-8'], ['10-11'], ['10-29'], ['11-16'], ['11-24'], ['12-5'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['16-19'], ['19-15'], ['6-9'], ['6-30'], ['8-26'], ['11-15'], ['24-3'], ['26-28'], ['7-4'], ['7-31'], ['8-18'], ['8-22'], ['8-31'], ['9-8'], ['10-11'], ['10-29'], ['11-16'], ['11-24'], ['12-5'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['16-19'], ['19-15'], ['6-9'], ['6-30'], ['8-26'], ['11-15'], ['24-3'], ['26-28'], ['7-4'], ['7-31'], ['8-18'], ['8-22'], ['8-31'], ['9-8'], ['10-11'], ['10-29'], ['11-16'], ['11-24'], ['12-5'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['16-19'], ['19-15'], ['6-9'], ['6-30'], ['8-26'], ['11-15'], ['24-3'], ['26-28'], ['7-4'], ['7-31'], ['8-18'], ['8-22'], ['8-31'], ['9-8'], ['10-11'], ['10-29'], ['11-16'], ['11-24'], ['12-5'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_0_depth_7500_results.json\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['16-19'], ['19-15'], ['6-9'], ['6-30'], ['8-26'], ['11-15'], ['24-3'], ['26-28'], ['7-4'], ['7-31'], ['8-18'], ['8-22'], ['8-31'], ['9-8'], ['10-11'], ['10-29'], ['11-16'], ['11-24'], ['12-5'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['19-15'], ['16-19'], ['11-15'], ['24-3'], ['26-28'], ['6-9'], ['6-30'], ['8-26'], ['7-4'], ['7-31'], ['8-31'], ['12-16'], ['13-11'], ['14-7'], ['14-18'], ['16-4'], ['17-0'], ['17-18'], ['17-22'], ['18-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 109\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['19-15'], ['16-19'], ['11-15'], ['24-3'], ['26-28'], ['6-9'], ['8-26'], ['6-30'], ['7-4'], ['14-18'], ['17-0'], ['17-22'], ['19-14'], ['21-1'], ['21-30'], ['24-15'], ['24-29'], ['25-0'], ['7-31'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 109\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['19-15'], ['16-19'], ['11-15'], ['24-3'], ['26-28'], ['6-9'], ['8-26'], ['6-30'], ['7-4'], ['14-18'], ['17-0'], ['17-22'], ['19-14'], ['21-1'], ['21-30'], ['24-15'], ['24-29'], ['25-0'], ['12-26'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 109\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['19-15'], ['16-19'], ['11-15'], ['24-3'], ['26-28'], ['6-9'], ['8-26'], ['6-30'], ['7-4'], ['14-18'], ['17-0'], ['17-22'], ['19-14'], ['21-1'], ['21-30'], ['24-15'], ['24-29'], ['25-0'], ['12-26'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_1250_depth_7500_results.json\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['19-15'], ['16-19'], ['11-15'], ['24-3'], ['26-28'], ['6-9'], ['8-26'], ['6-30'], ['21-30'], ['7-4'], ['17-0'], ['17-22'], ['19-14'], ['21-1'], ['24-15'], ['24-29'], ['25-0'], ['12-26'], ['14-18'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 49.38122034072876\n",
      "Response: William Ruto, the President of Kenya.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 109\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['19-15'], ['16-19'], ['11-15'], ['24-3'], ['26-28'], ['6-9'], ['8-26'], ['6-30'], ['21-30'], ['7-4'], ['17-0'], ['17-22'], ['19-14'], ['21-1'], ['24-29'], ['25-0'], ['14-18'], ['24-15'], ['12-26'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 109\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['19-15'], ['16-19'], ['11-15'], ['24-3'], ['26-28'], ['6-9'], ['8-26'], ['6-30'], ['7-4'], ['17-0'], ['17-22'], ['19-14'], ['21-1'], ['24-29'], ['25-0'], ['21-30'], ['14-18'], ['24-15'], ['12-26'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 109\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['19-15'], ['16-19'], ['11-15'], ['24-3'], ['26-28'], ['6-9'], ['8-26'], ['6-30'], ['7-4'], ['17-0'], ['17-22'], ['19-14'], ['21-1'], ['24-29'], ['25-0'], ['14-18'], ['21-30'], ['20-10'], ['24-15'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_2500_depth_7500_results.json\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['19-15'], ['16-19'], ['11-15'], ['24-3'], ['26-28'], ['6-9'], ['8-26'], ['6-30'], ['7-4'], ['17-0'], ['17-22'], ['19-14'], ['21-1'], ['24-29'], ['25-0'], ['21-30'], ['14-18'], ['31-16'], ['24-15'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['8-26'], ['24-3'], ['26-28'], ['6-9'], ['7-12'], ['17-22'], ['24-29'], ['6-30'], ['21-30'], ['14-18'], ['17-0'], ['19-14'], ['21-1'], ['25-0'], ['7-4'], ['16-30'], ['24-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 109\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['8-26'], ['24-3'], ['26-28'], ['6-9'], ['7-12'], ['17-22'], ['24-29'], ['14-18'], ['6-30'], ['17-0'], ['19-14'], ['21-1'], ['21-30'], ['25-0'], ['7-4'], ['16-30'], ['20-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 54.72884774208069\n",
      "Response: William Ruto.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 109\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['8-26'], ['24-3'], ['26-28'], ['6-9'], ['7-12'], ['17-22'], ['24-29'], ['14-18'], ['17-0'], ['19-14'], ['21-1'], ['25-0'], ['6-30'], ['21-30'], ['7-4'], ['20-10'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 54.72884774208069\n",
      "Response: William Ruto.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 109\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['8-26'], ['24-3'], ['26-28'], ['6-9'], ['7-12'], ['17-22'], ['24-29'], ['14-18'], ['17-0'], ['19-14'], ['21-1'], ['25-0'], ['6-30'], ['21-30'], ['7-4'], ['20-10'], ['17-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 54.72884774208069\n",
      "Response: William Ruto.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_3750_depth_7500_results.json\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['8-26'], ['24-3'], ['26-28'], ['6-9'], ['7-12'], ['17-22'], ['24-29'], ['14-18'], ['17-0'], ['19-14'], ['21-1'], ['25-0'], ['6-30'], ['21-30'], ['7-4'], ['31-16'], ['17-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['7-12'], ['8-26'], ['24-3'], ['6-9'], ['26-28'], ['17-22'], ['24-29'], ['21-30'], ['14-18'], ['19-14'], ['21-1'], ['6-30'], ['17-0'], ['25-0'], ['16-30'], ['18-30'], ['7-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 90.96159934997559\n",
      "Response: The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto, the President of Kenya.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 109\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['7-12'], ['8-26'], ['17-22'], ['24-3'], ['6-9'], ['26-28'], ['21-30'], ['14-18'], ['24-29'], ['11-2'], ['19-14'], ['21-1'], ['17-0'], ['25-0'], ['6-30'], ['16-30'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 109\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['11-15'], ['16-19'], ['7-12'], ['19-15'], ['8-26'], ['17-22'], ['24-3'], ['6-9'], ['21-30'], ['26-28'], ['11-2'], ['14-18'], ['24-29'], ['6-16'], ['19-14'], ['21-1'], ['17-0'], ['25-0'], ['16-30'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 2801\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['11-15'], ['16-19'], ['7-12'], ['19-15'], ['8-26'], ['17-22'], ['24-3'], ['6-9'], ['21-30'], ['26-28'], ['11-2'], ['14-18'], ['24-29'], ['6-16'], ['19-14'], ['21-1'], ['17-0'], ['25-0'], ['16-30'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 54.72884774208069\n",
      "Response: William Ruto.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_5000_depth_7500_results.json\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['11-15'], ['16-19'], ['7-12'], ['19-15'], ['8-26'], ['17-22'], ['24-3'], ['6-9'], ['21-30'], ['26-28'], ['11-2'], ['14-18'], ['24-29'], ['19-14'], ['21-1'], ['6-16'], ['17-0'], ['25-0'], ['6-30'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant/llama-2-7b-80k_id_422_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/422.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['16-19'], ['19-15'], ['6-9'], ['6-30'], ['8-26'], ['11-15'], ['24-3'], ['26-28'], ['7-4'], ['7-31'], ['8-18'], ['8-22'], ['8-31'], ['9-8'], ['10-11'], ['10-29'], ['11-16'], ['11-24'], ['12-5'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant_misleading/llama-2-7b-80k_id_422_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['16-19'], ['19-15'], ['6-9'], ['6-30'], ['8-26'], ['11-15'], ['24-3'], ['26-28'], ['7-4'], ['7-31'], ['8-18'], ['8-22'], ['8-31'], ['9-8'], ['10-11'], ['10-29'], ['11-16'], ['11-24'], ['12-5'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant_misleading/llama-2-7b-80k_id_422_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['16-19'], ['19-15'], ['6-9'], ['6-30'], ['8-26'], ['11-15'], ['24-3'], ['26-28'], ['7-4'], ['7-31'], ['8-18'], ['8-22'], ['8-31'], ['9-8'], ['10-11'], ['10-29'], ['11-16'], ['11-24'], ['12-5'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant_misleading/llama-2-7b-80k_id_422_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['16-19'], ['19-15'], ['6-9'], ['6-30'], ['8-26'], ['11-15'], ['24-3'], ['26-28'], ['7-4'], ['7-31'], ['8-18'], ['8-22'], ['8-31'], ['9-8'], ['10-11'], ['10-29'], ['11-16'], ['11-24'], ['12-5'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant_misleading/llama-2-7b-80k_id_422_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['16-19'], ['19-15'], ['6-9'], ['6-30'], ['8-26'], ['11-15'], ['24-3'], ['26-28'], ['7-4'], ['7-31'], ['8-18'], ['8-22'], ['8-31'], ['9-8'], ['10-11'], ['10-29'], ['11-16'], ['11-24'], ['12-5'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant_misleading/llama-2-7b-80k_id_422_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['19-15'], ['16-19'], ['11-15'], ['6-9'], ['24-3'], ['26-28'], ['6-30'], ['8-26'], ['24-29'], ['25-0'], ['14-18'], ['17-0'], ['18-10'], ['19-9'], ['19-14'], ['21-1'], ['21-30'], ['22-8'], ['22-22'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant_misleading/llama-2-7b-80k_id_422_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 158\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['19-15'], ['16-19'], ['11-15'], ['6-9'], ['24-3'], ['26-28'], ['8-26'], ['6-30'], ['25-0'], ['17-0'], ['19-14'], ['21-1'], ['24-29'], ['31-16'], ['7-4'], ['8-31'], ['12-16'], ['14-7'], ['14-9'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant_misleading/llama-2-7b-80k_id_422_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 158\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['19-15'], ['16-19'], ['11-15'], ['6-9'], ['24-3'], ['26-28'], ['8-26'], ['6-30'], ['25-0'], ['17-0'], ['19-14'], ['21-1'], ['31-16'], ['7-4'], ['8-31'], ['12-16'], ['14-7'], ['14-9'], ['16-30'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant_misleading/llama-2-7b-80k_id_422_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 158\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['19-15'], ['16-19'], ['11-15'], ['6-9'], ['24-3'], ['26-28'], ['8-26'], ['6-30'], ['25-0'], ['17-0'], ['19-14'], ['21-1'], ['31-16'], ['7-4'], ['8-31'], ['12-16'], ['14-7'], ['14-9'], ['16-30'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant_misleading/llama-2-7b-80k_id_422_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['19-15'], ['16-19'], ['6-9'], ['11-15'], ['24-3'], ['26-28'], ['8-26'], ['6-30'], ['31-16'], ['25-0'], ['17-0'], ['19-14'], ['21-1'], ['24-29'], ['7-4'], ['12-16'], ['14-9'], ['16-30'], ['17-22'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant_misleading/llama-2-7b-80k_id_422_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['19-15'], ['16-19'], ['11-15'], ['24-3'], ['26-28'], ['6-9'], ['8-26'], ['6-30'], ['31-16'], ['25-0'], ['17-0'], ['19-14'], ['21-1'], ['24-29'], ['17-22'], ['7-4'], ['12-16'], ['14-9'], ['16-30'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant_misleading/llama-2-7b-80k_id_422_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 158\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['19-15'], ['16-19'], ['11-15'], ['24-3'], ['26-28'], ['6-9'], ['8-26'], ['6-30'], ['31-16'], ['25-0'], ['17-0'], ['19-14'], ['21-1'], ['17-22'], ['24-29'], ['12-16'], ['18-30'], ['7-4'], ['8-31'], ['14-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant_misleading/llama-2-7b-80k_id_422_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 158\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['19-15'], ['16-19'], ['11-15'], ['24-3'], ['26-28'], ['6-9'], ['8-26'], ['6-30'], ['31-16'], ['25-0'], ['17-0'], ['19-14'], ['21-1'], ['17-22'], ['12-16'], ['18-30'], ['24-29'], ['8-31'], ['7-4'], ['14-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant_misleading/llama-2-7b-80k_id_422_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 158\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['19-15'], ['16-19'], ['11-15'], ['24-3'], ['26-28'], ['8-26'], ['6-9'], ['6-30'], ['31-16'], ['25-0'], ['17-0'], ['19-14'], ['21-1'], ['17-22'], ['12-16'], ['18-30'], ['8-31'], ['24-29'], ['14-18'], ['7-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant_misleading/llama-2-7b-80k_id_422_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['19-15'], ['16-19'], ['24-3'], ['26-28'], ['11-15'], ['8-26'], ['6-9'], ['31-16'], ['6-30'], ['25-0'], ['17-0'], ['19-14'], ['21-1'], ['17-22'], ['12-16'], ['18-30'], ['16-24'], ['21-30'], ['24-29'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 55.552440881729126\n",
      "Response: William Ruto\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant_misleading/llama-2-7b-80k_id_422_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['19-15'], ['16-19'], ['24-3'], ['26-28'], ['11-15'], ['8-26'], ['6-9'], ['6-30'], ['31-16'], ['25-0'], ['17-0'], ['17-22'], ['19-14'], ['21-1'], ['12-16'], ['18-30'], ['21-30'], ['24-29'], ['8-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 75.42503476142883\n",
      "Response: William Ruto was in the United States around the time of the state dinner, although his schedule was packed with other meetings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_422_irrelevant_misleading/llama-2-7b-80k_id_422_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 158\n",
      "The guest of honor at the most recent state dinner hosted by the President of the United States was William Ruto.\n",
      "[['19-15'], ['16-19'], ['11-15'], ['24-3'], ['8-26'], ['26-28'], ['17-22'], ['7-12'], ['6-9'], ['31-16'], ['6-30'], ['25-0'], ['17-0'], ['19-14'], ['21-1'], ['14-18'], ['18-30'], ['21-30'], ['24-29'], ['12-16']]\n",
=======
      "Depth: 75%\n",
      "Score: 26.590177416801453\n",
      "Response: Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['7-4'], ['17-22'], ['11-2'], ['12-26'], ['18-30'], ['7-12'], ['22-22'], ['24-8'], ['26-28'], ['6-16'], ['13-11'], ['24-24'], ['24-3']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['7-4'], ['17-22'], ['11-2'], ['7-12'], ['18-30'], ['12-26'], ['22-22'], ['24-8'], ['26-28'], ['6-16'], ['24-3'], ['24-24'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1172\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['17-22'], ['7-4'], ['11-2'], ['7-12'], ['18-30'], ['22-22'], ['12-26'], ['6-16'], ['24-8'], ['24-3'], ['26-28'], ['24-24'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 89.9113416671753\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre. The team leaders arrive at the IMO a few days in advance of the contestants and form the IMO jury which is responsible\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2370\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['17-22'], ['11-2'], ['7-4'], ['7-12'], ['6-16'], ['22-22'], ['18-30'], ['24-8'], ['12-26'], ['24-3'], ['26-28'], ['24-24'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3581\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['17-22'], ['11-2'], ['7-4'], ['7-12'], ['6-16'], ['22-22'], ['18-30'], ['24-8'], ['24-3'], ['12-26'], ['24-24'], ['26-28'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['17-22'], ['11-2'], ['7-4'], ['7-12'], ['18-30'], ['6-16'], ['22-22'], ['12-26'], ['24-8'], ['24-3'], ['24-24'], ['26-28'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The host city of the upcoming International Olympiad in Informatics (IOI) is Sucre.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_578_irrelevant_misleading/llama-2-7b-80k_id_578_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['0-9'], ['6-30'], ['13-11'], ['14-24'], ['19-15'], ['21-30'], ['24-8'], ['0-1'], ['0-14'], ['1-25'], ['6-11'], ['6-17'], ['7-13'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['0-9'], ['6-30'], ['13-11'], ['14-24'], ['19-15'], ['21-30'], ['24-8'], ['0-1'], ['0-14'], ['1-25'], ['6-11'], ['6-17'], ['7-13'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['0-9'], ['6-30'], ['13-11'], ['14-24'], ['19-15'], ['21-30'], ['24-8'], ['0-1'], ['0-14'], ['1-25'], ['6-11'], ['6-17'], ['7-13'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['0-9'], ['6-30'], ['13-11'], ['14-24'], ['19-15'], ['21-30'], ['24-8'], ['0-1'], ['0-14'], ['1-25'], ['6-11'], ['6-17'], ['7-13'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_0_depth_7500_results.json\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['0-9'], ['6-30'], ['13-11'], ['14-24'], ['19-15'], ['21-30'], ['24-8'], ['0-1'], ['0-14'], ['1-25'], ['6-11'], ['6-17'], ['7-13'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['6-30'], ['13-11'], ['19-15'], ['21-30'], ['0-9'], ['14-24'], ['24-8'], ['8-25'], ['8-26'], ['18-15'], ['19-10'], ['22-22'], ['24-3'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_1250_depth_0_results.json\n",
      "insertion at 243\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['19-15'], ['6-30'], ['21-30'], ['13-11'], ['24-8'], ['0-9'], ['14-24'], ['8-26'], ['29-19'], ['18-15'], ['18-30'], ['22-22'], ['24-3'], ['29-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 475\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['19-15'], ['6-30'], ['21-30'], ['24-8'], ['13-11'], ['8-26'], ['0-9'], ['14-24'], ['17-22'], ['18-30'], ['29-19'], ['10-18'], ['21-16'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 755\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['19-15'], ['6-30'], ['21-30'], ['24-8'], ['13-11'], ['8-26'], ['10-18'], ['14-24'], ['17-22'], ['18-30'], ['0-9'], ['21-16'], ['29-19'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_1250_depth_7500_results.json\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['7-4'], ['31-16'], ['19-15'], ['6-30'], ['21-30'], ['24-8'], ['8-26'], ['13-11'], ['17-22'], ['18-30'], ['10-18'], ['14-24'], ['21-16'], ['29-19'], ['0-9'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['19-15'], ['6-30'], ['21-30'], ['8-26'], ['24-8'], ['13-11'], ['17-22'], ['18-30'], ['7-12'], ['10-18'], ['14-24'], ['29-19'], ['21-16'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_2500_depth_0_results.json\n",
      "insertion at 565\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['19-15'], ['8-26'], ['6-30'], ['21-30'], ['24-8'], ['13-11'], ['7-12'], ['10-18'], ['17-22'], ['18-30'], ['29-19'], ['14-24'], ['22-22'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 755\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['7-4'], ['31-16'], ['19-15'], ['8-26'], ['6-30'], ['21-30'], ['24-8'], ['13-11'], ['10-18'], ['7-12'], ['17-22'], ['18-30'], ['29-19'], ['14-24'], ['22-22'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 755\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['19-15'], ['7-4'], ['31-16'], ['8-26'], ['6-30'], ['21-30'], ['24-8'], ['13-11'], ['10-18'], ['7-12'], ['17-22'], ['18-30'], ['29-19'], ['14-24'], ['22-22'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_2500_depth_7500_results.json\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['8-26'], ['19-15'], ['31-16'], ['7-4'], ['6-30'], ['21-30'], ['24-8'], ['13-11'], ['10-18'], ['17-22'], ['18-30'], ['7-12'], ['29-19'], ['29-26'], ['14-24'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['8-26'], ['19-15'], ['7-4'], ['31-16'], ['6-30'], ['21-30'], ['24-8'], ['13-11'], ['7-12'], ['10-18'], ['17-22'], ['18-30'], ['29-19'], ['21-16'], ['22-22'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_3750_depth_0_results.json\n",
      "insertion at 755\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['19-15'], ['31-16'], ['7-4'], ['6-30'], ['21-30'], ['24-8'], ['13-11'], ['7-12'], ['10-18'], ['17-22'], ['18-30'], ['29-19'], ['22-22'], ['24-3'], ['29-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 755\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['19-15'], ['31-16'], ['6-30'], ['7-4'], ['21-30'], ['24-8'], ['7-12'], ['13-11'], ['10-18'], ['17-22'], ['18-30'], ['29-19'], ['24-30'], ['22-22'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2492\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['19-15'], ['31-16'], ['6-30'], ['7-4'], ['21-30'], ['24-8'], ['7-12'], ['17-22'], ['13-11'], ['10-18'], ['18-30'], ['29-19'], ['15-14'], ['24-30'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_3750_depth_7500_results.json\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['19-15'], ['6-30'], ['31-16'], ['7-4'], ['21-30'], ['24-8'], ['17-22'], ['7-12'], ['13-11'], ['10-18'], ['18-30'], ['29-26'], ['29-19'], ['24-30'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['19-15'], ['31-16'], ['6-30'], ['7-4'], ['21-30'], ['24-8'], ['7-12'], ['17-22'], ['13-11'], ['10-18'], ['18-30'], ['29-19'], ['29-26'], ['29-21'], ['24-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 60.03795862197876\n",
      "Response: In the Shadow of the Cypress (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_5000_depth_0_results.json\n",
      "insertion at 755\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['19-15'], ['31-16'], ['6-30'], ['7-4'], ['21-30'], ['7-12'], ['24-8'], ['17-22'], ['13-11'], ['10-18'], ['18-30'], ['29-26'], ['29-19'], ['29-21'], ['24-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 755\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['19-15'], ['31-16'], ['6-30'], ['7-4'], ['21-30'], ['7-12'], ['24-8'], ['17-22'], ['13-11'], ['10-18'], ['18-30'], ['29-26'], ['29-21'], ['24-30'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 2492\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['24-29'], ['31-16'], ['6-30'], ['21-30'], ['7-4'], ['7-12'], ['24-8'], ['17-22'], ['10-18'], ['13-11'], ['18-30'], ['29-26'], ['29-21'], ['24-30'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 55.0794243812561\n",
      "Response: In the Shadow of the Cypress, 2023\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_5000_depth_7500_results.json\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['19-15'], ['31-16'], ['6-30'], ['21-30'], ['7-4'], ['24-8'], ['7-12'], ['17-22'], ['13-11'], ['10-18'], ['18-30'], ['29-26'], ['29-21'], ['24-30'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant/llama-2-7b-80k_id_579_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/579.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['0-9'], ['6-30'], ['13-11'], ['14-24'], ['19-15'], ['21-30'], ['24-8'], ['0-1'], ['0-14'], ['1-25'], ['6-11'], ['6-17'], ['7-13'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['0-9'], ['6-30'], ['13-11'], ['14-24'], ['19-15'], ['21-30'], ['24-8'], ['0-1'], ['0-14'], ['1-25'], ['6-11'], ['6-17'], ['7-13'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['0-9'], ['6-30'], ['13-11'], ['14-24'], ['19-15'], ['21-30'], ['24-8'], ['0-1'], ['0-14'], ['1-25'], ['6-11'], ['6-17'], ['7-13'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['0-9'], ['6-30'], ['13-11'], ['14-24'], ['19-15'], ['21-30'], ['24-8'], ['0-1'], ['0-14'], ['1-25'], ['6-11'], ['6-17'], ['7-13'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_0_depth_7500_results.json\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['0-9'], ['6-30'], ['13-11'], ['14-24'], ['19-15'], ['21-30'], ['24-8'], ['0-1'], ['0-14'], ['1-25'], ['6-11'], ['6-17'], ['7-13'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['31-16'], ['7-4'], ['19-15'], ['21-30'], ['0-9'], ['6-30'], ['13-11'], ['14-24'], ['24-8'], ['19-10'], ['29-21'], ['16-24'], ['17-22'], ['18-15'], ['21-16'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 243\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['31-16'], ['19-15'], ['7-4'], ['21-30'], ['24-8'], ['6-30'], ['13-11'], ['0-9'], ['14-24'], ['17-22'], ['29-21'], ['29-19'], ['19-10'], ['16-24'], ['18-15'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 493\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['31-16'], ['19-15'], ['7-4'], ['21-30'], ['24-8'], ['6-30'], ['13-11'], ['29-21'], ['17-22'], ['0-9'], ['14-24'], ['12-26'], ['16-24'], ['19-10'], ['29-19'], ['8-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 756\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['24-29'], ['31-16'], ['21-30'], ['7-4'], ['24-8'], ['6-30'], ['13-11'], ['17-22'], ['29-21'], ['12-26'], ['8-26'], ['16-24'], ['15-14'], ['18-30'], ['0-9'], ['14-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_1250_depth_7500_results.json\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['24-29'], ['31-16'], ['21-30'], ['7-4'], ['6-30'], ['8-26'], ['24-8'], ['12-26'], ['17-22'], ['13-11'], ['29-21'], ['29-19'], ['15-14'], ['16-24'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['24-29'], ['31-16'], ['21-30'], ['7-4'], ['6-30'], ['8-26'], ['24-8'], ['12-26'], ['17-22'], ['29-21'], ['13-11'], ['29-19'], ['16-24'], ['15-14'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 493\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['24-29'], ['31-16'], ['21-30'], ['7-4'], ['8-26'], ['6-30'], ['24-8'], ['17-22'], ['29-21'], ['12-26'], ['13-11'], ['29-19'], ['15-14'], ['16-24'], ['18-30'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 810\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['24-29'], ['21-30'], ['31-16'], ['8-26'], ['6-30'], ['7-4'], ['17-22'], ['24-8'], ['15-14'], ['29-21'], ['13-11'], ['12-26'], ['29-19'], ['10-18'], ['18-30'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 810\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['21-30'], ['24-29'], ['31-16'], ['8-26'], ['6-30'], ['7-4'], ['17-22'], ['15-14'], ['24-8'], ['29-21'], ['13-11'], ['29-19'], ['10-18'], ['12-26'], ['18-30'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_2500_depth_7500_results.json\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['24-29'], ['21-30'], ['31-16'], ['8-26'], ['6-30'], ['7-4'], ['17-22'], ['24-8'], ['15-14'], ['29-21'], ['13-11'], ['29-19'], ['10-18'], ['12-26'], ['18-30'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['21-30'], ['24-29'], ['31-16'], ['8-26'], ['6-30'], ['17-22'], ['24-8'], ['7-4'], ['15-14'], ['29-21'], ['29-19'], ['13-11'], ['10-18'], ['12-26'], ['18-30'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 810\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['21-30'], ['24-29'], ['31-16'], ['8-26'], ['6-30'], ['17-22'], ['24-8'], ['15-14'], ['7-4'], ['29-21'], ['13-11'], ['10-18'], ['29-19'], ['18-30'], ['12-26'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 810\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['21-30'], ['24-29'], ['8-26'], ['31-16'], ['6-30'], ['15-14'], ['17-22'], ['24-8'], ['29-21'], ['10-18'], ['13-11'], ['7-4'], ['29-19'], ['18-30'], ['7-12'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2547\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['8-26'], ['21-30'], ['24-29'], ['31-16'], ['17-22'], ['6-30'], ['24-8'], ['15-14'], ['7-4'], ['10-18'], ['13-11'], ['29-21'], ['29-19'], ['18-30'], ['7-12'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_3750_depth_7500_results.json\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['8-26'], ['21-30'], ['24-29'], ['31-16'], ['6-30'], ['17-22'], ['24-8'], ['7-4'], ['15-14'], ['10-18'], ['29-21'], ['13-11'], ['29-19'], ['18-30'], ['7-12'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 8.540207892656326\n",
      "Response: The House That Jack Built.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 810\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['8-26'], ['21-30'], ['24-29'], ['31-16'], ['17-22'], ['6-30'], ['24-8'], ['15-14'], ['10-18'], ['7-4'], ['13-11'], ['29-21'], ['29-19'], ['18-30'], ['7-12'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 810\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['8-26'], ['21-30'], ['24-29'], ['31-16'], ['17-22'], ['6-30'], ['24-8'], ['15-14'], ['10-18'], ['7-4'], ['29-21'], ['13-11'], ['29-19'], ['7-12'], ['18-30'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 2547\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 6.054239720106125\n",
      "Response: The House That Jack Built\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_5000_depth_7500_results.json\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['8-26'], ['24-29'], ['21-30'], ['31-16'], ['6-30'], ['17-22'], ['24-8'], ['15-14'], ['10-18'], ['7-4'], ['13-11'], ['29-21'], ['29-19'], ['18-30'], ['7-12'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_relevant_misleading/llama-2-7b-80k_id_579_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['0-9'], ['6-30'], ['13-11'], ['14-24'], ['19-15'], ['21-30'], ['24-8'], ['0-1'], ['0-14'], ['1-25'], ['6-11'], ['6-17'], ['7-13'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['0-9'], ['6-30'], ['13-11'], ['14-24'], ['19-15'], ['21-30'], ['24-8'], ['0-1'], ['0-14'], ['1-25'], ['6-11'], ['6-17'], ['7-13'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['0-9'], ['6-30'], ['13-11'], ['14-24'], ['19-15'], ['21-30'], ['24-8'], ['0-1'], ['0-14'], ['1-25'], ['6-11'], ['6-17'], ['7-13'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['0-9'], ['6-30'], ['13-11'], ['14-24'], ['19-15'], ['21-30'], ['24-8'], ['0-1'], ['0-14'], ['1-25'], ['6-11'], ['6-17'], ['7-13'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_0_depth_7500_results.json\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['0-9'], ['6-30'], ['13-11'], ['14-24'], ['19-15'], ['21-30'], ['24-8'], ['0-1'], ['0-14'], ['1-25'], ['6-11'], ['6-17'], ['7-13'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 10.090766847133636\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 256\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['7-4'], ['31-16'], ['6-30'], ['19-15'], ['24-8'], ['13-11'], ['21-30'], ['8-26'], ['0-9'], ['14-24'], ['17-22'], ['8-25'], ['14-9'], ['14-29'], ['16-30'], ['18-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 492\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['7-4'], ['31-16'], ['8-26'], ['6-30'], ['19-15'], ['24-8'], ['13-11'], ['21-30'], ['17-22'], ['0-9'], ['14-24'], ['7-12'], ['14-9'], ['18-30'], ['22-22'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 722\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['8-26'], ['6-30'], ['19-15'], ['24-8'], ['13-11'], ['17-22'], ['21-30'], ['14-24'], ['0-9'], ['7-12'], ['14-9'], ['18-30'], ['22-22'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_1250_depth_7500_results.json\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['7-4'], ['31-16'], ['8-26'], ['6-30'], ['24-8'], ['19-15'], ['17-22'], ['13-11'], ['21-30'], ['14-24'], ['0-9'], ['7-12'], ['14-9'], ['18-30'], ['22-22'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 10.090766847133636\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 492\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['8-26'], ['7-4'], ['31-16'], ['6-30'], ['24-8'], ['19-15'], ['17-22'], ['21-30'], ['13-11'], ['7-12'], ['14-24'], ['0-9'], ['8-22'], ['22-22'], ['24-3'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1005\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['7-4'], ['31-16'], ['6-30'], ['19-15'], ['24-8'], ['17-22'], ['21-30'], ['13-11'], ['7-12'], ['14-24'], ['22-22'], ['24-3'], ['29-19'], ['29-21'], ['0-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1669\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 45.60868442058563\n",
      "Response: In the Shadow of the Cypress, by Griffith & Harold Prince\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_2500_depth_7500_results.json\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['31-16'], ['7-4'], ['6-30'], ['19-15'], ['24-8'], ['17-22'], ['21-30'], ['13-11'], ['7-12'], ['14-24'], ['22-22'], ['24-3'], ['29-19'], ['29-21'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 27.852723002433777\n",
      "Response: The Outsiders (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 808\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['31-16'], ['7-4'], ['6-30'], ['19-15'], ['24-8'], ['17-22'], ['21-30'], ['13-11'], ['7-12'], ['14-24'], ['22-22'], ['24-3'], ['29-19'], ['29-21'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1669\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['17-22'], ['7-4'], ['19-15'], ['31-16'], ['6-30'], ['21-30'], ['24-8'], ['7-12'], ['13-11'], ['14-24'], ['24-3'], ['29-19'], ['8-22'], ['22-22'], ['29-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2636\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['17-22'], ['7-4'], ['19-15'], ['31-16'], ['6-30'], ['21-30'], ['24-8'], ['7-12'], ['13-11'], ['14-24'], ['24-3'], ['29-19'], ['8-22'], ['22-22'], ['29-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_3750_depth_7500_results.json\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['17-22'], ['31-16'], ['19-15'], ['7-4'], ['6-30'], ['24-8'], ['21-30'], ['7-12'], ['13-11'], ['8-22'], ['14-24'], ['24-3'], ['29-19'], ['22-22'], ['29-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 10.090766847133636\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1005\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['17-22'], ['19-15'], ['31-16'], ['6-30'], ['7-4'], ['24-8'], ['21-30'], ['7-12'], ['13-11'], ['8-22'], ['14-24'], ['24-3'], ['29-19'], ['22-22'], ['29-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2337\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['17-22'], ['19-15'], ['31-16'], ['6-30'], ['7-4'], ['24-8'], ['7-12'], ['21-30'], ['13-11'], ['8-22'], ['14-24'], ['24-3'], ['29-19'], ['22-22'], ['29-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3403\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['17-22'], ['19-15'], ['7-12'], ['31-16'], ['6-30'], ['7-4'], ['21-30'], ['24-8'], ['13-11'], ['8-22'], ['29-19'], ['14-24'], ['24-3'], ['22-22'], ['29-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 82.44823813438416\n",
      "Response: In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film. Richard Nash, Music by John Kander, Lyrics by Fred Ebb\",David Merrick\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_5000_depth_7500_results.json\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['17-22'], ['19-15'], ['31-16'], ['6-30'], ['7-12'], ['21-30'], ['7-4'], ['24-8'], ['13-11'], ['8-22'], ['29-19'], ['14-24'], ['24-3'], ['22-22'], ['29-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant/llama-2-7b-80k_id_579_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/579.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['0-9'], ['6-30'], ['13-11'], ['14-24'], ['19-15'], ['21-30'], ['24-8'], ['0-1'], ['0-14'], ['1-25'], ['6-11'], ['6-17'], ['7-13'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['0-9'], ['6-30'], ['13-11'], ['14-24'], ['19-15'], ['21-30'], ['24-8'], ['0-1'], ['0-14'], ['1-25'], ['6-11'], ['6-17'], ['7-13'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['0-9'], ['6-30'], ['13-11'], ['14-24'], ['19-15'], ['21-30'], ['24-8'], ['0-1'], ['0-14'], ['1-25'], ['6-11'], ['6-17'], ['7-13'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['0-9'], ['6-30'], ['13-11'], ['14-24'], ['19-15'], ['21-30'], ['24-8'], ['0-1'], ['0-14'], ['1-25'], ['6-11'], ['6-17'], ['7-13'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['0-9'], ['6-30'], ['13-11'], ['14-24'], ['19-15'], ['21-30'], ['24-8'], ['0-1'], ['0-14'], ['1-25'], ['6-11'], ['6-17'], ['7-13'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 12.416800111532211\n",
      "Response: \"The Windshield Wiper\"\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 256\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['7-4'], ['31-16'], ['6-30'], ['19-15'], ['21-30'], ['24-8'], ['13-11'], ['8-26'], ['14-24'], ['0-9'], ['17-22'], ['8-22'], ['8-25'], ['14-9'], ['14-29'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 510\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['7-4'], ['31-16'], ['8-26'], ['6-30'], ['19-15'], ['24-8'], ['21-30'], ['13-11'], ['17-22'], ['14-24'], ['0-9'], ['7-12'], ['8-22'], ['14-9'], ['14-29'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 740\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['24-29'], ['31-16'], ['8-26'], ['6-30'], ['19-15'], ['24-8'], ['21-30'], ['13-11'], ['17-22'], ['14-24'], ['0-9'], ['7-12'], ['8-22'], ['14-9'], ['14-29'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['7-4'], ['31-16'], ['8-26'], ['6-30'], ['24-8'], ['19-15'], ['17-22'], ['21-30'], ['13-11'], ['14-24'], ['0-9'], ['7-12'], ['14-9'], ['18-30'], ['22-22'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 27.852723002433777\n",
      "Response: The Outsiders (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 510\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['31-16'], ['7-4'], ['8-26'], ['6-30'], ['19-15'], ['24-8'], ['21-30'], ['17-22'], ['13-11'], ['14-24'], ['7-12'], ['0-9'], ['14-9'], ['18-30'], ['22-22'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1023\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['31-16'], ['8-26'], ['7-4'], ['19-15'], ['6-30'], ['24-8'], ['21-30'], ['17-22'], ['13-11'], ['7-12'], ['14-24'], ['14-9'], ['18-30'], ['22-22'], ['29-19'], ['0-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1700\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['8-26'], ['31-16'], ['7-4'], ['19-15'], ['24-8'], ['6-30'], ['21-30'], ['17-22'], ['13-11'], ['7-12'], ['14-24'], ['14-9'], ['18-30'], ['22-22'], ['29-19'], ['14-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 63.21929693222046\n",
      "Response: In the Shadow of the Cypress\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['8-26'], ['31-16'], ['7-4'], ['19-15'], ['24-8'], ['6-30'], ['21-30'], ['17-22'], ['13-11'], ['7-12'], ['14-24'], ['18-30'], ['14-9'], ['22-22'], ['29-19'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 43.42797100543976\n",
      "Response: The Oscar for Best Animated Short Film went to a different movie this year. How Now, Dow Jones Book by Max Shulman, Music by Elmer Bernstein, Lyrics by Alan Jay Lerner\",David Merrick\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 826\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 23.814165592193604\n",
      "Response: \"The Simpsons Movie\"\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1700\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "-- Test Summary -- \n",
      "Duration: 3.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 43.42797100543976\n",
      "Response: The Oscar for Best Animated Short Film went to a different movie this year. How Now, Dow Jones Book by Max Shulman, Music by Elmer Bernstein, Lyrics by Alan Jay Lerner\",David Merrick\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2392\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['8-26'], ['31-16'], ['7-4'], ['19-15'], ['24-8'], ['6-30'], ['21-30'], ['17-22'], ['13-11'], ['7-12'], ['14-24'], ['18-30'], ['14-9'], ['22-22'], ['29-19'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 61.74280047416687\n",
      "Response: The Oscar for Best Animated Short Film went to a movie called \"Hair Love.\"\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['8-26'], ['31-16'], ['19-15'], ['6-30'], ['7-4'], ['24-8'], ['21-30'], ['17-22'], ['13-11'], ['7-12'], ['14-24'], ['18-30'], ['14-9'], ['22-22'], ['29-19'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 2.0946046337485313\n",
      "Response: The Wiz Book by William F. Brown, Music & Lyrics by Charlie Smalls\",Robert Stigwood\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1023\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "-- Test Summary -- \n",
      "Duration: 3.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 4.028676450252533\n",
      "Response: The Wiz. by William F. Brown, Music by Charlie Smalls, Lyrics by Smalls and Luther Henderson\",Robert Stigwood\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2258\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "-- Test Summary -- \n",
      "Duration: 3.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 1.3476227410137653\n",
      "Response: The Wiz Book by William F. Brown, Music by Charlie Smalls, Lyrics by Smalls and Luther Henderson\",Robert Stigwood\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3476\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 31.099694967269897\n",
      "Response: The Oscar went to a short film with a tree in its title. by William F. Brown, Music & Lyrics by Charlie Smalls\",Robert Stigwood\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "In the Shadow of the Cypress won the latest Academy Award for Best Animated Short Film.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['8-26'], ['31-16'], ['6-30'], ['19-15'], ['7-4'], ['24-8'], ['21-30'], ['17-22'], ['13-11'], ['7-12'], ['14-24'], ['18-30'], ['8-22'], ['14-9'], ['22-22'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 57.79562592506409\n",
      "Response: In the Shadow of the Cypress.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_579_irrelevant_misleading/llama-2-7b-80k_id_579_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['8-26'], ['16-24'], ['17-22'], ['21-30'], ['24-29'], ['31-16'], ['6-30'], ['7-4'], ['11-15'], ['12-26'], ['13-11'], ['15-5'], ['15-14'], ['16-30'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['8-26'], ['16-24'], ['17-22'], ['21-30'], ['24-29'], ['31-16'], ['6-30'], ['7-4'], ['11-15'], ['12-26'], ['13-11'], ['15-5'], ['15-14'], ['16-30'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['8-26'], ['16-24'], ['17-22'], ['21-30'], ['24-29'], ['31-16'], ['6-30'], ['7-4'], ['11-15'], ['12-26'], ['13-11'], ['15-5'], ['15-14'], ['16-30'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['8-26'], ['16-24'], ['17-22'], ['21-30'], ['24-29'], ['31-16'], ['6-30'], ['7-4'], ['11-15'], ['12-26'], ['13-11'], ['15-5'], ['15-14'], ['16-30'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_0_depth_7500_results.json\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['8-26'], ['16-24'], ['17-22'], ['21-30'], ['24-29'], ['31-16'], ['6-30'], ['7-4'], ['11-15'], ['12-26'], ['13-11'], ['15-5'], ['15-14'], ['16-30'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['8-26'], ['17-22'], ['24-29'], ['16-24'], ['21-30'], ['31-16'], ['11-15'], ['15-14'], ['20-8'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['15-5'], ['16-30'], ['17-0'], ['19-9'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_1250_depth_0_results.json\n",
      "insertion at 240\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['17-22'], ['24-29'], ['8-26'], ['16-24'], ['21-30'], ['31-16'], ['11-15'], ['15-14'], ['20-8'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['15-5'], ['16-30'], ['17-0'], ['19-9'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 490\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['17-22'], ['24-29'], ['8-26'], ['21-30'], ['16-24'], ['31-16'], ['11-15'], ['15-14'], ['20-8'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['15-5'], ['16-30'], ['17-0'], ['19-9'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 722\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['8-26'], ['16-24'], ['31-16'], ['13-11'], ['17-0'], ['11-15'], ['15-14'], ['20-8'], ['6-30'], ['7-4'], ['12-26'], ['15-5'], ['16-30'], ['19-9'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_1250_depth_7500_results.json\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['8-26'], ['16-24'], ['31-16'], ['13-11'], ['17-0'], ['11-15'], ['15-14'], ['20-8'], ['6-30'], ['7-4'], ['16-30'], ['19-9'], ['19-10'], ['19-13'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['8-26'], ['21-30'], ['16-24'], ['31-16'], ['13-11'], ['11-15'], ['15-14'], ['20-8'], ['17-0'], ['6-30'], ['7-4'], ['16-30'], ['19-9'], ['19-10'], ['19-13'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_2500_depth_0_results.json\n",
      "insertion at 567\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['8-26'], ['21-30'], ['16-24'], ['31-16'], ['13-11'], ['11-15'], ['15-14'], ['20-8'], ['17-0'], ['6-30'], ['7-4'], ['16-30'], ['19-9'], ['19-10'], ['19-13'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1130\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['8-26'], ['16-24'], ['31-16'], ['13-11'], ['11-15'], ['15-14'], ['20-8'], ['17-0'], ['6-30'], ['7-4'], ['16-30'], ['19-9'], ['19-10'], ['19-13'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1687\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['8-26'], ['16-24'], ['31-16'], ['13-11'], ['11-15'], ['15-14'], ['20-8'], ['17-0'], ['6-30'], ['7-4'], ['16-30'], ['18-30'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_2500_depth_7500_results.json\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['8-26'], ['16-24'], ['31-16'], ['13-11'], ['11-15'], ['15-14'], ['20-8'], ['17-0'], ['6-30'], ['7-4'], ['16-30'], ['18-30'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['8-26'], ['16-24'], ['31-16'], ['11-15'], ['13-11'], ['15-14'], ['20-8'], ['17-0'], ['6-30'], ['7-4'], ['7-12'], ['16-30'], ['18-30'], ['19-9'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 58.9897096157074\n",
      "Response: Hurricane Milton, Hurricane Milton, Hurricane Milton, Hurricane Milton, Hurricane Milton, Hurricane Milton, Hurricane Milton, Hurricane Milton, Hurr\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_3750_depth_0_results.json\n",
      "insertion at 835\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['8-26'], ['16-24'], ['31-16'], ['11-15'], ['13-11'], ['15-14'], ['20-8'], ['17-0'], ['6-30'], ['7-4'], ['7-12'], ['16-30'], ['18-30'], ['19-9'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1731\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['8-26'], ['16-24'], ['31-16'], ['11-15'], ['13-11'], ['15-14'], ['20-8'], ['17-0'], ['6-30'], ['7-4'], ['7-12'], ['16-30'], ['18-30'], ['19-9'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2393\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['8-26'], ['16-24'], ['31-16'], ['11-15'], ['13-11'], ['15-14'], ['20-8'], ['17-0'], ['6-30'], ['7-4'], ['7-12'], ['16-30'], ['18-30'], ['19-9'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_3750_depth_7500_results.json\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['16-24'], ['8-26'], ['31-16'], ['11-15'], ['13-11'], ['15-14'], ['20-8'], ['17-0'], ['6-30'], ['7-4'], ['16-30'], ['18-30'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['8-26'], ['16-24'], ['31-16'], ['11-15'], ['13-11'], ['15-14'], ['20-8'], ['17-0'], ['18-30'], ['6-30'], ['7-4'], ['7-12'], ['16-30'], ['19-9'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 78.34653854370117\n",
      "Response: Hurricane Milton, Hurricane Milton, Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1173\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['8-26'], ['16-24'], ['31-16'], ['11-15'], ['15-14'], ['13-11'], ['20-8'], ['17-0'], ['18-30'], ['6-30'], ['7-4'], ['7-12'], ['16-30'], ['19-9'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2351\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['8-26'], ['16-24'], ['31-16'], ['11-15'], ['15-14'], ['13-11'], ['20-8'], ['17-0'], ['18-30'], ['6-30'], ['7-4'], ['7-12'], ['16-30'], ['19-9'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 2393\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['8-26'], ['16-24'], ['31-16'], ['11-15'], ['15-14'], ['13-11'], ['18-30'], ['20-8'], ['17-0'], ['6-30'], ['7-4'], ['7-12'], ['16-30'], ['19-9'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_5000_depth_7500_results.json\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['8-26'], ['16-24'], ['31-16'], ['11-15'], ['15-14'], ['13-11'], ['18-30'], ['20-8'], ['17-0'], ['6-30'], ['7-4'], ['16-30'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant/llama-2-7b-80k_id_586_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/586.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['8-26'], ['16-24'], ['17-22'], ['21-30'], ['24-29'], ['31-16'], ['6-30'], ['7-4'], ['11-15'], ['12-26'], ['13-11'], ['15-5'], ['15-14'], ['16-30'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['8-26'], ['16-24'], ['17-22'], ['21-30'], ['24-29'], ['31-16'], ['6-30'], ['7-4'], ['11-15'], ['12-26'], ['13-11'], ['15-5'], ['15-14'], ['16-30'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['8-26'], ['16-24'], ['17-22'], ['21-30'], ['24-29'], ['31-16'], ['6-30'], ['7-4'], ['11-15'], ['12-26'], ['13-11'], ['15-5'], ['15-14'], ['16-30'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['8-26'], ['16-24'], ['17-22'], ['21-30'], ['24-29'], ['31-16'], ['6-30'], ['7-4'], ['11-15'], ['12-26'], ['13-11'], ['15-5'], ['15-14'], ['16-30'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_0_depth_7500_results.json\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['8-26'], ['16-24'], ['17-22'], ['21-30'], ['24-29'], ['31-16'], ['6-30'], ['7-4'], ['11-15'], ['12-26'], ['13-11'], ['15-5'], ['15-14'], ['16-30'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['8-26'], ['16-24'], ['17-22'], ['21-30'], ['31-16'], ['11-15'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['15-5'], ['15-14'], ['16-30'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 240\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['8-26'], ['16-24'], ['21-30'], ['31-16'], ['11-15'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['15-5'], ['15-14'], ['16-30'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 508\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['21-30'], ['17-22'], ['8-26'], ['16-24'], ['31-16'], ['11-15'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['15-5'], ['15-14'], ['16-30'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 740\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['21-30'], ['17-22'], ['8-26'], ['16-24'], ['31-16'], ['13-11'], ['16-30'], ['11-15'], ['6-30'], ['7-4'], ['12-26'], ['15-5'], ['15-14'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['21-30'], ['17-22'], ['8-26'], ['31-16'], ['16-24'], ['13-11'], ['16-30'], ['17-0'], ['11-15'], ['6-30'], ['7-4'], ['15-5'], ['18-30'], ['19-9'], ['19-10'], ['19-13'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['21-30'], ['17-22'], ['8-26'], ['31-16'], ['16-24'], ['13-11'], ['16-30'], ['17-0'], ['11-15'], ['6-30'], ['7-4'], ['15-5'], ['19-9'], ['19-10'], ['19-13'], ['20-8'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 558\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['21-30'], ['17-22'], ['8-26'], ['31-16'], ['16-24'], ['13-11'], ['16-30'], ['17-0'], ['11-15'], ['18-30'], ['6-30'], ['7-4'], ['15-5'], ['19-9'], ['19-10'], ['19-13'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1124\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['21-30'], ['17-22'], ['8-26'], ['31-16'], ['16-24'], ['13-11'], ['17-0'], ['18-30'], ['16-30'], ['11-15'], ['6-30'], ['7-4'], ['15-5'], ['19-9'], ['19-10'], ['19-13'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1670\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['21-30'], ['17-22'], ['8-26'], ['31-16'], ['16-24'], ['17-0'], ['18-30'], ['13-11'], ['16-30'], ['11-15'], ['6-30'], ['7-4'], ['15-5'], ['19-9'], ['19-10'], ['19-13'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['21-30'], ['17-22'], ['8-26'], ['31-16'], ['16-24'], ['17-0'], ['18-30'], ['13-11'], ['16-30'], ['11-15'], ['6-30'], ['7-4'], ['15-5'], ['19-9'], ['19-10'], ['19-13'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['21-30'], ['17-22'], ['8-26'], ['31-16'], ['16-24'], ['17-0'], ['18-30'], ['13-11'], ['11-15'], ['16-30'], ['6-30'], ['7-4'], ['15-5'], ['19-9'], ['19-10'], ['19-13'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 876\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['21-30'], ['17-22'], ['8-26'], ['16-24'], ['31-16'], ['13-11'], ['17-0'], ['18-30'], ['11-15'], ['16-30'], ['19-9'], ['20-8'], ['6-30'], ['7-4'], ['15-5'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1737\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['21-30'], ['17-22'], ['8-26'], ['16-24'], ['31-16'], ['13-11'], ['17-0'], ['18-30'], ['11-15'], ['16-30'], ['19-9'], ['20-8'], ['6-30'], ['7-4'], ['15-5'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2502\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['21-30'], ['17-22'], ['8-26'], ['16-24'], ['31-16'], ['17-0'], ['18-30'], ['13-11'], ['11-15'], ['16-30'], ['19-9'], ['20-8'], ['6-30'], ['7-4'], ['15-5'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['21-30'], ['17-22'], ['16-24'], ['8-26'], ['31-16'], ['18-30'], ['17-0'], ['13-11'], ['11-15'], ['16-30'], ['19-9'], ['20-8'], ['6-30'], ['7-4'], ['19-10'], ['19-13'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['21-30'], ['17-22'], ['16-24'], ['8-26'], ['31-16'], ['18-30'], ['17-0'], ['13-11'], ['20-8'], ['11-15'], ['16-30'], ['19-9'], ['6-30'], ['7-4'], ['19-10'], ['19-13'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1171\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['21-30'], ['17-22'], ['16-24'], ['8-26'], ['18-30'], ['31-16'], ['17-0'], ['13-11'], ['20-8'], ['11-15'], ['16-30'], ['19-9'], ['6-30'], ['7-4'], ['19-10'], ['19-13'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2385\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['21-30'], ['17-22'], ['16-24'], ['18-30'], ['8-26'], ['31-16'], ['17-0'], ['13-11'], ['20-8'], ['11-15'], ['16-30'], ['19-9'], ['6-30'], ['7-4'], ['19-10'], ['19-13'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 2502\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['21-30'], ['17-22'], ['18-30'], ['16-24'], ['8-26'], ['17-0'], ['31-16'], ['13-11'], ['20-8'], ['16-30'], ['19-9'], ['11-15'], ['6-30'], ['7-4'], ['19-10'], ['19-13'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['21-30'], ['17-22'], ['18-30'], ['16-24'], ['8-26'], ['31-16'], ['17-0'], ['13-11'], ['20-8'], ['11-15'], ['19-9'], ['15-14'], ['16-30'], ['6-30'], ['7-4'], ['19-13'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_relevant_misleading/llama-2-7b-80k_id_586_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['8-26'], ['16-24'], ['17-22'], ['21-30'], ['24-29'], ['31-16'], ['6-30'], ['7-4'], ['11-15'], ['12-26'], ['13-11'], ['15-5'], ['15-14'], ['16-30'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['8-26'], ['16-24'], ['17-22'], ['21-30'], ['24-29'], ['31-16'], ['6-30'], ['7-4'], ['11-15'], ['12-26'], ['13-11'], ['15-5'], ['15-14'], ['16-30'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['8-26'], ['16-24'], ['17-22'], ['21-30'], ['24-29'], ['31-16'], ['6-30'], ['7-4'], ['11-15'], ['12-26'], ['13-11'], ['15-5'], ['15-14'], ['16-30'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['8-26'], ['16-24'], ['17-22'], ['21-30'], ['24-29'], ['31-16'], ['6-30'], ['7-4'], ['11-15'], ['12-26'], ['13-11'], ['15-5'], ['15-14'], ['16-30'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_0_depth_7500_results.json\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['8-26'], ['16-24'], ['17-22'], ['21-30'], ['24-29'], ['31-16'], ['6-30'], ['7-4'], ['11-15'], ['12-26'], ['13-11'], ['15-5'], ['15-14'], ['16-30'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 48.02330136299133\n",
      "Response: Hurricane Katrina\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 237\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['8-26'], ['16-24'], ['17-22'], ['21-30'], ['31-16'], ['13-11'], ['17-0'], ['6-30'], ['7-4'], ['11-15'], ['12-26'], ['15-5'], ['15-14'], ['16-30'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 489\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['21-30'], ['24-29'], ['8-26'], ['16-24'], ['17-22'], ['31-16'], ['17-0'], ['13-11'], ['6-30'], ['7-4'], ['11-15'], ['12-26'], ['15-5'], ['15-14'], ['16-30'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 758\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['21-30'], ['24-29'], ['8-26'], ['16-24'], ['17-22'], ['31-16'], ['17-0'], ['13-11'], ['22-8'], ['22-27'], ['6-30'], ['7-4'], ['11-15'], ['12-26'], ['15-5'], ['15-14'], ['16-30'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_1250_depth_7500_results.json\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['21-30'], ['16-24'], ['8-26'], ['17-22'], ['31-16'], ['13-11'], ['17-0'], ['22-8'], ['22-27'], ['6-30'], ['7-4'], ['11-15'], ['15-14'], ['16-30'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['21-30'], ['8-26'], ['16-24'], ['31-16'], ['17-22'], ['13-11'], ['17-0'], ['11-15'], ['15-14'], ['20-8'], ['22-8'], ['22-27'], ['6-30'], ['7-4'], ['16-30'], ['19-9'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 553\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['21-30'], ['17-22'], ['8-26'], ['16-24'], ['31-16'], ['17-0'], ['13-11'], ['11-15'], ['15-14'], ['20-8'], ['22-8'], ['22-27'], ['6-30'], ['7-4'], ['16-30'], ['19-9'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1135\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['21-30'], ['17-22'], ['8-26'], ['16-24'], ['31-16'], ['17-0'], ['13-11'], ['11-15'], ['15-14'], ['16-30'], ['20-8'], ['22-8'], ['22-27'], ['6-30'], ['7-4'], ['19-9'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1670\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['8-26'], ['16-24'], ['31-16'], ['17-0'], ['13-11'], ['16-30'], ['22-27'], ['11-15'], ['15-14'], ['20-8'], ['22-8'], ['6-30'], ['7-4'], ['18-30'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_2500_depth_7500_results.json\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['16-24'], ['8-26'], ['31-16'], ['13-11'], ['17-0'], ['16-30'], ['22-27'], ['11-15'], ['15-14'], ['20-8'], ['22-8'], ['6-30'], ['7-4'], ['18-30'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['16-24'], ['8-26'], ['31-16'], ['17-0'], ['13-11'], ['11-15'], ['15-14'], ['16-30'], ['20-8'], ['22-27'], ['22-8'], ['6-30'], ['7-4'], ['18-30'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 868\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['16-24'], ['8-26'], ['31-16'], ['17-0'], ['13-11'], ['11-15'], ['15-14'], ['16-30'], ['20-8'], ['22-27'], ['18-30'], ['22-8'], ['6-30'], ['7-4'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1733\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['16-24'], ['8-26'], ['17-0'], ['31-16'], ['13-11'], ['16-30'], ['11-15'], ['15-14'], ['18-30'], ['20-8'], ['22-27'], ['22-8'], ['22-19'], ['6-30'], ['7-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2613\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['16-24'], ['17-0'], ['8-26'], ['31-16'], ['13-11'], ['16-30'], ['18-30'], ['11-15'], ['15-14'], ['20-8'], ['22-27'], ['22-8'], ['22-19'], ['6-30'], ['7-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_3750_depth_7500_results.json\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['16-24'], ['17-0'], ['8-26'], ['31-16'], ['13-11'], ['18-30'], ['16-30'], ['11-15'], ['20-8'], ['22-27'], ['15-14'], ['22-8'], ['22-19'], ['6-30'], ['7-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 48.02330136299133\n",
      "Response: Hurricane Katrina\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1172\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['21-30'], ['16-24'], ['17-0'], ['8-26'], ['31-16'], ['13-11'], ['18-30'], ['16-30'], ['11-15'], ['15-14'], ['20-8'], ['22-27'], ['22-8'], ['22-19'], ['6-30'], ['7-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2386\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['17-22'], ['24-29'], ['21-30'], ['17-0'], ['16-24'], ['8-26'], ['31-16'], ['18-30'], ['13-11'], ['16-30'], ['11-15'], ['15-14'], ['20-8'], ['22-27'], ['22-8'], ['22-19'], ['6-30'], ['7-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3571\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['17-22'], ['24-29'], ['21-30'], ['17-0'], ['16-24'], ['8-26'], ['31-16'], ['18-30'], ['13-11'], ['16-30'], ['11-15'], ['15-14'], ['20-8'], ['22-19'], ['22-27'], ['22-8'], ['6-30'], ['7-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_5000_depth_7500_results.json\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['17-22'], ['24-29'], ['21-30'], ['16-24'], ['17-0'], ['8-26'], ['31-16'], ['18-30'], ['13-11'], ['16-30'], ['11-15'], ['15-14'], ['20-8'], ['22-19'], ['22-27'], ['22-8'], ['6-30'], ['7-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant/llama-2-7b-80k_id_586_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/586.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['8-26'], ['16-24'], ['17-22'], ['21-30'], ['24-29'], ['31-16'], ['6-30'], ['7-4'], ['11-15'], ['12-26'], ['13-11'], ['15-5'], ['15-14'], ['16-30'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['8-26'], ['16-24'], ['17-22'], ['21-30'], ['24-29'], ['31-16'], ['6-30'], ['7-4'], ['11-15'], ['12-26'], ['13-11'], ['15-5'], ['15-14'], ['16-30'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['8-26'], ['16-24'], ['17-22'], ['21-30'], ['24-29'], ['31-16'], ['6-30'], ['7-4'], ['11-15'], ['12-26'], ['13-11'], ['15-5'], ['15-14'], ['16-30'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['8-26'], ['16-24'], ['17-22'], ['21-30'], ['24-29'], ['31-16'], ['6-30'], ['7-4'], ['11-15'], ['12-26'], ['13-11'], ['15-5'], ['15-14'], ['16-30'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['8-26'], ['16-24'], ['17-22'], ['21-30'], ['24-29'], ['31-16'], ['6-30'], ['7-4'], ['11-15'], ['12-26'], ['13-11'], ['15-5'], ['15-14'], ['16-30'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['8-26'], ['24-29'], ['16-24'], ['17-22'], ['21-30'], ['31-16'], ['11-15'], ['15-14'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['15-5'], ['16-30'], ['17-0'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 80.07398247718811\n",
      "Response: Hurricane Milton brought significant damage to parts of the Gulf Coast last year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 237\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['8-26'], ['17-22'], ['16-24'], ['21-30'], ['31-16'], ['11-15'], ['15-14'], ['17-0'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['15-5'], ['16-30'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 489\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['8-26'], ['17-22'], ['16-24'], ['21-30'], ['31-16'], ['17-0'], ['11-15'], ['15-14'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['15-5'], ['16-30'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 732\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['8-26'], ['17-22'], ['16-24'], ['21-30'], ['31-16'], ['17-0'], ['11-15'], ['15-14'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['15-5'], ['16-30'], ['19-9'], ['19-10'], ['19-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['8-26'], ['21-30'], ['31-16'], ['16-24'], ['17-22'], ['17-0'], ['13-11'], ['11-15'], ['6-30'], ['7-4'], ['15-5'], ['15-14'], ['16-30'], ['19-9'], ['19-10'], ['19-13'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['8-26'], ['21-30'], ['31-16'], ['16-24'], ['17-22'], ['17-0'], ['11-15'], ['13-11'], ['6-30'], ['7-4'], ['15-5'], ['16-30'], ['19-9'], ['19-10'], ['19-13'], ['20-8'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 553\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['16-24'], ['17-0'], ['11-15'], ['13-11'], ['6-30'], ['7-4'], ['15-5'], ['15-14'], ['16-30'], ['19-9'], ['19-10'], ['19-13'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1113\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['16-24'], ['17-0'], ['11-15'], ['13-11'], ['6-30'], ['7-4'], ['15-5'], ['16-30'], ['19-9'], ['19-10'], ['19-13'], ['20-8'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1671\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['16-24'], ['17-0'], ['13-11'], ['11-15'], ['6-30'], ['7-4'], ['15-5'], ['15-14'], ['16-30'], ['19-9'], ['19-10'], ['19-13'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['16-24'], ['17-0'], ['13-11'], ['11-15'], ['6-30'], ['7-4'], ['15-5'], ['16-30'], ['19-9'], ['19-13'], ['20-8'], ['22-8'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['16-24'], ['17-0'], ['13-11'], ['11-15'], ['6-30'], ['7-4'], ['15-5'], ['15-14'], ['16-30'], ['19-9'], ['19-13'], ['20-8'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 856\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['16-24'], ['17-0'], ['13-11'], ['11-15'], ['6-30'], ['7-4'], ['15-5'], ['15-14'], ['16-30'], ['19-9'], ['19-13'], ['20-8'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1747\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['8-26'], ['17-22'], ['21-30'], ['31-16'], ['17-0'], ['16-24'], ['13-11'], ['11-15'], ['6-30'], ['7-4'], ['15-5'], ['15-14'], ['16-30'], ['19-9'], ['19-13'], ['20-8'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2635\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['8-26'], ['21-30'], ['31-16'], ['17-0'], ['16-24'], ['13-11'], ['11-15'], ['6-30'], ['7-4'], ['15-5'], ['15-14'], ['16-30'], ['19-9'], ['19-13'], ['20-8'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['8-26'], ['21-30'], ['31-16'], ['16-24'], ['17-0'], ['13-11'], ['11-15'], ['15-14'], ['6-30'], ['7-4'], ['15-5'], ['19-9'], ['19-13'], ['20-8'], ['22-8'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['8-26'], ['21-30'], ['31-16'], ['16-24'], ['17-0'], ['13-11'], ['11-15'], ['15-14'], ['6-30'], ['7-4'], ['15-5'], ['19-9'], ['19-13'], ['20-8'], ['22-8'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1190\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['8-26'], ['21-30'], ['31-16'], ['16-24'], ['17-0'], ['13-11'], ['11-15'], ['15-14'], ['6-30'], ['7-4'], ['15-5'], ['19-9'], ['19-13'], ['20-8'], ['22-8'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2381\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['8-26'], ['21-30'], ['31-16'], ['16-24'], ['17-0'], ['13-11'], ['11-15'], ['15-14'], ['18-30'], ['6-30'], ['7-4'], ['15-5'], ['19-9'], ['19-13'], ['20-8'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3575\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['8-26'], ['21-30'], ['31-16'], ['17-0'], ['16-24'], ['13-11'], ['11-15'], ['15-14'], ['18-30'], ['6-30'], ['7-4'], ['15-5'], ['19-9'], ['19-13'], ['20-8'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 80.93523979187012\n",
      "Response: Hurricane Milton\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The most recent hurricane that affected the Southeastern Coast of the United States is Hurricane Milton.\n",
      "[['16-19'], ['19-15'], ['24-29'], ['17-22'], ['8-26'], ['21-30'], ['31-16'], ['16-24'], ['17-0'], ['13-11'], ['11-15'], ['18-30'], ['15-14'], ['19-9'], ['19-13'], ['22-8'], ['6-30'], ['7-4'], ['15-5'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 77.3811936378479\n",
      "Response: Hurricane Milton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_586_irrelevant_misleading/llama-2-7b-80k_id_586_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: King Gizzard's most recent studio album is Flight b741.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['19-15'], ['21-30'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['0-9'], ['8-22'], ['10-29'], ['12-16'], ['13-11'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['19-15'], ['21-30'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['0-9'], ['8-22'], ['10-29'], ['12-16'], ['13-11'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['19-15'], ['21-30'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['0-9'], ['8-22'], ['10-29'], ['12-16'], ['13-11'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['19-15'], ['21-30'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['0-9'], ['8-22'], ['10-29'], ['12-16'], ['13-11'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_0_depth_7500_results.json\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['19-15'], ['21-30'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['0-9'], ['8-22'], ['10-29'], ['12-16'], ['13-11'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['19-15'], ['21-30'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['14-7'], ['22-22'], ['0-9'], ['8-22'], ['10-29'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 60.571324825286865\n",
      "Response: Flight b741\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_1250_depth_0_results.json\n",
      "insertion at 234\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['8-26'], ['19-15'], ['21-30'], ['6-30'], ['7-4'], ['15-14'], ['17-22'], ['7-28'], ['12-26'], ['29-26'], ['22-22'], ['14-7'], ['19-9'], ['19-10'], ['20-1'], ['20-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 490\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['8-26'], ['19-15'], ['21-30'], ['6-30'], ['7-4'], ['15-14'], ['17-22'], ['7-28'], ['12-26'], ['29-26'], ['22-22'], ['7-12'], ['19-9'], ['20-1'], ['22-27'], ['24-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 770\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['6-30'], ['7-4'], ['15-14'], ['17-22'], ['7-28'], ['12-26'], ['29-26'], ['7-12'], ['22-22'], ['19-9'], ['20-1'], ['22-27'], ['24-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 60.571324825286865\n",
      "Response: Flight b741\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_1250_depth_7500_results.json\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['6-9'], ['11-15'], ['8-26'], ['19-15'], ['21-30'], ['6-30'], ['7-4'], ['17-22'], ['15-14'], ['12-26'], ['7-28'], ['29-26'], ['22-22'], ['25-3'], ['12-16'], ['19-9'], ['20-1'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['6-30'], ['7-4'], ['17-22'], ['15-14'], ['12-26'], ['7-28'], ['29-26'], ['20-1'], ['22-22'], ['24-16'], ['25-3'], ['12-16'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 60.571324825286865\n",
      "Response: Flight b741\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_2500_depth_0_results.json\n",
      "insertion at 568\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['6-30'], ['7-4'], ['15-14'], ['12-26'], ['7-28'], ['20-1'], ['22-22'], ['24-16'], ['29-26'], ['7-12'], ['21-28'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 55.812013149261475\n",
      "Response: Flight b741.W.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 870\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['6-30'], ['7-4'], ['15-14'], ['12-26'], ['7-12'], ['7-28'], ['20-1'], ['24-16'], ['29-26'], ['21-28'], ['22-22'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 60.571324825286865\n",
      "Response: Flight b741\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 870\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['6-30'], ['7-4'], ['15-14'], ['7-12'], ['7-28'], ['12-26'], ['20-1'], ['24-16'], ['29-26'], ['21-28'], ['22-22'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 60.571324825286865\n",
      "Response: Flight b741\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_2500_depth_7500_results.json\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['6-30'], ['15-14'], ['7-12'], ['7-28'], ['12-26'], ['29-26'], ['20-1'], ['24-16'], ['21-28'], ['22-22'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 60.571324825286865\n",
      "Response: Flight b741\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['6-30'], ['17-22'], ['7-4'], ['15-14'], ['7-12'], ['12-26'], ['7-28'], ['29-26'], ['20-1'], ['21-28'], ['24-16'], ['25-3'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 60.571324825286865\n",
      "Response: Flight b741\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_3750_depth_0_results.json\n",
      "insertion at 870\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['6-30'], ['17-22'], ['7-4'], ['15-14'], ['7-12'], ['12-26'], ['7-28'], ['29-26'], ['24-16'], ['20-1'], ['21-28'], ['25-3'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 870\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['6-30'], ['17-22'], ['7-4'], ['7-12'], ['15-14'], ['29-26'], ['12-26'], ['7-28'], ['24-16'], ['20-1'], ['21-28'], ['6-16'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2325\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['6-30'], ['7-4'], ['7-12'], ['15-14'], ['29-26'], ['12-26'], ['24-16'], ['7-28'], ['20-1'], ['21-28'], ['14-18'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_3750_depth_7500_results.json\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['6-30'], ['7-4'], ['15-14'], ['7-12'], ['29-26'], ['12-26'], ['7-28'], ['24-16'], ['20-1'], ['21-28'], ['31-16'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['6-30'], ['7-4'], ['15-14'], ['7-12'], ['29-26'], ['12-26'], ['7-28'], ['24-16'], ['21-28'], ['20-1'], ['31-16'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 60.571324825286865\n",
      "Response: Flight b741\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_5000_depth_0_results.json\n",
      "insertion at 870\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['6-30'], ['7-4'], ['7-12'], ['15-14'], ['29-26'], ['12-26'], ['24-16'], ['7-28'], ['20-1'], ['21-28'], ['31-16'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 60.571324825286865\n",
      "Response: Flight b741\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2325\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['6-30'], ['7-12'], ['7-4'], ['15-14'], ['29-26'], ['12-26'], ['24-16'], ['7-28'], ['20-1'], ['21-28'], ['31-16'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3298\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['6-30'], ['7-12'], ['7-4'], ['15-14'], ['29-26'], ['12-26'], ['24-16'], ['20-1'], ['21-28'], ['7-28'], ['31-16'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_5000_depth_7500_results.json\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['6-30'], ['7-4'], ['7-12'], ['15-14'], ['29-26'], ['12-26'], ['24-16'], ['7-28'], ['20-1'], ['31-16'], ['21-28'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
<<<<<<< Updated upstream
      "Writing at results/graph/llama-2-7b-80k_id_423_relevant_misleading/llama-2-7b-80k_id_423_relevant_misleading_len_5000_depth_10000_results.json\n",
=======
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['7-4'], ['11-15'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['19-15'], ['24-29'], ['11-2'], ['12-26'], ['16-24'], ['17-31'], ['19-10'], ['31-16'], ['6-30'], ['13-11'], ['15-29'], ['21-30'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 97.80500531196594\n",
      "Response: The Patriots last played the Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['7-4'], ['11-15'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['19-15'], ['24-29'], ['11-2'], ['12-26'], ['16-24'], ['17-31'], ['19-10'], ['31-16'], ['6-30'], ['13-11'], ['15-29'], ['21-30'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 97.80500531196594\n",
      "Response: The Patriots last played the Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['7-4'], ['11-15'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['19-15'], ['24-29'], ['11-2'], ['12-26'], ['16-24'], ['17-31'], ['19-10'], ['31-16'], ['6-30'], ['13-11'], ['15-29'], ['21-30'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 97.80500531196594\n",
      "Response: The Patriots last played the Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['7-4'], ['11-15'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['19-15'], ['24-29'], ['11-2'], ['12-26'], ['16-24'], ['17-31'], ['19-10'], ['31-16'], ['6-30'], ['13-11'], ['15-29'], ['21-30'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 97.80500531196594\n",
      "Response: The Patriots last played the Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_0_depth_7500_results.json\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['7-4'], ['11-15'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['19-15'], ['24-29'], ['11-2'], ['12-26'], ['16-24'], ['17-31'], ['19-10'], ['31-16'], ['6-30'], ['13-11'], ['15-29'], ['21-30'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 97.80500531196594\n",
      "Response: The Patriots last played the Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['19-15'], ['24-29'], ['11-2'], ['12-26'], ['16-24'], ['17-31'], ['19-10'], ['31-16'], ['7-12'], ['6-30'], ['13-11'], ['15-29'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 46\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['11-2'], ['24-29'], ['19-15'], ['7-12'], ['17-31'], ['19-10'], ['16-24'], ['12-26'], ['31-16'], ['21-30'], ['6-30'], ['13-11'], ['15-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 46\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['11-2'], ['17-22'], ['18-30'], ['7-12'], ['24-29'], ['19-15'], ['17-31'], ['19-10'], ['16-24'], ['12-26'], ['31-16'], ['21-30'], ['14-18'], ['6-30'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 748\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['11-2'], ['17-22'], ['18-30'], ['7-12'], ['24-29'], ['19-15'], ['17-31'], ['19-10'], ['16-24'], ['12-26'], ['31-16'], ['21-30'], ['14-18'], ['6-30'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['11-2'], ['17-22'], ['18-30'], ['19-15'], ['7-12'], ['24-29'], ['12-26'], ['19-10'], ['17-31'], ['16-24'], ['31-16'], ['21-30'], ['14-18'], ['6-30'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['11-2'], ['17-22'], ['18-30'], ['7-12'], ['19-15'], ['24-29'], ['12-26'], ['19-10'], ['17-31'], ['16-24'], ['31-16'], ['21-30'], ['14-18'], ['6-30'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 99.72555041313171\n",
      "Response: The Patriots last played the Miami Dolphins on November 25, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 544\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['11-2'], ['17-22'], ['7-12'], ['18-30'], ['19-15'], ['24-29'], ['19-10'], ['12-26'], ['17-31'], ['16-24'], ['21-30'], ['31-16'], ['14-18'], ['17-0'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1079\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['11-2'], ['17-22'], ['7-12'], ['18-30'], ['19-15'], ['24-29'], ['19-10'], ['12-26'], ['16-24'], ['17-31'], ['21-30'], ['14-18'], ['31-16'], ['17-0'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1690\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['11-2'], ['17-22'], ['7-12'], ['18-30'], ['19-15'], ['24-29'], ['21-30'], ['19-10'], ['16-24'], ['17-31'], ['12-26'], ['14-18'], ['31-16'], ['17-0'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['11-2'], ['17-22'], ['7-12'], ['18-30'], ['19-15'], ['24-29'], ['21-30'], ['12-26'], ['19-10'], ['14-18'], ['16-24'], ['31-16'], ['17-31'], ['17-0'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['11-2'], ['17-22'], ['7-12'], ['18-30'], ['19-15'], ['24-29'], ['21-30'], ['14-18'], ['12-26'], ['19-10'], ['16-24'], ['17-31'], ['31-16'], ['17-0'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 858\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['11-2'], ['17-22'], ['7-12'], ['18-30'], ['19-15'], ['24-29'], ['21-30'], ['14-18'], ['12-26'], ['19-10'], ['16-24'], ['17-31'], ['31-16'], ['17-0'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1720\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['11-2'], ['7-12'], ['17-22'], ['19-15'], ['18-30'], ['24-29'], ['21-30'], ['14-18'], ['19-10'], ['12-26'], ['16-24'], ['17-31'], ['31-16'], ['17-0'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2644\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['11-2'], ['7-12'], ['17-22'], ['19-15'], ['18-30'], ['24-29'], ['21-30'], ['14-18'], ['19-10'], ['17-31'], ['12-26'], ['16-24'], ['31-16'], ['17-0'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['11-2'], ['17-22'], ['7-12'], ['19-15'], ['18-30'], ['24-29'], ['21-30'], ['14-18'], ['12-26'], ['19-10'], ['16-24'], ['17-31'], ['31-16'], ['17-0'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['11-2'], ['17-22'], ['7-12'], ['19-15'], ['18-30'], ['24-29'], ['21-30'], ['14-18'], ['12-26'], ['19-10'], ['16-24'], ['17-31'], ['31-16'], ['17-0'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1148\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['11-2'], ['7-12'], ['17-22'], ['19-15'], ['18-30'], ['21-30'], ['24-29'], ['14-18'], ['12-26'], ['19-10'], ['16-24'], ['17-31'], ['31-16'], ['17-0'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2184\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['11-2'], ['7-12'], ['7-4'], ['17-22'], ['19-15'], ['18-30'], ['21-30'], ['14-18'], ['24-29'], ['19-10'], ['12-26'], ['16-24'], ['17-31'], ['31-16'], ['17-0'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3548\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['11-2'], ['7-12'], ['7-4'], ['17-22'], ['19-15'], ['18-30'], ['21-30'], ['14-18'], ['24-29'], ['19-10'], ['12-26'], ['16-24'], ['17-31'], ['31-16'], ['17-0'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['11-2'], ['7-4'], ['7-12'], ['17-22'], ['19-15'], ['18-30'], ['21-30'], ['14-18'], ['24-29'], ['12-26'], ['19-10'], ['16-24'], ['17-31'], ['31-16'], ['17-0'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_relevant_misleading/llama-2-7b-80k_id_439_relevant_misleading_len_5000_depth_10000_results.json\n",
=======
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant/llama-2-7b-80k_id_587_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/587.txt\n",
>>>>>>> Stashed changes
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n"
=======
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
>>>>>>> Stashed changes
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
<<<<<<< Updated upstream
      "- Needle: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
=======
      "- Needle: King Gizzard's most recent studio album is Flight b741.\n",
>>>>>>> Stashed changes
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
<<<<<<< Updated upstream
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['7-4'], ['11-15'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['19-15'], ['24-29'], ['11-2'], ['12-26'], ['16-24'], ['17-31'], ['19-10'], ['31-16'], ['6-30'], ['13-11'], ['15-29'], ['21-30'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 97.80500531196594\n",
      "Response: The Patriots last played the Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['7-4'], ['11-15'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['19-15'], ['24-29'], ['11-2'], ['12-26'], ['16-24'], ['17-31'], ['19-10'], ['31-16'], ['6-30'], ['13-11'], ['15-29'], ['21-30'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 97.80500531196594\n",
      "Response: The Patriots last played the Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['7-4'], ['11-15'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['19-15'], ['24-29'], ['11-2'], ['12-26'], ['16-24'], ['17-31'], ['19-10'], ['31-16'], ['6-30'], ['13-11'], ['15-29'], ['21-30'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 97.80500531196594\n",
      "Response: The Patriots last played the Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['7-4'], ['11-15'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['19-15'], ['24-29'], ['11-2'], ['12-26'], ['16-24'], ['17-31'], ['19-10'], ['31-16'], ['6-30'], ['13-11'], ['15-29'], ['21-30'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 97.80500531196594\n",
      "Response: The Patriots last played the Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_0_depth_7500_results.json\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['7-4'], ['11-15'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['19-15'], ['24-29'], ['11-2'], ['12-26'], ['16-24'], ['17-31'], ['19-10'], ['31-16'], ['6-30'], ['13-11'], ['15-29'], ['21-30'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 97.80500531196594\n",
      "Response: The Patriots last played the Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['24-29'], ['11-2'], ['19-15'], ['19-10'], ['16-24'], ['17-31'], ['12-26'], ['31-16'], ['21-30'], ['6-30'], ['7-12'], ['13-11'], ['15-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['11-2'], ['24-29'], ['19-15'], ['19-10'], ['16-24'], ['17-31'], ['21-30'], ['7-12'], ['12-26'], ['31-16'], ['6-30'], ['31-24'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 472\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['18-30'], ['11-2'], ['24-29'], ['19-15'], ['7-12'], ['19-10'], ['17-31'], ['21-30'], ['16-24'], ['6-30'], ['12-26'], ['31-16'], ['14-18'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 735\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['18-30'], ['11-2'], ['24-29'], ['19-15'], ['19-10'], ['7-12'], ['21-30'], ['17-31'], ['16-24'], ['6-30'], ['12-26'], ['31-16'], ['14-18'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_1250_depth_7500_results.json\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['18-30'], ['11-2'], ['19-15'], ['24-29'], ['19-10'], ['21-30'], ['7-12'], ['12-26'], ['16-24'], ['17-31'], ['31-16'], ['6-30'], ['14-18'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['18-30'], ['11-2'], ['19-15'], ['24-29'], ['19-10'], ['21-30'], ['7-12'], ['12-26'], ['16-24'], ['17-31'], ['31-16'], ['6-30'], ['14-18'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 551\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['8-26'], ['6-9'], ['17-22'], ['18-30'], ['11-2'], ['7-12'], ['19-15'], ['24-29'], ['19-10'], ['21-30'], ['17-31'], ['16-24'], ['12-26'], ['6-30'], ['14-18'], ['31-16'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1107\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-4'], ['6-9'], ['17-22'], ['18-30'], ['11-2'], ['7-12'], ['24-29'], ['19-15'], ['19-10'], ['21-30'], ['17-31'], ['16-24'], ['14-18'], ['12-26'], ['6-30'], ['31-16'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1703\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-4'], ['6-9'], ['17-22'], ['11-2'], ['18-30'], ['7-12'], ['24-29'], ['19-15'], ['19-10'], ['21-30'], ['17-31'], ['14-18'], ['16-24'], ['12-26'], ['6-30'], ['31-16'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_2500_depth_7500_results.json\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-4'], ['6-9'], ['17-22'], ['11-2'], ['18-30'], ['7-12'], ['19-15'], ['24-29'], ['21-30'], ['19-10'], ['16-24'], ['17-31'], ['12-26'], ['14-18'], ['6-30'], ['31-16'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 31.46596848964691\n",
      "Response: 12/24/2011\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 735\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['18-30'], ['7-12'], ['19-15'], ['24-29'], ['19-10'], ['21-30'], ['14-18'], ['17-31'], ['16-24'], ['12-26'], ['6-30'], ['31-16'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1703\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['7-12'], ['18-30'], ['19-15'], ['24-29'], ['19-10'], ['21-30'], ['14-18'], ['17-31'], ['16-24'], ['12-26'], ['6-30'], ['31-16'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2631\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 46.18957042694092\n",
      "Response: November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_3750_depth_7500_results.json\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['18-30'], ['7-12'], ['19-15'], ['21-30'], ['24-29'], ['19-10'], ['14-18'], ['16-24'], ['12-26'], ['17-31'], ['31-16'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['7-12'], ['18-30'], ['19-15'], ['21-30'], ['24-29'], ['19-10'], ['14-18'], ['16-24'], ['17-31'], ['12-26'], ['31-16'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1180\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['11-2'], ['7-12'], ['18-30'], ['19-15'], ['21-30'], ['19-10'], ['24-29'], ['14-18'], ['16-24'], ['17-31'], ['12-26'], ['6-30'], ['31-16'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2379\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['7-12'], ['11-2'], ['18-30'], ['19-15'], ['19-10'], ['21-30'], ['24-29'], ['14-18'], ['17-31'], ['16-24'], ['12-26'], ['6-30'], ['31-16'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3548\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['7-12'], ['11-2'], ['18-30'], ['19-15'], ['21-30'], ['19-10'], ['24-29'], ['14-18'], ['17-31'], ['16-24'], ['12-26'], ['17-0'], ['31-16'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_5000_depth_7500_results.json\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['11-2'], ['7-12'], ['18-30'], ['19-15'], ['21-30'], ['19-10'], ['24-29'], ['14-18'], ['17-31'], ['16-24'], ['12-26'], ['17-0'], ['31-16'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant/llama-2-7b-80k_id_439_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_irrelevant/439.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['7-4'], ['11-15'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['19-15'], ['24-29'], ['11-2'], ['12-26'], ['16-24'], ['17-31'], ['19-10'], ['31-16'], ['6-30'], ['13-11'], ['15-29'], ['21-30'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 97.80500531196594\n",
      "Response: The Patriots last played the Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['7-4'], ['11-15'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['19-15'], ['24-29'], ['11-2'], ['12-26'], ['16-24'], ['17-31'], ['19-10'], ['31-16'], ['6-30'], ['13-11'], ['15-29'], ['21-30'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 97.80500531196594\n",
      "Response: The Patriots last played the Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['7-4'], ['11-15'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['19-15'], ['24-29'], ['11-2'], ['12-26'], ['16-24'], ['17-31'], ['19-10'], ['31-16'], ['6-30'], ['13-11'], ['15-29'], ['21-30'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 97.80500531196594\n",
      "Response: The Patriots last played the Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['7-4'], ['11-15'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['19-15'], ['24-29'], ['11-2'], ['12-26'], ['16-24'], ['17-31'], ['19-10'], ['31-16'], ['6-30'], ['13-11'], ['15-29'], ['21-30'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 97.80500531196594\n",
      "Response: The Patriots last played the Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['7-4'], ['11-15'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['19-15'], ['24-29'], ['11-2'], ['12-26'], ['16-24'], ['17-31'], ['19-10'], ['31-16'], ['6-30'], ['13-11'], ['15-29'], ['21-30'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 97.80500531196594\n",
      "Response: The Patriots last played the Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['24-29'], ['11-2'], ['19-15'], ['19-10'], ['16-24'], ['17-31'], ['12-26'], ['31-16'], ['21-30'], ['6-30'], ['7-12'], ['13-11'], ['15-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['18-30'], ['17-22'], ['11-2'], ['24-29'], ['19-15'], ['19-10'], ['16-24'], ['17-31'], ['21-30'], ['7-12'], ['12-26'], ['31-16'], ['6-30'], ['31-24'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 472\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['18-30'], ['11-2'], ['24-29'], ['19-15'], ['7-12'], ['19-10'], ['17-31'], ['21-30'], ['16-24'], ['6-30'], ['12-26'], ['31-16'], ['14-18'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 735\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['18-30'], ['11-2'], ['24-29'], ['19-15'], ['19-10'], ['7-12'], ['21-30'], ['17-31'], ['16-24'], ['6-30'], ['12-26'], ['31-16'], ['14-18'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['18-30'], ['11-2'], ['19-15'], ['24-29'], ['19-10'], ['21-30'], ['7-12'], ['12-26'], ['16-24'], ['17-31'], ['31-16'], ['6-30'], ['14-18'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['6-9'], ['8-26'], ['17-22'], ['18-30'], ['11-2'], ['19-15'], ['24-29'], ['19-10'], ['21-30'], ['7-12'], ['12-26'], ['17-31'], ['16-24'], ['31-16'], ['6-30'], ['14-18'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 99.72555041313171\n",
      "Response: The Patriots last played the Miami Dolphins on November 25, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 551\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['8-26'], ['6-9'], ['17-22'], ['11-2'], ['18-30'], ['7-12'], ['19-15'], ['24-29'], ['19-10'], ['21-30'], ['17-31'], ['12-26'], ['16-24'], ['31-16'], ['6-30'], ['14-18'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1107\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['8-26'], ['6-9'], ['17-22'], ['11-2'], ['18-30'], ['7-12'], ['24-29'], ['19-15'], ['21-30'], ['19-10'], ['17-31'], ['12-26'], ['16-24'], ['14-18'], ['31-16'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1698\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-4'], ['6-9'], ['17-22'], ['11-2'], ['18-30'], ['7-12'], ['24-29'], ['19-15'], ['21-30'], ['19-10'], ['16-24'], ['17-31'], ['12-26'], ['14-18'], ['31-16'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-4'], ['6-9'], ['17-22'], ['11-2'], ['18-30'], ['7-12'], ['19-15'], ['24-29'], ['21-30'], ['19-10'], ['12-26'], ['16-24'], ['17-31'], ['14-18'], ['31-16'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-4'], ['6-9'], ['17-22'], ['11-2'], ['18-30'], ['7-12'], ['19-15'], ['24-29'], ['21-30'], ['19-10'], ['12-26'], ['16-24'], ['17-31'], ['14-18'], ['31-16'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 99.70589876174927\n",
      "Response: The Patriots last played the Miami Dolphins on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 735\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['6-9'], ['11-2'], ['18-30'], ['7-12'], ['24-29'], ['19-15'], ['21-30'], ['19-10'], ['12-26'], ['17-31'], ['16-24'], ['14-18'], ['31-16'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1736\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['7-4'], ['6-9'], ['11-2'], ['7-12'], ['18-30'], ['24-29'], ['19-15'], ['21-30'], ['19-10'], ['14-18'], ['12-26'], ['17-31'], ['16-24'], ['31-16'], ['6-30'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2598\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['7-4'], ['6-9'], ['11-2'], ['7-12'], ['18-30'], ['24-29'], ['19-15'], ['21-30'], ['19-10'], ['14-18'], ['12-26'], ['17-31'], ['16-24'], ['31-16'], ['24-3'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['7-4'], ['6-9'], ['11-2'], ['7-12'], ['18-30'], ['24-29'], ['19-15'], ['21-30'], ['19-10'], ['14-18'], ['12-26'], ['16-24'], ['17-31'], ['31-16'], ['17-0'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['7-4'], ['6-9'], ['11-2'], ['7-12'], ['18-30'], ['19-15'], ['24-29'], ['21-30'], ['19-10'], ['14-18'], ['12-26'], ['16-24'], ['17-31'], ['31-16'], ['17-0'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 99.70589876174927\n",
      "Response: The Patriots last played the Miami Dolphins on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1193\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['7-4'], ['11-2'], ['6-9'], ['7-12'], ['18-30'], ['19-15'], ['24-29'], ['21-30'], ['19-10'], ['14-18'], ['12-26'], ['17-31'], ['16-24'], ['31-16'], ['17-0'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 99.70589876174927\n",
      "Response: The Patriots last played the Miami Dolphins on November 22, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2346\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['6-9'], ['7-12'], ['18-30'], ['19-15'], ['21-30'], ['24-29'], ['19-10'], ['14-18'], ['12-26'], ['17-31'], ['16-24'], ['31-16'], ['24-3'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3572\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['6-9'], ['7-4'], ['7-12'], ['18-30'], ['21-30'], ['19-15'], ['24-29'], ['19-10'], ['14-18'], ['12-26'], ['17-31'], ['16-24'], ['24-3'], ['6-16'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['11-2'], ['6-9'], ['7-4'], ['7-12'], ['18-30'], ['19-15'], ['21-30'], ['24-29'], ['19-10'], ['14-18'], ['12-26'], ['16-24'], ['17-31'], ['17-0'], ['24-3'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Patriots last played the Miami Dolphins on November 24, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_439_irrelevant_misleading/llama-2-7b-80k_id_439_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: There won't be a FIFA World Cup this year.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['16-19'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['16-19'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['16-19'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['16-19'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_0_depth_7500_results.json\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['16-19'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['16-19'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 63.39378356933594\n",
      "Response: No, the FIFA World Cup will not be hosted this year. The FIFA World Cup is a major international football tournament that is held every four years. It is organized by the Fédération Internationale de Football Association (FIFA), the sport's\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_1250_depth_0_results.json\n",
      "insertion at 238\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['16-19'], ['11-15'], ['6-17'], ['11-8'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 64.28676247596741\n",
      "Response: No, the FIFA World Cup will not be hosted this year. The FIFA World Cup is an international association football competition that is held every four years. The competition is organized by the Fédération Internationale de Football Association (FIFA), the sport'\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 516\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['11-15'], ['21-16'], ['6-17'], ['11-8'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['17-0'], ['18-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 64.193594455719\n",
      "Response: No, the FIFA World Cup will not be hosted this year. The FIFA World Cup is an international association football competition that is held every four years. The tournament is organized by the Fédération Internationale de Football Association (FIFA), the sport'\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 723\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['11-15'], ['21-16'], ['6-17'], ['11-8'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['17-0'], ['18-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 64.28676247596741\n",
      "Response: No, the FIFA World Cup will not be hosted this year. The FIFA World Cup is an international association football competition that is held every four years. The competition is organized by the Fédération Internationale de Football Association (FIFA), the sport'\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_1250_depth_7500_results.json\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['25-3'], ['6-9'], ['24-30'], ['21-16'], ['11-15'], ['12-26'], ['13-11'], ['17-0'], ['12-16'], ['13-23'], ['15-5'], ['21-5'], ['24-16'], ['24-29'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 11.441656947135925\n",
      "Response: No.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_2500_depth_0_results.json\n",
      "insertion at 535\n",
      "There won't be a FIFA World Cup this year.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 11.441656947135925\n",
      "Response: No.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1121\n",
      "There won't be a FIFA World Cup this year.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 11.441656947135925\n",
      "Response: No.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1681\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['25-3'], ['6-9'], ['24-30'], ['21-16'], ['11-15'], ['12-26'], ['13-11'], ['17-0'], ['12-16'], ['13-23'], ['15-5'], ['21-5'], ['24-16'], ['24-29'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 52.01462507247925\n",
      "Response: No. The FIFA World Cup is a soccer tournament that is held every four years. The next World Cup will be held in 2022.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_2500_depth_7500_results.json\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['16-19'], ['19-15'], ['21-30'], ['25-3'], ['21-16'], ['6-9'], ['24-30'], ['11-15'], ['12-26'], ['13-11'], ['17-0'], ['12-16'], ['13-23'], ['15-5'], ['21-5'], ['24-16'], ['24-29'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 11.441656947135925\n",
      "Response: No.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_3750_depth_0_results.json\n",
      "insertion at 867\n",
      "There won't be a FIFA World Cup this year.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 11.441656947135925\n",
      "Response: No.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1756\n",
      "There won't be a FIFA World Cup this year.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 11.441656947135925\n",
      "Response: No.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2645\n",
      "There won't be a FIFA World Cup this year.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 11.441656947135925\n",
      "Response: No.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_3750_depth_7500_results.json\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['19-15'], ['16-19'], ['21-30'], ['25-3'], ['21-16'], ['12-26'], ['13-11'], ['11-15'], ['6-9'], ['17-0'], ['24-30'], ['12-16'], ['13-23'], ['15-5'], ['24-16'], ['24-29'], ['29-19'], ['29-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['19-15'], ['16-19'], ['21-30'], ['25-3'], ['21-16'], ['12-26'], ['13-11'], ['11-15'], ['6-9'], ['17-0'], ['24-30'], ['12-16'], ['13-23'], ['15-5'], ['24-16'], ['24-29'], ['29-19'], ['29-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1192\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['19-15'], ['16-19'], ['21-30'], ['25-3'], ['21-16'], ['12-26'], ['13-11'], ['11-15'], ['6-9'], ['17-0'], ['24-30'], ['12-16'], ['13-23'], ['15-5'], ['24-16'], ['24-29'], ['29-19'], ['29-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2291\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['19-15'], ['16-19'], ['21-30'], ['25-3'], ['12-26'], ['13-11'], ['21-16'], ['6-9'], ['11-15'], ['17-0'], ['24-30'], ['12-16'], ['13-23'], ['15-5'], ['24-16'], ['24-29'], ['29-19'], ['29-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3585\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['19-15'], ['16-19'], ['21-30'], ['25-3'], ['12-26'], ['13-11'], ['21-16'], ['6-9'], ['11-15'], ['17-0'], ['24-30'], ['12-16'], ['13-23'], ['15-5'], ['24-16'], ['24-29'], ['29-19'], ['29-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 63.443970680236816\n",
      "Response: No, the FIFA World Cup will not be hosted this year. The FIFA World Cup is a major international football tournament that is held every four years. The tournament is organized by the Fédération Internationale de Football Association (FIFA), the sport'\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_5000_depth_7500_results.json\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['19-15'], ['21-30'], ['16-19'], ['25-3'], ['13-11'], ['12-26'], ['21-16'], ['11-15'], ['17-0'], ['6-9'], ['24-30'], ['12-16'], ['13-23'], ['24-16'], ['24-29'], ['29-19'], ['29-21'], ['21-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant/llama-2-7b-80k_id_44_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_relevant/44.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: There won't be a FIFA World Cup this year.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['16-19'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['16-19'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['16-19'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['16-19'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_0_depth_7500_results.json\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['16-19'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['16-19'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 66.15109443664551\n",
      "Response: No, the FIFA World Cup will not be held this year. The FIFA World Cup is a quadrennial international football tournament contested by the senior men's national teams of the members of the Fédération Internationale de Football Association (FI\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 238\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['16-19'], ['21-16'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['17-0'], ['18-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 66.74989461898804\n",
      "Response: No, the FIFA World Cup will not be held this year. The FIFA World Cup is a quadrennial international football tournament contested by the senior men's national teams of the member associations of FIFA, the sport's global governing\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 516\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['6-9'], ['24-30'], ['25-3'], ['21-16'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['17-0'], ['18-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 66.74989461898804\n",
      "Response: No, the FIFA World Cup will not be held this year. The FIFA World Cup is a quadrennial international football tournament contested by the senior men's national teams of the member associations of FIFA, the sport's global governing\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 723\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['6-9'], ['21-16'], ['24-30'], ['25-3'], ['11-15'], ['6-17'], ['11-8'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['17-0'], ['18-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 66.74989461898804\n",
      "Response: No, the FIFA World Cup will not be held this year. The FIFA World Cup is a quadrennial international football tournament contested by the senior men's national teams of the member associations of FIFA, the sport's global governing\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_1250_depth_7500_results.json\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['21-16'], ['25-3'], ['6-9'], ['24-30'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['11-8'], ['13-23'], ['15-5'], ['15-14'], ['17-0'], ['18-31'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 71.7802345752716\n",
      "Response: No, the FIFA World Cup will not be held this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['21-16'], ['25-3'], ['6-9'], ['24-30'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['11-8'], ['13-23'], ['15-5'], ['15-14'], ['17-0'], ['18-31'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 535\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['21-16'], ['25-3'], ['6-9'], ['24-30'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['11-8'], ['13-23'], ['15-5'], ['15-14'], ['17-0'], ['18-31'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1143\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['21-16'], ['25-3'], ['6-9'], ['24-30'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['11-8'], ['13-23'], ['15-5'], ['15-14'], ['17-0'], ['18-31'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1689\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['21-16'], ['25-3'], ['6-9'], ['24-30'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['11-8'], ['13-23'], ['15-5'], ['15-14'], ['17-0'], ['18-31'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_2500_depth_7500_results.json\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['21-16'], ['25-3'], ['6-9'], ['24-30'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['17-0'], ['11-8'], ['13-23'], ['15-5'], ['15-14'], ['18-31'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['25-3'], ['21-16'], ['6-9'], ['24-30'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['17-0'], ['11-8'], ['13-23'], ['15-5'], ['15-14'], ['18-31'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 867\n",
      "There won't be a FIFA World Cup this year.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 10.532115399837494\n",
      "Response: No, it won't.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1763\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['21-16'], ['25-3'], ['6-9'], ['24-30'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['17-0'], ['11-8'], ['13-23'], ['15-5'], ['15-14'], ['18-31'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 63.443970680236816\n",
      "Response: No, the FIFA World Cup will not be hosted this year. The FIFA World Cup is a major international football tournament that is held every four years. The tournament is organized by the Fédération Internationale de Football Association (FIFA), the sport'\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2612\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['21-16'], ['25-3'], ['6-9'], ['24-30'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['17-0'], ['19-9'], ['11-8'], ['13-23'], ['15-5'], ['15-14'], ['18-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_3750_depth_7500_results.json\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['21-16'], ['25-3'], ['11-15'], ['6-9'], ['12-26'], ['24-30'], ['12-16'], ['13-11'], ['17-0'], ['19-9'], ['11-8'], ['13-23'], ['15-14'], ['21-5'], ['24-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['21-16'], ['25-3'], ['11-15'], ['6-9'], ['12-26'], ['24-30'], ['12-16'], ['13-11'], ['17-0'], ['19-9'], ['11-8'], ['13-23'], ['15-14'], ['21-5'], ['24-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1143\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['21-16'], ['25-3'], ['11-15'], ['6-9'], ['12-26'], ['24-30'], ['12-16'], ['13-11'], ['17-0'], ['19-9'], ['11-8'], ['13-23'], ['15-14'], ['21-5'], ['24-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2337\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['21-16'], ['25-3'], ['11-15'], ['6-9'], ['12-26'], ['24-30'], ['12-16'], ['13-11'], ['17-0'], ['19-9'], ['11-8'], ['13-23'], ['15-14'], ['21-5'], ['24-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3583\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['21-16'], ['25-3'], ['11-15'], ['6-9'], ['12-26'], ['24-30'], ['12-16'], ['13-11'], ['17-0'], ['19-9'], ['24-29'], ['11-8'], ['13-23'], ['15-14'], ['21-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_5000_depth_7500_results.json\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['19-15'], ['16-19'], ['21-30'], ['21-16'], ['25-3'], ['11-15'], ['12-26'], ['6-9'], ['12-16'], ['13-11'], ['17-0'], ['19-9'], ['24-29'], ['24-30'], ['11-8'], ['13-23'], ['15-14'], ['24-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_relevant_misleading/llama-2-7b-80k_id_44_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: There won't be a FIFA World Cup this year.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['16-19'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['16-19'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['16-19'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['16-19'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_0_depth_7500_results.json\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['16-19'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['16-19'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 237\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['16-19'], ['21-16'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['17-0'], ['18-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 517\n",
      "There won't be a FIFA World Cup this year.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 11.441656947135925\n",
      "Response: No.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 737\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['21-16'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['17-0'], ['18-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_1250_depth_7500_results.json\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['19-15'], ['16-19'], ['21-30'], ['25-3'], ['6-9'], ['24-30'], ['21-16'], ['11-15'], ['12-26'], ['13-11'], ['17-0'], ['11-8'], ['12-16'], ['13-23'], ['15-5'], ['15-14'], ['19-14'], ['21-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['19-15'], ['16-19'], ['21-30'], ['25-3'], ['6-9'], ['24-30'], ['21-16'], ['11-15'], ['12-26'], ['13-11'], ['17-0'], ['11-8'], ['12-16'], ['13-23'], ['15-5'], ['15-14'], ['19-14'], ['21-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 569\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['25-3'], ['6-9'], ['24-30'], ['21-16'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['17-0'], ['11-8'], ['13-23'], ['15-5'], ['15-14'], ['19-14'], ['21-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1110\n",
      "There won't be a FIFA World Cup this year.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 11.441656947135925\n",
      "Response: No.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1674\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['21-30'], ['19-15'], ['25-3'], ['21-16'], ['6-9'], ['24-30'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['17-0'], ['24-29'], ['11-8'], ['13-23'], ['15-5'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_2500_depth_7500_results.json\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['16-19'], ['19-15'], ['21-30'], ['25-3'], ['21-16'], ['11-15'], ['6-9'], ['24-30'], ['12-16'], ['12-26'], ['13-11'], ['17-0'], ['15-14'], ['24-29'], ['11-8'], ['13-23'], ['15-5'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['11-15'], ['25-3'], ['21-16'], ['6-9'], ['24-30'], ['12-16'], ['12-26'], ['13-11'], ['17-0'], ['15-14'], ['24-29'], ['11-8'], ['13-23'], ['15-5'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 852\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['11-15'], ['21-16'], ['25-3'], ['6-9'], ['24-30'], ['12-16'], ['12-26'], ['13-11'], ['17-0'], ['15-14'], ['24-29'], ['11-8'], ['13-23'], ['15-5'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1720\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['11-15'], ['21-30'], ['19-15'], ['21-16'], ['25-3'], ['6-9'], ['24-30'], ['12-26'], ['13-11'], ['17-0'], ['12-16'], ['15-14'], ['24-29'], ['11-8'], ['13-23'], ['15-5'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2637\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['16-19'], ['7-4'], ['11-15'], ['21-30'], ['19-15'], ['21-16'], ['25-3'], ['6-9'], ['24-30'], ['12-26'], ['13-11'], ['17-0'], ['12-16'], ['15-14'], ['24-29'], ['11-8'], ['13-23'], ['14-18'], ['15-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_3750_depth_7500_results.json\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['19-15'], ['11-15'], ['21-30'], ['21-16'], ['25-3'], ['12-26'], ['13-11'], ['17-0'], ['6-9'], ['12-16'], ['15-14'], ['24-30'], ['24-29'], ['11-8'], ['13-23'], ['15-5'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['16-19'], ['7-4'], ['11-15'], ['19-15'], ['21-30'], ['21-16'], ['25-3'], ['12-26'], ['13-11'], ['17-0'], ['6-9'], ['12-16'], ['15-14'], ['24-30'], ['24-29'], ['11-8'], ['13-23'], ['14-18'], ['15-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1179\n",
      "There won't be a FIFA World Cup this year.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 11.441656947135925\n",
      "Response: No.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2374\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['16-19'], ['7-4'], ['11-15'], ['19-15'], ['21-30'], ['21-16'], ['25-3'], ['12-26'], ['13-11'], ['17-0'], ['6-9'], ['12-16'], ['15-14'], ['24-30'], ['14-18'], ['24-29'], ['7-12'], ['11-8'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3484\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['16-19'], ['7-4'], ['11-15'], ['19-15'], ['21-30'], ['21-16'], ['25-3'], ['12-26'], ['13-11'], ['17-0'], ['14-18'], ['6-9'], ['7-12'], ['12-16'], ['15-14'], ['24-30'], ['24-29'], ['11-8'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_5000_depth_7500_results.json\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['16-19'], ['7-4'], ['19-15'], ['11-15'], ['21-30'], ['21-16'], ['25-3'], ['13-11'], ['12-26'], ['17-0'], ['15-14'], ['12-16'], ['14-18'], ['24-29'], ['6-9'], ['7-12'], ['24-30'], ['11-8'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant/llama-2-7b-80k_id_44_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_irrelevant/44.txt\n",
>>>>>>> Stashed changes
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
=======
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n"
>>>>>>> Stashed changes
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
<<<<<<< Updated upstream
      "- Needle: The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
=======
      "- Needle: There won't be a FIFA World Cup this year.\n",
>>>>>>> Stashed changes
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
<<<<<<< Updated upstream
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
=======
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['19-15'], ['21-30'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['0-9'], ['8-22'], ['10-29'], ['12-16'], ['13-11'], ['14-7']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['19-15'], ['21-30'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['0-9'], ['8-22'], ['10-29'], ['12-16'], ['13-11'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['19-15'], ['21-30'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['0-9'], ['8-22'], ['10-29'], ['12-16'], ['13-11'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['19-15'], ['21-30'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['0-9'], ['8-22'], ['10-29'], ['12-16'], ['13-11'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_0_depth_7500_results.json\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['19-15'], ['21-30'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['0-9'], ['8-22'], ['10-29'], ['12-16'], ['13-11'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['19-15'], ['21-30'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['0-9'], ['8-22'], ['10-29'], ['12-16'], ['13-11'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 234\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['6-9'], ['8-26'], ['6-30'], ['19-15'], ['21-30'], ['7-4'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['12-16'], ['19-9'], ['22-27'], ['24-16'], ['25-3'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 490\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['24-29'], ['8-26'], ['19-15'], ['21-30'], ['6-30'], ['7-4'], ['15-14'], ['29-26'], ['7-28'], ['12-26'], ['17-22'], ['19-9'], ['22-27'], ['24-16'], ['25-3'], ['26-25'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 723\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['24-29'], ['8-26'], ['19-15'], ['21-30'], ['6-30'], ['7-4'], ['15-14'], ['12-26'], ['17-22'], ['29-26'], ['7-28'], ['19-9'], ['22-27'], ['24-16'], ['25-3'], ['29-19'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_1250_depth_7500_results.json\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['11-15'], ['8-26'], ['19-15'], ['21-30'], ['6-30'], ['7-4'], ['15-14'], ['12-26'], ['17-22'], ['7-28'], ['29-26'], ['25-3'], ['29-19'], ['16-24'], ['19-9'], ['22-27'], ['24-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['19-15'], ['21-30'], ['6-30'], ['7-4'], ['15-14'], ['12-26'], ['17-22'], ['7-28'], ['29-26'], ['25-3'], ['29-19'], ['16-24'], ['19-9'], ['22-27'], ['24-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 60.571324825286865\n",
      "Response: Flight b741\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 566\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['6-9'], ['11-15'], ['8-26'], ['19-15'], ['21-30'], ['6-30'], ['7-4'], ['15-14'], ['12-26'], ['17-22'], ['7-28'], ['29-26'], ['29-19'], ['25-3'], ['24-16'], ['31-16'], ['16-24'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 921\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['6-9'], ['11-15'], ['8-26'], ['19-15'], ['21-30'], ['7-4'], ['6-30'], ['15-14'], ['12-26'], ['17-22'], ['7-28'], ['29-26'], ['29-19'], ['24-16'], ['25-3'], ['31-16'], ['7-12'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 921\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['6-9'], ['11-15'], ['8-26'], ['19-15'], ['21-30'], ['7-4'], ['6-30'], ['15-14'], ['12-26'], ['17-22'], ['7-28'], ['29-26'], ['7-12'], ['24-16'], ['29-19'], ['25-3'], ['29-21'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
<<<<<<< Updated upstream
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant/llama-2-7b-80k_id_423_irrelevant_len_2500_depth_7500_results.json\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 45.488643646240234\n",
      "Response: The Tortured Poets Department is the album by The Tortured Poets Department.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant/llama-2-7b-80k_id_423_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 4.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 46.16744518280029\n",
      "Response: The Tortured Poets Department is a compilation album by the American rock band The Tortured Poets Department. It was released on October 1, 2002, by the independent record label, The Tortured Poets\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant/llama-2-7b-80k_id_423_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 879\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 44.535672664642334\n",
      "Response: The Tortured Poets Department is a compilation album by the American rock band The Tortured Poets Department. It was released on October 1, 2002, by the band's own label, Tortured Po\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant/llama-2-7b-80k_id_423_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1750\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 42.17897653579712\n",
      "Response: The Tortured Poets Department is the 1999 album by the band The Tortured Poets Department.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant/llama-2-7b-80k_id_423_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2617\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 43.28800439834595\n",
      "Response: The Tortured Poets Department is a 2019 album by the American indie rock band The Tortured Poets Department.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant/llama-2-7b-80k_id_423_irrelevant_len_3750_depth_7500_results.json\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 45.488643646240234\n",
      "Response: The Tortured Poets Department is the album by The Tortured Poets Department.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant/llama-2-7b-80k_id_423_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "[['11-15'], ['7-12'], ['14-3'], ['11-2'], ['11-26'], ['14-18'], ['14-24'], ['14-26'], ['14-29'], ['15-12'], ['16-19'], ['17-22'], ['22-22'], ['24-29'], ['25-21'], ['0-0'], ['0-1'], ['0-2'], ['0-3'], ['0-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 5.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 58.49371552467346\n",
      "Response: The Tortured Poets Department is a compilation of the best-selling music singles. The criterion for inclusion is to sell at least ten million copies worldwide. The singles listed here were cited by reliable sources from various media, such\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant/llama-2-7b-80k_id_423_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1193\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
=======
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['16-19'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['16-19'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['16-19'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['16-19'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['7-4'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['16-19'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['16-19'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['17-0'], ['18-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 237\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['16-19'], ['21-16'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['17-0'], ['18-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 517\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['21-16'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['17-0'], ['18-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 759\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['6-9'], ['19-15'], ['21-30'], ['24-30'], ['25-3'], ['21-16'], ['6-17'], ['11-8'], ['11-15'], ['12-16'], ['12-26'], ['13-11'], ['13-23'], ['15-5'], ['15-14'], ['17-0'], ['18-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 66.11227989196777\n",
      "Response: No, the FIFA World Cup will not be held this year. The FIFA World Cup is a major international football tournament that is held every four years. The tournament is organized by FIFA, the international governing body of football, and is contested by\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['7-4'], ['16-19'], ['19-15'], ['21-30'], ['25-3'], ['6-9'], ['21-16'], ['24-30'], ['11-15'], ['12-26'], ['13-11'], ['15-14'], ['17-0'], ['12-16'], ['13-23'], ['15-5'], ['19-14'], ['21-5'], ['24-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['17-22'], ['16-19'], ['7-4'], ['19-15'], ['21-30'], ['25-3'], ['6-9'], ['21-16'], ['24-30'], ['11-15'], ['12-26'], ['13-11'], ['15-14'], ['17-0'], ['12-16'], ['13-23'], ['15-5'], ['19-14'], ['21-5'], ['24-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 71.7802345752716\n",
      "Response: No, the FIFA World Cup will not be held this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 569\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['16-19'], ['17-22'], ['7-4'], ['19-15'], ['21-30'], ['21-16'], ['25-3'], ['6-9'], ['11-15'], ['24-30'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['17-0'], ['13-23'], ['15-5'], ['19-14'], ['21-5'], ['24-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1132\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['16-19'], ['17-22'], ['7-4'], ['19-15'], ['21-30'], ['21-16'], ['11-15'], ['25-3'], ['6-9'], ['24-30'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['17-0'], ['13-23'], ['15-5'], ['19-14'], ['21-5'], ['24-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 71.7802345752716\n",
      "Response: No, the FIFA World Cup will not be held this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1703\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['16-19'], ['17-22'], ['7-4'], ['19-15'], ['21-30'], ['11-15'], ['21-16'], ['25-3'], ['6-9'], ['24-30'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['17-0'], ['13-23'], ['15-5'], ['19-14'], ['21-5'], ['24-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 71.7802345752716\n",
      "Response: No, the FIFA World Cup will not be held this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['16-19'], ['17-22'], ['7-4'], ['19-15'], ['21-30'], ['11-15'], ['21-16'], ['25-3'], ['6-9'], ['24-30'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['17-0'], ['13-23'], ['24-16'], ['24-29'], ['11-8'], ['15-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 71.7802345752716\n",
      "Response: No, the FIFA World Cup will not be held this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['16-19'], ['17-22'], ['7-4'], ['11-15'], ['19-15'], ['21-30'], ['21-16'], ['25-3'], ['6-9'], ['24-30'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['17-0'], ['13-23'], ['24-16'], ['24-29'], ['11-8'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 71.7802345752716\n",
      "Response: No, the FIFA World Cup will not be held this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 874\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['16-19'], ['17-22'], ['7-4'], ['11-15'], ['19-15'], ['21-30'], ['21-16'], ['25-3'], ['6-9'], ['24-30'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['17-0'], ['13-23'], ['24-16'], ['24-29'], ['11-8'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 71.7802345752716\n",
      "Response: No, the FIFA World Cup will not be held this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1766\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['16-19'], ['17-22'], ['7-4'], ['11-15'], ['19-15'], ['21-30'], ['21-16'], ['25-3'], ['6-9'], ['24-30'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['17-0'], ['13-23'], ['24-16'], ['24-29'], ['11-8'], ['15-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 71.7802345752716\n",
      "Response: No, the FIFA World Cup will not be held this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2589\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['16-19'], ['17-22'], ['11-15'], ['7-4'], ['19-15'], ['21-30'], ['21-16'], ['25-3'], ['6-9'], ['24-30'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['17-0'], ['24-29'], ['13-23'], ['24-16'], ['11-8'], ['15-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['16-19'], ['17-22'], ['11-15'], ['7-4'], ['19-15'], ['21-30'], ['21-16'], ['25-3'], ['12-26'], ['13-11'], ['15-14'], ['12-16'], ['6-9'], ['24-30'], ['17-0'], ['24-29'], ['13-23'], ['24-16'], ['11-8'], ['21-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 71.7802345752716\n",
      "Response: No, the FIFA World Cup will not be held this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "There won't be a FIFA World Cup this year.\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 10.532115399837494\n",
      "Response: No, it won't.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1132\n",
      "There won't be a FIFA World Cup this year.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 10.532115399837494\n",
      "Response: No, it won't.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2364\n",
      "There won't be a FIFA World Cup this year.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 10.532115399837494\n",
      "Response: No, it won't.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3574\n",
      "There won't be a FIFA World Cup this year.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 10.532115399837494\n",
      "Response: No, it won't.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "There won't be a FIFA World Cup this year.\n",
      "[['16-19'], ['17-22'], ['11-15'], ['7-4'], ['19-15'], ['21-30'], ['21-16'], ['25-3'], ['12-26'], ['13-11'], ['15-14'], ['12-16'], ['17-0'], ['24-29'], ['6-9'], ['24-30'], ['13-23'], ['24-16'], ['11-8'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 68.16167831420898\n",
      "Response: No, the FIFA World Cup will not be hosted this year.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_44_irrelevant_misleading/llama-2-7b-80k_id_44_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-10'], ['19-15'], ['22-8'], ['26-28'], ['0-14'], ['7-13'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-10'], ['19-15'], ['22-8'], ['26-28'], ['0-14'], ['7-13'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-10'], ['19-15'], ['22-8'], ['26-28'], ['0-14'], ['7-13'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-10'], ['19-15'], ['22-8'], ['26-28'], ['0-14'], ['7-13'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_0_depth_7500_results.json\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-10'], ['19-15'], ['22-8'], ['26-28'], ['0-14'], ['7-13'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['6-30'], ['7-4'], ['17-22'], ['19-10'], ['22-8'], ['12-26'], ['13-11'], ['14-18'], ['18-30'], ['19-15'], ['26-28'], ['15-14'], ['8-26'], ['16-30'], ['18-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_1250_depth_0_results.json\n",
      "insertion at 229\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['6-30'], ['7-4'], ['22-8'], ['19-15'], ['12-26'], ['17-22'], ['19-10'], ['13-11'], ['14-18'], ['18-30'], ['26-28'], ['8-26'], ['15-14'], ['26-26'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 83.8680624961853\n",
      "Response: Zootopia 2, by Walt Disney Animation Studios, directed by Walt Disney Animation Studios, written by Walt Disney Animation Studios, produced by Walt Disney Animation Studios, composed by Walt Disney Animation Studios\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 499\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 49.65211749076843\n",
      "Response: Zootopia 2. Hee\",\"Homer Brightman, Ralph Wright, Bill Peet, Ted Sears, Webb Smith, Joe Grant, Dick Huemer, Elmer Plummer, James Bodrero, Del Connell\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 499\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 49.65211749076843\n",
      "Response: Zootopia 2. Hee\",\"Homer Brightman, Ralph Wright, Bill Peet, Ted Sears, Webb Smith, Joe Grant, Dick Huemer, Elmer Plummer, James Bodrero, Del Connell\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_1250_depth_7500_results.json\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['21-30'], ['6-9'], ['6-30'], ['19-15'], ['22-8'], ['12-26'], ['13-11'], ['17-22'], ['19-10'], ['7-4'], ['8-26'], ['18-30'], ['26-28'], ['15-14'], ['14-18'], ['31-16'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['21-30'], ['6-9'], ['6-30'], ['8-26'], ['19-10'], ['22-8'], ['17-22'], ['19-15'], ['13-11'], ['7-4'], ['12-26'], ['15-14'], ['26-28'], ['18-30'], ['14-18'], ['31-16'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_2500_depth_0_results.json\n",
      "insertion at 499\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['21-30'], ['6-9'], ['6-30'], ['8-26'], ['22-8'], ['19-10'], ['19-15'], ['17-22'], ['26-28'], ['7-4'], ['12-26'], ['13-11'], ['15-14'], ['18-30'], ['31-16'], ['14-18'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1075\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['6-9'], ['11-15'], ['6-30'], ['8-26'], ['22-8'], ['19-15'], ['17-22'], ['19-10'], ['26-28'], ['7-4'], ['12-26'], ['13-11'], ['15-14'], ['18-30'], ['31-16'], ['14-18'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1439\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 34.411031007766724\n",
      "Response: The Aristocats\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_2500_depth_7500_results.json\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['6-9'], ['11-15'], ['6-30'], ['8-26'], ['22-8'], ['19-15'], ['17-22'], ['19-10'], ['13-11'], ['26-28'], ['7-4'], ['12-26'], ['15-14'], ['18-30'], ['31-16'], ['14-18'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['6-9'], ['11-15'], ['8-26'], ['6-30'], ['22-8'], ['17-22'], ['19-10'], ['19-15'], ['13-11'], ['26-28'], ['7-4'], ['12-26'], ['15-14'], ['18-30'], ['31-16'], ['14-18'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_3750_depth_0_results.json\n",
      "insertion at 814\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['6-9'], ['11-15'], ['8-26'], ['6-30'], ['22-8'], ['17-22'], ['19-10'], ['19-15'], ['13-11'], ['26-28'], ['7-4'], ['15-14'], ['18-30'], ['31-16'], ['12-26'], ['19-9'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1439\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['6-9'], ['11-15'], ['8-26'], ['6-30'], ['22-8'], ['19-10'], ['17-22'], ['19-15'], ['13-11'], ['26-28'], ['7-4'], ['18-30'], ['31-16'], ['12-26'], ['15-14'], ['19-9'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2587\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['6-9'], ['11-15'], ['8-26'], ['6-30'], ['22-8'], ['19-10'], ['17-22'], ['19-15'], ['13-11'], ['7-4'], ['26-28'], ['18-30'], ['31-16'], ['15-14'], ['12-26'], ['19-9'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_3750_depth_7500_results.json\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['6-9'], ['11-15'], ['8-26'], ['6-30'], ['22-8'], ['19-10'], ['17-22'], ['19-15'], ['13-11'], ['26-28'], ['31-16'], ['7-4'], ['18-30'], ['12-26'], ['15-14'], ['19-9'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['6-9'], ['11-15'], ['8-26'], ['22-8'], ['6-30'], ['19-10'], ['17-22'], ['19-15'], ['13-11'], ['26-28'], ['7-4'], ['31-16'], ['18-30'], ['15-14'], ['12-26'], ['19-9'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1179\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['6-9'], ['11-15'], ['8-26'], ['22-8'], ['6-30'], ['19-10'], ['17-22'], ['19-15'], ['13-11'], ['26-28'], ['7-4'], ['18-30'], ['31-16'], ['15-14'], ['12-26'], ['19-9'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2164\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['6-9'], ['21-30'], ['11-15'], ['8-26'], ['22-8'], ['6-30'], ['19-10'], ['17-22'], ['19-15'], ['13-11'], ['26-28'], ['7-4'], ['31-16'], ['18-30'], ['15-14'], ['12-26'], ['19-9'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3006\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['6-9'], ['21-30'], ['11-15'], ['8-26'], ['6-30'], ['22-8'], ['19-10'], ['17-22'], ['19-15'], ['13-11'], ['26-28'], ['7-4'], ['31-16'], ['18-30'], ['15-14'], ['12-26'], ['26-26'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_5000_depth_7500_results.json\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['6-9'], ['11-15'], ['8-26'], ['6-30'], ['22-8'], ['19-10'], ['19-15'], ['17-22'], ['13-11'], ['26-28'], ['7-4'], ['31-16'], ['18-30'], ['15-14'], ['12-26'], ['26-26'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant/llama-2-7b-80k_id_441_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_relevant/441.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-10'], ['19-15'], ['22-8'], ['26-28'], ['0-14'], ['7-13'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-10'], ['19-15'], ['22-8'], ['26-28'], ['0-14'], ['7-13'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-10'], ['19-15'], ['22-8'], ['26-28'], ['0-14'], ['7-13'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-10'], ['19-15'], ['22-8'], ['26-28'], ['0-14'], ['7-13'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_0_depth_7500_results.json\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-10'], ['19-15'], ['22-8'], ['26-28'], ['0-14'], ['7-13'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['6-30'], ['7-4'], ['22-8'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['19-10'], ['19-15'], ['26-28'], ['12-26'], ['18-30'], ['8-26'], ['13-23'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 229\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['21-30'], ['6-9'], ['6-30'], ['7-4'], ['22-8'], ['13-11'], ['19-15'], ['14-18'], ['15-14'], ['17-22'], ['19-10'], ['26-28'], ['18-30'], ['8-26'], ['12-26'], ['19-9'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 499\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['21-30'], ['6-9'], ['6-30'], ['7-4'], ['22-8'], ['19-15'], ['13-11'], ['17-22'], ['15-14'], ['19-10'], ['26-28'], ['8-26'], ['12-26'], ['14-18'], ['18-30'], ['19-9'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 499\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['11-15'], ['6-9'], ['6-30'], ['7-4'], ['22-8'], ['19-15'], ['17-22'], ['13-11'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['26-28'], ['18-30'], ['14-18'], ['19-9'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['11-15'], ['6-9'], ['6-30'], ['22-8'], ['19-15'], ['7-4'], ['13-11'], ['17-22'], ['8-26'], ['12-26'], ['15-14'], ['19-10'], ['26-28'], ['18-30'], ['14-18'], ['31-16'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['11-15'], ['6-9'], ['6-30'], ['22-8'], ['8-26'], ['19-15'], ['7-4'], ['13-11'], ['17-22'], ['15-14'], ['19-10'], ['26-28'], ['12-26'], ['18-30'], ['14-18'], ['19-9'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 499\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['6-9'], ['11-15'], ['6-30'], ['22-8'], ['8-26'], ['19-15'], ['13-11'], ['7-4'], ['17-22'], ['19-10'], ['15-14'], ['26-28'], ['12-26'], ['18-30'], ['14-18'], ['19-9'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1095\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['6-9'], ['11-15'], ['6-30'], ['22-8'], ['8-26'], ['19-15'], ['7-4'], ['13-11'], ['17-22'], ['19-10'], ['15-14'], ['26-28'], ['12-26'], ['18-30'], ['19-9'], ['14-18'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1478\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['6-9'], ['11-15'], ['6-30'], ['22-8'], ['8-26'], ['19-15'], ['7-4'], ['13-11'], ['17-22'], ['19-10'], ['12-26'], ['15-14'], ['26-28'], ['18-30'], ['19-9'], ['7-31'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['6-9'], ['11-15'], ['6-30'], ['8-26'], ['22-8'], ['19-15'], ['7-4'], ['13-11'], ['17-22'], ['19-10'], ['12-26'], ['15-14'], ['26-28'], ['18-30'], ['19-9'], ['7-31'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 26.126527786254883\n",
      "Response: The Hunchback of Notre Dame, the 1996 film.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 834\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 8.61004889011383\n",
      "Response: The Hunchback of Notre Dame\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1478\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 26.126527786254883\n",
      "Response: The Hunchback of Notre Dame, the 1996 film.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2646\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "-- Test Summary -- \n",
      "Duration: 3.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 9.62776392698288\n",
      "Response: The Hunchback of Notre Dame,The Hunchback of Notre Dame,The Hunchback of Notre Dame,The Hunchback of Notre Dame,The Hunchback of Notre Dame,The Hunchback of\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['6-9'], ['11-15'], ['6-30'], ['8-26'], ['22-8'], ['19-15'], ['13-11'], ['17-22'], ['7-4'], ['19-10'], ['12-26'], ['15-14'], ['26-28'], ['18-30'], ['31-16'], ['19-9'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 29.363322257995605\n",
      "Response: Winnie the Pooh,\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1095\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 29.363322257995605\n",
      "Response: Winnie the Pooh,\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2203\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 29.363322257995605\n",
      "Response: Winnie the Pooh,\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3122\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['6-9'], ['11-15'], ['6-30'], ['8-26'], ['22-8'], ['19-15'], ['13-11'], ['17-22'], ['7-4'], ['12-26'], ['19-10'], ['15-14'], ['26-28'], ['18-30'], ['31-16'], ['19-9'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 50.551390647888184\n",
      "Response: Winnie the Pooh, by A. A. Milne,Walt Disney Animation Studios,Don Hall,Steve Anderson,Kristen Anderson-Lopez,Robert Lopez\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['11-15'], ['6-9'], ['6-30'], ['8-26'], ['22-8'], ['19-15'], ['13-11'], ['17-22'], ['7-4'], ['12-26'], ['19-10'], ['15-14'], ['26-28'], ['18-30'], ['31-16'], ['19-9'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_relevant_misleading/llama-2-7b-80k_id_441_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-10'], ['19-15'], ['22-8'], ['26-28'], ['0-14'], ['7-13'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-10'], ['19-15'], ['22-8'], ['26-28'], ['0-14'], ['7-13'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-10'], ['19-15'], ['22-8'], ['26-28'], ['0-14'], ['7-13'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-10'], ['19-15'], ['22-8'], ['26-28'], ['0-14'], ['7-13'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_0_depth_7500_results.json\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-10'], ['19-15'], ['22-8'], ['26-28'], ['0-14'], ['7-13'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 12.271647155284882\n",
      "Response: Brave\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 195\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['21-30'], ['6-30'], ['6-9'], ['7-4'], ['13-11'], ['19-15'], ['22-8'], ['12-26'], ['17-22'], ['18-30'], ['19-10'], ['26-28'], ['14-18'], ['15-14'], ['8-26'], ['7-31'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 507\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['17-22'], ['19-15'], ['7-4'], ['13-11'], ['22-8'], ['12-26'], ['19-10'], ['26-28'], ['18-30'], ['8-26'], ['14-18'], ['15-14'], ['26-26'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 743\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['19-15'], ['7-4'], ['13-11'], ['17-22'], ['22-8'], ['12-26'], ['8-26'], ['19-10'], ['26-28'], ['18-30'], ['14-18'], ['15-14'], ['26-26'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_1250_depth_7500_results.json\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['13-11'], ['19-15'], ['17-22'], ['22-8'], ['12-26'], ['8-26'], ['19-10'], ['26-28'], ['18-30'], ['15-14'], ['14-18'], ['26-26'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['19-15'], ['7-4'], ['13-11'], ['17-22'], ['22-8'], ['8-26'], ['12-26'], ['19-10'], ['26-28'], ['18-30'], ['15-14'], ['14-18'], ['26-26'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 78.27939987182617\n",
      "Response: The next Walt Disney Animation Studios film is Coco 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 507\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['6-30'], ['8-26'], ['19-15'], ['13-11'], ['17-22'], ['7-4'], ['22-8'], ['12-26'], ['26-28'], ['19-10'], ['18-30'], ['15-14'], ['7-12'], ['26-26'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1131\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['8-26'], ['6-30'], ['19-15'], ['13-11'], ['17-22'], ['22-8'], ['7-4'], ['12-26'], ['26-28'], ['19-10'], ['7-12'], ['18-30'], ['15-14'], ['26-26'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1447\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['21-30'], ['8-26'], ['6-30'], ['19-15'], ['17-22'], ['13-11'], ['22-8'], ['7-4'], ['12-26'], ['26-28'], ['19-10'], ['7-12'], ['15-14'], ['18-30'], ['26-26'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_2500_depth_7500_results.json\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['8-26'], ['6-30'], ['19-15'], ['17-22'], ['13-11'], ['7-4'], ['22-8'], ['12-26'], ['26-28'], ['19-10'], ['7-12'], ['15-14'], ['18-30'], ['26-26'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['8-26'], ['6-30'], ['17-22'], ['19-15'], ['13-11'], ['22-8'], ['7-4'], ['7-12'], ['26-28'], ['12-26'], ['19-10'], ['15-14'], ['18-30'], ['26-26'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00002384185791\n",
      "Response: The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 743\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['8-26'], ['6-30'], ['17-22'], ['19-15'], ['22-8'], ['13-11'], ['7-12'], ['7-4'], ['26-28'], ['19-10'], ['12-26'], ['15-14'], ['18-30'], ['26-26'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1447\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['8-26'], ['6-30'], ['7-12'], ['17-22'], ['19-15'], ['22-8'], ['13-11'], ['7-4'], ['26-28'], ['19-10'], ['12-26'], ['15-14'], ['11-2'], ['26-26'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2628\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['8-26'], ['6-30'], ['7-12'], ['17-22'], ['19-15'], ['22-8'], ['13-11'], ['7-4'], ['26-28'], ['19-10'], ['12-26'], ['15-14'], ['11-2'], ['26-26'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_3750_depth_7500_results.json\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['8-26'], ['6-30'], ['17-22'], ['7-12'], ['19-15'], ['13-11'], ['22-8'], ['7-4'], ['26-28'], ['19-10'], ['12-26'], ['15-14'], ['31-16'], ['18-30'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['6-30'], ['19-15'], ['13-11'], ['22-8'], ['7-4'], ['26-28'], ['19-10'], ['12-26'], ['15-14'], ['18-30'], ['31-16'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1131\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['6-30'], ['19-15'], ['13-11'], ['22-8'], ['7-4'], ['26-28'], ['19-10'], ['12-26'], ['15-14'], ['18-30'], ['31-16'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2383\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['6-30'], ['19-15'], ['13-11'], ['22-8'], ['7-4'], ['26-28'], ['19-10'], ['12-26'], ['15-14'], ['31-16'], ['18-30'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3552\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['8-26'], ['17-22'], ['7-12'], ['6-30'], ['19-15'], ['13-11'], ['22-8'], ['7-4'], ['26-28'], ['19-10'], ['12-26'], ['15-14'], ['31-16'], ['18-30'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_5000_depth_7500_results.json\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['8-26'], ['17-22'], ['6-30'], ['7-12'], ['13-11'], ['19-15'], ['22-8'], ['7-4'], ['26-28'], ['19-10'], ['12-26'], ['15-14'], ['31-16'], ['18-30'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant/llama-2-7b-80k_id_441_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_irrelevant/441.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-10'], ['19-15'], ['22-8'], ['26-28'], ['0-14'], ['7-13'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-10'], ['19-15'], ['22-8'], ['26-28'], ['0-14'], ['7-13'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-10'], ['19-15'], ['22-8'], ['26-28'], ['0-14'], ['7-13'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-10'], ['19-15'], ['22-8'], ['26-28'], ['0-14'], ['7-13'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['12-26'], ['13-11'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-10'], ['19-15'], ['22-8'], ['26-28'], ['0-14'], ['7-13'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 12.271647155284882\n",
      "Response: Brave\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 195\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['21-30'], ['6-30'], ['6-9'], ['7-4'], ['13-11'], ['19-15'], ['22-8'], ['12-26'], ['17-22'], ['18-30'], ['19-10'], ['26-28'], ['14-18'], ['15-14'], ['8-26'], ['7-31'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 507\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['17-22'], ['19-15'], ['7-4'], ['13-11'], ['22-8'], ['12-26'], ['19-10'], ['26-28'], ['18-30'], ['8-26'], ['14-18'], ['15-14'], ['26-26'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 743\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['19-15'], ['7-4'], ['13-11'], ['17-22'], ['22-8'], ['12-26'], ['8-26'], ['19-10'], ['26-28'], ['18-30'], ['14-18'], ['15-14'], ['26-26'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['13-11'], ['19-15'], ['17-22'], ['22-8'], ['12-26'], ['8-26'], ['19-10'], ['26-28'], ['18-30'], ['15-14'], ['14-18'], ['26-26'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 36.165690422058105\n",
      "Response: Toy Story 5.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 507\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 36.165690422058105\n",
      "Response: Toy Story 5.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1131\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 36.165690422058105\n",
      "Response: Toy Story 5.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1447\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['6-30'], ['17-22'], ['19-15'], ['7-4'], ['8-26'], ['13-11'], ['22-8'], ['12-26'], ['26-28'], ['19-10'], ['18-30'], ['15-14'], ['14-18'], ['26-26'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00002384185791\n",
      "Response: The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['6-30'], ['7-4'], ['19-15'], ['8-26'], ['13-11'], ['17-22'], ['22-8'], ['12-26'], ['26-28'], ['19-10'], ['18-30'], ['15-14'], ['31-16'], ['26-26'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['6-30'], ['8-26'], ['13-11'], ['17-22'], ['7-4'], ['22-8'], ['19-15'], ['12-26'], ['19-10'], ['26-28'], ['15-14'], ['18-30'], ['7-12'], ['14-18'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00002384185791\n",
      "Response: The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 743\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['8-26'], ['6-30'], ['17-22'], ['13-11'], ['22-8'], ['19-15'], ['7-4'], ['7-12'], ['26-28'], ['12-26'], ['19-10'], ['15-14'], ['18-30'], ['31-16'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00002384185791\n",
      "Response: The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1447\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['8-26'], ['7-12'], ['6-30'], ['17-22'], ['13-11'], ['22-8'], ['19-15'], ['7-4'], ['26-28'], ['19-10'], ['12-26'], ['15-14'], ['18-30'], ['26-26'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00002384185791\n",
      "Response: The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2648\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['8-26'], ['7-12'], ['6-30'], ['17-22'], ['13-11'], ['22-8'], ['19-15'], ['7-4'], ['26-28'], ['19-10'], ['12-26'], ['15-14'], ['18-30'], ['26-26'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['8-26'], ['6-30'], ['7-12'], ['13-11'], ['17-22'], ['22-8'], ['7-4'], ['19-15'], ['26-28'], ['12-26'], ['19-10'], ['15-14'], ['18-30'], ['31-16'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['8-26'], ['7-12'], ['6-30'], ['17-22'], ['13-11'], ['22-8'], ['19-15'], ['7-4'], ['19-10'], ['26-28'], ['12-26'], ['15-14'], ['18-30'], ['31-16'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1131\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['8-26'], ['7-12'], ['6-30'], ['17-22'], ['13-11'], ['19-15'], ['22-8'], ['7-4'], ['19-10'], ['26-28'], ['12-26'], ['15-14'], ['18-30'], ['31-16'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2085\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['6-30'], ['19-15'], ['22-8'], ['13-11'], ['7-4'], ['19-10'], ['26-28'], ['15-14'], ['18-30'], ['12-26'], ['31-16'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3559\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['6-30'], ['19-15'], ['22-8'], ['13-11'], ['7-4'], ['19-10'], ['26-28'], ['15-14'], ['18-30'], ['31-16'], ['12-26'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 72.90757894515991\n",
      "Response: Zootopia 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The next Walt Disney Animation Studios film is Zootopia 2.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['21-30'], ['6-9'], ['8-26'], ['7-12'], ['17-22'], ['6-30'], ['19-15'], ['22-8'], ['13-11'], ['7-4'], ['19-10'], ['26-28'], ['31-16'], ['15-14'], ['18-30'], ['12-26'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 74.20203685760498\n",
      "Response: Zootopia 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_441_irrelevant_misleading/llama-2-7b-80k_id_441_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['1-26'], ['6-30'], ['7-31'], ['8-26'], ['9-8'], ['10-2'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['16-4'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['18-11'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['1-26'], ['6-30'], ['7-31'], ['8-26'], ['9-8'], ['10-2'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['16-4'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['18-11'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['1-26'], ['6-30'], ['7-31'], ['8-26'], ['9-8'], ['10-2'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['16-4'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['18-11'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['1-26'], ['6-30'], ['7-31'], ['8-26'], ['9-8'], ['10-2'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['16-4'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['18-11'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_0_depth_7500_results.json\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['1-26'], ['6-30'], ['7-31'], ['8-26'], ['9-8'], ['10-2'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['16-4'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['18-11'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['8-26'], ['12-26'], ['16-24'], ['19-15'], ['21-30'], ['23-8'], ['1-26'], ['6-30'], ['7-31'], ['9-8'], ['10-2'], ['12-16'], ['13-11'], ['15-14'], ['16-4'], ['16-5'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_1250_depth_0_results.json\n",
      "insertion at 229\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['31-16'], ['11-15'], ['19-15'], ['23-8'], ['8-26'], ['12-26'], ['15-14'], ['16-24'], ['18-30'], ['21-30'], ['24-8'], ['1-26'], ['6-30'], ['7-31'], ['9-8'], ['10-2'], ['12-16'], ['13-11'], ['16-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 499\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['31-16'], ['11-15'], ['19-15'], ['18-30'], ['23-8'], ['8-26'], ['15-14'], ['16-24'], ['21-30'], ['24-8'], ['6-30'], ['7-31'], ['12-26'], ['16-4'], ['16-5'], ['16-30'], ['17-22'], ['24-29'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 73.33691716194153\n",
      "Response: Moana 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 499\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['31-16'], ['11-15'], ['19-15'], ['18-30'], ['23-8'], ['8-26'], ['15-14'], ['16-24'], ['21-30'], ['24-8'], ['6-30'], ['7-31'], ['16-4'], ['16-5'], ['16-30'], ['17-22'], ['24-29'], ['12-26'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 73.33691716194153\n",
      "Response: Moana 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_1250_depth_7500_results.json\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['31-16'], ['19-15'], ['11-15'], ['18-30'], ['15-14'], ['16-24'], ['23-8'], ['8-26'], ['21-30'], ['24-8'], ['6-30'], ['7-31'], ['16-4'], ['16-30'], ['17-22'], ['24-29'], ['12-26'], ['16-5'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['31-16'], ['19-15'], ['11-15'], ['18-30'], ['8-26'], ['23-8'], ['15-14'], ['16-24'], ['21-30'], ['24-8'], ['6-30'], ['7-31'], ['12-26'], ['16-4'], ['16-30'], ['17-22'], ['24-29'], ['16-5'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_2500_depth_0_results.json\n",
      "insertion at 499\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['31-16'], ['19-15'], ['11-15'], ['18-30'], ['8-26'], ['15-14'], ['21-30'], ['23-8'], ['24-8'], ['16-24'], ['6-30'], ['7-31'], ['16-4'], ['16-30'], ['17-22'], ['24-29'], ['12-26'], ['16-5'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1075\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['31-16'], ['19-15'], ['18-30'], ['8-26'], ['11-15'], ['15-14'], ['21-30'], ['23-8'], ['24-8'], ['16-24'], ['6-30'], ['16-30'], ['17-22'], ['19-10'], ['24-29'], ['7-31'], ['16-4'], ['12-26'], ['16-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1439\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['31-16'], ['19-15'], ['18-30'], ['8-26'], ['11-15'], ['15-14'], ['21-30'], ['23-8'], ['24-8'], ['19-10'], ['6-30'], ['16-24'], ['16-30'], ['17-22'], ['24-29'], ['7-31'], ['16-4'], ['26-28'], ['30-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_2500_depth_7500_results.json\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['31-16'], ['19-15'], ['18-30'], ['8-26'], ['11-15'], ['15-14'], ['21-30'], ['23-8'], ['24-8'], ['19-10'], ['6-30'], ['16-24'], ['16-30'], ['17-22'], ['24-29'], ['7-31'], ['12-26'], ['16-4'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['31-16'], ['19-15'], ['8-26'], ['11-15'], ['18-30'], ['15-14'], ['21-30'], ['23-8'], ['24-8'], ['19-10'], ['6-30'], ['16-24'], ['16-30'], ['17-22'], ['24-29'], ['7-31'], ['12-26'], ['16-4'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_3750_depth_0_results.json\n",
      "insertion at 814\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['31-16'], ['19-15'], ['8-26'], ['15-14'], ['18-30'], ['11-15'], ['21-30'], ['23-8'], ['24-8'], ['19-10'], ['6-30'], ['16-30'], ['24-29'], ['16-24'], ['17-22'], ['30-5'], ['7-31'], ['12-26'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1439\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['31-16'], ['19-15'], ['8-26'], ['18-30'], ['15-14'], ['21-30'], ['23-8'], ['24-8'], ['11-15'], ['19-10'], ['6-30'], ['16-30'], ['24-29'], ['17-22'], ['16-24'], ['7-31'], ['24-3'], ['29-26'], ['30-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2587\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['31-16'], ['19-15'], ['8-26'], ['18-30'], ['15-14'], ['21-30'], ['23-8'], ['24-8'], ['19-10'], ['6-30'], ['11-15'], ['16-30'], ['24-29'], ['17-22'], ['16-24'], ['7-31'], ['24-3'], ['29-26'], ['30-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_3750_depth_7500_results.json\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['31-16'], ['19-15'], ['8-26'], ['18-30'], ['15-14'], ['19-10'], ['21-30'], ['23-8'], ['24-8'], ['11-15'], ['6-30'], ['24-29'], ['16-30'], ['17-22'], ['16-24'], ['7-31'], ['24-3'], ['29-26'], ['30-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['31-16'], ['19-15'], ['8-26'], ['18-30'], ['19-10'], ['21-30'], ['23-8'], ['24-8'], ['15-14'], ['11-15'], ['6-30'], ['24-29'], ['16-30'], ['16-24'], ['17-22'], ['24-3'], ['7-31'], ['30-5'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 5.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 52.88958549499512\n",
      "Response: Moana 2 The 2018-19 season is the 11th season in the history of the New York Islanders and their first season as the Islanders since the 2014-15 season\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1179\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['31-16'], ['19-15'], ['8-26'], ['18-30'], ['19-10'], ['21-30'], ['24-8'], ['15-14'], ['23-8'], ['6-30'], ['11-15'], ['24-29'], ['16-30'], ['17-22'], ['16-24'], ['24-3'], ['7-31'], ['13-11'], ['30-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2164\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['31-16'], ['19-15'], ['19-10'], ['8-26'], ['18-30'], ['21-30'], ['24-8'], ['15-14'], ['23-8'], ['6-30'], ['24-29'], ['11-15'], ['16-30'], ['17-22'], ['24-3'], ['16-24'], ['7-31'], ['13-11'], ['30-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3006\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['31-16'], ['19-15'], ['19-10'], ['8-26'], ['18-30'], ['15-14'], ['21-30'], ['24-8'], ['23-8'], ['6-30'], ['24-29'], ['11-15'], ['16-30'], ['17-22'], ['24-3'], ['13-11'], ['16-24'], ['30-5'], ['6-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_5000_depth_7500_results.json\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['31-16'], ['19-15'], ['19-10'], ['8-26'], ['15-14'], ['18-30'], ['21-30'], ['24-8'], ['23-8'], ['6-30'], ['24-29'], ['11-15'], ['16-30'], ['17-22'], ['24-3'], ['16-24'], ['6-9'], ['13-11'], ['30-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant/llama-2-7b-80k_id_442_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_relevant/442.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['1-26'], ['6-30'], ['7-31'], ['8-26'], ['9-8'], ['10-2'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['16-4'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['18-11'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['1-26'], ['6-30'], ['7-31'], ['8-26'], ['9-8'], ['10-2'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['16-4'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['18-11'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['1-26'], ['6-30'], ['7-31'], ['8-26'], ['9-8'], ['10-2'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['16-4'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['18-11'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['1-26'], ['6-30'], ['7-31'], ['8-26'], ['9-8'], ['10-2'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['16-4'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['18-11'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_0_depth_7500_results.json\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['1-26'], ['6-30'], ['7-31'], ['8-26'], ['9-8'], ['10-2'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['16-4'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['18-11'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['12-26'], ['16-24'], ['19-15'], ['1-26'], ['6-30'], ['7-31'], ['8-26'], ['9-8'], ['10-2'], ['12-16'], ['13-11'], ['15-14'], ['16-4'], ['16-5'], ['16-30'], ['17-22'], ['18-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 229\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['12-26'], ['16-24'], ['19-15'], ['23-8'], ['24-8'], ['1-26'], ['6-30'], ['7-31'], ['8-26'], ['9-8'], ['10-2'], ['12-16'], ['13-11'], ['15-14'], ['16-4'], ['16-5'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 499\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['19-15'], ['16-24'], ['23-8'], ['24-8'], ['8-26'], ['12-26'], ['17-22'], ['18-30'], ['21-30'], ['24-29'], ['30-5'], ['1-26'], ['6-30'], ['7-31'], ['9-8'], ['10-2'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 73.33691716194153\n",
      "Response: Moana 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 499\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['31-16'], ['16-24'], ['23-8'], ['24-8'], ['8-26'], ['17-22'], ['18-30'], ['21-30'], ['24-29'], ['30-5'], ['12-26'], ['1-26'], ['6-30'], ['7-31'], ['9-8'], ['10-2'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 73.33691716194153\n",
      "Response: Moana 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['31-16'], ['16-24'], ['18-30'], ['23-8'], ['24-8'], ['24-29'], ['8-26'], ['12-26'], ['17-22'], ['21-30'], ['30-5'], ['15-14'], ['19-10'], ['6-30'], ['7-31'], ['13-11'], ['16-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['31-16'], ['23-8'], ['8-26'], ['12-26'], ['16-24'], ['18-30'], ['24-8'], ['24-29'], ['17-22'], ['21-30'], ['30-5'], ['15-14'], ['19-10'], ['6-30'], ['7-31'], ['13-11'], ['16-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 499\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['31-16'], ['8-26'], ['16-24'], ['18-30'], ['23-8'], ['24-8'], ['24-29'], ['12-26'], ['17-22'], ['19-10'], ['21-30'], ['30-5'], ['6-30'], ['15-14'], ['26-28'], ['7-31'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1094\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['31-16'], ['8-26'], ['16-24'], ['18-30'], ['19-10'], ['23-8'], ['24-8'], ['24-29'], ['17-22'], ['21-30'], ['12-26'], ['26-28'], ['30-5'], ['6-30'], ['15-14'], ['13-11'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1480\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['19-15'], ['31-16'], ['11-15'], ['19-10'], ['8-26'], ['18-30'], ['23-8'], ['24-8'], ['24-29'], ['16-24'], ['17-22'], ['21-30'], ['26-28'], ['6-30'], ['12-26'], ['15-14'], ['30-5'], ['16-30'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['19-15'], ['31-16'], ['11-15'], ['19-10'], ['18-30'], ['24-29'], ['8-26'], ['23-8'], ['24-8'], ['16-24'], ['17-22'], ['21-30'], ['12-26'], ['15-14'], ['26-28'], ['6-30'], ['30-5'], ['16-30'], ['6-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['31-16'], ['8-26'], ['19-10'], ['18-30'], ['24-29'], ['23-8'], ['24-8'], ['16-24'], ['17-22'], ['21-30'], ['12-26'], ['15-14'], ['26-28'], ['6-30'], ['30-5'], ['16-30'], ['6-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 833\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['31-16'], ['8-26'], ['19-10'], ['24-29'], ['18-30'], ['23-8'], ['24-8'], ['15-14'], ['16-24'], ['17-22'], ['21-30'], ['12-26'], ['26-28'], ['6-30'], ['30-5'], ['6-9'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1480\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['31-16'], ['8-26'], ['19-10'], ['24-29'], ['18-30'], ['23-8'], ['24-8'], ['15-14'], ['16-24'], ['17-22'], ['21-30'], ['12-26'], ['26-28'], ['6-9'], ['6-30'], ['30-5'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2547\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['19-10'], ['31-16'], ['8-26'], ['24-29'], ['18-30'], ['15-14'], ['16-24'], ['23-8'], ['24-8'], ['17-22'], ['21-30'], ['6-30'], ['12-26'], ['26-28'], ['30-5'], ['6-9'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['19-10'], ['31-16'], ['24-29'], ['8-26'], ['18-30'], ['15-14'], ['16-24'], ['23-8'], ['24-8'], ['17-22'], ['21-30'], ['12-26'], ['6-9'], ['6-30'], ['26-28'], ['30-5'], ['20-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['8-26'], ['19-10'], ['31-16'], ['24-29'], ['18-30'], ['15-14'], ['17-22'], ['16-24'], ['21-30'], ['23-8'], ['24-8'], ['11-2'], ['12-26'], ['6-9'], ['6-30'], ['26-28'], ['30-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1094\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['8-26'], ['19-10'], ['17-22'], ['24-29'], ['31-16'], ['11-2'], ['18-30'], ['7-12'], ['15-14'], ['21-30'], ['6-16'], ['16-24'], ['23-8'], ['24-8'], ['6-9'], ['6-30'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2205\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['19-15'], ['7-12'], ['11-2'], ['19-10'], ['17-22'], ['24-29'], ['31-16'], ['18-30'], ['6-16'], ['21-30'], ['15-14'], ['6-9'], ['14-18'], ['6-30'], ['16-24'], ['23-8'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3135\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['19-15'], ['11-2'], ['19-10'], ['7-12'], ['17-22'], ['24-29'], ['31-16'], ['6-16'], ['18-30'], ['15-14'], ['21-30'], ['6-9'], ['14-18'], ['6-30'], ['16-24'], ['23-8'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['19-10'], ['11-2'], ['24-29'], ['7-12'], ['17-22'], ['31-16'], ['18-30'], ['6-16'], ['15-14'], ['6-9'], ['21-30'], ['16-24'], ['12-26'], ['6-30'], ['14-18'], ['23-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_relevant_misleading/llama-2-7b-80k_id_442_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['1-26'], ['6-30'], ['7-31'], ['8-26'], ['9-8'], ['10-2'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['16-4'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['18-11'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['1-26'], ['6-30'], ['7-31'], ['8-26'], ['9-8'], ['10-2'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['16-4'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['18-11'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['1-26'], ['6-30'], ['7-31'], ['8-26'], ['9-8'], ['10-2'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['16-4'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['18-11'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['1-26'], ['6-30'], ['7-31'], ['8-26'], ['9-8'], ['10-2'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['16-4'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['18-11'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_0_depth_7500_results.json\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['1-26'], ['6-30'], ['7-31'], ['8-26'], ['9-8'], ['10-2'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['16-4'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['18-11'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['19-15'], ['24-29'], ['6-30'], ['8-26'], ['12-16'], ['13-11'], ['15-14'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['18-30'], ['21-30'], ['23-8'], ['24-8'], ['1-26'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 195\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['19-15'], ['18-30'], ['23-8'], ['24-8'], ['24-29'], ['6-30'], ['8-26'], ['12-16'], ['13-11'], ['15-14'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['21-30'], ['1-26'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 507\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['19-15'], ['18-30'], ['23-8'], ['24-8'], ['6-30'], ['8-26'], ['13-11'], ['15-14'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['21-30'], ['24-29'], ['7-31'], ['12-16'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 73.33691716194153\n",
      "Response: Moana 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 743\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['19-15'], ['31-16'], ['11-15'], ['23-8'], ['24-8'], ['6-30'], ['8-26'], ['13-11'], ['15-14'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['18-30'], ['21-30'], ['24-29'], ['7-31'], ['12-16'], ['16-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 73.33691716194153\n",
      "Response: Moana 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_1250_depth_7500_results.json\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['19-15'], ['31-16'], ['11-15'], ['16-24'], ['23-8'], ['24-8'], ['24-29'], ['6-30'], ['8-26'], ['13-11'], ['15-14'], ['16-5'], ['16-30'], ['17-22'], ['18-30'], ['21-30'], ['7-31'], ['19-10'], ['16-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 44.392648339271545\n",
      "Response: Coco 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 507\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 44.392648339271545\n",
      "Response: Coco 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1131\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 44.392648339271545\n",
      "Response: Coco 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1447\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['17-22'], ['31-16'], ['8-26'], ['7-12'], ['21-30'], ['15-14'], ['19-10'], ['24-8'], ['24-29'], ['6-30'], ['13-11'], ['16-24'], ['16-30'], ['18-30'], ['23-8'], ['7-31'], ['16-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_2500_depth_7500_results.json\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['17-22'], ['31-16'], ['8-26'], ['21-30'], ['15-14'], ['19-10'], ['24-29'], ['7-12'], ['16-24'], ['24-8'], ['6-30'], ['13-11'], ['16-30'], ['18-30'], ['23-8'], ['6-9'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['17-22'], ['8-26'], ['31-16'], ['21-30'], ['7-12'], ['15-14'], ['19-10'], ['24-8'], ['24-29'], ['6-30'], ['13-11'], ['16-24'], ['6-9'], ['16-30'], ['18-30'], ['23-8'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 743\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['17-22'], ['8-26'], ['31-16'], ['21-30'], ['15-14'], ['7-12'], ['24-8'], ['19-10'], ['24-29'], ['6-30'], ['13-11'], ['6-9'], ['16-24'], ['7-31'], ['16-5'], ['16-30'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1447\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['7-12'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['31-16'], ['15-14'], ['24-29'], ['24-8'], ['19-10'], ['6-30'], ['13-11'], ['6-9'], ['18-30'], ['7-31'], ['16-24'], ['16-30'], ['16-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2628\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['7-12'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['31-16'], ['15-14'], ['19-10'], ['24-8'], ['24-29'], ['6-30'], ['13-11'], ['18-30'], ['6-9'], ['16-30'], ['7-31'], ['16-24'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_3750_depth_7500_results.json\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['17-22'], ['7-12'], ['21-30'], ['31-16'], ['8-26'], ['15-14'], ['24-29'], ['19-10'], ['24-8'], ['6-30'], ['13-11'], ['6-9'], ['18-30'], ['16-30'], ['16-24'], ['7-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['7-12'], ['17-22'], ['21-30'], ['8-26'], ['15-14'], ['31-16'], ['24-29'], ['19-10'], ['24-8'], ['6-30'], ['13-11'], ['18-30'], ['6-9'], ['16-24'], ['16-30'], ['7-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1131\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['7-12'], ['17-22'], ['21-30'], ['8-26'], ['31-16'], ['15-14'], ['24-29'], ['19-10'], ['24-8'], ['6-30'], ['13-11'], ['18-30'], ['6-9'], ['16-30'], ['16-24'], ['7-31'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2383\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['7-12'], ['17-22'], ['21-30'], ['8-26'], ['31-16'], ['15-14'], ['24-29'], ['19-10'], ['24-8'], ['6-30'], ['13-11'], ['18-30'], ['16-30'], ['6-9'], ['14-18'], ['26-26'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3552\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['7-12'], ['17-22'], ['21-30'], ['31-16'], ['8-26'], ['15-14'], ['19-10'], ['24-29'], ['24-8'], ['6-30'], ['13-11'], ['18-30'], ['16-30'], ['14-18'], ['26-26'], ['6-9'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 73.33691716194153\n",
      "Response: Moana 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_5000_depth_7500_results.json\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['17-22'], ['7-12'], ['21-30'], ['31-16'], ['8-26'], ['15-14'], ['19-10'], ['24-29'], ['24-8'], ['6-30'], ['13-11'], ['18-30'], ['16-30'], ['16-24'], ['26-26'], ['6-9'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant/llama-2-7b-80k_id_442_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_irrelevant/442.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['1-26'], ['6-30'], ['7-31'], ['8-26'], ['9-8'], ['10-2'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['16-4'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['18-11'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['1-26'], ['6-30'], ['7-31'], ['8-26'], ['9-8'], ['10-2'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['16-4'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['18-11'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['1-26'], ['6-30'], ['7-31'], ['8-26'], ['9-8'], ['10-2'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['16-4'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['18-11'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['1-26'], ['6-30'], ['7-31'], ['8-26'], ['9-8'], ['10-2'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['16-4'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['18-11'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['1-26'], ['6-30'], ['7-31'], ['8-26'], ['9-8'], ['10-2'], ['12-16'], ['12-26'], ['13-11'], ['15-14'], ['16-4'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['18-11'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['19-15'], ['24-29'], ['6-30'], ['8-26'], ['12-16'], ['13-11'], ['15-14'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['18-30'], ['21-30'], ['23-8'], ['24-8'], ['1-26'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 195\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['19-15'], ['18-30'], ['23-8'], ['24-8'], ['24-29'], ['6-30'], ['8-26'], ['12-16'], ['13-11'], ['15-14'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['21-30'], ['1-26'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 507\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['31-16'], ['19-15'], ['18-30'], ['23-8'], ['24-8'], ['6-30'], ['8-26'], ['13-11'], ['15-14'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['21-30'], ['24-29'], ['7-31'], ['12-16'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 73.33691716194153\n",
      "Response: Moana 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 743\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['19-15'], ['31-16'], ['11-15'], ['23-8'], ['24-8'], ['6-30'], ['8-26'], ['13-11'], ['15-14'], ['16-5'], ['16-24'], ['16-30'], ['17-22'], ['18-30'], ['21-30'], ['24-29'], ['7-31'], ['12-16'], ['16-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 73.33691716194153\n",
      "Response: Moana 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['19-15'], ['31-16'], ['11-15'], ['16-24'], ['23-8'], ['24-8'], ['24-29'], ['6-30'], ['8-26'], ['13-11'], ['15-14'], ['16-5'], ['16-30'], ['17-22'], ['18-30'], ['21-30'], ['7-31'], ['19-10'], ['16-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 26.48530602455139\n",
      "Response: Toy Story 5.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 507\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['19-15'], ['31-16'], ['11-15'], ['24-8'], ['24-29'], ['13-11'], ['16-24'], ['17-22'], ['18-30'], ['21-30'], ['23-8'], ['6-30'], ['8-26'], ['15-14'], ['16-5'], ['16-30'], ['19-10'], ['7-31'], ['16-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 73.33691716194153\n",
      "Response: Moana 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1131\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 26.51340365409851\n",
      "Response: Coco\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1447\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['17-22'], ['21-30'], ['31-16'], ['7-12'], ['24-29'], ['8-26'], ['19-10'], ['24-8'], ['6-9'], ['13-11'], ['18-30'], ['15-14'], ['16-24'], ['23-8'], ['6-30'], ['14-18'], ['16-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['17-22'], ['21-30'], ['31-16'], ['24-29'], ['19-10'], ['7-12'], ['8-26'], ['24-8'], ['6-9'], ['13-11'], ['15-14'], ['18-30'], ['16-24'], ['23-8'], ['6-30'], ['14-18'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['17-22'], ['21-30'], ['31-16'], ['7-12'], ['19-10'], ['24-29'], ['24-8'], ['8-26'], ['13-11'], ['6-9'], ['15-14'], ['18-30'], ['14-18'], ['16-24'], ['16-30'], ['23-8'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 743\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['17-22'], ['21-30'], ['31-16'], ['7-12'], ['24-29'], ['24-8'], ['19-10'], ['8-26'], ['13-11'], ['15-14'], ['6-9'], ['14-18'], ['16-30'], ['18-30'], ['16-24'], ['23-8'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1447\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['7-12'], ['19-15'], ['17-22'], ['21-30'], ['24-29'], ['31-16'], ['8-26'], ['24-8'], ['6-9'], ['15-14'], ['19-10'], ['13-11'], ['14-18'], ['16-30'], ['18-30'], ['6-16'], ['6-30'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2528\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['7-12'], ['19-15'], ['17-22'], ['21-30'], ['31-16'], ['8-26'], ['15-14'], ['24-8'], ['24-29'], ['19-10'], ['6-9'], ['13-11'], ['14-18'], ['16-30'], ['18-30'], ['6-30'], ['26-26'], ['6-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['7-12'], ['17-22'], ['21-30'], ['31-16'], ['15-14'], ['24-29'], ['8-26'], ['24-8'], ['19-10'], ['6-9'], ['13-11'], ['14-18'], ['16-30'], ['18-30'], ['6-30'], ['16-24'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['7-12'], ['17-22'], ['21-30'], ['31-16'], ['8-26'], ['15-14'], ['24-29'], ['24-8'], ['19-10'], ['6-9'], ['14-18'], ['13-11'], ['16-30'], ['18-30'], ['6-30'], ['16-24'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1131\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['7-12'], ['17-22'], ['21-30'], ['31-16'], ['8-26'], ['24-8'], ['24-29'], ['15-14'], ['19-10'], ['13-11'], ['14-18'], ['6-9'], ['16-30'], ['18-30'], ['26-26'], ['6-30'], ['16-24']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
<<<<<<< Updated upstream
      "Score: 42.78956651687622\n",
      "Response: The Tortured Poets Department is a 1993 album by the band The Tortured Poets Department.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant/llama-2-7b-80k_id_423_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2337\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 43.28800439834595\n",
      "Response: The Tortured Poets Department is a 2019 album by the American indie rock band The Tortured Poets Department.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant/llama-2-7b-80k_id_423_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3557\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 3.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 43.28800439834595\n",
      "Response: The Tortured Poets Department is a 2019 album by the American indie rock band The Tortured Poets Department.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant/llama-2-7b-80k_id_423_irrelevant_len_5000_depth_7500_results.json\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 45.488643646240234\n",
      "Response: The Tortured Poets Department is the album by The Tortured Poets Department.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant/llama-2-7b-80k_id_423_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/423.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 45.488643646240234\n",
      "Response: The Tortured Poets Department is the album by The Tortured Poets Department.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant_misleading/llama-2-7b-80k_id_423_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 45.488643646240234\n",
      "Response: The Tortured Poets Department is the album by The Tortured Poets Department.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant_misleading/llama-2-7b-80k_id_423_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 45.488643646240234\n",
      "Response: The Tortured Poets Department is the album by The Tortured Poets Department.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant_misleading/llama-2-7b-80k_id_423_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 45.488643646240234\n",
      "Response: The Tortured Poets Department is the album by The Tortured Poets Department.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant_misleading/llama-2-7b-80k_id_423_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 45.488643646240234\n",
      "Response: The Tortured Poets Department is the album by The Tortured Poets Department.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant_misleading/llama-2-7b-80k_id_423_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 42.96025633811951\n",
      "Response: The Tortured Poets Department is a 1993 album by the band The Tortured Poets.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant_misleading/llama-2-7b-80k_id_423_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 115\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 42.78956651687622\n",
      "Response: The Tortured Poets Department is a 1993 album by the band The Tortured Poets Department.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant_misleading/llama-2-7b-80k_id_423_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 329\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 43.52944791316986\n",
      "Response: The Tortured Poets Department is a 2014 album by the band The Tortured Poets Department.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant_misleading/llama-2-7b-80k_id_423_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 329\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 43.52944791316986\n",
      "Response: The Tortured Poets Department is a 2014 album by the band The Tortured Poets Department.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant_misleading/llama-2-7b-80k_id_423_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 45.488643646240234\n",
      "Response: The Tortured Poets Department is the album by The Tortured Poets Department.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant_misleading/llama-2-7b-80k_id_423_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "[['11-15'], ['7-12'], ['17-18'], ['12-2'], ['12-16'], ['13-11'], ['14-3'], ['15-14'], ['16-19'], ['17-22'], ['19-7'], ['19-12'], ['20-3'], ['21-30'], ['23-7'], ['0-0'], ['0-1'], ['0-2'], ['0-3'], ['0-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 70.82314491271973\n",
      "Response: The Tortured Poets Department is an album with moderate Spotify streams.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant_misleading/llama-2-7b-80k_id_423_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 329\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "[['7-12'], ['11-15'], ['17-18'], ['17-22'], ['12-2'], ['12-16'], ['15-14'], ['19-7'], ['21-30'], ['23-7'], ['13-11'], ['14-3'], ['16-19'], ['17-16'], ['19-12'], ['19-15'], ['20-3'], ['22-22'], ['24-3'], ['24-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 70.82314491271973\n",
      "Response: The Tortured Poets Department is an album with moderate Spotify streams.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant_misleading/llama-2-7b-80k_id_423_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1117\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 43.52944791316986\n",
      "Response: The Tortured Poets Department is a 2014 album by the band The Tortured Poets Department.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant_misleading/llama-2-7b-80k_id_423_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1705\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 34.46078300476074\n",
      "Response: The Tortured Poets Department is a book by author and poet, John Green.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant_misleading/llama-2-7b-80k_id_423_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 44.64392960071564\n",
      "Response: The Tortured Poets Department is the debut album by the band The Tortured Poets Department.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant_misleading/llama-2-7b-80k_id_423_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 42.78956651687622\n",
      "Response: The Tortured Poets Department is a 1993 album by the band The Tortured Poets Department.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant_misleading/llama-2-7b-80k_id_423_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 879\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 42.78956651687622\n",
      "Response: The Tortured Poets Department is a 1993 album by the band The Tortured Poets Department.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant_misleading/llama-2-7b-80k_id_423_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1705\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 43.28800439834595\n",
      "Response: The Tortured Poets Department is a 2019 album by the American indie rock band The Tortured Poets Department.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant_misleading/llama-2-7b-80k_id_423_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2644\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 43.28800439834595\n",
      "Response: The Tortured Poets Department is a 2019 album by the American indie rock band The Tortured Poets Department.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_423_irrelevant_misleading/llama-2-7b-80k_id_423_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The Tortured Poets Department holds the record for the most Spotify streams reached in a single day.\n",
=======
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_2500_depth_7500_results.json\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['6-9'], ['11-15'], ['8-26'], ['19-15'], ['21-30'], ['7-4'], ['17-22'], ['6-30'], ['15-14'], ['12-26'], ['7-28'], ['29-26'], ['16-24'], ['29-19'], ['24-16'], ['31-16'], ['7-12'], ['25-3']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 92.13809967041016\n",
      "Response: Flight b741 is the name of King Gizzard's most recent studio album with the code b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['6-9'], ['8-26'], ['11-15'], ['19-15'], ['7-4'], ['21-30'], ['15-14'], ['6-30'], ['17-22'], ['12-26'], ['7-28'], ['29-26'], ['16-24'], ['29-19'], ['25-3'], ['31-16'], ['7-12'], ['24-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 856\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['6-9'], ['8-26'], ['11-15'], ['19-15'], ['21-30'], ['7-4'], ['17-22'], ['15-14'], ['6-30'], ['12-26'], ['29-26'], ['7-28'], ['16-24'], ['7-12'], ['29-19'], ['24-16'], ['25-3'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 921\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['6-9'], ['8-26'], ['11-15'], ['19-15'], ['21-30'], ['7-4'], ['17-22'], ['15-14'], ['6-30'], ['12-26'], ['29-26'], ['7-12'], ['7-28'], ['16-24'], ['29-19'], ['24-16'], ['25-3'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2376\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['6-9'], ['8-26'], ['11-15'], ['19-15'], ['21-30'], ['7-4'], ['17-22'], ['15-14'], ['12-26'], ['6-30'], ['7-12'], ['29-26'], ['7-28'], ['16-24'], ['29-19'], ['24-16'], ['31-16'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_3750_depth_7500_results.json\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['6-9'], ['8-26'], ['19-15'], ['11-15'], ['21-30'], ['7-4'], ['17-22'], ['12-26'], ['15-14'], ['6-30'], ['29-26'], ['16-24'], ['7-12'], ['7-28'], ['29-19'], ['24-16'], ['25-3'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 92.13809967041016\n",
      "Response: Flight b741 is the name of King Gizzard's most recent studio album with the code b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['6-9'], ['19-15'], ['8-26'], ['11-15'], ['21-30'], ['7-4'], ['17-22'], ['12-26'], ['15-14'], ['6-30'], ['29-26'], ['16-24'], ['7-12'], ['7-28'], ['29-19'], ['24-16'], ['25-3'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 921\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['6-9'], ['19-15'], ['8-26'], ['11-15'], ['21-30'], ['7-4'], ['17-22'], ['15-14'], ['12-26'], ['6-30'], ['7-12'], ['29-26'], ['16-24'], ['7-28'], ['29-19'], ['24-16'], ['25-3'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2376\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['6-9'], ['19-15'], ['8-26'], ['11-15'], ['21-30'], ['7-4'], ['17-22'], ['15-14'], ['12-26'], ['7-12'], ['6-30'], ['29-26'], ['16-24'], ['7-28'], ['29-19'], ['24-16'], ['25-3'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3402\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['6-9'], ['19-15'], ['8-26'], ['21-30'], ['11-15'], ['7-4'], ['17-22'], ['15-14'], ['12-26'], ['7-12'], ['6-30'], ['29-26'], ['16-24'], ['7-28'], ['29-19'], ['24-16'], ['17-0'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_5000_depth_7500_results.json\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['6-9'], ['19-15'], ['8-26'], ['21-30'], ['11-15'], ['7-4'], ['17-22'], ['15-14'], ['12-26'], ['6-30'], ['7-12'], ['29-26'], ['16-24'], ['7-28'], ['29-19'], ['24-16'], ['31-16'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_relevant_misleading/llama-2-7b-80k_id_587_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: King Gizzard's most recent studio album is Flight b741.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['19-15'], ['21-30'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['0-9'], ['8-22'], ['10-29'], ['12-16'], ['13-11'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['19-15'], ['21-30'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['0-9'], ['8-22'], ['10-29'], ['12-16'], ['13-11'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['19-15'], ['21-30'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['0-9'], ['8-22'], ['10-29'], ['12-16'], ['13-11'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['19-15'], ['21-30'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['0-9'], ['8-22'], ['10-29'], ['12-16'], ['13-11'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_0_depth_7500_results.json\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['19-15'], ['21-30'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['0-9'], ['8-22'], ['10-29'], ['12-16'], ['13-11'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['8-26'], ['19-15'], ['21-30'], ['6-30'], ['7-4'], ['17-22'], ['7-28'], ['12-26'], ['29-26'], ['15-14'], ['16-30'], ['7-12'], ['13-11'], ['14-7'], ['19-10'], ['20-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 72.42634892463684\n",
      "Response: Kendrick Lamar's most recent studio album is Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 233\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['8-26'], ['19-15'], ['21-30'], ['7-4'], ['17-22'], ['6-30'], ['7-28'], ['12-26'], ['7-12'], ['29-26'], ['15-14'], ['19-10'], ['16-30'], ['13-11'], ['20-1'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 74.90087747573853\n",
      "Response: Gizzard's most recent studio album is Flight b741. He signed a recording contract with Top Dawg Entertainment in 2005, and his subsequent mixtapes were Training Day (2005), No\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 485\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 34.9988579750061\n",
      "Response: Flight, M.A.A.D City (2012),\"1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,1,\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 748\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['6-30'], ['7-12'], ['7-28'], ['12-26'], ['29-26'], ['15-14'], ['19-10'], ['16-30'], ['13-11'], ['20-1'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_1250_depth_7500_results.json\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['6-9'], ['8-26'], ['19-15'], ['7-4'], ['21-30'], ['17-22'], ['6-30'], ['7-28'], ['12-26'], ['7-12'], ['15-14'], ['29-26'], ['19-10'], ['16-30'], ['13-11'], ['17-31'], ['20-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 60.571324825286865\n",
      "Response: Flight b741\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['6-30'], ['7-12'], ['7-28'], ['12-26'], ['15-14'], ['29-26'], ['19-10'], ['16-30'], ['17-31'], ['13-11'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 60.571324825286865\n",
      "Response: Flight b741\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 558\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['21-30'], ['7-4'], ['6-30'], ['7-12'], ['7-28'], ['12-26'], ['29-26'], ['15-14'], ['19-10'], ['13-11'], ['14-18'], ['16-30'], ['20-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1037\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 49.20377731323242\n",
      "Response: Flight b741.D City\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1534\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['21-30'], ['7-4'], ['6-30'], ['7-12'], ['7-28'], ['12-26'], ['29-26'], ['15-14'], ['19-10'], ['13-11'], ['14-18'], ['16-30'], ['20-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_2500_depth_7500_results.json\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['21-30'], ['7-4'], ['6-30'], ['7-12'], ['7-28'], ['12-26'], ['15-14'], ['29-26'], ['19-10'], ['13-11'], ['14-18'], ['16-30'], ['20-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 35.08458137512207\n",
      "Response: Kendrick Lamar albums discography.1\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 748\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['21-30'], ['7-4'], ['6-30'], ['7-12'], ['7-28'], ['12-26'], ['15-14'], ['29-26'], ['19-10'], ['13-11'], ['14-18'], ['20-1'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1534\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['21-30'], ['7-4'], ['6-30'], ['7-12'], ['7-28'], ['12-26'], ['29-26'], ['15-14'], ['19-10'], ['13-11'], ['14-18'], ['20-1'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2644\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['21-30'], ['7-4'], ['6-30'], ['7-12'], ['7-28'], ['12-26'], ['29-26'], ['15-14'], ['19-10'], ['14-18'], ['13-11'], ['20-1'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_3750_depth_7500_results.json\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['6-9'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['7-4'], ['6-30'], ['7-12'], ['7-28'], ['12-26'], ['15-14'], ['29-26'], ['19-10'], ['14-18'], ['13-11'], ['20-1'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 13.327550888061523\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1037\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 49.20377731323242\n",
      "Response: Flight b741.D City\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2029\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['7-4'], ['21-30'], ['6-30'], ['7-12'], ['12-26'], ['7-28'], ['15-14'], ['29-26'], ['19-10'], ['13-11'], ['14-18'], ['20-1'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3474\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['7-4'], ['21-30'], ['7-12'], ['6-30'], ['12-26'], ['7-28'], ['15-14'], ['29-26'], ['19-10'], ['13-11'], ['14-18'], ['20-1'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_5000_depth_7500_results.json\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['19-15'], ['7-4'], ['21-30'], ['6-30'], ['7-12'], ['12-26'], ['7-28'], ['15-14'], ['29-26'], ['19-10'], ['13-11'], ['14-18'], ['20-1'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant/llama-2-7b-80k_id_587_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/587.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: King Gizzard's most recent studio album is Flight b741.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['19-15'], ['21-30'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['0-9'], ['8-22'], ['10-29'], ['12-16'], ['13-11'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['19-15'], ['21-30'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['0-9'], ['8-22'], ['10-29'], ['12-16'], ['13-11'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['19-15'], ['21-30'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['0-9'], ['8-22'], ['10-29'], ['12-16'], ['13-11'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['19-15'], ['21-30'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['0-9'], ['8-22'], ['10-29'], ['12-16'], ['13-11'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['19-15'], ['21-30'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['0-9'], ['8-22'], ['10-29'], ['12-16'], ['13-11'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['19-15'], ['21-30'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['22-22'], ['0-9'], ['8-22'], ['10-29'], ['12-16'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 60.571324825286865\n",
      "Response: Flight b741\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 233\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['8-26'], ['6-30'], ['19-15'], ['21-30'], ['7-4'], ['7-28'], ['12-26'], ['15-14'], ['17-22'], ['29-26'], ['22-22'], ['19-9'], ['20-1'], ['22-27'], ['24-16'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 513\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['24-29'], ['8-26'], ['6-30'], ['19-15'], ['7-4'], ['21-30'], ['15-14'], ['7-28'], ['17-22'], ['29-26'], ['12-26'], ['19-9'], ['20-1'], ['22-22'], ['24-16'], ['31-16'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 741\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['19-15'], ['7-4'], ['21-30'], ['15-14'], ['7-28'], ['17-22'], ['12-26'], ['29-26'], ['31-16'], ['19-9'], ['20-1'], ['22-22'], ['7-12'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 60.571324825286865\n",
      "Response: Flight b741\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['11-15'], ['8-26'], ['19-15'], ['6-30'], ['7-4'], ['21-30'], ['15-14'], ['7-28'], ['17-22'], ['12-26'], ['29-26'], ['31-16'], ['19-9'], ['20-1'], ['22-22'], ['25-3'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 60.571324825286865\n",
      "Response: Flight b741\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['19-15'], ['7-4'], ['21-30'], ['15-14'], ['7-28'], ['17-22'], ['12-26'], ['29-26'], ['31-16'], ['19-9'], ['19-10'], ['20-1'], ['22-22'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 556\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['6-30'], ['19-15'], ['7-4'], ['21-30'], ['15-14'], ['7-28'], ['17-22'], ['12-26'], ['29-26'], ['31-16'], ['19-9'], ['20-1'], ['7-12'], ['29-19'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1065\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 49.65131878852844\n",
      "Response: Flight b741.D City.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1562\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['11-15'], ['8-26'], ['6-30'], ['19-15'], ['7-4'], ['21-30'], ['15-14'], ['17-22'], ['12-26'], ['7-28'], ['29-26'], ['31-16'], ['19-9'], ['20-1'], ['7-12'], ['29-19'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['11-15'], ['8-26'], ['6-30'], ['19-15'], ['7-4'], ['21-30'], ['15-14'], ['17-22'], ['12-26'], ['7-28'], ['29-26'], ['31-16'], ['19-9'], ['29-19'], ['12-16'], ['13-11'], ['20-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['11-15'], ['8-26'], ['19-15'], ['6-30'], ['7-4'], ['21-30'], ['15-14'], ['17-22'], ['12-26'], ['7-28'], ['29-26'], ['31-16'], ['19-9'], ['29-19'], ['12-16'], ['13-11'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 776\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['11-15'], ['8-26'], ['19-15'], ['6-30'], ['7-4'], ['21-30'], ['15-14'], ['17-22'], ['12-26'], ['7-28'], ['29-26'], ['31-16'], ['19-9'], ['7-12'], ['29-19'], ['12-16'], ['20-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1562\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['6-9'], ['11-15'], ['8-26'], ['19-15'], ['21-30'], ['6-30'], ['15-14'], ['7-4'], ['17-22'], ['12-26'], ['7-28'], ['31-16'], ['29-26'], ['7-12'], ['19-9'], ['29-19'], ['12-16'], ['20-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2080\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['24-29'], ['6-9'], ['11-15'], ['8-26'], ['19-15'], ['21-30'], ['6-30'], ['15-14'], ['7-4'], ['17-22'], ['12-26'], ['31-16'], ['7-28'], ['29-26'], ['7-12'], ['19-9'], ['29-19'], ['20-1'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['11-15'], ['19-15'], ['8-26'], ['21-30'], ['7-4'], ['15-14'], ['6-30'], ['17-22'], ['12-26'], ['31-16'], ['29-26'], ['7-28'], ['19-9'], ['7-12'], ['29-19'], ['20-1'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 92.13809967041016\n",
      "Response: Flight b741 is the name of King Gizzard's most recent studio album with the code b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['11-15'], ['19-15'], ['8-26'], ['21-30'], ['7-4'], ['15-14'], ['6-30'], ['17-22'], ['12-26'], ['31-16'], ['29-26'], ['7-28'], ['19-9'], ['7-12'], ['29-19'], ['19-10'], ['20-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1065\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['11-15'], ['19-15'], ['8-26'], ['21-30'], ['7-4'], ['15-14'], ['6-30'], ['17-22'], ['12-26'], ['31-16'], ['29-26'], ['7-28'], ['7-12'], ['19-9'], ['20-1'], ['29-19'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 53.0320405960083\n",
      "Response: Flight b741.A.A.D City has spent more weeks on the Billboard 200 chart than any hip-hop studio album in history, having tallied 550 weeks by May 202\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2080\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['11-15'], ['19-15'], ['8-26'], ['21-30'], ['7-4'], ['15-14'], ['6-30'], ['17-22'], ['12-26'], ['31-16'], ['29-26'], ['7-12'], ['7-28'], ['19-9'], ['20-1'], ['29-19'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3578\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['11-15'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['15-14'], ['6-30'], ['17-22'], ['12-26'], ['31-16'], ['7-12'], ['29-26'], ['19-9'], ['7-28'], ['20-1'], ['22-22'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 61.440396308898926\n",
      "Response: Flight b741. 2012 Label: Top Dawg, Aftermath, Interscope Formats: CD, LP, digital download, streaming\",2,1,23,2,20,47\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "King Gizzard's most recent studio album is Flight b741.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['11-15'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['6-30'], ['15-14'], ['17-22'], ['12-26'], ['31-16'], ['29-26'], ['7-12'], ['7-28'], ['19-9'], ['20-1'], ['29-19'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 58.54194760322571\n",
      "Response: Flight b741.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_587_irrelevant_misleading/llama-2-7b-80k_id_587_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['6-30'], ['11-2'], ['12-26'], ['14-15'], ['17-22'], ['18-30'], ['7-4'], ['10-18'], ['12-2'], ['13-23'], ['14-7'], ['14-13'], ['14-18'], ['15-14'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['6-30'], ['11-2'], ['12-26'], ['14-15'], ['17-22'], ['18-30'], ['7-4'], ['10-18'], ['12-2'], ['13-23'], ['14-7'], ['14-13'], ['14-18'], ['15-14'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['6-30'], ['11-2'], ['12-26'], ['14-15'], ['17-22'], ['18-30'], ['7-4'], ['10-18'], ['12-2'], ['13-23'], ['14-7'], ['14-13'], ['14-18'], ['15-14'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['6-30'], ['11-2'], ['12-26'], ['14-15'], ['17-22'], ['18-30'], ['7-4'], ['10-18'], ['12-2'], ['13-23'], ['14-7'], ['14-13'], ['14-18'], ['15-14'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_0_depth_7500_results.json\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['6-30'], ['11-2'], ['12-26'], ['14-15'], ['17-22'], ['18-30'], ['7-4'], ['10-18'], ['12-2'], ['13-23'], ['14-7'], ['14-13'], ['14-18'], ['15-14'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 40.37846922874451\n",
      "Response: Hacks (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_1250_depth_0_results.json\n",
      "insertion at 245\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 42.05288887023926\n",
      "Response: Hacks (2022)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 378\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['6-30'], ['11-2'], ['17-22'], ['18-30'], ['14-15'], ['12-26'], ['7-4'], ['12-2'], ['19-15'], ['13-23'], ['15-14'], ['21-30'], ['10-18'], ['14-18'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 378\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['6-30'], ['11-2'], ['17-22'], ['18-30'], ['7-4'], ['14-15'], ['12-2'], ['19-15'], ['12-26'], ['13-23'], ['15-14'], ['21-30'], ['10-18'], ['14-18'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_1250_depth_7500_results.json\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 42.05288887023926\n",
      "Response: Hacks (2022)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_2500_depth_0_results.json\n",
      "insertion at 378\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['11-2'], ['18-30'], ['6-30'], ['17-22'], ['7-4'], ['12-2'], ['19-15'], ['14-15'], ['13-23'], ['15-14'], ['21-30'], ['12-26'], ['10-18'], ['14-18'], ['18-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 378\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['11-2'], ['18-30'], ['6-30'], ['17-22'], ['7-4'], ['12-2'], ['19-15'], ['14-15'], ['13-23'], ['15-14'], ['21-30'], ['10-18'], ['12-26'], ['14-18'], ['18-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 378\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['11-2'], ['18-30'], ['6-30'], ['17-22'], ['12-2'], ['19-15'], ['7-4'], ['13-23'], ['14-15'], ['15-14'], ['21-30'], ['10-18'], ['7-28'], ['12-26'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_2500_depth_7500_results.json\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 40.37846922874451\n",
      "Response: Hacks (2024)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_3750_depth_0_results.json\n",
      "insertion at 378\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 42.05288887023926\n",
      "Response: Hacks (2022)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 378\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 42.05288887023926\n",
      "Response: Hacks (2022)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 378\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 42.05288887023926\n",
      "Response: Hacks (2022)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_3750_depth_7500_results.json\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 21.90052568912506\n",
      "Response: The Flintstones (1961–1966)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_5000_depth_0_results.json\n",
      "insertion at 378\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 42.05288887023926\n",
      "Response: Hacks (2022)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 378\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 42.05288887023926\n",
      "Response: Hacks (2022)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3563\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['11-2'], ['16-1'], ['17-22'], ['19-15'], ['18-30'], ['12-2'], ['6-30'], ['7-4'], ['21-30'], ['15-14'], ['13-23'], ['10-18'], ['14-15'], ['7-12'], ['14-18'], ['7-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_5000_depth_7500_results.json\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant/llama-2-7b-80k_id_588_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/588.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['6-30'], ['11-2'], ['12-26'], ['14-15'], ['17-22'], ['18-30'], ['7-4'], ['10-18'], ['12-2'], ['13-23'], ['14-7'], ['14-13'], ['14-18'], ['15-14'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['6-30'], ['11-2'], ['12-26'], ['14-15'], ['17-22'], ['18-30'], ['7-4'], ['10-18'], ['12-2'], ['13-23'], ['14-7'], ['14-13'], ['14-18'], ['15-14'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['6-30'], ['11-2'], ['12-26'], ['14-15'], ['17-22'], ['18-30'], ['7-4'], ['10-18'], ['12-2'], ['13-23'], ['14-7'], ['14-13'], ['14-18'], ['15-14'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['6-30'], ['11-2'], ['12-26'], ['14-15'], ['17-22'], ['18-30'], ['7-4'], ['10-18'], ['12-2'], ['13-23'], ['14-7'], ['14-13'], ['14-18'], ['15-14'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_0_depth_7500_results.json\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['6-30'], ['11-2'], ['12-26'], ['14-15'], ['17-22'], ['18-30'], ['7-4'], ['10-18'], ['12-2'], ['13-23'], ['14-7'], ['14-13'], ['14-18'], ['15-14'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 42.05288887023926\n",
      "Response: Hacks (2022)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 231\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['11-2'], ['18-30'], ['6-30'], ['17-22'], ['14-15'], ['12-26'], ['7-4'], ['19-15'], ['10-18'], ['13-23'], ['15-14'], ['12-2'], ['14-13'], ['14-18'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 405\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['11-2'], ['18-30'], ['17-22'], ['6-30'], ['7-4'], ['14-15'], ['19-15'], ['12-26'], ['10-18'], ['13-23'], ['15-14'], ['12-2'], ['21-30'], ['14-18'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 405\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['11-2'], ['18-30'], ['17-22'], ['7-4'], ['6-30'], ['19-15'], ['14-15'], ['10-18'], ['13-23'], ['15-14'], ['12-26'], ['12-2'], ['21-30'], ['14-18'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 42.05288887023926\n",
      "Response: Hacks (2022)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 405\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 405\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1572\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['18-30'], ['11-2'], ['17-22'], ['6-30'], ['7-4'], ['19-15'], ['14-15'], ['10-18'], ['15-14'], ['13-23'], ['21-30'], ['12-26'], ['12-2'], ['14-18'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 38.327810168266296\n",
      "Response: Hacks.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 405\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 38.327810168266296\n",
      "Response: Hacks.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1572\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['18-30'], ['19-15'], ['11-2'], ['17-22'], ['6-30'], ['7-4'], ['14-15'], ['13-23'], ['10-18'], ['15-14'], ['21-30'], ['12-26'], ['14-18'], ['12-2'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 1572\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['18-30'], ['6-9'], ['16-1'], ['19-15'], ['11-2'], ['17-22'], ['6-30'], ['7-4'], ['13-23'], ['14-15'], ['10-18'], ['15-14'], ['14-18'], ['21-30'], ['12-26'], ['19-10'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 38.327810168266296\n",
      "Response: Hacks.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 405\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 38.327810168266296\n",
      "Response: Hacks.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 1572\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 38.327810168266296\n",
      "Response: Hacks.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3315\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 29.797354340553284\n",
      "Response: The Mary Tyler Moore Show (Season 1).\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_relevant_misleading/llama-2-7b-80k_id_588_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['6-30'], ['11-2'], ['12-26'], ['14-15'], ['17-22'], ['18-30'], ['7-4'], ['10-18'], ['12-2'], ['13-23'], ['14-7'], ['14-13'], ['14-18'], ['15-14'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['6-30'], ['11-2'], ['12-26'], ['14-15'], ['17-22'], ['18-30'], ['7-4'], ['10-18'], ['12-2'], ['13-23'], ['14-7'], ['14-13'], ['14-18'], ['15-14'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['6-30'], ['11-2'], ['12-26'], ['14-15'], ['17-22'], ['18-30'], ['7-4'], ['10-18'], ['12-2'], ['13-23'], ['14-7'], ['14-13'], ['14-18'], ['15-14'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['6-30'], ['11-2'], ['12-26'], ['14-15'], ['17-22'], ['18-30'], ['7-4'], ['10-18'], ['12-2'], ['13-23'], ['14-7'], ['14-13'], ['14-18'], ['15-14'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_0_depth_7500_results.json\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['6-30'], ['11-2'], ['12-26'], ['14-15'], ['17-22'], ['18-30'], ['7-4'], ['10-18'], ['12-2'], ['13-23'], ['14-7'], ['14-13'], ['14-18'], ['15-14'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['16-1'], ['6-9'], ['11-2'], ['17-22'], ['14-15'], ['18-30'], ['6-30'], ['12-26'], ['19-15'], ['14-18'], ['7-4'], ['13-23'], ['15-14'], ['19-10'], ['21-30'], ['10-18'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 18\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['16-1'], ['6-9'], ['11-2'], ['17-22'], ['19-15'], ['14-15'], ['18-30'], ['6-30'], ['7-4'], ['12-26'], ['13-23'], ['15-14'], ['14-18'], ['10-18'], ['19-10'], ['21-30'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 510\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['16-1'], ['6-9'], ['11-2'], ['17-22'], ['7-4'], ['19-15'], ['18-30'], ['14-15'], ['6-30'], ['13-23'], ['12-26'], ['14-18'], ['10-18'], ['15-14'], ['21-30'], ['12-2'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 758\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['16-1'], ['6-9'], ['11-2'], ['7-4'], ['19-15'], ['17-22'], ['18-30'], ['13-23'], ['14-15'], ['6-30'], ['10-18'], ['12-2'], ['15-14'], ['20-30'], ['21-30'], ['14-18'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_1250_depth_7500_results.json\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['16-1'], ['6-9'], ['11-2'], ['19-15'], ['17-22'], ['7-4'], ['13-23'], ['18-30'], ['14-15'], ['15-14'], ['21-30'], ['6-30'], ['12-2'], ['14-18'], ['10-18'], ['20-30'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 527\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['16-1'], ['6-9'], ['11-2'], ['19-15'], ['17-22'], ['7-4'], ['13-23'], ['18-30'], ['12-2'], ['21-30'], ['6-30'], ['7-12'], ['14-15'], ['15-14'], ['20-30'], ['10-18'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 805\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['16-1'], ['6-9'], ['11-2'], ['19-15'], ['17-22'], ['7-4'], ['13-23'], ['18-30'], ['12-2'], ['7-12'], ['21-30'], ['6-30'], ['14-15'], ['20-30'], ['10-18'], ['15-14'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 805\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['16-1'], ['6-9'], ['11-2'], ['19-15'], ['7-4'], ['17-22'], ['18-30'], ['13-23'], ['12-2'], ['7-12'], ['21-30'], ['6-30'], ['14-15'], ['20-30'], ['10-18'], ['19-10'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_2500_depth_7500_results.json\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['16-1'], ['6-9'], ['11-2'], ['19-15'], ['17-22'], ['7-4'], ['13-23'], ['18-30'], ['21-30'], ['7-12'], ['12-2'], ['14-15'], ['6-30'], ['19-10'], ['10-18'], ['20-30'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 805\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['16-1'], ['6-9'], ['11-2'], ['19-15'], ['17-22'], ['7-4'], ['18-30'], ['7-12'], ['13-23'], ['21-30'], ['12-2'], ['6-30'], ['10-18'], ['20-30'], ['14-15'], ['19-10'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 805\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['16-1'], ['6-9'], ['11-2'], ['19-15'], ['17-22'], ['7-4'], ['18-30'], ['7-12'], ['13-23'], ['21-30'], ['12-2'], ['6-30'], ['20-30'], ['10-18'], ['15-14'], ['19-10'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 805\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['16-1'], ['11-2'], ['19-15'], ['17-22'], ['7-4'], ['7-12'], ['18-30'], ['13-23'], ['21-30'], ['6-30'], ['10-18'], ['12-2'], ['20-30'], ['15-14'], ['19-10'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_3750_depth_7500_results.json\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['16-1'], ['6-9'], ['11-2'], ['19-15'], ['17-22'], ['7-4'], ['7-12'], ['18-30'], ['13-23'], ['21-30'], ['10-18'], ['12-2'], ['20-30'], ['6-30'], ['14-18'], ['15-14'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 805\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['16-1'], ['6-9'], ['11-2'], ['19-15'], ['17-22'], ['7-12'], ['7-4'], ['18-30'], ['21-30'], ['13-23'], ['10-18'], ['12-2'], ['20-30'], ['6-30'], ['14-18'], ['15-14'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 805\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['16-1'], ['6-9'], ['11-2'], ['19-15'], ['17-22'], ['7-12'], ['7-4'], ['18-30'], ['21-30'], ['13-23'], ['10-18'], ['12-2'], ['20-30'], ['6-30'], ['14-18'], ['15-14'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 805\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['16-1'], ['6-9'], ['11-2'], ['19-15'], ['7-12'], ['17-22'], ['7-4'], ['21-30'], ['18-30'], ['13-23'], ['10-18'], ['12-2'], ['20-30'], ['6-30'], ['12-4'], ['14-18'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_5000_depth_7500_results.json\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant/llama-2-7b-80k_id_588_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/588.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['6-30'], ['11-2'], ['12-26'], ['14-15'], ['17-22'], ['18-30'], ['7-4'], ['10-18'], ['12-2'], ['13-23'], ['14-7'], ['14-13'], ['14-18'], ['15-14'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['6-30'], ['11-2'], ['12-26'], ['14-15'], ['17-22'], ['18-30'], ['7-4'], ['10-18'], ['12-2'], ['13-23'], ['14-7'], ['14-13'], ['14-18'], ['15-14'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['6-30'], ['11-2'], ['12-26'], ['14-15'], ['17-22'], ['18-30'], ['7-4'], ['10-18'], ['12-2'], ['13-23'], ['14-7'], ['14-13'], ['14-18'], ['15-14'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['6-30'], ['11-2'], ['12-26'], ['14-15'], ['17-22'], ['18-30'], ['7-4'], ['10-18'], ['12-2'], ['13-23'], ['14-7'], ['14-13'], ['14-18'], ['15-14'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['6-30'], ['11-2'], ['12-26'], ['14-15'], ['17-22'], ['18-30'], ['7-4'], ['10-18'], ['12-2'], ['13-23'], ['14-7'], ['14-13'], ['14-18'], ['15-14'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 18\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 510\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 739\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 554\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 901\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 901\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 854\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 901\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 1894\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['18-30'], ['6-30'], ['11-2'], ['12-26'], ['14-15'], ['17-22'], ['15-14'], ['7-4'], ['10-18'], ['12-2'], ['13-23'], ['14-7'], ['14-13'], ['14-18'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 901\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 1894\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['16-1'], ['18-30'], ['6-30'], ['11-2'], ['12-26'], ['14-15'], ['17-22'], ['14-7'], ['15-14'], ['17-0'], ['21-30'], ['7-4'], ['10-18'], ['12-2'], ['13-23'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 67.72061586380005\n",
      "Response: Hacks, specifically for its third season.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 2703\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The comedy series that won the most recent Primetime Emmy Award for Outstanding Comedy Series is Hacks, specifically for its third season.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 42.125508189201355\n",
      "Response: Hacks\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_588_irrelevant_misleading/llama-2-7b-80k_id_588_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['7-13'], ['8-6'], ['8-22'], ['8-25'], ['8-31'], ['9-8'], ['9-30'], ['10-7'], ['10-21'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['7-13'], ['8-6'], ['8-22'], ['8-25'], ['8-31'], ['9-8'], ['9-30'], ['10-7'], ['10-21'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['7-13'], ['8-6'], ['8-22'], ['8-25'], ['8-31'], ['9-8'], ['9-30'], ['10-7'], ['10-21'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['7-13'], ['8-6'], ['8-22'], ['8-25'], ['8-31'], ['9-8'], ['9-30'], ['10-7'], ['10-21'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_0_depth_7500_results.json\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['7-13'], ['8-6'], ['8-22'], ['8-25'], ['8-31'], ['9-8'], ['9-30'], ['10-7'], ['10-21'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['21-30'], ['6-30'], ['24-29'], ['19-15'], ['31-16'], ['7-4'], ['20-29'], ['11-15'], ['8-31'], ['10-7'], ['11-14'], ['13-11'], ['14-7'], ['14-9'], ['14-24'], ['15-14'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_1250_depth_0_results.json\n",
      "insertion at 202\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['8-26'], ['21-30'], ['6-9'], ['6-30'], ['24-29'], ['19-15'], ['31-16'], ['7-4'], ['20-29'], ['11-15'], ['13-11'], ['14-7'], ['21-26'], ['24-11'], ['26-27'], ['8-31'], ['9-8'], ['10-7'], ['11-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 488\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['8-26'], ['21-30'], ['6-30'], ['24-29'], ['6-9'], ['19-15'], ['7-4'], ['31-16'], ['20-29'], ['13-11'], ['11-15'], ['14-7'], ['21-26'], ['24-11'], ['26-27'], ['9-8'], ['26-28'], ['8-31'], ['10-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 757\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['8-26'], ['21-30'], ['6-30'], ['24-29'], ['19-15'], ['6-9'], ['7-4'], ['31-16'], ['20-29'], ['13-11'], ['11-15'], ['21-26'], ['24-11'], ['26-27'], ['9-8'], ['14-7'], ['26-28'], ['8-31'], ['10-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_1250_depth_7500_results.json\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['8-26'], ['21-30'], ['6-9'], ['19-15'], ['24-29'], ['6-30'], ['7-4'], ['11-15'], ['31-16'], ['20-29'], ['17-22'], ['13-11'], ['12-26'], ['14-7'], ['21-26'], ['15-14'], ['24-11'], ['26-27'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 93.7211275100708\n",
      "Response: Peking University. The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 8.880142867565155\n",
      "Response: St. Petersburg Institute of Fine Mechanics and Optics\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_2500_depth_0_results.json\n",
      "insertion at 567\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 8.880142867565155\n",
      "Response: St. Petersburg Institute of Fine Mechanics and Optics\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1128\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 8.880142867565155\n",
      "Response: St. Petersburg Institute of Fine Mechanics and Optics\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1699\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['8-26'], ['21-30'], ['6-9'], ['19-15'], ['24-29'], ['6-30'], ['7-4'], ['11-15'], ['31-16'], ['20-29'], ['17-22'], ['13-11'], ['12-26'], ['21-26'], ['14-7'], ['24-11'], ['26-27'], ['26-28'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_2500_depth_7500_results.json\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['8-26'], ['21-30'], ['19-15'], ['6-9'], ['24-29'], ['6-30'], ['7-4'], ['11-15'], ['31-16'], ['20-29'], ['17-22'], ['13-11'], ['12-26'], ['21-26'], ['14-7'], ['24-11'], ['26-27'], ['26-28'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 20.04047781229019\n",
      "Response: St. Petersburg State University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_3750_depth_0_results.json\n",
      "insertion at 847\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 20.04047781229019\n",
      "Response: St. Petersburg State University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1765\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 20.04047781229019\n",
      "Response: St. Petersburg State University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2647\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['8-26'], ['21-30'], ['19-15'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['11-15'], ['31-16'], ['20-29'], ['17-22'], ['13-11'], ['21-26'], ['12-26'], ['24-11'], ['26-27'], ['26-28'], ['14-7'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_3750_depth_7500_results.json\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['8-26'], ['21-30'], ['19-15'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['31-16'], ['11-15'], ['20-29'], ['17-22'], ['13-11'], ['12-26'], ['21-26'], ['14-7'], ['24-11'], ['26-27'], ['26-28'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 33.45850110054016\n",
      "Response: Moscow State University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1176\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 33.45850110054016\n",
      "Response: Moscow State University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2382\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 4.582032561302185\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3576\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 4.582032561302185\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_5000_depth_7500_results.json\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['8-26'], ['21-30'], ['19-15'], ['24-29'], ['6-9'], ['6-30'], ['7-4'], ['31-16'], ['11-15'], ['20-29'], ['17-22'], ['13-11'], ['12-26'], ['14-7'], ['21-26'], ['24-11'], ['26-27'], ['26-28'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant/llama-2-7b-80k_id_589_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/589.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['7-13'], ['8-6'], ['8-22'], ['8-25'], ['8-31'], ['9-8'], ['9-30'], ['10-7'], ['10-21'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['7-13'], ['8-6'], ['8-22'], ['8-25'], ['8-31'], ['9-8'], ['9-30'], ['10-7'], ['10-21'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['7-13'], ['8-6'], ['8-22'], ['8-25'], ['8-31'], ['9-8'], ['9-30'], ['10-7'], ['10-21'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['7-13'], ['8-6'], ['8-22'], ['8-25'], ['8-31'], ['9-8'], ['9-30'], ['10-7'], ['10-21'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_0_depth_7500_results.json\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['7-13'], ['8-6'], ['8-22'], ['8-25'], ['8-31'], ['9-8'], ['9-30'], ['10-7'], ['10-21'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['19-15'], ['8-26'], ['21-30'], ['6-30'], ['31-16'], ['20-29'], ['7-4'], ['11-15'], ['14-7'], ['14-9'], ['14-24'], ['17-18'], ['17-22'], ['21-5'], ['24-11'], ['26-27'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 202\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['24-29'], ['6-9'], ['19-15'], ['21-30'], ['8-26'], ['6-30'], ['31-16'], ['20-29'], ['7-4'], ['11-15'], ['24-11'], ['14-7'], ['14-9'], ['14-24'], ['17-18'], ['17-22'], ['21-5'], ['21-26'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 488\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['24-29'], ['19-15'], ['6-9'], ['21-30'], ['8-26'], ['6-30'], ['31-16'], ['20-29'], ['7-4'], ['24-11'], ['11-15'], ['14-7'], ['21-26'], ['26-27'], ['26-28'], ['13-11'], ['14-9'], ['14-24'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 720\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['24-29'], ['19-15'], ['21-30'], ['6-9'], ['8-26'], ['6-30'], ['31-16'], ['20-29'], ['7-4'], ['24-11'], ['11-15'], ['14-7'], ['21-26'], ['26-27'], ['26-28'], ['13-11'], ['8-6'], ['14-9'], ['14-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['19-15'], ['21-30'], ['6-9'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['11-15'], ['31-16'], ['20-29'], ['17-22'], ['12-26'], ['14-7'], ['26-28'], ['13-11'], ['21-26'], ['24-11'], ['26-27'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 84.56051349639893\n",
      "Response: Peking University. The most recent ACM-ICPC World Finals was won by Peking University. The 2018–19 season was the 117th season in the existence of the AIK\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['19-15'], ['6-9'], ['21-30'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['11-15'], ['31-16'], ['20-29'], ['17-22'], ['12-26'], ['14-7'], ['26-28'], ['13-11'], ['14-9'], ['21-26'], ['24-11'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 567\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['21-30'], ['19-15'], ['24-29'], ['8-26'], ['6-30'], ['7-4'], ['11-15'], ['31-16'], ['20-29'], ['17-22'], ['14-7'], ['12-26'], ['24-11'], ['26-28'], ['13-11'], ['14-9'], ['21-26'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1138\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['19-15'], ['21-30'], ['24-29'], ['8-26'], ['6-30'], ['11-15'], ['7-4'], ['31-16'], ['20-29'], ['17-22'], ['14-7'], ['12-26'], ['26-28'], ['24-11'], ['7-12'], ['8-22'], ['13-11'], ['14-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1658\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['19-15'], ['21-30'], ['24-29'], ['8-26'], ['6-30'], ['11-15'], ['7-4'], ['31-16'], ['20-29'], ['17-22'], ['14-7'], ['26-28'], ['12-26'], ['24-11'], ['13-11'], ['7-12'], ['21-26'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['19-15'], ['6-9'], ['21-30'], ['24-29'], ['8-26'], ['6-30'], ['11-15'], ['7-4'], ['31-16'], ['20-29'], ['17-22'], ['14-7'], ['12-26'], ['26-28'], ['24-11'], ['13-11'], ['8-22'], ['7-12'], ['21-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['19-15'], ['24-29'], ['21-30'], ['8-26'], ['11-15'], ['6-30'], ['7-4'], ['20-29'], ['31-16'], ['14-7'], ['17-22'], ['12-26'], ['26-28'], ['24-11'], ['13-11'], ['7-12'], ['8-22'], ['14-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 870\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['19-15'], ['24-29'], ['21-30'], ['8-26'], ['11-15'], ['6-30'], ['7-4'], ['20-29'], ['31-16'], ['14-7'], ['17-22'], ['26-28'], ['12-26'], ['24-11'], ['7-12'], ['13-11'], ['8-22'], ['14-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1748\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['19-15'], ['21-30'], ['24-29'], ['8-26'], ['11-15'], ['6-30'], ['7-4'], ['20-29'], ['31-16'], ['14-7'], ['17-22'], ['26-28'], ['24-11'], ['7-12'], ['12-26'], ['13-11'], ['21-26'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2641\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['19-15'], ['24-29'], ['21-30'], ['8-26'], ['11-15'], ['6-30'], ['7-4'], ['20-29'], ['31-16'], ['14-7'], ['26-28'], ['17-22'], ['24-11'], ['7-12'], ['12-26'], ['21-26'], ['13-11'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['19-15'], ['6-9'], ['24-29'], ['21-30'], ['8-26'], ['6-30'], ['11-15'], ['7-4'], ['31-16'], ['20-29'], ['14-7'], ['17-22'], ['26-28'], ['12-26'], ['24-11'], ['7-12'], ['13-11'], ['21-26'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['19-15'], ['6-9'], ['24-29'], ['8-26'], ['6-30'], ['11-15'], ['7-4'], ['31-16'], ['20-29'], ['14-7'], ['17-22'], ['26-28'], ['12-26'], ['24-11'], ['7-12'], ['13-11'], ['21-26'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1173\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['19-15'], ['24-29'], ['6-9'], ['8-26'], ['6-30'], ['11-15'], ['7-4'], ['31-16'], ['20-29'], ['14-7'], ['26-28'], ['17-22'], ['24-11'], ['12-26'], ['7-12'], ['21-26'], ['13-11'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2360\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['24-29'], ['19-15'], ['6-9'], ['8-26'], ['6-30'], ['11-15'], ['7-4'], ['31-16'], ['20-29'], ['14-7'], ['26-28'], ['17-22'], ['24-11'], ['7-12'], ['12-26'], ['21-26'], ['26-27'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3549\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['19-15'], ['6-9'], ['8-26'], ['6-30'], ['11-15'], ['7-4'], ['20-29'], ['31-16'], ['26-28'], ['7-12'], ['14-7'], ['17-22'], ['24-11'], ['12-26'], ['21-26'], ['26-27'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['19-15'], ['6-9'], ['8-26'], ['6-30'], ['11-15'], ['7-4'], ['20-29'], ['31-16'], ['14-7'], ['26-28'], ['17-22'], ['24-11'], ['7-12'], ['12-26'], ['21-26'], ['26-27'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_relevant_misleading/llama-2-7b-80k_id_589_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['7-13'], ['8-6'], ['8-22'], ['8-25'], ['8-31'], ['9-8'], ['9-30'], ['10-7'], ['10-21'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['7-13'], ['8-6'], ['8-22'], ['8-25'], ['8-31'], ['9-8'], ['9-30'], ['10-7'], ['10-21'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['7-13'], ['8-6'], ['8-22'], ['8-25'], ['8-31'], ['9-8'], ['9-30'], ['10-7'], ['10-21'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['7-13'], ['8-6'], ['8-22'], ['8-25'], ['8-31'], ['9-8'], ['9-30'], ['10-7'], ['10-21'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_0_depth_7500_results.json\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['7-13'], ['8-6'], ['8-22'], ['8-25'], ['8-31'], ['9-8'], ['9-30'], ['10-7'], ['10-21'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['19-15'], ['21-30'], ['6-9'], ['6-30'], ['8-26'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['11-15'], ['13-11'], ['8-25'], ['8-31'], ['11-14'], ['14-7'], ['14-9'], ['14-24'], ['15-14'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['19-15'], ['21-30'], ['6-9'], ['6-30'], ['8-26'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['11-15'], ['13-11'], ['8-25'], ['8-31'], ['11-14'], ['14-7'], ['14-9'], ['14-24'], ['15-14'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['19-15'], ['21-30'], ['6-9'], ['6-30'], ['8-26'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['11-15'], ['13-11'], ['7-12'], ['8-25'], ['8-31'], ['11-14'], ['14-7'], ['14-9'], ['14-24'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['19-15'], ['21-30'], ['6-9'], ['6-30'], ['8-26'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['11-15'], ['13-11'], ['7-12'], ['8-25'], ['8-31'], ['11-14'], ['14-7'], ['14-9'], ['14-24'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_1250_depth_7500_results.json\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['19-15'], ['21-30'], ['6-30'], ['8-26'], ['24-29'], ['6-9'], ['31-16'], ['7-4'], ['20-29'], ['11-15'], ['13-11'], ['7-12'], ['17-22'], ['8-31'], ['14-7'], ['14-9'], ['14-24'], ['15-14'], ['21-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['19-15'], ['24-29'], ['8-26'], ['6-9'], ['6-30'], ['20-29'], ['31-16'], ['7-4'], ['11-15'], ['7-12'], ['13-11'], ['17-22'], ['8-31'], ['14-7'], ['14-9'], ['14-24'], ['15-14'], ['21-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['19-15'], ['24-29'], ['8-26'], ['6-9'], ['6-30'], ['20-29'], ['31-16'], ['7-4'], ['11-15'], ['7-12'], ['17-22'], ['13-11'], ['8-31'], ['14-7'], ['14-9'], ['14-24'], ['15-14'], ['21-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1129\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['19-15'], ['24-29'], ['8-26'], ['6-9'], ['6-30'], ['20-29'], ['31-16'], ['11-15'], ['7-4'], ['7-12'], ['17-22'], ['13-11'], ['14-7'], ['21-26'], ['24-11'], ['26-27'], ['8-31'], ['14-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1397\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['19-15'], ['24-29'], ['8-26'], ['6-9'], ['6-30'], ['20-29'], ['11-15'], ['7-4'], ['31-16'], ['7-12'], ['17-22'], ['13-11'], ['14-7'], ['21-26'], ['24-11'], ['26-27'], ['8-31'], ['14-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_2500_depth_7500_results.json\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['19-15'], ['24-29'], ['8-26'], ['6-9'], ['6-30'], ['20-29'], ['11-15'], ['7-4'], ['31-16'], ['7-12'], ['17-22'], ['13-11'], ['14-7'], ['21-26'], ['24-11'], ['26-27'], ['8-31'], ['14-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['24-29'], ['19-15'], ['8-26'], ['6-9'], ['6-30'], ['20-29'], ['11-15'], ['7-4'], ['31-16'], ['7-12'], ['17-22'], ['13-11'], ['14-7'], ['21-26'], ['24-11'], ['26-27'], ['8-31'], ['14-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['24-29'], ['19-15'], ['8-26'], ['6-9'], ['6-30'], ['11-15'], ['20-29'], ['7-4'], ['7-12'], ['31-16'], ['17-22'], ['13-11'], ['14-7'], ['21-26'], ['24-11'], ['26-27'], ['8-31'], ['14-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1397\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['24-29'], ['19-15'], ['8-26'], ['6-9'], ['6-30'], ['11-15'], ['20-29'], ['7-12'], ['7-4'], ['31-16'], ['17-22'], ['13-11'], ['21-26'], ['24-11'], ['26-27'], ['14-7'], ['8-31'], ['14-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2213\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['24-29'], ['19-15'], ['8-26'], ['6-9'], ['6-30'], ['11-15'], ['20-29'], ['7-4'], ['7-12'], ['31-16'], ['17-22'], ['13-11'], ['21-26'], ['24-11'], ['26-27'], ['14-7'], ['8-31'], ['14-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_3750_depth_7500_results.json\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['24-29'], ['19-15'], ['8-26'], ['6-9'], ['6-30'], ['11-15'], ['20-29'], ['7-4'], ['7-12'], ['31-16'], ['17-22'], ['13-11'], ['21-26'], ['24-11'], ['26-27'], ['14-7'], ['8-31'], ['14-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['24-29'], ['19-15'], ['8-26'], ['6-9'], ['6-30'], ['11-15'], ['20-29'], ['7-12'], ['7-4'], ['31-16'], ['17-22'], ['13-11'], ['21-26'], ['24-11'], ['26-27'], ['14-7'], ['8-31'], ['14-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1185\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['24-29'], ['19-15'], ['8-26'], ['6-9'], ['11-15'], ['6-30'], ['20-29'], ['7-12'], ['7-4'], ['31-16'], ['17-22'], ['13-11'], ['21-26'], ['24-11'], ['26-27'], ['14-7'], ['8-31'], ['14-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2213\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['24-29'], ['19-15'], ['8-26'], ['6-9'], ['11-15'], ['6-30'], ['20-29'], ['7-12'], ['7-4'], ['17-22'], ['31-16'], ['13-11'], ['21-26'], ['24-11'], ['26-27'], ['14-7'], ['8-31'], ['14-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 2213\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['24-29'], ['19-15'], ['8-26'], ['6-9'], ['11-15'], ['6-30'], ['20-29'], ['7-12'], ['7-4'], ['17-22'], ['31-16'], ['13-11'], ['21-26'], ['24-11'], ['26-27'], ['14-7'], ['8-31'], ['14-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_5000_depth_7500_results.json\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['24-29'], ['19-15'], ['8-26'], ['6-9'], ['6-30'], ['11-15'], ['20-29'], ['7-12'], ['7-4'], ['17-22'], ['31-16'], ['13-11'], ['21-26'], ['24-11'], ['26-27'], ['14-7'], ['8-31'], ['14-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant/llama-2-7b-80k_id_589_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/589.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['7-13'], ['8-6'], ['8-22'], ['8-25'], ['8-31'], ['9-8'], ['9-30'], ['10-7'], ['10-21'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['7-13'], ['8-6'], ['8-22'], ['8-25'], ['8-31'], ['9-8'], ['9-30'], ['10-7'], ['10-21'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['7-13'], ['8-6'], ['8-22'], ['8-25'], ['8-31'], ['9-8'], ['9-30'], ['10-7'], ['10-21'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['7-13'], ['8-6'], ['8-22'], ['8-25'], ['8-31'], ['9-8'], ['9-30'], ['10-7'], ['10-21'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['7-13'], ['8-6'], ['8-22'], ['8-25'], ['8-31'], ['9-8'], ['9-30'], ['10-7'], ['10-21'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['19-15'], ['21-30'], ['6-9'], ['6-30'], ['8-26'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['11-15'], ['13-11'], ['8-25'], ['8-31'], ['11-14'], ['14-7'], ['14-9'], ['14-24'], ['15-14'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['19-15'], ['21-30'], ['6-9'], ['6-30'], ['8-26'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['11-15'], ['13-11'], ['8-25'], ['8-31'], ['11-14'], ['14-7'], ['14-9'], ['14-24'], ['15-14'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['19-15'], ['21-30'], ['6-9'], ['6-30'], ['8-26'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['11-15'], ['13-11'], ['7-12'], ['8-25'], ['8-31'], ['11-14'], ['14-7'], ['14-9'], ['14-24'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['19-15'], ['21-30'], ['6-9'], ['6-30'], ['8-26'], ['24-29'], ['31-16'], ['7-4'], ['20-29'], ['11-15'], ['13-11'], ['7-12'], ['8-25'], ['8-31'], ['11-14'], ['14-7'], ['14-9'], ['14-24'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['19-15'], ['21-30'], ['6-30'], ['8-26'], ['24-29'], ['6-9'], ['31-16'], ['7-4'], ['20-29'], ['11-15'], ['13-11'], ['7-12'], ['17-22'], ['8-31'], ['14-7'], ['14-9'], ['14-24'], ['15-14'], ['21-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['19-15'], ['24-29'], ['6-9'], ['8-26'], ['6-30'], ['20-29'], ['31-16'], ['7-4'], ['11-15'], ['7-12'], ['13-11'], ['17-22'], ['14-7'], ['14-9'], ['21-26'], ['24-11'], ['26-27'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['19-15'], ['24-29'], ['6-9'], ['8-26'], ['6-30'], ['20-29'], ['31-16'], ['7-4'], ['7-12'], ['11-15'], ['17-22'], ['13-11'], ['14-7'], ['14-9'], ['21-26'], ['24-11'], ['26-27'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1129\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['24-29'], ['19-15'], ['6-9'], ['8-26'], ['6-30'], ['20-29'], ['31-16'], ['7-12'], ['11-15'], ['7-4'], ['17-22'], ['13-11'], ['14-7'], ['21-26'], ['24-11'], ['26-27'], ['14-9'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1420\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['19-15'], ['6-9'], ['8-26'], ['6-30'], ['20-29'], ['31-16'], ['7-12'], ['11-15'], ['7-4'], ['17-22'], ['13-11'], ['14-7'], ['21-26'], ['24-11'], ['26-27'], ['14-9'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['19-15'], ['6-9'], ['8-26'], ['6-30'], ['20-29'], ['31-16'], ['7-4'], ['7-12'], ['11-15'], ['17-22'], ['13-11'], ['14-7'], ['21-26'], ['24-11'], ['26-27'], ['14-9'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['24-29'], ['19-15'], ['6-9'], ['8-26'], ['6-30'], ['20-29'], ['31-16'], ['7-12'], ['11-15'], ['7-4'], ['17-22'], ['14-7'], ['13-11'], ['21-26'], ['24-11'], ['26-27'], ['14-9'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['24-29'], ['19-15'], ['6-9'], ['8-26'], ['6-30'], ['20-29'], ['7-12'], ['11-15'], ['31-16'], ['7-4'], ['17-22'], ['14-7'], ['13-11'], ['21-26'], ['24-11'], ['26-27'], ['14-9'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1420\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['19-15'], ['6-9'], ['8-26'], ['6-30'], ['20-29'], ['7-12'], ['11-15'], ['31-16'], ['17-22'], ['7-4'], ['14-7'], ['13-11'], ['21-26'], ['24-11'], ['26-27'], ['14-9'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2262\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['19-15'], ['6-9'], ['8-26'], ['6-30'], ['20-29'], ['7-12'], ['11-15'], ['31-16'], ['7-4'], ['17-22'], ['14-7'], ['13-11'], ['21-26'], ['24-11'], ['26-27'], ['14-9'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['19-15'], ['6-9'], ['8-26'], ['6-30'], ['20-29'], ['11-15'], ['7-12'], ['31-16'], ['7-4'], ['17-22'], ['14-7'], ['13-11'], ['21-26'], ['24-11'], ['26-27'], ['14-9'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['24-29'], ['19-15'], ['6-9'], ['8-26'], ['6-30'], ['20-29'], ['11-15'], ['7-12'], ['31-16'], ['7-4'], ['17-22'], ['14-7'], ['13-11'], ['21-26'], ['24-11'], ['26-27'], ['14-9'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1185\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['21-30'], ['24-29'], ['19-15'], ['6-9'], ['8-26'], ['6-30'], ['20-29'], ['11-15'], ['7-12'], ['31-16'], ['7-4'], ['17-22'], ['14-7'], ['13-11'], ['21-26'], ['24-11'], ['26-27'], ['14-9'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 57.76846408843994\n",
      "Response: Peking University\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2262\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['19-15'], ['6-9'], ['8-26'], ['6-30'], ['11-15'], ['20-29'], ['7-12'], ['31-16'], ['7-4'], ['14-7'], ['17-22'], ['13-11'], ['24-11'], ['21-26'], ['26-27'], ['14-9'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 2262\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['19-15'], ['6-9'], ['8-26'], ['6-30'], ['11-15'], ['7-12'], ['20-29'], ['14-7'], ['31-16'], ['7-4'], ['17-22'], ['24-11'], ['13-11'], ['21-26'], ['26-27'], ['14-9'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The most recent ACM-ICPC World Finals was won by Peking University.\n",
      "[['16-19'], ['24-29'], ['21-30'], ['19-15'], ['6-9'], ['8-26'], ['6-30'], ['11-15'], ['7-12'], ['20-29'], ['14-7'], ['31-16'], ['7-4'], ['17-22'], ['24-11'], ['13-11'], ['21-26'], ['26-27'], ['14-9'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 55.98067045211792\n",
      "Response: Peking University.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_589_irrelevant_misleading/llama-2-7b-80k_id_589_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['8-26'], ['12-26'], ['29-19'], ['31-16'], ['0-9'], ['0-11'], ['11-2'], ['12-2'], ['17-0'], ['20-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['8-26'], ['12-26'], ['29-19'], ['31-16'], ['0-9'], ['0-11'], ['11-2'], ['12-2'], ['17-0'], ['20-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['8-26'], ['12-26'], ['29-19'], ['31-16'], ['0-9'], ['0-11'], ['11-2'], ['12-2'], ['17-0'], ['20-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['8-26'], ['12-26'], ['29-19'], ['31-16'], ['0-9'], ['0-11'], ['11-2'], ['12-2'], ['17-0'], ['20-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_0_depth_7500_results.json\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['8-26'], ['12-26'], ['29-19'], ['31-16'], ['0-9'], ['0-11'], ['11-2'], ['12-2'], ['17-0'], ['20-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['8-26'], ['12-26'], ['29-19'], ['31-16'], ['29-26'], ['0-9'], ['0-11'], ['11-2'], ['12-2'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 67.01275706291199\n",
      "Response: The winner of the most recent season of America's Got Talent was Darci Lynne Farmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_1250_depth_0_results.json\n",
      "insertion at 185\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['8-26'], ['18-30'], ['6-30'], ['12-26'], ['29-19'], ['31-16'], ['11-2'], ['20-27'], ['24-3'], ['26-3'], ['7-12'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 498\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['7-4'], ['24-29'], ['8-26'], ['18-30'], ['6-30'], ['7-12'], ['29-19'], ['12-26'], ['31-16'], ['11-2'], ['20-27'], ['24-3'], ['26-3'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 738\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['7-4'], ['8-26'], ['24-29'], ['18-30'], ['7-12'], ['6-30'], ['29-19'], ['11-2'], ['31-16'], ['12-26'], ['20-27'], ['24-3'], ['26-3'], ['21-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_1250_depth_7500_results.json\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['11-2'], ['29-19'], ['7-12'], ['12-26'], ['31-16'], ['20-27'], ['24-3'], ['26-3'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 19.37774419784546\n",
      "Response: Terry Crews\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_2500_depth_0_results.json\n",
      "insertion at 559\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['29-19'], ['7-12'], ['11-2'], ['12-26'], ['31-16'], ['20-27'], ['24-3'], ['28-14'], ['21-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 60.50991415977478\n",
      "Response: Richard Goodall\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1099\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['29-19'], ['7-12'], ['11-2'], ['31-16'], ['12-26'], ['20-27'], ['24-3'], ['28-14'], ['21-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 60.50991415977478\n",
      "Response: Richard Goodall\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1690\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['29-19'], ['7-12'], ['31-16'], ['11-2'], ['12-26'], ['20-27'], ['24-3'], ['28-14'], ['21-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 60.50991415977478\n",
      "Response: Richard Goodall\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_2500_depth_7500_results.json\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['17-22'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['29-19'], ['11-2'], ['31-16'], ['12-26'], ['7-12'], ['20-27'], ['28-14'], ['21-5'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['17-22'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['29-19'], ['7-12'], ['11-2'], ['31-16'], ['12-26'], ['20-27'], ['28-14'], ['21-5'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 65.90358018875122\n",
      "Response: The most recent season of America's Got Talent was won by a magician named Shin Lim. He won the show's 13th season, which aired in 2018.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_3750_depth_0_results.json\n",
      "insertion at 810\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['7-12'], ['29-19'], ['11-2'], ['31-16'], ['12-26'], ['20-27'], ['28-14'], ['21-5'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1747\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['7-4'], ['24-29'], ['7-12'], ['18-30'], ['6-30'], ['29-19'], ['11-2'], ['31-16'], ['20-27'], ['12-26'], ['28-14'], ['24-3'], ['21-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2644\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['7-4'], ['24-29'], ['7-12'], ['18-30'], ['6-30'], ['29-19'], ['11-2'], ['20-27'], ['31-16'], ['28-14'], ['24-3'], ['12-26'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_3750_depth_7500_results.json\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['7-4'], ['24-29'], ['7-12'], ['18-30'], ['6-30'], ['29-19'], ['11-2'], ['20-27'], ['28-14'], ['31-16'], ['12-26'], ['21-5'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['7-4'], ['24-29'], ['7-12'], ['18-30'], ['6-30'], ['29-19'], ['11-2'], ['20-27'], ['28-14'], ['31-16'], ['12-26'], ['21-5'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 65.56406617164612\n",
      "Response: The most recent season of America's Got Talent was won by a 10-year-old singer named Grace VanderWaal. She was the first winner of the show to be a singer-songwriter.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1195\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['7-4'], ['24-29'], ['7-12'], ['18-30'], ['29-19'], ['6-30'], ['11-2'], ['20-27'], ['28-14'], ['31-16'], ['26-28'], ['12-26'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2383\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['21-30'], ['7-4'], ['7-12'], ['24-29'], ['29-19'], ['18-30'], ['6-30'], ['11-2'], ['28-14'], ['20-27'], ['31-16'], ['26-28'], ['24-3'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3587\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['21-30'], ['7-12'], ['7-4'], ['24-29'], ['29-19'], ['11-2'], ['18-30'], ['6-30'], ['28-14'], ['20-27'], ['31-16'], ['24-3'], ['26-3'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_5000_depth_7500_results.json\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['7-4'], ['24-29'], ['7-12'], ['29-19'], ['11-2'], ['18-30'], ['6-30'], ['28-14'], ['20-27'], ['31-16'], ['26-28'], ['24-3'], ['26-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
<<<<<<< Updated upstream
      "Writing at results/graph/llama-2-7b-80k_id_424_irrelevant/llama-2-7b-80k_id_424_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/424.txt\n",
=======
      "Score: 73.33691716194153\n",
      "Response: Moana 2.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2084\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['7-12'], ['21-30'], ['17-22'], ['31-16'], ['8-26'], ['24-8'], ['15-14'], ['24-29'], ['19-10'], ['14-18'], ['6-9'], ['13-11'], ['18-30'], ['16-30'], ['26-26'], ['6-30'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3567\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['21-30'], ['7-12'], ['17-22'], ['31-16'], ['8-26'], ['24-8'], ['15-14'], ['19-10'], ['24-29'], ['13-11'], ['14-18'], ['6-9'], ['18-30'], ['26-26'], ['6-30'], ['16-24'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The most recent Walt Disney Animation Studios's animated film sequel is Moana 2.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['21-30'], ['17-22'], ['7-12'], ['31-16'], ['8-26'], ['15-14'], ['19-10'], ['24-8'], ['24-29'], ['6-9'], ['13-11'], ['14-18'], ['18-30'], ['16-24'], ['26-26'], ['6-30'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 71.74752950668335\n",
      "Response: Moana 2\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_442_irrelevant_misleading/llama-2-7b-80k_id_442_irrelevant_misleading_len_5000_depth_10000_results.json\n",
>>>>>>> Stashed changes
=======
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant/llama-2-7b-80k_id_590_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/590.txt\n",
>>>>>>> Stashed changes
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
      "- Needle: Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
=======
      "- Needle: The latest NFL season began on September 5, 2024.\n",
>>>>>>> Stashed changes
=======
      "- Needle: Richard Goodall won the most recent season of America's Got Talent.\n",
>>>>>>> Stashed changes
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
      "Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['7-4'], ['19-15'], ['8-26'], ['21-30'], ['24-29'], ['12-26'], ['6-30'], ['31-16'], ['11-2'], ['14-18'], ['17-22'], ['22-8'], ['26-3'], ['29-19'], ['29-21'], ['12-2'], ['16-1']]\n",
=======
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['8-26'], ['12-26'], ['29-19'], ['31-16'], ['0-9'], ['0-11'], ['11-2'], ['12-2'], ['17-0'], ['20-27']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['8-26'], ['12-26'], ['29-19'], ['31-16'], ['0-9'], ['0-11'], ['11-2'], ['12-2'], ['17-0'], ['20-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['8-26'], ['12-26'], ['29-19'], ['31-16'], ['0-9'], ['0-11'], ['11-2'], ['12-2'], ['17-0'], ['20-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['8-26'], ['12-26'], ['29-19'], ['31-16'], ['0-9'], ['0-11'], ['11-2'], ['12-2'], ['17-0'], ['20-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_0_depth_7500_results.json\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['8-26'], ['12-26'], ['29-19'], ['31-16'], ['0-9'], ['0-11'], ['11-2'], ['12-2'], ['17-0'], ['20-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
<<<<<<< Updated upstream
      "Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['7-4'], ['19-15'], ['24-29'], ['8-26'], ['21-30'], ['12-26'], ['6-30'], ['31-16'], ['17-22'], ['11-2'], ['14-18'], ['22-8'], ['26-3'], ['29-19'], ['29-21'], ['7-12'], ['16-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_424_irrelevant_misleading/llama-2-7b-80k_id_424_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 241\n",
      "Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-4'], ['19-15'], ['24-29'], ['21-30'], ['12-26'], ['6-30'], ['17-22'], ['31-16'], ['7-12'], ['11-2'], ['14-18'], ['26-3'], ['16-1'], ['22-8'], ['29-19'], ['6-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 83.52980613708496\n",
      "Response: Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected. However, after the 1988 presidential election, the shine had dulled on\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_424_irrelevant_misleading/llama-2-7b-80k_id_424_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 438\n",
      "Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['24-29'], ['21-30'], ['7-4'], ['19-15'], ['17-22'], ['12-26'], ['6-30'], ['7-12'], ['31-16'], ['11-2'], ['6-16'], ['26-3'], ['14-18'], ['16-1'], ['29-19'], ['21-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 76.44389271736145\n",
      "Response: Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected. Yet, in the chronology of \"major conflicts\" involving the United States, the Vietnam War is the\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_424_irrelevant_misleading/llama-2-7b-80k_id_424_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 743\n",
      "Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['12-26'], ['6-30'], ['7-12'], ['6-16'], ['31-16'], ['11-2'], ['26-3'], ['16-1'], ['14-18'], ['29-19'], ['20-29']]\n",
=======
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['18-30'], ['19-10'], ['12-26'], ['11-2'], ['14-15'], ['6-30'], ['14-19'], ['16-24'], ['19-15'], ['21-30'], ['0-22'], ['0-28'], ['1-25'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['18-30'], ['19-10'], ['12-26'], ['11-2'], ['14-15'], ['6-30'], ['14-19'], ['16-24'], ['19-15'], ['21-30'], ['0-22'], ['0-28'], ['1-25'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['18-30'], ['19-10'], ['12-26'], ['11-2'], ['14-15'], ['6-30'], ['14-19'], ['16-24'], ['19-15'], ['21-30'], ['0-22'], ['0-28'], ['1-25'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['18-30'], ['19-10'], ['12-26'], ['11-2'], ['14-15'], ['6-30'], ['14-19'], ['16-24'], ['19-15'], ['21-30'], ['0-22'], ['0-28'], ['1-25'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_0_depth_7500_results.json\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['18-30'], ['19-10'], ['12-26'], ['11-2'], ['14-15'], ['6-30'], ['14-19'], ['16-24'], ['19-15'], ['21-30'], ['0-22'], ['0-28'], ['1-25'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['7-4'], ['8-26'], ['18-30'], ['19-10'], ['11-2'], ['12-26'], ['14-15'], ['16-24'], ['21-30'], ['6-30'], ['14-19'], ['19-15'], ['14-18'], ['17-31'], ['31-15'], ['11-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_1250_depth_0_results.json\n",
      "insertion at 246\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['7-4'], ['8-26'], ['18-30'], ['19-10'], ['11-2'], ['12-26'], ['14-15'], ['7-12'], ['19-15'], ['21-30'], ['16-24'], ['6-30'], ['14-18'], ['14-19'], ['17-31'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 488\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['7-4'], ['8-26'], ['11-2'], ['19-10'], ['18-30'], ['12-26'], ['7-12'], ['14-15'], ['19-15'], ['21-30'], ['14-18'], ['16-24'], ['6-30'], ['14-19'], ['17-31'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 752\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['7-4'], ['8-26'], ['11-2'], ['19-10'], ['18-30'], ['7-12'], ['14-15'], ['12-26'], ['19-15'], ['21-30'], ['14-18'], ['16-24'], ['6-30'], ['14-19'], ['17-31'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_1250_depth_7500_results.json\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['7-4'], ['11-2'], ['19-10'], ['18-30'], ['12-26'], ['14-15'], ['7-12'], ['19-15'], ['21-30'], ['16-24'], ['6-30'], ['14-18'], ['14-19'], ['17-31'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['7-4'], ['11-2'], ['19-10'], ['18-30'], ['7-12'], ['12-26'], ['14-15'], ['19-15'], ['21-30'], ['14-18'], ['16-24'], ['6-30'], ['14-19'], ['17-31'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_2500_depth_0_results.json\n",
      "insertion at 561\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['7-4'], ['11-2'], ['19-10'], ['7-12'], ['18-30'], ['12-26'], ['14-15'], ['21-30'], ['14-18'], ['19-15'], ['16-24'], ['17-31'], ['6-30'], ['14-19'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1125\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['7-12'], ['19-10'], ['18-30'], ['12-26'], ['14-15'], ['14-18'], ['21-30'], ['19-15'], ['17-31'], ['16-24'], ['15-14'], ['6-30'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1711\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['7-12'], ['19-10'], ['18-30'], ['12-26'], ['14-15'], ['19-15'], ['21-30'], ['14-18'], ['17-31'], ['16-24'], ['15-14'], ['6-30'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_2500_depth_7500_results.json\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['7-12'], ['19-10'], ['18-30'], ['19-15'], ['21-30'], ['12-26'], ['14-15'], ['14-18'], ['17-31'], ['16-24'], ['6-30'], ['15-14'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['7-12'], ['19-10'], ['18-30'], ['14-18'], ['21-30'], ['12-26'], ['19-15'], ['14-15'], ['17-31'], ['15-14'], ['16-24'], ['6-30'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_3750_depth_0_results.json\n",
      "insertion at 881\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['11-2'], ['7-4'], ['7-12'], ['19-10'], ['18-30'], ['14-18'], ['21-30'], ['12-26'], ['19-15'], ['17-31'], ['14-15'], ['15-14'], ['16-24'], ['6-30'], ['17-0']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_424_irrelevant_misleading/llama-2-7b-80k_id_424_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['7-4'], ['17-22'], ['12-26'], ['6-30'], ['31-16'], ['6-16'], ['7-12'], ['11-2'], ['26-3'], ['14-18'], ['16-1'], ['29-19'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_424_irrelevant_misleading/llama-2-7b-80k_id_424_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['7-12'], ['6-16'], ['12-26'], ['11-2'], ['6-30'], ['31-16'], ['16-1'], ['26-3'], ['20-29'], ['14-18'], ['21-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_424_irrelevant_misleading/llama-2-7b-80k_id_424_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 527\n",
      "Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['6-16'], ['7-12'], ['11-2'], ['12-26'], ['6-30'], ['31-16'], ['16-1'], ['26-3'], ['20-29'], ['14-18'], ['21-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_424_irrelevant_misleading/llama-2-7b-80k_id_424_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1135\n",
      "Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['6-16'], ['7-12'], ['11-2'], ['6-30'], ['12-26'], ['31-16'], ['16-1'], ['26-3'], ['20-29'], ['14-18'], ['21-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_424_irrelevant_misleading/llama-2-7b-80k_id_424_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1425\n",
      "Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['6-16'], ['7-12'], ['11-2'], ['6-30'], ['12-26'], ['16-1'], ['31-16'], ['26-3'], ['20-29'], ['14-18'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_424_irrelevant_misleading/llama-2-7b-80k_id_424_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['6-16'], ['7-12'], ['11-2'], ['6-30'], ['31-16'], ['12-26'], ['16-1'], ['20-29'], ['26-3'], ['14-18'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_424_irrelevant_misleading/llama-2-7b-80k_id_424_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['6-16'], ['7-12'], ['11-2'], ['6-30'], ['31-16'], ['12-26'], ['16-1'], ['20-29'], ['26-3'], ['14-18'], ['21-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_424_irrelevant_misleading/llama-2-7b-80k_id_424_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 872\n",
      "Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['17-22'], ['7-4'], ['6-16'], ['7-12'], ['11-2'], ['6-30'], ['16-1'], ['31-16'], ['12-26'], ['20-29'], ['26-3'], ['14-18'], ['21-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
<<<<<<< Updated upstream
      "Score: 79.16253805160522\n",
      "Response: Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected. In 2018, Gallagher noted that when given the opportunity to elect Vietnam veterans\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_424_irrelevant_misleading/llama-2-7b-80k_id_424_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1727\n",
      "Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['17-22'], ['6-16'], ['7-4'], ['7-12'], ['11-2'], ['16-1'], ['6-30'], ['31-16'], ['12-26'], ['20-29'], ['26-3'], ['14-18'], ['21-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_424_irrelevant_misleading/llama-2-7b-80k_id_424_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2543\n",
      "Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['17-22'], ['6-16'], ['7-4'], ['7-12'], ['11-2'], ['16-1'], ['6-30'], ['31-16'], ['12-26'], ['26-3'], ['20-29'], ['21-27'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_424_irrelevant_misleading/llama-2-7b-80k_id_424_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['17-22'], ['6-16'], ['7-4'], ['7-12'], ['11-2'], ['16-1'], ['6-30'], ['31-16'], ['12-26'], ['26-3'], ['20-29'], ['21-27'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_424_irrelevant_misleading/llama-2-7b-80k_id_424_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['17-22'], ['6-16'], ['7-12'], ['7-4'], ['11-2'], ['16-1'], ['20-29'], ['6-30'], ['31-16'], ['12-26'], ['26-3'], ['21-27'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_424_irrelevant_misleading/llama-2-7b-80k_id_424_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1186\n",
      "Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['17-22'], ['6-16'], ['7-12'], ['7-4'], ['11-2'], ['16-1'], ['20-29'], ['26-3'], ['6-30'], ['31-16'], ['12-26'], ['21-27'], ['14-18']]\n",
=======
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1731\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['11-2'], ['7-12'], ['7-4'], ['19-10'], ['18-30'], ['14-18'], ['19-15'], ['21-30'], ['17-31'], ['12-26'], ['14-15'], ['15-14'], ['16-24'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2588\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['11-2'], ['7-12'], ['7-4'], ['19-10'], ['18-30'], ['14-18'], ['19-15'], ['21-30'], ['17-31'], ['12-26'], ['14-15'], ['15-14'], ['16-24'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_3750_depth_7500_results.json\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['11-2'], ['7-12'], ['7-4'], ['19-10'], ['18-30'], ['21-30'], ['14-18'], ['19-15'], ['17-31'], ['12-26'], ['14-15'], ['15-14'], ['16-24'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['11-2'], ['7-12'], ['7-4'], ['19-10'], ['18-30'], ['14-18'], ['21-30'], ['19-15'], ['17-31'], ['12-26'], ['14-15'], ['15-14'], ['16-24'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1178\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['11-2'], ['7-12'], ['7-4'], ['19-10'], ['18-30'], ['14-18'], ['21-30'], ['19-15'], ['17-31'], ['12-26'], ['14-15'], ['15-14'], ['16-24'], ['6-30'], ['17-0']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
<<<<<<< Updated upstream
      "Score: 100.0\n",
      "Response: Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_424_irrelevant_misleading/llama-2-7b-80k_id_424_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2381\n",
      "Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['17-22'], ['6-16'], ['7-12'], ['7-4'], ['11-2'], ['16-1'], ['20-29'], ['26-3'], ['6-30'], ['31-16'], ['12-26'], ['21-27'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_424_irrelevant_misleading/llama-2-7b-80k_id_424_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3558\n",
      "Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['17-22'], ['6-16'], ['7-12'], ['7-4'], ['11-2'], ['16-1'], ['20-29'], ['6-30'], ['26-3'], ['31-16'], ['12-26'], ['21-27'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 79.20197248458862\n",
      "Response: Muse Bihi Abdi is still in office, having successfully run for and won re-election in a tightly contested campaign.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_424_irrelevant_misleading/llama-2-7b-80k_id_424_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['24-29'], ['19-15'], ['17-22'], ['6-16'], ['7-12'], ['7-4'], ['11-2'], ['16-1'], ['20-29'], ['6-30'], ['31-16'], ['26-3'], ['12-26'], ['21-27'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Muse Bihi Abdi was the most recent incumbent president worldwide who ran for re-election but was not reelected.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_424_irrelevant_misleading/llama-2-7b-80k_id_424_irrelevant_misleading_len_5000_depth_10000_results.json\n",
=======
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2366\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['11-2'], ['7-12'], ['7-4'], ['19-10'], ['18-30'], ['14-18'], ['21-30'], ['17-31'], ['19-15'], ['12-26'], ['14-15'], ['15-14'], ['16-24'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3572\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['11-2'], ['7-12'], ['7-4'], ['19-10'], ['18-30'], ['14-18'], ['21-30'], ['17-31'], ['19-15'], ['14-15'], ['12-26'], ['15-14'], ['16-24'], ['17-0'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_5000_depth_7500_results.json\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['11-2'], ['7-12'], ['7-4'], ['19-10'], ['18-30'], ['21-30'], ['14-18'], ['17-31'], ['19-15'], ['12-26'], ['14-15'], ['15-14'], ['16-24'], ['17-0'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant/llama-2-7b-80k_id_444_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_relevant/444.txt\n",
>>>>>>> Stashed changes
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
=======
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n"
>>>>>>> Stashed changes
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
<<<<<<< Updated upstream
      "- Needle: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
=======
      "- Needle: The latest NFL season began on September 5, 2024.\n",
>>>>>>> Stashed changes
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
<<<<<<< Updated upstream
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['16-19'], ['21-30'], ['24-29'], ['11-2'], ['19-15'], ['17-22'], ['6-30'], ['19-12'], ['31-16'], ['14-18'], ['24-30'], ['26-25'], ['26-28'], ['6-20'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['16-19'], ['21-30'], ['24-29'], ['11-2'], ['19-15'], ['17-22'], ['6-30'], ['19-12'], ['31-16'], ['14-18'], ['24-30'], ['26-25'], ['26-28'], ['6-20'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['16-19'], ['21-30'], ['24-29'], ['11-2'], ['19-15'], ['17-22'], ['6-30'], ['19-12'], ['31-16'], ['14-18'], ['24-30'], ['26-25'], ['26-28'], ['6-20'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['16-19'], ['21-30'], ['24-29'], ['11-2'], ['19-15'], ['17-22'], ['6-30'], ['19-12'], ['31-16'], ['14-18'], ['24-30'], ['26-25'], ['26-28'], ['6-20'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_0_depth_7500_results.json\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['16-19'], ['21-30'], ['24-29'], ['11-2'], ['19-15'], ['17-22'], ['6-30'], ['19-12'], ['31-16'], ['14-18'], ['24-30'], ['26-25'], ['26-28'], ['6-20'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['7-4'], ['12-26'], ['11-2'], ['21-30'], ['24-29'], ['19-15'], ['17-22'], ['6-30'], ['19-12'], ['31-16'], ['14-18'], ['24-30'], ['26-25'], ['26-28'], ['6-20'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 74.3202805519104\n",
      "Response: The current ATP top-ranked men's singles tennis player is Novak Djokovic.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_1250_depth_0_results.json\n",
      "insertion at 242\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['7-4'], ['11-2'], ['12-26'], ['24-29'], ['21-30'], ['19-15'], ['17-22'], ['31-16'], ['6-30'], ['19-12'], ['14-18'], ['26-25'], ['26-28'], ['24-30'], ['6-20'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 509\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['11-2'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['21-30'], ['12-26'], ['31-16'], ['6-30'], ['14-18'], ['19-12'], ['26-25'], ['26-28'], ['24-30'], ['22-22'], ['6-20']]\n",
=======
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['18-30'], ['19-10'], ['12-26'], ['11-2'], ['14-15'], ['6-30'], ['14-19'], ['16-24'], ['19-15'], ['21-30'], ['0-22'], ['0-28'], ['1-25'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['18-30'], ['19-10'], ['12-26'], ['11-2'], ['14-15'], ['6-30'], ['14-19'], ['16-24'], ['19-15'], ['21-30'], ['0-22'], ['0-28'], ['1-25'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['18-30'], ['19-10'], ['12-26'], ['11-2'], ['14-15'], ['6-30'], ['14-19'], ['16-24'], ['19-15'], ['21-30'], ['0-22'], ['0-28'], ['1-25'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['18-30'], ['19-10'], ['12-26'], ['11-2'], ['14-15'], ['6-30'], ['14-19'], ['16-24'], ['19-15'], ['21-30'], ['0-22'], ['0-28'], ['1-25'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_0_depth_7500_results.json\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['18-30'], ['19-10'], ['12-26'], ['11-2'], ['14-15'], ['6-30'], ['14-19'], ['16-24'], ['19-15'], ['21-30'], ['0-22'], ['0-28'], ['1-25'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['7-4'], ['8-26'], ['18-30'], ['19-10'], ['11-2'], ['12-26'], ['14-15'], ['21-30'], ['6-30'], ['14-19'], ['16-24'], ['19-15'], ['14-18'], ['31-15'], ['15-14'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 246\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['8-26'], ['7-4'], ['19-10'], ['18-30'], ['11-2'], ['12-26'], ['14-15'], ['7-12'], ['21-30'], ['19-15'], ['6-30'], ['14-18'], ['14-19'], ['16-24'], ['15-14'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 488\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['19-10'], ['11-2'], ['18-30'], ['12-26'], ['7-12'], ['14-15'], ['21-30'], ['14-18'], ['16-24'], ['19-15'], ['6-30'], ['14-19'], ['15-14'], ['17-0']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
<<<<<<< Updated upstream
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 769\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['11-2'], ['24-29'], ['7-4'], ['19-15'], ['21-30'], ['17-22'], ['12-26'], ['31-16'], ['6-30'], ['14-18'], ['19-12'], ['26-28'], ['26-25'], ['22-22'], ['24-30'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 98.50592017173767\n",
      "Response: Jannik Sinner is the current ATP top-ranked men's singles tennis player.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_1250_depth_7500_results.json\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['7-4'], ['19-15'], ['11-2'], ['21-30'], ['17-22'], ['12-26'], ['31-16'], ['6-30'], ['19-12'], ['14-18'], ['26-28'], ['26-25'], ['22-22'], ['24-30'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 48.22368025779724\n",
      "Response: Novak Djokovic\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_2500_depth_0_results.json\n",
      "insertion at 546\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['7-4'], ['19-15'], ['11-2'], ['21-30'], ['17-22'], ['12-26'], ['31-16'], ['6-30'], ['14-18'], ['19-12'], ['26-28'], ['22-22'], ['26-25'], ['24-30'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 60.69037318229675\n",
      "Response: Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1070\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['7-4'], ['19-15'], ['11-2'], ['21-30'], ['17-22'], ['12-26'], ['31-16'], ['6-30'], ['14-18'], ['19-12'], ['26-28'], ['22-22'], ['26-25'], ['24-30'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 60.69037318229675\n",
      "Response: Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1680\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['7-4'], ['19-15'], ['21-30'], ['11-2'], ['17-22'], ['12-26'], ['31-16'], ['6-30'], ['14-18'], ['26-28'], ['19-12'], ['22-22'], ['26-25'], ['7-12'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 60.69037318229675\n",
      "Response: Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_2500_depth_7500_results.json\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['19-15'], ['7-4'], ['21-30'], ['11-2'], ['17-22'], ['12-26'], ['31-16'], ['6-30'], ['26-28'], ['19-12'], ['22-22'], ['14-18'], ['26-25'], ['17-0'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['19-15'], ['7-4'], ['11-2'], ['21-30'], ['17-22'], ['12-26'], ['31-16'], ['6-30'], ['26-28'], ['19-12'], ['14-18'], ['22-22'], ['26-25'], ['18-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 74.3202805519104\n",
      "Response: The current ATP top-ranked men's singles tennis player is Novak Djokovic.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_3750_depth_0_results.json\n",
      "insertion at 870\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['24-29'], ['19-15'], ['7-4'], ['11-2'], ['21-30'], ['17-22'], ['12-26'], ['6-30'], ['31-16'], ['26-28'], ['14-18'], ['19-12'], ['22-22'], ['26-25'], ['7-12'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 60.69037318229675\n",
      "Response: Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1720\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['24-29'], ['19-15'], ['7-4'], ['21-30'], ['11-2'], ['17-22'], ['12-26'], ['6-30'], ['31-16'], ['26-28'], ['14-18'], ['22-22'], ['19-12'], ['7-12'], ['18-30'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 60.69037318229675\n",
      "Response: Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2483\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['24-29'], ['19-15'], ['7-4'], ['21-30'], ['17-22'], ['11-2'], ['12-26'], ['6-30'], ['31-16'], ['26-28'], ['22-22'], ['14-18'], ['19-12'], ['7-12'], ['18-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 60.69037318229675\n",
      "Response: Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_3750_depth_7500_results.json\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['24-29'], ['19-15'], ['7-4'], ['21-30'], ['17-22'], ['11-2'], ['12-26'], ['6-30'], ['31-16'], ['26-28'], ['22-22'], ['19-12'], ['14-18'], ['7-12'], ['17-0'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['24-29'], ['19-15'], ['7-4'], ['21-30'], ['17-22'], ['11-2'], ['12-26'], ['6-30'], ['31-16'], ['26-28'], ['22-22'], ['19-12'], ['7-12'], ['14-18'], ['18-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 74.3202805519104\n",
      "Response: The current ATP top-ranked men's singles tennis player is Novak Djokovic.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1070\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['24-29'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['7-4'], ['12-26'], ['6-30'], ['31-16'], ['26-28'], ['7-12'], ['22-22'], ['14-18'], ['19-12'], ['18-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 1957\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['24-29'], ['17-22'], ['19-15'], ['11-2'], ['21-30'], ['7-4'], ['12-26'], ['31-16'], ['6-30'], ['7-12'], ['26-28'], ['22-22'], ['14-18'], ['19-12'], ['18-30'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3559\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['24-29'], ['17-22'], ['19-15'], ['11-2'], ['21-30'], ['7-4'], ['12-26'], ['31-16'], ['6-30'], ['7-12'], ['26-28'], ['22-22'], ['14-18'], ['19-12'], ['18-30'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_5000_depth_7500_results.json\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['24-29'], ['17-22'], ['19-15'], ['21-30'], ['11-2'], ['7-4'], ['12-26'], ['31-16'], ['6-30'], ['26-28'], ['7-12'], ['22-22'], ['14-18'], ['19-12'], ['18-30'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant/llama-2-7b-80k_id_427_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/427.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['16-19'], ['21-30'], ['24-29'], ['11-2'], ['19-15'], ['17-22'], ['6-30'], ['19-12'], ['31-16'], ['14-18'], ['24-30'], ['26-25'], ['26-28'], ['6-20'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['16-19'], ['21-30'], ['24-29'], ['11-2'], ['19-15'], ['17-22'], ['6-30'], ['19-12'], ['31-16'], ['14-18'], ['24-30'], ['26-25'], ['26-28'], ['6-20'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['16-19'], ['21-30'], ['24-29'], ['11-2'], ['19-15'], ['17-22'], ['6-30'], ['19-12'], ['31-16'], ['14-18'], ['24-30'], ['26-25'], ['26-28'], ['6-20'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['16-19'], ['21-30'], ['24-29'], ['11-2'], ['19-15'], ['17-22'], ['6-30'], ['19-12'], ['31-16'], ['14-18'], ['24-30'], ['26-25'], ['26-28'], ['6-20'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_0_depth_7500_results.json\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['16-19'], ['21-30'], ['24-29'], ['11-2'], ['19-15'], ['17-22'], ['6-30'], ['19-12'], ['31-16'], ['14-18'], ['24-30'], ['26-25'], ['26-28'], ['6-20'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['7-4'], ['12-26'], ['24-29'], ['21-30'], ['11-2'], ['19-15'], ['17-22'], ['6-30'], ['19-12'], ['31-16'], ['14-18'], ['24-30'], ['26-28'], ['26-25'], ['22-22'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 98.50592017173767\n",
      "Response: Jannik Sinner is the current ATP top-ranked men's singles tennis player.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 242\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['7-4'], ['12-26'], ['21-30'], ['19-15'], ['11-2'], ['17-22'], ['31-16'], ['6-30'], ['19-12'], ['14-18'], ['26-28'], ['24-30'], ['26-25'], ['22-22'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 98.50592017173767\n",
      "Response: Jannik Sinner is the current ATP top-ranked men's singles tennis player.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 495\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['7-4'], ['12-26'], ['21-30'], ['19-15'], ['11-2'], ['17-22'], ['31-16'], ['6-30'], ['14-18'], ['19-12'], ['26-28'], ['24-30'], ['26-25'], ['22-22'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 98.50592017173767\n",
      "Response: Jannik Sinner is the current ATP top-ranked men's singles tennis player.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 758\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['7-4'], ['19-15'], ['21-30'], ['12-26'], ['11-2'], ['17-22'], ['31-16'], ['6-30'], ['14-18'], ['19-12'], ['26-28'], ['24-30'], ['22-22'], ['26-25'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 98.50592017173767\n",
      "Response: Jannik Sinner is the current ATP top-ranked men's singles tennis player.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['19-15'], ['7-4'], ['21-30'], ['12-26'], ['11-2'], ['17-22'], ['31-16'], ['6-30'], ['19-12'], ['26-28'], ['14-18'], ['22-22'], ['24-30'], ['26-25'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['19-15'], ['21-30'], ['7-4'], ['12-26'], ['11-2'], ['17-22'], ['31-16'], ['6-30'], ['26-28'], ['14-18'], ['19-12'], ['22-22'], ['24-30'], ['26-25'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 98.50592017173767\n",
      "Response: Jannik Sinner is the current ATP top-ranked men's singles tennis player.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 569\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['19-15'], ['21-30'], ['7-4'], ['12-26'], ['11-2'], ['17-22'], ['31-16'], ['26-28'], ['6-30'], ['14-18'], ['22-22'], ['19-12'], ['24-30'], ['26-25'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 98.50592017173767\n",
      "Response: Jannik Sinner is the current ATP top-ranked men's singles tennis player.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1134\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['19-15'], ['21-30'], ['7-4'], ['12-26'], ['11-2'], ['17-22'], ['31-16'], ['26-28'], ['6-30'], ['14-18'], ['22-22'], ['19-12'], ['24-30'], ['26-27'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 98.50592017173767\n",
      "Response: Jannik Sinner is the current ATP top-ranked men's singles tennis player.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1677\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['19-15'], ['21-30'], ['7-4'], ['12-26'], ['11-2'], ['17-22'], ['31-16'], ['26-28'], ['6-30'], ['22-22'], ['14-18'], ['19-12'], ['26-27'], ['24-30'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 98.50592017173767\n",
      "Response: Jannik Sinner is the current ATP top-ranked men's singles tennis player.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['19-15'], ['24-29'], ['21-30'], ['7-4'], ['12-26'], ['17-22'], ['11-2'], ['31-16'], ['26-28'], ['6-30'], ['22-22'], ['14-18'], ['19-12'], ['15-14'], ['24-30'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['19-15'], ['21-30'], ['7-4'], ['12-26'], ['17-22'], ['11-2'], ['31-16'], ['26-28'], ['6-30'], ['22-22'], ['14-18'], ['19-12'], ['15-14'], ['26-27'], ['24-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 98.50592017173767\n",
      "Response: Jannik Sinner is the current ATP top-ranked men's singles tennis player.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 879\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['19-15'], ['21-30'], ['7-4'], ['12-26'], ['17-22'], ['11-2'], ['31-16'], ['26-28'], ['22-22'], ['6-30'], ['14-18'], ['19-12'], ['26-27'], ['15-14'], ['24-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 98.50592017173767\n",
      "Response: Jannik Sinner is the current ATP top-ranked men's singles tennis player.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1739\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['19-15'], ['21-30'], ['7-4'], ['12-26'], ['17-22'], ['11-2'], ['31-16'], ['26-28'], ['22-22'], ['6-30'], ['14-18'], ['19-12'], ['26-27'], ['15-14'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 60.69037318229675\n",
      "Response: Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2613\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['19-15'], ['21-30'], ['7-4'], ['12-26'], ['17-22'], ['31-16'], ['11-2'], ['26-28'], ['22-22'], ['6-30'], ['14-18'], ['19-12'], ['26-27'], ['15-14'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 60.69037318229675\n",
      "Response: Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['19-15'], ['21-30'], ['7-4'], ['12-26'], ['17-22'], ['31-16'], ['11-2'], ['26-28'], ['22-22'], ['6-30'], ['14-18'], ['19-12'], ['26-27'], ['15-14'], ['24-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['19-15'], ['21-30'], ['7-4'], ['12-26'], ['17-22'], ['31-16'], ['11-2'], ['26-28'], ['6-30'], ['22-22'], ['14-18'], ['19-12'], ['26-27'], ['15-14'], ['24-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 98.50592017173767\n",
      "Response: Jannik Sinner is the current ATP top-ranked men's singles tennis player.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1142\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['19-15'], ['21-30'], ['7-4'], ['12-26'], ['17-22'], ['31-16'], ['11-2'], ['26-28'], ['6-30'], ['22-22'], ['14-18'], ['26-27'], ['19-12'], ['15-14'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 98.50592017173767\n",
      "Response: Jannik Sinner is the current ATP top-ranked men's singles tennis player.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2061\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['19-15'], ['21-30'], ['7-4'], ['12-26'], ['17-22'], ['31-16'], ['26-28'], ['11-2'], ['6-30'], ['22-22'], ['14-18'], ['26-27'], ['19-12'], ['15-14'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 61.82398796081543\n",
      "Response: Jannik Sinner\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3499\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['19-15'], ['21-30'], ['7-4'], ['12-26'], ['31-16'], ['17-22'], ['6-30'], ['11-2'], ['26-28'], ['22-22'], ['14-18'], ['26-27'], ['15-14'], ['19-12'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 60.69037318229675\n",
      "Response: Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['24-29'], ['19-15'], ['21-30'], ['7-4'], ['12-26'], ['17-22'], ['31-16'], ['6-30'], ['11-2'], ['26-28'], ['22-22'], ['26-27'], ['14-18'], ['19-12'], ['15-14'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_relevant_misleading/llama-2-7b-80k_id_427_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['16-19'], ['21-30'], ['24-29'], ['11-2'], ['19-15'], ['17-22'], ['6-30'], ['19-12'], ['31-16'], ['14-18'], ['24-30'], ['26-25'], ['26-28'], ['6-20'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['16-19'], ['21-30'], ['24-29'], ['11-2'], ['19-15'], ['17-22'], ['6-30'], ['19-12'], ['31-16'], ['14-18'], ['24-30'], ['26-25'], ['26-28'], ['6-20'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['16-19'], ['21-30'], ['24-29'], ['11-2'], ['19-15'], ['17-22'], ['6-30'], ['19-12'], ['31-16'], ['14-18'], ['24-30'], ['26-25'], ['26-28'], ['6-20'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['16-19'], ['21-30'], ['24-29'], ['11-2'], ['19-15'], ['17-22'], ['6-30'], ['19-12'], ['31-16'], ['14-18'], ['24-30'], ['26-25'], ['26-28'], ['6-20'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_0_depth_7500_results.json\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['16-19'], ['21-30'], ['24-29'], ['11-2'], ['19-15'], ['17-22'], ['6-30'], ['19-12'], ['31-16'], ['14-18'], ['24-30'], ['26-25'], ['26-28'], ['6-20'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 48.22368025779724\n",
      "Response: Novak Djokovic\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 250\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['7-4'], ['12-26'], ['24-29'], ['21-30'], ['19-15'], ['11-2'], ['17-22'], ['31-16'], ['6-30'], ['19-12'], ['14-18'], ['26-28'], ['24-30'], ['26-25'], ['22-22'], ['6-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 334\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['7-4'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['12-26'], ['17-22'], ['31-16'], ['6-30'], ['19-12'], ['26-28'], ['14-18'], ['24-30'], ['26-25'], ['22-22'], ['6-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 612\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['19-15'], ['7-4'], ['24-29'], ['11-2'], ['21-30'], ['17-22'], ['12-26'], ['31-16'], ['6-30'], ['26-28'], ['19-12'], ['14-18'], ['24-30'], ['26-25'], ['22-22'], ['6-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_1250_depth_7500_results.json\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['19-15'], ['7-4'], ['24-29'], ['21-30'], ['11-2'], ['17-22'], ['12-26'], ['31-16'], ['6-30'], ['26-28'], ['19-12'], ['14-18'], ['24-30'], ['26-25'], ['22-22'], ['6-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['8-26'], ['16-19'], ['19-15'], ['24-29'], ['11-2'], ['21-30'], ['7-4'], ['17-22'], ['12-26'], ['31-16'], ['6-30'], ['26-28'], ['19-12'], ['14-18'], ['26-25'], ['22-22'], ['24-30'], ['6-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 74.53417778015137\n",
      "Response: The current ATP top-ranked men's singles tennis player is Roger Federer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 334\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['19-15'], ['11-2'], ['24-29'], ['17-22'], ['21-30'], ['7-4'], ['12-26'], ['31-16'], ['6-30'], ['26-28'], ['19-12'], ['14-18'], ['22-22'], ['26-25'], ['24-30'], ['6-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1081\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['19-15'], ['24-29'], ['11-2'], ['21-30'], ['17-22'], ['7-4'], ['12-26'], ['31-16'], ['6-30'], ['26-28'], ['19-12'], ['14-18'], ['22-22'], ['26-25'], ['24-30'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 60.69037318229675\n",
      "Response: Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1319\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['19-15'], ['24-29'], ['11-2'], ['17-22'], ['21-30'], ['7-4'], ['12-26'], ['31-16'], ['6-30'], ['26-28'], ['14-18'], ['19-12'], ['22-22'], ['24-30'], ['7-12'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_2500_depth_7500_results.json\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['19-15'], ['24-29'], ['21-30'], ['11-2'], ['17-22'], ['7-4'], ['12-26'], ['31-16'], ['6-30'], ['26-28'], ['19-12'], ['14-18'], ['22-22'], ['24-30'], ['26-25'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['19-15'], ['24-29'], ['11-2'], ['17-22'], ['21-30'], ['7-4'], ['12-26'], ['31-16'], ['26-28'], ['6-30'], ['14-18'], ['19-12'], ['22-22'], ['7-12'], ['24-30'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 74.3202805519104\n",
      "Response: The current ATP top-ranked men's singles tennis player is Novak Djokovic.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 612\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['11-2'], ['17-22'], ['24-29'], ['21-30'], ['7-4'], ['12-26'], ['31-16'], ['26-28'], ['6-30'], ['14-18'], ['22-22'], ['19-12'], ['7-12'], ['24-30'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1319\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['24-29'], ['11-2'], ['17-22'], ['21-30'], ['7-4'], ['12-26'], ['31-16'], ['26-28'], ['6-30'], ['14-18'], ['22-22'], ['19-12'], ['7-12'], ['24-30'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 60.69037318229675\n",
      "Response: Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2533\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['24-29'], ['11-2'], ['17-22'], ['21-30'], ['7-4'], ['12-26'], ['31-16'], ['26-28'], ['6-30'], ['22-22'], ['14-18'], ['7-12'], ['19-12'], ['24-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 60.69037318229675\n",
      "Response: Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_3750_depth_7500_results.json\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['24-29'], ['17-22'], ['11-2'], ['21-30'], ['7-4'], ['12-26'], ['31-16'], ['26-28'], ['6-30'], ['22-22'], ['14-18'], ['19-12'], ['7-12'], ['17-0'], ['24-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['24-29'], ['17-22'], ['11-2'], ['21-30'], ['7-4'], ['12-26'], ['31-16'], ['26-28'], ['6-30'], ['14-18'], ['22-22'], ['7-12'], ['19-12'], ['17-0'], ['24-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 74.3202805519104\n",
      "Response: The current ATP top-ranked men's singles tennis player is Novak Djokovic.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1081\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['19-15'], ['11-2'], ['24-29'], ['17-22'], ['21-30'], ['7-4'], ['12-26'], ['26-28'], ['31-16'], ['6-30'], ['7-12'], ['14-18'], ['22-22'], ['19-12'], ['17-0'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2257\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['19-15'], ['24-29'], ['17-22'], ['11-2'], ['21-30'], ['7-4'], ['12-26'], ['26-28'], ['31-16'], ['6-30'], ['7-12'], ['14-18'], ['22-22'], ['19-12'], ['17-0'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 60.69037318229675\n",
      "Response: Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3508\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['19-15'], ['24-29'], ['17-22'], ['11-2'], ['21-30'], ['7-4'], ['12-26'], ['26-28'], ['31-16'], ['6-30'], ['7-12'], ['14-18'], ['22-22'], ['19-12'], ['17-0'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 60.69037318229675\n",
      "Response: Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_5000_depth_7500_results.json\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['19-15'], ['24-29'], ['17-22'], ['11-2'], ['21-30'], ['7-4'], ['12-26'], ['26-28'], ['31-16'], ['6-30'], ['7-12'], ['22-22'], ['14-18'], ['19-12'], ['17-0'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant/llama-2-7b-80k_id_427_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/427.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['16-19'], ['21-30'], ['24-29'], ['11-2'], ['19-15'], ['17-22'], ['6-30'], ['19-12'], ['31-16'], ['14-18'], ['24-30'], ['26-25'], ['26-28'], ['6-20'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant_misleading/llama-2-7b-80k_id_427_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['16-19'], ['21-30'], ['24-29'], ['11-2'], ['19-15'], ['17-22'], ['6-30'], ['19-12'], ['31-16'], ['14-18'], ['24-30'], ['26-25'], ['26-28'], ['6-20'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant_misleading/llama-2-7b-80k_id_427_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['16-19'], ['21-30'], ['24-29'], ['11-2'], ['19-15'], ['17-22'], ['6-30'], ['19-12'], ['31-16'], ['14-18'], ['24-30'], ['26-25'], ['26-28'], ['6-20'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant_misleading/llama-2-7b-80k_id_427_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['16-19'], ['21-30'], ['24-29'], ['11-2'], ['19-15'], ['17-22'], ['6-30'], ['19-12'], ['31-16'], ['14-18'], ['24-30'], ['26-25'], ['26-28'], ['6-20'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant_misleading/llama-2-7b-80k_id_427_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['7-4'], ['12-26'], ['16-19'], ['21-30'], ['24-29'], ['11-2'], ['19-15'], ['17-22'], ['6-30'], ['19-12'], ['31-16'], ['14-18'], ['24-30'], ['26-25'], ['26-28'], ['6-20'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_427_irrelevant_misleading/llama-2-7b-80k_id_427_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current ATP top-ranked men's singles tennis player is Jannik Sinner.\n",
      "[['6-9'], ['11-15'], ['8-26'], ['16-19'], ['7-4'], ['12-26'], ['24-29'], ['21-30'], ['19-15'], ['11-2'], ['17-22'], ['19-12'], ['31-16'], ['6-30'], ['26-28'], ['24-30'], ['14-18'], ['26-25'], ['22-22'], ['18-30']]\n",
=======
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['8-26'], ['12-26'], ['29-19'], ['31-16'], ['29-26'], ['0-9'], ['0-11'], ['11-2'], ['12-2'], ['17-0']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 67.01275706291199\n",
      "Response: The winner of the most recent season of America's Got Talent was Darci Lynne Farmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 185\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['24-29'], ['7-4'], ['8-26'], ['18-30'], ['29-19'], ['31-16'], ['6-30'], ['12-26'], ['11-2'], ['20-27'], ['17-0'], ['24-3'], ['26-3'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 498\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-29'], ['7-4'], ['8-26'], ['18-30'], ['7-12'], ['29-19'], ['31-16'], ['11-2'], ['6-30'], ['12-26'], ['20-27'], ['24-3'], ['26-3'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 738\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['24-29'], ['8-26'], ['7-4'], ['7-12'], ['18-30'], ['11-2'], ['29-19'], ['31-16'], ['20-27'], ['12-26'], ['17-0'], ['24-3'], ['26-3'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_1250_depth_7500_results.json\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['18-30'], ['11-2'], ['7-12'], ['29-19'], ['31-16'], ['12-26'], ['6-30'], ['17-0'], ['20-27'], ['24-3'], ['26-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['18-30'], ['7-12'], ['11-2'], ['29-19'], ['31-16'], ['12-26'], ['6-30'], ['17-0'], ['20-27'], ['24-3'], ['26-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 63.54779005050659\n",
      "Response: The winner of the most recent season of America's Got Talent was Tyler Butler-Figueroa, a 10-year-old violinist from New York City.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 559\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['18-30'], ['7-12'], ['11-2'], ['29-19'], ['31-16'], ['12-26'], ['20-27'], ['6-30'], ['17-0'], ['24-3'], ['26-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 60.50991415977478\n",
      "Response: Richard Goodall\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1125\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['18-30'], ['7-12'], ['11-2'], ['31-16'], ['29-19'], ['12-26'], ['20-27'], ['17-0'], ['24-3'], ['6-30'], ['26-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 60.50991415977478\n",
      "Response: Richard Goodall\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1685\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['18-30'], ['7-12'], ['11-2'], ['31-16'], ['29-19'], ['12-26'], ['20-27'], ['17-0'], ['24-3'], ['28-14'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_2500_depth_7500_results.json\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['18-30'], ['11-2'], ['7-12'], ['29-19'], ['31-16'], ['12-26'], ['28-14'], ['6-30'], ['20-27'], ['17-0'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['18-30'], ['11-2'], ['7-12'], ['29-19'], ['31-16'], ['12-26'], ['28-14'], ['6-30'], ['20-27'], ['24-3'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 60.50991415977478\n",
      "Response: Richard Goodall\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 810\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['18-30'], ['11-2'], ['7-12'], ['12-26'], ['29-19'], ['31-16'], ['28-14'], ['20-27'], ['24-3'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 60.50991415977478\n",
      "Response: Richard Goodall\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1746\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['18-30'], ['7-12'], ['11-2'], ['12-26'], ['28-14'], ['29-19'], ['31-16'], ['20-27'], ['24-3'], ['26-3'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2598\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['17-22'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['7-12'], ['18-30'], ['11-2'], ['12-26'], ['28-14'], ['24-3'], ['20-27'], ['26-3'], ['29-19'], ['31-16'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_3750_depth_7500_results.json\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['17-22'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['18-30'], ['7-12'], ['11-2'], ['12-26'], ['28-14'], ['29-19'], ['20-27'], ['24-3'], ['26-3'], ['31-16'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['17-22'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['18-30'], ['7-12'], ['11-2'], ['12-26'], ['28-14'], ['29-19'], ['20-27'], ['24-3'], ['26-3'], ['31-16'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 58.7016761302948\n",
      "Response: Richard Goodall.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1125\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['17-22'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['18-30'], ['7-12'], ['11-2'], ['12-26'], ['28-14'], ['24-3'], ['29-19'], ['20-27'], ['22-22'], ['26-3'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 58.7016761302948\n",
      "Response: Richard Goodall.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2315\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['17-22'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['18-30'], ['7-12'], ['11-2'], ['12-26'], ['28-14'], ['24-3'], ['20-27'], ['22-22'], ['29-19'], ['26-3'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 58.7016761302948\n",
      "Response: Richard Goodall.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3579\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['17-22'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['18-30'], ['7-12'], ['11-2'], ['28-14'], ['12-26'], ['24-3'], ['20-27'], ['22-22'], ['29-19'], ['26-3'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 84.86613035202026\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent. The winning act that achieves the most votes is crowned the winner and receives a cash prize. Although stipulated as $1 million per the program's\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_5000_depth_7500_results.json\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['17-22'], ['21-30'], ['8-26'], ['24-29'], ['7-4'], ['18-30'], ['11-2'], ['12-26'], ['28-14'], ['7-12'], ['20-27'], ['24-3'], ['29-19'], ['22-22'], ['26-3'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_relevant_misleading/llama-2-7b-80k_id_590_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['8-26'], ['12-26'], ['29-19'], ['31-16'], ['0-9'], ['0-11'], ['11-2'], ['12-2'], ['17-0'], ['20-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['8-26'], ['12-26'], ['29-19'], ['31-16'], ['0-9'], ['0-11'], ['11-2'], ['12-2'], ['17-0'], ['20-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['8-26'], ['12-26'], ['29-19'], ['31-16'], ['0-9'], ['0-11'], ['11-2'], ['12-2'], ['17-0'], ['20-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['8-26'], ['12-26'], ['29-19'], ['31-16'], ['0-9'], ['0-11'], ['11-2'], ['12-2'], ['17-0'], ['20-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_0_depth_7500_results.json\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['8-26'], ['12-26'], ['29-19'], ['31-16'], ['0-9'], ['0-11'], ['11-2'], ['12-2'], ['17-0'], ['20-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['8-26'], ['12-26'], ['29-19'], ['31-16'], ['29-26'], ['0-9'], ['0-11'], ['11-2'], ['12-2'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 66.77371263504028\n",
      "Response: The winner of the most recent season of America's Got Talent is Darci Lynne Farmer. She is a ventriloquist from Oklahoma who won the show's twelfth season in 2017.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 209\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['8-26'], ['6-30'], ['31-16'], ['12-26'], ['29-19'], ['7-12'], ['11-2'], ['20-27'], ['26-3'], ['29-26'], ['21-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 510\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['7-4'], ['24-29'], ['8-26'], ['18-30'], ['6-30'], ['7-12'], ['31-16'], ['29-19'], ['11-2'], ['12-26'], ['20-27'], ['24-3'], ['26-3'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 645\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['7-4'], ['8-26'], ['24-29'], ['18-30'], ['7-12'], ['6-30'], ['31-16'], ['11-2'], ['29-19'], ['20-27'], ['12-26'], ['26-3'], ['24-3'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 86.86032295227051\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent. The winners of the twenty-six seasons have been: Javier Colon, Jermaine Paul, Cassadee Pope, Danielle Bradbery, T\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_1250_depth_7500_results.json\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['18-30'], ['7-12'], ['6-30'], ['31-16'], ['29-19'], ['11-2'], ['20-27'], ['12-26'], ['26-3'], ['28-14'], ['21-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['18-30'], ['7-12'], ['6-30'], ['31-16'], ['29-19'], ['11-2'], ['20-27'], ['12-26'], ['26-3'], ['28-14'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 67.01275706291199\n",
      "Response: The winner of the most recent season of America's Got Talent was Darci Lynne Farmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 568\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['7-12'], ['18-30'], ['6-30'], ['29-19'], ['11-2'], ['31-16'], ['20-27'], ['26-3'], ['12-26'], ['28-14'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1097\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['7-4'], ['7-12'], ['24-29'], ['18-30'], ['6-30'], ['29-19'], ['11-2'], ['31-16'], ['20-27'], ['26-3'], ['14-18'], ['29-26'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1680\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['7-4'], ['7-12'], ['24-29'], ['18-30'], ['6-30'], ['29-19'], ['11-2'], ['31-16'], ['20-27'], ['26-3'], ['14-18'], ['24-3'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_2500_depth_7500_results.json\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['7-4'], ['7-12'], ['24-29'], ['18-30'], ['29-19'], ['6-30'], ['11-2'], ['31-16'], ['20-27'], ['26-3'], ['14-18'], ['28-14'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['7-4'], ['7-12'], ['24-29'], ['18-30'], ['29-19'], ['6-30'], ['11-2'], ['31-16'], ['20-27'], ['26-3'], ['14-18'], ['28-14'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 67.01275706291199\n",
      "Response: The winner of the most recent season of America's Got Talent was Darci Lynne Farmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 853\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['21-30'], ['7-4'], ['7-12'], ['24-29'], ['18-30'], ['29-19'], ['6-30'], ['11-2'], ['31-16'], ['20-27'], ['26-3'], ['14-18'], ['24-3'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1680\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['21-30'], ['7-12'], ['7-4'], ['24-29'], ['18-30'], ['29-19'], ['6-30'], ['11-2'], ['31-16'], ['20-27'], ['26-3'], ['14-18'], ['24-3'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2643\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['21-30'], ['7-12'], ['7-4'], ['24-29'], ['18-30'], ['29-19'], ['6-30'], ['11-2'], ['31-16'], ['14-18'], ['20-27'], ['26-3'], ['24-3'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_3750_depth_7500_results.json\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['21-30'], ['7-12'], ['7-4'], ['24-29'], ['18-30'], ['29-19'], ['6-30'], ['11-2'], ['31-16'], ['14-18'], ['20-27'], ['26-3'], ['28-14'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['21-30'], ['7-12'], ['7-4'], ['24-29'], ['18-30'], ['29-19'], ['6-30'], ['11-2'], ['31-16'], ['14-18'], ['20-27'], ['26-3'], ['28-14'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 67.01275706291199\n",
      "Response: The winner of the most recent season of America's Got Talent was Darci Lynne Farmer.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1190\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['21-30'], ['7-12'], ['7-4'], ['24-29'], ['18-30'], ['29-19'], ['6-30'], ['11-2'], ['14-18'], ['31-16'], ['20-27'], ['26-3'], ['28-14'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2320\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['21-30'], ['7-12'], ['7-4'], ['24-29'], ['18-30'], ['29-19'], ['11-2'], ['6-30'], ['14-18'], ['20-27'], ['26-3'], ['31-16'], ['24-3'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3545\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['7-12'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['29-19'], ['11-2'], ['6-30'], ['14-18'], ['20-27'], ['26-3'], ['31-16'], ['24-3'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_5000_depth_7500_results.json\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['8-26'], ['19-15'], ['21-30'], ['7-12'], ['7-4'], ['24-29'], ['18-30'], ['29-19'], ['11-2'], ['6-30'], ['14-18'], ['20-27'], ['26-3'], ['31-16'], ['28-14'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant/llama-2-7b-80k_id_590_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/590.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['8-26'], ['12-26'], ['29-19'], ['31-16'], ['0-9'], ['0-11'], ['11-2'], ['12-2'], ['17-0'], ['20-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['8-26'], ['12-26'], ['29-19'], ['31-16'], ['0-9'], ['0-11'], ['11-2'], ['12-2'], ['17-0'], ['20-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['8-26'], ['12-26'], ['29-19'], ['31-16'], ['0-9'], ['0-11'], ['11-2'], ['12-2'], ['17-0'], ['20-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['8-26'], ['12-26'], ['29-19'], ['31-16'], ['0-9'], ['0-11'], ['11-2'], ['12-2'], ['17-0'], ['20-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['8-26'], ['12-26'], ['29-19'], ['31-16'], ['0-9'], ['0-11'], ['11-2'], ['12-2'], ['17-0'], ['20-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['6-30'], ['8-26'], ['12-26'], ['29-19'], ['31-16'], ['29-26'], ['0-9'], ['0-11'], ['11-2'], ['12-2'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 66.77371263504028\n",
      "Response: The winner of the most recent season of America's Got Talent is Darci Lynne Farmer. She is a ventriloquist from Oklahoma who won the show's twelfth season in 2017.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 209\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['18-30'], ['8-26'], ['6-30'], ['31-16'], ['12-26'], ['29-19'], ['7-12'], ['11-2'], ['20-27'], ['26-3'], ['29-26'], ['21-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 510\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['6-9'], ['19-15'], ['21-30'], ['7-4'], ['24-29'], ['8-26'], ['18-30'], ['6-30'], ['7-12'], ['31-16'], ['29-19'], ['11-2'], ['12-26'], ['20-27'], ['24-3'], ['26-3'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 645\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['7-4'], ['8-26'], ['24-29'], ['18-30'], ['7-12'], ['6-30'], ['31-16'], ['11-2'], ['29-19'], ['20-27'], ['12-26'], ['26-3'], ['24-3'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 86.86032295227051\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent. The winners of the twenty-six seasons have been: Javier Colon, Jermaine Paul, Cassadee Pope, Danielle Bradbery, T\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['18-30'], ['7-12'], ['6-30'], ['31-16'], ['29-19'], ['11-2'], ['20-27'], ['12-26'], ['26-3'], ['28-14'], ['21-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['18-30'], ['7-12'], ['6-30'], ['31-16'], ['29-19'], ['11-2'], ['12-26'], ['20-27'], ['28-14'], ['26-3'], ['21-5']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 60.50991415977478\n",
      "Response: Richard Goodall\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 568\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['7-12'], ['18-30'], ['6-30'], ['11-2'], ['31-16'], ['29-19'], ['20-27'], ['12-26'], ['28-14'], ['26-3'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1097\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['7-12'], ['24-29'], ['18-30'], ['11-2'], ['6-30'], ['20-27'], ['29-19'], ['31-16'], ['28-14'], ['12-26'], ['29-26'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1706\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['7-12'], ['7-4'], ['24-29'], ['18-30'], ['11-2'], ['28-14'], ['31-16'], ['6-30'], ['20-27'], ['29-19'], ['12-26'], ['29-26'], ['26-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['7-12'], ['24-29'], ['18-30'], ['11-2'], ['6-30'], ['28-14'], ['29-19'], ['31-16'], ['20-27'], ['12-26'], ['29-26'], ['26-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['7-12'], ['24-29'], ['18-30'], ['11-2'], ['28-14'], ['6-30'], ['29-19'], ['31-16'], ['20-27'], ['12-26'], ['29-26'], ['26-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 60.50991415977478\n",
      "Response: Richard Goodall\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 853\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['7-12'], ['18-30'], ['11-2'], ['28-14'], ['6-30'], ['20-27'], ['29-19'], ['31-16'], ['12-26'], ['29-26'], ['26-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 60.50991415977478\n",
      "Response: Richard Goodall\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1706\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['7-12'], ['18-30'], ['28-14'], ['11-2'], ['20-27'], ['6-30'], ['12-26'], ['29-19'], ['31-16'], ['29-26'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 60.50991415977478\n",
      "Response: Richard Goodall\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2610\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['7-12'], ['7-4'], ['24-29'], ['18-30'], ['11-2'], ['28-14'], ['20-27'], ['6-30'], ['12-26'], ['29-19'], ['31-16'], ['29-26'], ['26-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['7-12'], ['18-30'], ['11-2'], ['28-14'], ['12-26'], ['20-27'], ['29-19'], ['6-30'], ['31-16'], ['29-26'], ['26-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['7-12'], ['18-30'], ['28-14'], ['11-2'], ['12-26'], ['20-27'], ['29-19'], ['6-30'], ['31-16'], ['29-26'], ['26-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 60.50991415977478\n",
      "Response: Richard Goodall\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1190\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['7-12'], ['7-4'], ['24-29'], ['18-30'], ['11-2'], ['28-14'], ['12-26'], ['20-27'], ['29-19'], ['6-30'], ['31-16'], ['29-26'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2369\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['21-30'], ['19-15'], ['8-26'], ['7-12'], ['24-29'], ['7-4'], ['18-30'], ['11-2'], ['28-14'], ['12-26'], ['20-27'], ['29-19'], ['29-26'], ['6-30'], ['24-3'], ['26-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3539\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['7-12'], ['24-29'], ['7-4'], ['11-2'], ['18-30'], ['28-14'], ['12-26'], ['20-27'], ['29-19'], ['24-3'], ['26-3'], ['29-26'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "Richard Goodall won the most recent season of America's Got Talent.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['7-12'], ['24-29'], ['7-4'], ['11-2'], ['18-30'], ['28-14'], ['12-26'], ['20-27'], ['29-19'], ['24-3'], ['26-3'], ['29-26'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: Richard Goodall won the most recent season of America's Got Talent.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_590_irrelevant_misleading/llama-2-7b-80k_id_590_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The all-time highest value of Alphabet was in April 2024.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['6-9'], ['11-15'], ['16-19'], ['8-26'], ['14-18'], ['15-14'], ['15-29'], ['17-22'], ['18-30'], ['19-15'], ['0-9'], ['7-4'], ['12-4'], ['14-15'], ['15-5'], ['16-24'], ['17-0'], ['17-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['6-9'], ['11-15'], ['16-19'], ['8-26'], ['14-18'], ['15-14'], ['15-29'], ['17-22'], ['18-30'], ['19-15'], ['0-9'], ['7-4'], ['12-4'], ['14-15'], ['15-5'], ['16-24'], ['17-0'], ['17-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['6-9'], ['11-15'], ['16-19'], ['8-26'], ['14-18'], ['15-14'], ['15-29'], ['17-22'], ['18-30'], ['19-15'], ['0-9'], ['7-4'], ['12-4'], ['14-15'], ['15-5'], ['16-24'], ['17-0'], ['17-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['6-9'], ['11-15'], ['16-19'], ['8-26'], ['14-18'], ['15-14'], ['15-29'], ['17-22'], ['18-30'], ['19-15'], ['0-9'], ['7-4'], ['12-4'], ['14-15'], ['15-5'], ['16-24'], ['17-0'], ['17-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_0_depth_7500_results.json\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['6-9'], ['11-15'], ['16-19'], ['8-26'], ['14-18'], ['15-14'], ['15-29'], ['17-22'], ['18-30'], ['19-15'], ['0-9'], ['7-4'], ['12-4'], ['14-15'], ['15-5'], ['16-24'], ['17-0'], ['17-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['11-15'], ['6-9'], ['16-19'], ['18-30'], ['8-26'], ['14-18'], ['15-14'], ['15-29'], ['17-22'], ['19-15'], ['31-15'], ['14-15'], ['31-24'], ['7-4'], ['19-10'], ['21-26'], ['21-30'], ['22-22'], ['23-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 70.53124904632568\n",
      "Response: In April 2022, Alphabet's market capitalization reached its highest-ever recorded value of $2.2 trillion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_1250_depth_0_results.json\n",
      "insertion at 78\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['11-15'], ['6-9'], ['16-19'], ['18-30'], ['8-26'], ['14-18'], ['15-14'], ['17-22'], ['19-15'], ['15-29'], ['31-15'], ['21-30'], ['31-24'], ['14-15'], ['19-10'], ['21-26'], ['22-22'], ['23-8'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 78\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['11-15'], ['6-9'], ['16-19'], ['18-30'], ['8-26'], ['14-18'], ['15-14'], ['17-22'], ['19-15'], ['31-15'], ['15-29'], ['21-30'], ['31-24'], ['19-10'], ['21-26'], ['22-22'], ['23-8'], ['24-3'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 78\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['11-15'], ['12-26'], ['6-9'], ['16-19'], ['18-30'], ['31-15'], ['8-26'], ['14-18'], ['15-14'], ['17-22'], ['19-15'], ['21-30'], ['15-29'], ['31-24'], ['19-10'], ['21-26'], ['22-22'], ['23-8'], ['24-3'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_1250_depth_7500_results.json\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['11-15'], ['12-26'], ['16-19'], ['6-9'], ['18-30'], ['15-14'], ['8-26'], ['14-18'], ['17-22'], ['19-15'], ['21-30'], ['31-15'], ['15-29'], ['17-0'], ['19-10'], ['21-26'], ['22-22'], ['24-3'], ['23-8'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['12-26'], ['18-30'], ['15-14'], ['14-18'], ['8-26'], ['17-22'], ['19-15'], ['21-30'], ['31-15'], ['15-29'], ['17-0'], ['19-10'], ['21-26'], ['22-22'], ['24-3'], ['23-8'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_2500_depth_0_results.json\n",
      "insertion at 78\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['12-26'], ['18-30'], ['15-14'], ['14-18'], ['8-26'], ['17-22'], ['19-15'], ['21-30'], ['31-15'], ['15-29'], ['19-10'], ['21-26'], ['22-22'], ['24-3'], ['17-0'], ['23-8'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 917\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['18-30'], ['12-26'], ['15-14'], ['14-18'], ['8-26'], ['17-22'], ['21-30'], ['19-15'], ['31-15'], ['22-22'], ['19-10'], ['21-26'], ['24-3'], ['15-29'], ['17-0'], ['23-8'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1700\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 44.111934304237366\n",
      "Response: In April 2024.1\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_2500_depth_7500_results.json\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['12-26'], ['18-30'], ['15-14'], ['14-18'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['31-15'], ['22-22'], ['21-26'], ['24-3'], ['17-0'], ['19-10'], ['15-29'], ['23-8'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['18-30'], ['14-18'], ['12-26'], ['15-14'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['31-15'], ['22-22'], ['21-26'], ['24-3'], ['17-0'], ['19-10'], ['23-8'], ['15-29'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_3750_depth_0_results.json\n",
      "insertion at 866\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['18-30'], ['14-18'], ['15-14'], ['12-26'], ['17-22'], ['21-30'], ['19-15'], ['8-26'], ['31-15'], ['22-22'], ['21-26'], ['24-3'], ['17-0'], ['19-10'], ['23-8'], ['15-29'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1700\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 44.111934304237366\n",
      "Response: In April 2024.1\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2100\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['18-30'], ['14-18'], ['15-14'], ['21-30'], ['17-22'], ['12-26'], ['19-15'], ['8-26'], ['22-22'], ['31-15'], ['21-26'], ['24-3'], ['17-0'], ['19-10'], ['23-8'], ['14-15'], ['15-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_3750_depth_7500_results.json\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['18-30'], ['15-14'], ['12-26'], ['14-18'], ['21-30'], ['17-22'], ['19-15'], ['8-26'], ['22-22'], ['31-15'], ['17-0'], ['21-26'], ['24-3'], ['19-10'], ['23-8'], ['14-15'], ['15-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['11-15'], ['16-19'], ['18-30'], ['6-9'], ['14-18'], ['15-14'], ['17-22'], ['21-30'], ['12-26'], ['19-15'], ['8-26'], ['31-15'], ['22-22'], ['17-0'], ['21-26'], ['24-3'], ['19-10'], ['23-8'], ['14-15'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_5000_depth_0_results.json\n",
      "insertion at 917\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['18-30'], ['14-18'], ['15-14'], ['8-26'], ['17-22'], ['21-30'], ['12-26'], ['19-15'], ['22-22'], ['31-15'], ['17-0'], ['21-26'], ['24-3'], ['19-10'], ['23-8'], ['14-15'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 77.81689167022705\n",
      "Response: The highest-ever recorded value of Alphabet's market capitalization was in April 2024.1\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2100\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['18-30'], ['14-18'], ['21-30'], ['15-14'], ['8-26'], ['17-22'], ['19-15'], ['12-26'], ['22-22'], ['31-15'], ['17-0'], ['21-26'], ['24-3'], ['19-10'], ['23-8'], ['14-15'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 2903\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['18-30'], ['21-30'], ['14-18'], ['15-14'], ['8-26'], ['17-22'], ['19-15'], ['12-26'], ['22-22'], ['31-15'], ['17-0'], ['21-26'], ['24-3'], ['19-10'], ['23-8'], ['14-15'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_5000_depth_7500_results.json\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['18-30'], ['21-30'], ['14-18'], ['15-14'], ['17-22'], ['8-26'], ['19-15'], ['12-26'], ['22-22'], ['31-15'], ['17-0'], ['21-26'], ['24-3'], ['19-10'], ['23-8'], ['14-15'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant/llama-2-7b-80k_id_92_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/92.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The all-time highest value of Alphabet was in April 2024.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['6-9'], ['11-15'], ['16-19'], ['8-26'], ['14-18'], ['15-14'], ['15-29'], ['17-22'], ['18-30'], ['19-15'], ['0-9'], ['7-4'], ['12-4'], ['14-15'], ['15-5'], ['16-24'], ['17-0'], ['17-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['6-9'], ['11-15'], ['16-19'], ['8-26'], ['14-18'], ['15-14'], ['15-29'], ['17-22'], ['18-30'], ['19-15'], ['0-9'], ['7-4'], ['12-4'], ['14-15'], ['15-5'], ['16-24'], ['17-0'], ['17-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['6-9'], ['11-15'], ['16-19'], ['8-26'], ['14-18'], ['15-14'], ['15-29'], ['17-22'], ['18-30'], ['19-15'], ['0-9'], ['7-4'], ['12-4'], ['14-15'], ['15-5'], ['16-24'], ['17-0'], ['17-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['6-9'], ['11-15'], ['16-19'], ['8-26'], ['14-18'], ['15-14'], ['15-29'], ['17-22'], ['18-30'], ['19-15'], ['0-9'], ['7-4'], ['12-4'], ['14-15'], ['15-5'], ['16-24'], ['17-0'], ['17-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_0_depth_7500_results.json\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['6-9'], ['11-15'], ['16-19'], ['8-26'], ['14-18'], ['15-14'], ['15-29'], ['17-22'], ['18-30'], ['19-15'], ['0-9'], ['7-4'], ['12-4'], ['14-15'], ['15-5'], ['16-24'], ['17-0'], ['17-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['6-9'], ['11-15'], ['16-19'], ['15-29'], ['8-26'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-15'], ['31-15'], ['31-24'], ['21-30'], ['0-9'], ['7-4'], ['12-4'], ['14-15'], ['15-5'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 74.53297972679138\n",
      "Response: In 2024, Alphabet's market capitalization reached its highest-ever recorded value in the month of August.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 78\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['6-9'], ['11-15'], ['16-19'], ['15-29'], ['31-15'], ['8-26'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-15'], ['31-24'], ['31-19'], ['21-30'], ['22-22'], ['17-0'], ['19-10'], ['23-8'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 77.28443741798401\n",
      "Response: In 2024, Alphabet's market capitalization reached its highest-ever recorded value in April 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 78\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['6-9'], ['11-15'], ['16-19'], ['31-15'], ['15-29'], ['31-19'], ['8-26'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-15'], ['31-24'], ['21-30'], ['22-22'], ['17-0'], ['19-10'], ['23-8'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 77.28443741798401\n",
      "Response: In 2024, Alphabet's market capitalization reached its highest-ever recorded value in April 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 78\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['31-15'], ['6-9'], ['11-15'], ['16-19'], ['31-19'], ['15-29'], ['8-26'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-15'], ['31-24'], ['21-30'], ['22-22'], ['30-9'], ['17-0'], ['19-10'], ['23-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 77.28443741798401\n",
      "Response: In 2024, Alphabet's market capitalization reached its highest-ever recorded value in April 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['11-15'], ['31-15'], ['31-19'], ['6-9'], ['16-19'], ['19-15'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['8-26'], ['15-29'], ['21-30'], ['22-22'], ['31-24'], ['30-9'], ['17-0'], ['24-3'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['31-15'], ['11-15'], ['16-19'], ['31-19'], ['6-9'], ['19-15'], ['14-18'], ['17-22'], ['21-30'], ['15-14'], ['18-30'], ['8-26'], ['15-29'], ['22-22'], ['31-24'], ['30-9'], ['24-3'], ['19-10'], ['23-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 76.54898166656494\n",
      "Response: In 2024, Alphabet's market capitalization reached its highest-ever recorded value in April.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 78\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['31-15'], ['12-26'], ['16-19'], ['31-19'], ['11-15'], ['6-9'], ['21-30'], ['14-18'], ['19-15'], ['17-22'], ['22-22'], ['15-14'], ['15-29'], ['18-30'], ['8-26'], ['30-9'], ['31-24'], ['24-3'], ['19-10'], ['23-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 76.54898166656494\n",
      "Response: In 2024, Alphabet's market capitalization reached its highest-ever recorded value in April.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 946\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['31-15'], ['12-26'], ['16-19'], ['21-30'], ['31-19'], ['11-15'], ['6-9'], ['14-18'], ['19-15'], ['22-22'], ['17-22'], ['18-30'], ['15-14'], ['15-29'], ['8-26'], ['24-3'], ['30-9'], ['31-24'], ['19-10'], ['23-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 76.54898166656494\n",
      "Response: In 2024, Alphabet's market capitalization reached its highest-ever recorded value in April.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1707\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 37.99135088920593\n",
      "Response: In April 2024.1,Third quarter,Third quarter.1,Fourth quarter,Fourth quarter.1\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['31-15'], ['16-19'], ['11-15'], ['21-30'], ['31-19'], ['6-9'], ['14-18'], ['19-15'], ['22-22'], ['18-30'], ['17-22'], ['15-14'], ['8-26'], ['15-29'], ['17-0'], ['19-10'], ['24-3'], ['30-9'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['31-15'], ['12-26'], ['16-19'], ['21-30'], ['11-15'], ['31-19'], ['6-9'], ['14-18'], ['19-15'], ['22-22'], ['18-30'], ['17-22'], ['15-14'], ['8-26'], ['15-29'], ['19-10'], ['17-0'], ['24-3'], ['31-24'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 77.2019624710083\n",
      "Response: In the year 2024, Alphabet's market capitalization reached its highest-ever recorded value in the month of April.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 866\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['31-15'], ['12-26'], ['21-30'], ['16-19'], ['11-15'], ['6-9'], ['14-18'], ['22-22'], ['31-19'], ['19-15'], ['18-30'], ['17-22'], ['15-14'], ['19-10'], ['8-26'], ['15-29'], ['24-3'], ['31-24'], ['17-0'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 76.54898166656494\n",
      "Response: In 2024, Alphabet's market capitalization reached its highest-ever recorded value in April.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1763\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['21-30'], ['16-19'], ['31-15'], ['12-26'], ['11-15'], ['22-22'], ['6-9'], ['14-18'], ['31-19'], ['18-30'], ['17-22'], ['19-15'], ['15-14'], ['19-10'], ['8-26'], ['24-3'], ['15-29'], ['17-0'], ['31-24'], ['23-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2191\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 43.39788258075714\n",
      "Response: In April 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['21-30'], ['12-26'], ['16-19'], ['31-15'], ['11-15'], ['14-18'], ['6-9'], ['22-22'], ['18-30'], ['17-22'], ['19-15'], ['31-19'], ['15-14'], ['8-26'], ['19-10'], ['17-0'], ['24-3'], ['17-31'], ['15-29'], ['21-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['21-30'], ['16-19'], ['11-15'], ['31-15'], ['12-26'], ['14-18'], ['6-9'], ['22-22'], ['18-30'], ['17-22'], ['19-15'], ['31-19'], ['15-14'], ['8-26'], ['24-3'], ['19-10'], ['17-0'], ['17-31'], ['15-29'], ['30-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 946\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['21-30'], ['16-19'], ['11-15'], ['31-15'], ['12-26'], ['14-18'], ['22-22'], ['18-30'], ['6-9'], ['17-22'], ['19-15'], ['31-19'], ['15-14'], ['8-26'], ['24-3'], ['19-10'], ['17-0'], ['17-31'], ['15-29'], ['30-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2191\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['21-30'], ['16-19'], ['11-15'], ['31-15'], ['12-26'], ['22-22'], ['14-18'], ['18-30'], ['17-22'], ['6-9'], ['19-15'], ['31-19'], ['15-14'], ['24-3'], ['8-26'], ['17-0'], ['19-10'], ['17-31'], ['15-29'], ['21-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3025\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['21-30'], ['16-19'], ['11-15'], ['22-22'], ['14-18'], ['31-15'], ['12-26'], ['18-30'], ['17-22'], ['6-9'], ['19-15'], ['15-14'], ['31-19'], ['24-3'], ['8-26'], ['17-0'], ['19-10'], ['17-31'], ['21-26'], ['15-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['21-30'], ['11-15'], ['16-19'], ['14-18'], ['12-26'], ['22-22'], ['31-15'], ['18-30'], ['17-22'], ['6-9'], ['19-15'], ['15-14'], ['17-0'], ['31-19'], ['24-3'], ['8-26'], ['19-10'], ['17-31'], ['21-26'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_relevant_misleading/llama-2-7b-80k_id_92_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The all-time highest value of Alphabet was in April 2024.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['6-9'], ['11-15'], ['16-19'], ['8-26'], ['14-18'], ['15-14'], ['15-29'], ['17-22'], ['18-30'], ['19-15'], ['0-9'], ['7-4'], ['12-4'], ['14-15'], ['15-5'], ['16-24'], ['17-0'], ['17-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['6-9'], ['11-15'], ['16-19'], ['8-26'], ['14-18'], ['15-14'], ['15-29'], ['17-22'], ['18-30'], ['19-15'], ['0-9'], ['7-4'], ['12-4'], ['14-15'], ['15-5'], ['16-24'], ['17-0'], ['17-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['6-9'], ['11-15'], ['16-19'], ['8-26'], ['14-18'], ['15-14'], ['15-29'], ['17-22'], ['18-30'], ['19-15'], ['0-9'], ['7-4'], ['12-4'], ['14-15'], ['15-5'], ['16-24'], ['17-0'], ['17-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['6-9'], ['11-15'], ['16-19'], ['8-26'], ['14-18'], ['15-14'], ['15-29'], ['17-22'], ['18-30'], ['19-15'], ['0-9'], ['7-4'], ['12-4'], ['14-15'], ['15-5'], ['16-24'], ['17-0'], ['17-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_0_depth_7500_results.json\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['6-9'], ['11-15'], ['16-19'], ['8-26'], ['14-18'], ['15-14'], ['15-29'], ['17-22'], ['18-30'], ['19-15'], ['0-9'], ['7-4'], ['12-4'], ['14-15'], ['15-5'], ['16-24'], ['17-0'], ['17-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['16-19'], ['6-9'], ['11-15'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-15'], ['8-26'], ['15-29'], ['17-31'], ['31-15'], ['31-24'], ['21-26'], ['21-30'], ['22-22'], ['0-9'], ['7-4'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 76.54898166656494\n",
      "Response: In 2024, Alphabet's market capitalization reached its highest-ever recorded value in April.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 230\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['16-19'], ['6-9'], ['11-15'], ['14-18'], ['17-22'], ['15-14'], ['18-30'], ['19-15'], ['8-26'], ['15-29'], ['17-31'], ['21-30'], ['21-26'], ['22-22'], ['31-15'], ['31-24'], ['7-4'], ['14-15'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 491\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['16-19'], ['6-9'], ['14-18'], ['11-15'], ['17-22'], ['19-15'], ['15-14'], ['18-30'], ['8-26'], ['15-29'], ['21-30'], ['17-31'], ['22-22'], ['21-26'], ['7-4'], ['14-15'], ['17-0'], ['19-10'], ['23-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 742\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['12-26'], ['14-18'], ['6-9'], ['11-15'], ['17-22'], ['19-15'], ['15-14'], ['18-30'], ['21-30'], ['22-22'], ['8-26'], ['15-29'], ['17-31'], ['21-26'], ['7-4'], ['14-15'], ['17-0'], ['19-10'], ['23-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_1250_depth_7500_results.json\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['12-26'], ['11-15'], ['14-18'], ['6-9'], ['17-22'], ['15-14'], ['19-15'], ['18-30'], ['21-30'], ['22-22'], ['8-26'], ['14-15'], ['17-0'], ['17-31'], ['21-26'], ['15-29'], ['7-4'], ['19-10'], ['23-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['14-18'], ['11-15'], ['12-26'], ['17-22'], ['6-9'], ['15-14'], ['18-30'], ['19-15'], ['21-30'], ['22-22'], ['15-29'], ['17-0'], ['17-31'], ['21-26'], ['8-26'], ['14-15'], ['19-10'], ['23-8'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 562\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['14-18'], ['11-15'], ['17-22'], ['6-9'], ['12-26'], ['15-14'], ['18-30'], ['19-15'], ['21-30'], ['22-22'], ['17-0'], ['17-31'], ['21-26'], ['14-15'], ['15-29'], ['8-26'], ['19-10'], ['23-8'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1116\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['14-18'], ['11-15'], ['17-22'], ['6-9'], ['15-14'], ['12-26'], ['18-30'], ['19-15'], ['21-30'], ['22-22'], ['17-0'], ['17-31'], ['21-26'], ['14-15'], ['15-29'], ['8-26'], ['19-10'], ['23-8'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1696\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['14-18'], ['11-15'], ['17-22'], ['6-9'], ['15-14'], ['18-30'], ['12-26'], ['19-15'], ['21-30'], ['22-22'], ['17-0'], ['17-31'], ['21-26'], ['14-15'], ['15-29'], ['19-10'], ['23-8'], ['8-26'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_2500_depth_7500_results.json\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['14-18'], ['11-15'], ['17-22'], ['15-14'], ['18-30'], ['6-9'], ['12-26'], ['19-15'], ['21-30'], ['17-0'], ['22-22'], ['14-15'], ['17-31'], ['21-26'], ['8-26'], ['15-29'], ['19-10'], ['23-8'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['14-18'], ['11-15'], ['17-22'], ['18-30'], ['15-14'], ['6-9'], ['12-26'], ['19-15'], ['21-30'], ['17-0'], ['22-22'], ['17-31'], ['14-15'], ['21-26'], ['15-29'], ['19-10'], ['23-8'], ['24-3'], ['8-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 871\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['14-18'], ['11-15'], ['17-22'], ['18-30'], ['15-14'], ['6-9'], ['12-26'], ['19-15'], ['21-30'], ['17-0'], ['22-22'], ['17-31'], ['14-15'], ['21-26'], ['19-10'], ['15-29'], ['23-8'], ['24-3'], ['8-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1744\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['14-18'], ['11-15'], ['17-22'], ['18-30'], ['15-14'], ['6-9'], ['19-15'], ['21-30'], ['12-26'], ['17-0'], ['22-22'], ['17-31'], ['21-26'], ['14-15'], ['19-10'], ['23-8'], ['24-3'], ['15-29'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2643\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['14-18'], ['11-15'], ['17-22'], ['18-30'], ['15-14'], ['6-9'], ['19-15'], ['21-30'], ['12-26'], ['17-0'], ['22-22'], ['17-31'], ['21-26'], ['14-15'], ['19-10'], ['23-8'], ['24-3'], ['15-29'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_3750_depth_7500_results.json\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['14-18'], ['11-15'], ['17-22'], ['15-14'], ['18-30'], ['6-9'], ['19-15'], ['21-30'], ['12-26'], ['17-0'], ['22-22'], ['17-31'], ['14-15'], ['21-26'], ['19-10'], ['23-8'], ['15-29'], ['24-3'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['14-18'], ['17-22'], ['11-15'], ['18-30'], ['15-14'], ['21-30'], ['19-15'], ['6-9'], ['12-26'], ['17-0'], ['17-31'], ['22-22'], ['21-26'], ['14-15'], ['19-10'], ['23-8'], ['24-3'], ['15-29'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1170\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['14-18'], ['17-22'], ['11-15'], ['18-30'], ['15-14'], ['21-30'], ['19-15'], ['6-9'], ['12-26'], ['17-0'], ['22-22'], ['17-31'], ['21-26'], ['14-15'], ['19-10'], ['23-8'], ['24-3'], ['26-26'], ['15-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2369\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['14-18'], ['17-22'], ['11-15'], ['18-30'], ['15-14'], ['21-30'], ['19-15'], ['6-9'], ['12-26'], ['22-22'], ['17-0'], ['17-31'], ['21-26'], ['14-15'], ['19-10'], ['23-8'], ['24-3'], ['26-26'], ['15-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3519\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['14-18'], ['17-22'], ['11-15'], ['18-30'], ['15-14'], ['21-30'], ['19-15'], ['6-9'], ['22-22'], ['12-26'], ['17-0'], ['17-31'], ['21-26'], ['14-15'], ['19-10'], ['23-8'], ['24-3'], ['26-26'], ['15-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_5000_depth_7500_results.json\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['14-18'], ['17-22'], ['11-15'], ['15-14'], ['18-30'], ['21-30'], ['19-15'], ['6-9'], ['12-26'], ['22-22'], ['17-0'], ['17-31'], ['21-26'], ['14-15'], ['19-10'], ['23-8'], ['24-3'], ['26-26'], ['15-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant/llama-2-7b-80k_id_92_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/92.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The all-time highest value of Alphabet was in April 2024.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['6-9'], ['11-15'], ['16-19'], ['8-26'], ['14-18'], ['15-14'], ['15-29'], ['17-22'], ['18-30'], ['19-15'], ['0-9'], ['7-4'], ['12-4'], ['14-15'], ['15-5'], ['16-24'], ['17-0'], ['17-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['6-9'], ['11-15'], ['16-19'], ['8-26'], ['14-18'], ['15-14'], ['15-29'], ['17-22'], ['18-30'], ['19-15'], ['0-9'], ['7-4'], ['12-4'], ['14-15'], ['15-5'], ['16-24'], ['17-0'], ['17-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['6-9'], ['11-15'], ['16-19'], ['8-26'], ['14-18'], ['15-14'], ['15-29'], ['17-22'], ['18-30'], ['19-15'], ['0-9'], ['7-4'], ['12-4'], ['14-15'], ['15-5'], ['16-24'], ['17-0'], ['17-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['6-9'], ['11-15'], ['16-19'], ['8-26'], ['14-18'], ['15-14'], ['15-29'], ['17-22'], ['18-30'], ['19-15'], ['0-9'], ['7-4'], ['12-4'], ['14-15'], ['15-5'], ['16-24'], ['17-0'], ['17-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['6-9'], ['11-15'], ['16-19'], ['8-26'], ['14-18'], ['15-14'], ['15-29'], ['17-22'], ['18-30'], ['19-15'], ['0-9'], ['7-4'], ['12-4'], ['14-15'], ['15-5'], ['16-24'], ['17-0'], ['17-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['16-19'], ['6-9'], ['11-15'], ['14-18'], ['15-14'], ['17-22'], ['18-30'], ['19-15'], ['8-26'], ['15-29'], ['17-31'], ['31-15'], ['31-24'], ['21-26'], ['21-30'], ['22-22'], ['0-9'], ['7-4'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 76.54898166656494\n",
      "Response: In 2024, Alphabet's market capitalization reached its highest-ever recorded value in April.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 230\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['16-19'], ['6-9'], ['11-15'], ['14-18'], ['17-22'], ['15-14'], ['18-30'], ['19-15'], ['8-26'], ['15-29'], ['17-31'], ['21-30'], ['21-26'], ['22-22'], ['31-15'], ['31-24'], ['7-4'], ['14-15'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 491\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['12-26'], ['16-19'], ['6-9'], ['14-18'], ['11-15'], ['17-22'], ['19-15'], ['15-14'], ['18-30'], ['8-26'], ['15-29'], ['21-30'], ['17-31'], ['22-22'], ['21-26'], ['7-4'], ['14-15'], ['17-0'], ['19-10'], ['23-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 742\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['12-26'], ['14-18'], ['6-9'], ['11-15'], ['17-22'], ['19-15'], ['15-14'], ['18-30'], ['21-30'], ['22-22'], ['8-26'], ['15-29'], ['17-31'], ['21-26'], ['7-4'], ['14-15'], ['17-0'], ['19-10'], ['23-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['12-26'], ['11-15'], ['14-18'], ['6-9'], ['17-22'], ['15-14'], ['19-15'], ['18-30'], ['21-30'], ['22-22'], ['8-26'], ['14-15'], ['17-0'], ['17-31'], ['21-26'], ['15-29'], ['7-4'], ['19-10'], ['23-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['12-26'], ['11-15'], ['14-18'], ['6-9'], ['17-22'], ['15-14'], ['19-15'], ['18-30'], ['21-30'], ['17-31'], ['22-22'], ['8-26'], ['14-15'], ['17-0'], ['21-26'], ['15-29'], ['7-4'], ['19-10'], ['23-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 562\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['11-15'], ['16-19'], ['12-26'], ['6-9'], ['14-18'], ['17-22'], ['15-14'], ['19-15'], ['18-30'], ['21-30'], ['17-31'], ['22-22'], ['8-26'], ['14-15'], ['17-0'], ['21-26'], ['15-29'], ['7-4'], ['19-10'], ['23-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1120\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['11-15'], ['16-19'], ['12-26'], ['6-9'], ['14-18'], ['17-22'], ['19-15'], ['15-14'], ['18-30'], ['21-30'], ['17-31'], ['22-22'], ['14-15'], ['17-0'], ['21-26'], ['8-26'], ['15-29'], ['19-10'], ['24-3'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1710\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['14-18'], ['6-9'], ['12-26'], ['19-15'], ['15-14'], ['18-30'], ['21-30'], ['22-22'], ['17-31'], ['14-15'], ['17-0'], ['21-26'], ['8-26'], ['19-10'], ['23-8'], ['24-3'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['12-26'], ['14-18'], ['6-9'], ['15-14'], ['19-15'], ['18-30'], ['21-30'], ['17-0'], ['17-31'], ['22-22'], ['14-15'], ['21-26'], ['8-26'], ['31-16'], ['19-10'], ['23-8'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['12-26'], ['14-18'], ['6-9'], ['15-14'], ['19-15'], ['18-30'], ['21-30'], ['17-0'], ['17-31'], ['22-22'], ['14-15'], ['21-26'], ['31-16'], ['8-26'], ['19-10'], ['23-8'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 68.02557706832886\n",
      "Response: In the second quarter of 2024, Alphabet's market capitalization reached an all-time high.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 871\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['14-18'], ['12-26'], ['6-9'], ['15-14'], ['19-15'], ['18-30'], ['21-30'], ['22-22'], ['17-0'], ['17-31'], ['14-15'], ['21-26'], ['31-16'], ['8-26'], ['23-8'], ['24-3'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1749\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['14-18'], ['6-9'], ['12-26'], ['15-14'], ['19-15'], ['18-30'], ['21-30'], ['22-22'], ['17-0'], ['17-31'], ['14-15'], ['21-26'], ['23-8'], ['24-3'], ['26-26'], ['31-16'], ['8-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2640\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['17-22'], ['11-15'], ['14-18'], ['6-9'], ['12-26'], ['15-14'], ['19-15'], ['18-30'], ['22-22'], ['21-30'], ['17-0'], ['17-31'], ['14-15'], ['21-26'], ['26-26'], ['23-8'], ['24-3'], ['31-16'], ['8-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['16-19'], ['17-22'], ['11-15'], ['14-18'], ['12-26'], ['15-14'], ['6-9'], ['19-15'], ['18-30'], ['21-30'], ['22-22'], ['17-0'], ['17-31'], ['14-15'], ['21-26'], ['26-26'], ['31-16'], ['23-8'], ['24-3'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['17-22'], ['16-19'], ['11-15'], ['14-18'], ['12-26'], ['15-14'], ['6-9'], ['19-15'], ['18-30'], ['21-30'], ['22-22'], ['17-0'], ['17-31'], ['14-15'], ['21-26'], ['26-26'], ['31-16'], ['23-8'], ['24-3'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1183\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['17-22'], ['16-19'], ['11-15'], ['14-18'], ['12-26'], ['15-14'], ['6-9'], ['19-15'], ['18-30'], ['22-22'], ['21-30'], ['17-31'], ['17-0'], ['14-15'], ['21-26'], ['23-8'], ['24-3'], ['26-26'], ['31-16'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2367\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['17-22'], ['16-19'], ['11-15'], ['14-18'], ['12-26'], ['15-14'], ['6-9'], ['19-15'], ['18-30'], ['22-22'], ['21-30'], ['17-31'], ['17-0'], ['14-15'], ['26-26'], ['21-26'], ['24-3'], ['23-8'], ['31-16'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3558\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['17-22'], ['16-19'], ['11-15'], ['14-18'], ['19-15'], ['6-9'], ['12-26'], ['15-14'], ['18-30'], ['22-22'], ['21-30'], ['17-31'], ['17-0'], ['21-26'], ['14-15'], ['26-26'], ['23-8'], ['24-3'], ['31-16'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The all-time highest value of Alphabet was in April 2024.\n",
      "[['17-22'], ['16-19'], ['11-15'], ['14-18'], ['15-14'], ['12-26'], ['19-15'], ['6-9'], ['18-30'], ['21-30'], ['22-22'], ['17-0'], ['17-31'], ['21-26'], ['14-15'], ['26-26'], ['23-8'], ['24-3'], ['31-16'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 76.98308229446411\n",
      "Response: In April 2024, Alphabet's market capitalization reached its highest-ever recorded value.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_92_irrelevant_misleading/llama-2-7b-80k_id_92_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: No one received a majority of the votes on the ninth ballot.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['24-29'], ['1-26'], ['7-4'], ['17-22'], ['21-30'], ['0-14'], ['13-11'], ['16-19'], ['0-8'], ['0-11'], ['6-9'], ['7-31'], ['8-26'], ['11-17'], ['12-4'], ['15-12'], ['16-24'], ['17-13'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 51.051437854766846\n",
      "Response: The ninth ballot was held on January 4, 2023, and it was the final ballot in the Speaker of the House election. The ninth ballot was a runoff between Kevin McCarthy and H\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['24-29'], ['1-26'], ['7-4'], ['17-22'], ['21-30'], ['0-14'], ['13-11'], ['16-19'], ['0-8'], ['0-11'], ['6-9'], ['7-31'], ['8-26'], ['11-17'], ['12-4'], ['15-12'], ['16-24'], ['17-13'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 51.051437854766846\n",
      "Response: The ninth ballot was held on January 4, 2023, and it was the final ballot in the Speaker of the House election. The ninth ballot was a runoff between Kevin McCarthy and H\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['24-29'], ['1-26'], ['7-4'], ['17-22'], ['21-30'], ['0-14'], ['13-11'], ['16-19'], ['0-8'], ['0-11'], ['6-9'], ['7-31'], ['8-26'], ['11-17'], ['12-4'], ['15-12'], ['16-24'], ['17-13'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 51.051437854766846\n",
      "Response: The ninth ballot was held on January 4, 2023, and it was the final ballot in the Speaker of the House election. The ninth ballot was a runoff between Kevin McCarthy and H\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['24-29'], ['1-26'], ['7-4'], ['17-22'], ['21-30'], ['0-14'], ['13-11'], ['16-19'], ['0-8'], ['0-11'], ['6-9'], ['7-31'], ['8-26'], ['11-17'], ['12-4'], ['15-12'], ['16-24'], ['17-13'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 51.051437854766846\n",
      "Response: The ninth ballot was held on January 4, 2023, and it was the final ballot in the Speaker of the House election. The ninth ballot was a runoff between Kevin McCarthy and H\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_0_depth_7500_results.json\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['24-29'], ['1-26'], ['7-4'], ['17-22'], ['21-30'], ['0-14'], ['13-11'], ['16-19'], ['0-8'], ['0-11'], ['6-9'], ['7-31'], ['8-26'], ['11-17'], ['12-4'], ['15-12'], ['16-24'], ['17-13'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 51.051437854766846\n",
      "Response: The ninth ballot was held on January 4, 2023, and it was the final ballot in the Speaker of the House election. The ninth ballot was a runoff between Kevin McCarthy and H\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['24-29'], ['1-26'], ['7-4'], ['17-22'], ['21-30'], ['16-19'], ['0-14'], ['13-11'], ['6-9'], ['8-26'], ['0-8'], ['0-11'], ['7-31'], ['11-17'], ['12-4'], ['15-12'], ['16-24'], ['17-13'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 54.24264669418335\n",
      "Response: On the ninth ballot, Kevin McCarthy received 200 votes, while Hakeem Jeffries received 212 votes. This means that McCarthy did not receive a majority of the votes cast, and the election\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_1250_depth_0_results.json\n",
      "insertion at 255\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['24-29'], ['1-26'], ['7-4'], ['17-22'], ['21-30'], ['16-19'], ['6-9'], ['0-14'], ['7-12'], ['13-11'], ['8-26'], ['0-8'], ['0-11'], ['7-31'], ['11-17'], ['12-4'], ['15-12'], ['16-24'], ['17-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 53.97490859031677\n",
      "Response: On the ninth ballot, Kevin McCarthy received 212 votes, while Hakeem Jeffries received 216 votes. This means that McCarthy did not receive a majority of the votes cast, and the election\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 508\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['24-29'], ['16-19'], ['7-12'], ['1-26'], ['6-9'], ['7-4'], ['17-22'], ['21-30'], ['8-26'], ['0-14'], ['13-11'], ['19-15'], ['0-8'], ['0-11'], ['7-31'], ['11-17'], ['12-4'], ['15-12'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 54.24264669418335\n",
      "Response: On the ninth ballot, Kevin McCarthy received 200 votes, while Hakeem Jeffries received 212 votes. This means that McCarthy did not receive a majority of the votes cast, and the election\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 738\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 46.84987962245941\n",
      "Response: On the ninth ballot, Kevin McCarthy received 200 votes, while Hakeem Jeffries received 212 votes. This was the first time in history that a candidate had received more votes than the incumbent\n",
      "\n",
<<<<<<< Updated upstream
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant/llama-2-7b-80k_id_43_relevant_len_1250_depth_7500_results.json\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['17-22'], ['7-4'], ['19-15'], ['21-30'], ['7-12'], ['26-28'], ['11-2'], ['6-30'], ['20-29'], ['29-26'], ['12-26'], ['15-14'], ['17-16'], ['22-31'], ['23-31']]\n",
=======
      "Score: 96.91976308822632\n",
      "Response: The latest NFL season began on September 5, 2024.m.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 752\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['11-2'], ['19-10'], ['18-30'], ['7-12'], ['12-26'], ['14-15'], ['14-18'], ['19-15'], ['21-30'], ['6-30'], ['16-24'], ['14-19'], ['15-14'], ['17-0']]\n",
=======
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_1250_depth_7500_results.json\n",
      "No one received a majority of the votes on the ninth ballot.\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 96.91976308822632\n",
      "Response: The latest NFL season began on September 5, 2024.m.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['11-2'], ['19-10'], ['18-30'], ['12-26'], ['7-12'], ['14-15'], ['21-30'], ['19-15'], ['14-18'], ['6-30'], ['16-24'], ['14-19'], ['15-14'], ['17-0']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
      "Score: 97.7651059627533\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO.\n",
=======
      "Score: 33.39889645576477\n",
      "Response: On the ninth ballot, the House of Representatives voted to elect Kevin McCarthy as Speaker of the House.\n",
>>>>>>> Stashed changes
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
<<<<<<< Updated upstream
      "Elon Musk is no longer X Corp.'s CEO.\n",
=======
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['11-2'], ['19-10'], ['18-30'], ['7-12'], ['12-26'], ['14-15'], ['21-30'], ['14-18'], ['19-15'], ['6-30'], ['16-24'], ['14-19'], ['15-14'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 561\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['11-2'], ['19-10'], ['7-12'], ['18-30'], ['12-26'], ['21-30'], ['14-15'], ['14-18'], ['19-15'], ['6-30'], ['16-24'], ['15-14'], ['14-19'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1069\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['11-2'], ['7-12'], ['19-10'], ['18-30'], ['12-26'], ['21-30'], ['14-15'], ['14-18'], ['19-15'], ['16-24'], ['6-30'], ['15-14'], ['17-31'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1655\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['11-2'], ['7-12'], ['19-10'], ['18-30'], ['12-26'], ['14-18'], ['21-30'], ['14-15'], ['19-15'], ['6-30'], ['15-14'], ['16-24'], ['17-31'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['11-2'], ['7-12'], ['19-10'], ['18-30'], ['12-26'], ['21-30'], ['14-18'], ['14-15'], ['19-15'], ['6-30'], ['16-24'], ['15-14'], ['17-31'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['7-12'], ['19-10'], ['18-30'], ['12-26'], ['21-30'], ['14-18'], ['14-15'], ['19-15'], ['6-30'], ['15-14'], ['16-24'], ['17-31'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 881\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['7-12'], ['19-10'], ['18-30'], ['12-26'], ['21-30'], ['14-18'], ['14-15'], ['19-15'], ['15-14'], ['16-24'], ['17-31'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1751\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['11-2'], ['7-12'], ['7-4'], ['19-10'], ['18-30'], ['12-26'], ['21-30'], ['14-18'], ['19-15'], ['14-15'], ['17-31'], ['15-14'], ['16-24'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2628\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['11-2'], ['7-12'], ['7-4'], ['19-10'], ['18-30'], ['21-30'], ['12-26'], ['14-18'], ['19-15'], ['14-15'], ['17-31'], ['15-14'], ['16-24'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['11-2'], ['7-4'], ['7-12'], ['19-10'], ['18-30'], ['21-30'], ['12-26'], ['14-18'], ['19-15'], ['14-15'], ['17-31'], ['16-24'], ['15-14'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['11-2'], ['7-12'], ['7-4'], ['19-10'], ['18-30'], ['12-26'], ['21-30'], ['14-18'], ['19-15'], ['17-31'], ['14-15'], ['16-24'], ['15-14'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1171\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['11-2'], ['7-12'], ['7-4'], ['19-10'], ['18-30'], ['12-26'], ['21-30'], ['14-18'], ['19-15'], ['17-31'], ['14-15'], ['16-24'], ['15-14'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2344\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['11-2'], ['7-12'], ['7-4'], ['19-10'], ['18-30'], ['21-30'], ['12-26'], ['14-18'], ['19-15'], ['17-31'], ['14-15'], ['16-24'], ['15-14'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3492\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['11-2'], ['7-12'], ['7-4'], ['19-10'], ['18-30'], ['21-30'], ['12-26'], ['14-18'], ['19-15'], ['17-31'], ['14-15'], ['16-24'], ['15-14'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['17-22'], ['11-2'], ['7-12'], ['7-4'], ['19-10'], ['18-30'], ['21-30'], ['12-26'], ['14-18'], ['19-15'], ['17-31'], ['14-15'], ['16-24'], ['15-14'], ['6-30'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_relevant_misleading/llama-2-7b-80k_id_444_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['18-30'], ['19-10'], ['12-26'], ['11-2'], ['14-15'], ['6-30'], ['14-19'], ['16-24'], ['19-15'], ['21-30'], ['0-22'], ['0-28'], ['1-25'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['18-30'], ['19-10'], ['12-26'], ['11-2'], ['14-15'], ['6-30'], ['14-19'], ['16-24'], ['19-15'], ['21-30'], ['0-22'], ['0-28'], ['1-25'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['18-30'], ['19-10'], ['12-26'], ['11-2'], ['14-15'], ['6-30'], ['14-19'], ['16-24'], ['19-15'], ['21-30'], ['0-22'], ['0-28'], ['1-25'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['18-30'], ['19-10'], ['12-26'], ['11-2'], ['14-15'], ['6-30'], ['14-19'], ['16-24'], ['19-15'], ['21-30'], ['0-22'], ['0-28'], ['1-25'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_0_depth_7500_results.json\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['18-30'], ['19-10'], ['12-26'], ['11-2'], ['14-15'], ['6-30'], ['14-19'], ['16-24'], ['19-15'], ['21-30'], ['0-22'], ['0-28'], ['1-25'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['7-4'], ['8-26'], ['19-10'], ['18-30'], ['11-2'], ['12-26'], ['14-15'], ['6-30'], ['21-30'], ['14-19'], ['16-24'], ['19-15'], ['14-18'], ['15-14'], ['31-15'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 73\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['7-4'], ['18-30'], ['19-10'], ['11-2'], ['12-26'], ['14-15'], ['21-30'], ['7-12'], ['14-18'], ['19-15'], ['6-30'], ['14-19'], ['16-24'], ['15-14'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 494\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['7-4'], ['18-30'], ['19-10'], ['11-2'], ['12-26'], ['7-12'], ['14-15'], ['14-18'], ['19-15'], ['21-30'], ['6-30'], ['14-19'], ['16-24'], ['15-14'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 733\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['7-4'], ['18-30'], ['19-10'], ['11-2'], ['7-12'], ['12-26'], ['14-15'], ['19-15'], ['6-30'], ['14-18'], ['21-30'], ['14-19'], ['15-14'], ['16-24'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 80.2503228187561\n",
      "Response: The latest NFL season began on September 5, 2024. It was tested in the FA Cup fifth round onwards, after which the Premier League confirmed that the technology would be used in matchweek 32, on 1\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_1250_depth_7500_results.json\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['18-30'], ['19-10'], ['11-2'], ['7-12'], ['12-26'], ['14-15'], ['19-15'], ['21-30'], ['6-30'], ['14-18'], ['14-19'], ['17-31'], ['15-14'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['11-2'], ['19-10'], ['18-30'], ['7-12'], ['12-26'], ['14-18'], ['14-15'], ['19-15'], ['21-30'], ['6-30'], ['14-19'], ['15-14'], ['17-31'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 562\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['11-2'], ['19-10'], ['18-30'], ['7-12'], ['14-18'], ['12-26'], ['14-15'], ['19-15'], ['21-30'], ['6-30'], ['14-19'], ['15-14'], ['17-31'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1116\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['11-2'], ['7-12'], ['18-30'], ['19-10'], ['14-18'], ['19-15'], ['21-30'], ['14-15'], ['12-26'], ['6-30'], ['17-31'], ['14-19'], ['15-14'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1686\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['11-2'], ['7-12'], ['18-30'], ['19-10'], ['21-30'], ['19-15'], ['14-15'], ['14-18'], ['6-30'], ['12-26'], ['17-31'], ['15-14'], ['14-19'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_2500_depth_7500_results.json\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['11-2'], ['18-30'], ['19-10'], ['7-12'], ['21-30'], ['19-15'], ['14-15'], ['12-26'], ['14-18'], ['6-30'], ['17-31'], ['15-14'], ['14-19'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['6-9'], ['7-4'], ['11-2'], ['7-12'], ['19-10'], ['18-30'], ['21-30'], ['14-18'], ['19-15'], ['14-15'], ['12-26'], ['17-31'], ['6-30'], ['15-14'], ['14-19'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 867\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['6-9'], ['7-4'], ['11-2'], ['7-12'], ['19-10'], ['18-30'], ['21-30'], ['14-18'], ['19-15'], ['14-15'], ['12-26'], ['17-31'], ['6-30'], ['15-14'], ['14-19'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1754\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['6-9'], ['7-4'], ['7-12'], ['11-2'], ['19-10'], ['18-30'], ['21-30'], ['14-18'], ['19-15'], ['14-15'], ['17-31'], ['6-30'], ['12-26'], ['15-14'], ['14-19'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 78.12251448631287\n",
      "Response: The latest NFL season began on September 5, 2024. The promoted teams are Leicester City, Ipswich Town and Southampton. Leicester City and Southampton returned after one-year absences,\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2356\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['6-9'], ['7-4'], ['7-12'], ['11-2'], ['19-10'], ['18-30'], ['21-30'], ['14-18'], ['19-15'], ['14-15'], ['17-31'], ['6-30'], ['12-26'], ['15-14'], ['17-0'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_3750_depth_7500_results.json\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['6-9'], ['7-4'], ['11-2'], ['7-12'], ['18-30'], ['19-10'], ['21-30'], ['14-18'], ['19-15'], ['14-15'], ['17-31'], ['6-30'], ['12-26'], ['15-14'], ['17-0'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['6-9'], ['7-4'], ['7-12'], ['11-2'], ['18-30'], ['19-10'], ['21-30'], ['14-18'], ['19-15'], ['17-31'], ['14-15'], ['6-30'], ['12-26'], ['15-14'], ['17-0'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1192\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['6-9'], ['7-12'], ['11-2'], ['7-4'], ['19-10'], ['18-30'], ['21-30'], ['14-18'], ['14-15'], ['17-31'], ['19-15'], ['6-30'], ['12-26'], ['15-14'], ['17-0'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2356\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['6-9'], ['7-12'], ['11-2'], ['7-4'], ['19-10'], ['18-30'], ['21-30'], ['14-18'], ['19-15'], ['14-15'], ['17-31'], ['6-30'], ['15-14'], ['12-26'], ['17-0'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 2839\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['6-9'], ['7-12'], ['11-2'], ['7-4'], ['18-30'], ['19-10'], ['21-30'], ['14-18'], ['19-15'], ['17-31'], ['14-15'], ['15-14'], ['6-30'], ['12-26'], ['17-0'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_5000_depth_7500_results.json\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['6-9'], ['7-12'], ['11-2'], ['7-4'], ['18-30'], ['19-10'], ['21-30'], ['14-18'], ['19-15'], ['17-31'], ['14-15'], ['12-26'], ['6-30'], ['15-14'], ['17-0'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant/llama-2-7b-80k_id_444_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_irrelevant/444.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['18-30'], ['19-10'], ['12-26'], ['11-2'], ['14-15'], ['6-30'], ['14-19'], ['16-24'], ['19-15'], ['21-30'], ['0-22'], ['0-28'], ['1-25'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['18-30'], ['19-10'], ['12-26'], ['11-2'], ['14-15'], ['6-30'], ['14-19'], ['16-24'], ['19-15'], ['21-30'], ['0-22'], ['0-28'], ['1-25'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['18-30'], ['19-10'], ['12-26'], ['11-2'], ['14-15'], ['6-30'], ['14-19'], ['16-24'], ['19-15'], ['21-30'], ['0-22'], ['0-28'], ['1-25'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['18-30'], ['19-10'], ['12-26'], ['11-2'], ['14-15'], ['6-30'], ['14-19'], ['16-24'], ['19-15'], ['21-30'], ['0-22'], ['0-28'], ['1-25'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['17-22'], ['8-26'], ['18-30'], ['19-10'], ['12-26'], ['11-2'], ['14-15'], ['6-30'], ['14-19'], ['16-24'], ['19-15'], ['21-30'], ['0-22'], ['0-28'], ['1-25'], ['1-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['7-4'], ['8-26'], ['19-10'], ['18-30'], ['11-2'], ['12-26'], ['14-15'], ['6-30'], ['21-30'], ['14-19'], ['16-24'], ['19-15'], ['14-18'], ['15-14'], ['31-15'], ['11-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 73\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['19-10'], ['18-30'], ['11-2'], ['12-26'], ['14-15'], ['7-12'], ['14-18'], ['21-30'], ['6-30'], ['19-15'], ['14-19'], ['16-24'], ['15-14'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 494\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['19-10'], ['18-30'], ['11-2'], ['12-26'], ['7-12'], ['14-15'], ['21-30'], ['14-18'], ['19-15'], ['6-30'], ['16-24'], ['14-19'], ['15-14'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 753\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['19-10'], ['11-2'], ['18-30'], ['7-12'], ['12-26'], ['21-30'], ['14-15'], ['19-15'], ['14-18'], ['6-30'], ['15-14'], ['16-24'], ['14-19'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['19-10'], ['11-2'], ['18-30'], ['12-26'], ['21-30'], ['7-12'], ['14-15'], ['14-18'], ['19-15'], ['6-30'], ['15-14'], ['14-19'], ['16-24'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['11-2'], ['19-10'], ['18-30'], ['7-12'], ['21-30'], ['12-26'], ['14-15'], ['14-18'], ['19-15'], ['6-30'], ['15-14'], ['14-19'], ['16-24'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 562\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['11-2'], ['19-10'], ['18-30'], ['7-12'], ['21-30'], ['12-26'], ['14-18'], ['14-15'], ['19-15'], ['6-30'], ['15-14'], ['14-19'], ['16-24'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1137\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['11-2'], ['19-10'], ['7-12'], ['18-30'], ['21-30'], ['12-26'], ['14-15'], ['14-18'], ['19-15'], ['6-30'], ['15-14'], ['16-24'], ['17-31'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1604\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['19-10'], ['7-12'], ['18-30'], ['21-30'], ['19-15'], ['14-18'], ['12-26'], ['14-15'], ['6-30'], ['15-14'], ['17-31'], ['14-19'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['7-4'], ['11-2'], ['19-10'], ['18-30'], ['7-12'], ['21-30'], ['19-15'], ['12-26'], ['14-18'], ['14-15'], ['6-30'], ['15-14'], ['17-31'], ['14-19'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['19-10'], ['7-12'], ['18-30'], ['21-30'], ['14-18'], ['19-15'], ['12-26'], ['14-15'], ['6-30'], ['15-14'], ['17-31'], ['14-19'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 864\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['19-10'], ['7-12'], ['18-30'], ['21-30'], ['14-18'], ['19-15'], ['12-26'], ['14-15'], ['6-30'], ['15-14'], ['17-31'], ['17-0'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1604\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['19-10'], ['7-12'], ['18-30'], ['21-30'], ['19-15'], ['14-18'], ['12-26'], ['14-15'], ['17-31'], ['6-30'], ['15-14'], ['17-0'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2474\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['7-12'], ['19-10'], ['18-30'], ['21-30'], ['19-15'], ['14-18'], ['14-15'], ['12-26'], ['17-31'], ['6-30'], ['15-14'], ['17-0'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['19-10'], ['7-12'], ['18-30'], ['21-30'], ['19-15'], ['14-18'], ['12-26'], ['14-15'], ['17-31'], ['6-30'], ['15-14'], ['17-0'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['11-2'], ['7-4'], ['7-12'], ['19-10'], ['18-30'], ['21-30'], ['19-15'], ['14-18'], ['12-26'], ['14-15'], ['17-31'], ['6-30'], ['15-14'], ['17-0'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1156\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['17-22'], ['8-26'], ['11-2'], ['7-12'], ['7-4'], ['19-10'], ['18-30'], ['21-30'], ['19-15'], ['14-18'], ['12-26'], ['14-15'], ['17-31'], ['6-30'], ['15-14'], ['14-19'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 1984\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['11-2'], ['7-12'], ['7-4'], ['19-10'], ['18-30'], ['21-30'], ['19-15'], ['14-18'], ['12-26'], ['14-15'], ['17-31'], ['15-14'], ['6-30'], ['14-19'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 2957\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['11-2'], ['7-12'], ['7-4'], ['19-10'], ['18-30'], ['21-30'], ['19-15'], ['14-18'], ['12-26'], ['14-15'], ['17-31'], ['15-14'], ['6-30'], ['14-19'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The latest NFL season began on September 5, 2024.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['11-2'], ['7-12'], ['7-4'], ['19-10'], ['18-30'], ['21-30'], ['19-15'], ['14-18'], ['12-26'], ['14-15'], ['17-31'], ['15-14'], ['6-30'], ['17-0'], ['14-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The latest NFL season began on September 5, 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_444_irrelevant_misleading/llama-2-7b-80k_id_444_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['17-22'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['14-15'], ['19-12'], ['20-8'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['17-22'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['14-15'], ['19-12'], ['20-8'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['17-22'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['14-15'], ['19-12'], ['20-8'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['17-22'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['14-15'], ['19-12'], ['20-8'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_0_depth_7500_results.json\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['17-22'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['14-15'], ['19-12'], ['20-8'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['8-26'], ['24-29'], ['11-2'], ['17-22'], ['22-22'], ['12-26'], ['15-14'], ['18-30'], ['26-28'], ['31-16'], ['20-29'], ['24-24'], ['26-26'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_1250_depth_0_results.json\n",
      "insertion at 195\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['8-26'], ['24-29'], ['11-2'], ['17-22'], ['22-22'], ['15-14'], ['18-30'], ['26-28'], ['31-16'], ['12-26'], ['20-29'], ['24-24'], ['26-26'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 461\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['11-2'], ['17-22'], ['24-29'], ['22-22'], ['15-14'], ['18-30'], ['26-28'], ['31-16'], ['12-26'], ['20-29'], ['24-24'], ['26-26'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 633\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['17-22'], ['11-2'], ['24-29'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['15-14'], ['12-26'], ['20-29'], ['24-24'], ['26-26'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_1250_depth_7500_results.json\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['17-22'], ['11-2'], ['24-29'], ['22-22'], ['18-30'], ['15-14'], ['26-28'], ['31-16'], ['12-26'], ['20-29'], ['24-24'], ['20-8'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['17-22'], ['11-2'], ['24-29'], ['18-30'], ['22-22'], ['15-14'], ['26-28'], ['31-16'], ['20-29'], ['12-26'], ['24-24'], ['20-8'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_2500_depth_0_results.json\n",
      "insertion at 561\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['8-26'], ['21-30'], ['7-4'], ['17-22'], ['11-2'], ['18-30'], ['24-29'], ['22-22'], ['15-14'], ['26-28'], ['31-16'], ['20-29'], ['7-12'], ['12-26'], ['24-24'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 75.41138529777527\n",
      "Response: The Boston Celtics won the latest NBA championship. The first parentheses in the Western champions and Eastern champions columns indicate the teams' playoff seed. The second parentheses indicate the number of times that teams have appeared in an NBA Finals as well as\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 633\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['18-30'], ['22-22'], ['26-28'], ['24-29'], ['15-14'], ['20-29'], ['31-16'], ['7-12'], ['24-24'], ['12-26'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1581\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['18-30'], ['22-22'], ['26-28'], ['24-29'], ['15-14'], ['20-29'], ['31-16'], ['7-12'], ['24-24'], ['12-26'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_2500_depth_7500_results.json\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['18-30'], ['22-22'], ['26-28'], ['24-29'], ['15-14'], ['20-29'], ['31-16'], ['7-12'], ['24-24'], ['12-26'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['18-30'], ['22-22'], ['26-28'], ['24-29'], ['15-14'], ['20-29'], ['31-16'], ['7-12'], ['24-24'], ['12-26'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_3750_depth_0_results.json\n",
      "insertion at 633\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['18-30'], ['22-22'], ['26-28'], ['24-29'], ['15-14'], ['20-29'], ['31-16'], ['7-12'], ['24-24'], ['20-8'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1581\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['22-22'], ['18-30'], ['26-28'], ['24-29'], ['15-14'], ['7-12'], ['20-29'], ['31-16'], ['24-24'], ['20-8'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2441\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['22-22'], ['18-30'], ['26-28'], ['24-29'], ['7-12'], ['20-29'], ['15-14'], ['31-16'], ['24-24'], ['20-8'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_3750_depth_7500_results.json\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['22-22'], ['26-28'], ['18-30'], ['24-29'], ['15-14'], ['20-29'], ['7-12'], ['31-16'], ['24-24'], ['20-8'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['11-2'], ['7-4'], ['22-22'], ['26-28'], ['24-29'], ['18-30'], ['20-29'], ['7-12'], ['15-14'], ['31-16'], ['20-8'], ['24-24'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_5000_depth_0_results.json\n",
      "insertion at 633\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['11-2'], ['7-4'], ['22-22'], ['26-28'], ['7-12'], ['24-29'], ['20-29'], ['18-30'], ['15-14'], ['31-16'], ['20-8'], ['24-24'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 1581\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['11-2'], ['7-4'], ['22-22'], ['7-12'], ['26-28'], ['20-29'], ['24-29'], ['18-30'], ['15-14'], ['31-16'], ['20-8'], ['24-24'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3197\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['11-2'], ['7-4'], ['7-12'], ['22-22'], ['26-28'], ['20-29'], ['24-29'], ['18-30'], ['15-14'], ['31-16'], ['20-8'], ['24-24'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_5000_depth_7500_results.json\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['11-2'], ['7-4'], ['22-22'], ['7-12'], ['26-28'], ['20-29'], ['24-29'], ['18-30'], ['15-14'], ['31-16'], ['20-8'], ['24-24'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant/llama-2-7b-80k_id_448_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_relevant/448.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['17-22'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['14-15'], ['19-12'], ['20-8'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['17-22'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['14-15'], ['19-12'], ['20-8'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['17-22'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['14-15'], ['19-12'], ['20-8'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['17-22'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['14-15'], ['19-12'], ['20-8'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_0_depth_7500_results.json\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['17-22'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['14-15'], ['19-12'], ['20-8'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['8-26'], ['24-29'], ['11-2'], ['17-22'], ['26-28'], ['31-16'], ['12-26'], ['15-14'], ['18-30'], ['22-22'], ['20-8'], ['20-29'], ['24-24'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 214\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['21-30'], ['7-4'], ['8-26'], ['24-29'], ['11-2'], ['17-22'], ['26-28'], ['18-30'], ['22-22'], ['31-16'], ['15-14'], ['12-26'], ['20-8'], ['20-29'], ['24-24'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 476\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['11-2'], ['18-30'], ['26-28'], ['31-16'], ['22-22'], ['15-14'], ['12-26'], ['20-29'], ['20-8'], ['24-24'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 668\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['18-30'], ['31-16'], ['11-2'], ['22-22'], ['26-28'], ['15-14'], ['20-29'], ['12-26'], ['20-8'], ['24-24'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['17-22'], ['24-29'], ['18-30'], ['11-2'], ['22-22'], ['31-16'], ['26-28'], ['15-14'], ['20-29'], ['12-26'], ['20-8'], ['24-24'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['8-26'], ['21-30'], ['7-4'], ['17-22'], ['24-29'], ['11-2'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['15-14'], ['20-29'], ['12-26'], ['20-8'], ['24-24'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 535\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['8-26'], ['21-30'], ['7-4'], ['17-22'], ['24-29'], ['11-2'], ['26-28'], ['18-30'], ['22-22'], ['15-14'], ['31-16'], ['20-29'], ['12-26'], ['20-8'], ['24-24'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 668\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['24-29'], ['11-2'], ['26-28'], ['18-30'], ['22-22'], ['15-14'], ['20-29'], ['31-16'], ['12-26'], ['20-8'], ['24-24'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1638\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['24-29'], ['11-2'], ['26-28'], ['22-22'], ['18-30'], ['15-14'], ['20-29'], ['31-16'], ['20-8'], ['24-24'], ['12-26'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['24-29'], ['26-28'], ['22-22'], ['18-30'], ['15-14'], ['20-29'], ['31-16'], ['12-26'], ['20-8'], ['24-24'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['24-29'], ['26-28'], ['22-22'], ['18-30'], ['15-14'], ['20-29'], ['31-16'], ['12-26'], ['20-8'], ['29-19'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 668\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['22-22'], ['24-29'], ['26-28'], ['18-30'], ['15-14'], ['20-29'], ['31-16'], ['20-8'], ['12-26'], ['7-12'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1638\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['22-22'], ['11-2'], ['26-28'], ['24-29'], ['18-30'], ['15-14'], ['20-29'], ['31-16'], ['20-8'], ['7-12'], ['12-26'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 73.1569766998291\n",
      "Response: The Boston Celtics.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2523\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['22-22'], ['26-28'], ['24-29'], ['18-30'], ['15-14'], ['20-29'], ['31-16'], ['7-12'], ['20-8'], ['29-19'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['22-22'], ['24-29'], ['26-28'], ['18-30'], ['15-14'], ['20-29'], ['31-16'], ['20-8'], ['12-26'], ['29-19'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['24-29'], ['22-22'], ['26-28'], ['18-30'], ['15-14'], ['20-29'], ['31-16'], ['7-12'], ['20-8'], ['12-26'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 668\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['11-2'], ['7-4'], ['22-22'], ['24-29'], ['26-28'], ['18-30'], ['15-14'], ['20-29'], ['31-16'], ['7-12'], ['20-8'], ['12-26'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 1638\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['11-2'], ['22-22'], ['7-4'], ['24-29'], ['26-28'], ['18-30'], ['15-14'], ['20-29'], ['7-12'], ['31-16'], ['20-8'], ['12-26'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3304\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['11-2'], ['22-22'], ['24-29'], ['7-4'], ['26-28'], ['18-30'], ['15-14'], ['20-29'], ['7-12'], ['31-16'], ['20-8'], ['29-19'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['11-2'], ['7-4'], ['22-22'], ['24-29'], ['26-28'], ['15-14'], ['18-30'], ['20-29'], ['7-12'], ['31-16'], ['20-8'], ['29-19'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_relevant_misleading/llama-2-7b-80k_id_448_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['17-22'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['14-15'], ['19-12'], ['20-8'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['17-22'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['14-15'], ['19-12'], ['20-8'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['17-22'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['14-15'], ['19-12'], ['20-8'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['17-22'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['14-15'], ['19-12'], ['20-8'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_0_depth_7500_results.json\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['17-22'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['14-15'], ['19-12'], ['20-8'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['17-22'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['14-15'], ['19-12'], ['20-8'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 64.42288160324097\n",
      "Response: The latest NBA championship was won by the Golden State Warriors in 2022.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 20\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['24-29'], ['17-22'], ['11-2'], ['22-22'], ['31-16'], ['18-30'], ['26-28'], ['12-26'], ['15-14'], ['20-8'], ['24-3'], ['24-24'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 497\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['17-22'], ['24-29'], ['11-2'], ['22-22'], ['31-16'], ['26-28'], ['18-30'], ['15-14'], ['12-26'], ['20-8'], ['24-3'], ['24-24'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 77.83856391906738\n",
      "Response: The Boston Celtics won the latest NBA championship. It was not until 1931 that a Southern club were crowned champions, when Herbert Chapman's Arsenal secured the title. Rules stipulating a maximum w\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 763\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['11-2'], ['24-29'], ['22-22'], ['31-16'], ['26-28'], ['18-30'], ['15-14'], ['12-26'], ['7-12'], ['20-8'], ['24-3'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_1250_depth_7500_results.json\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['11-2'], ['24-29'], ['22-22'], ['26-28'], ['31-16'], ['15-14'], ['18-30'], ['12-26'], ['7-12'], ['20-8'], ['24-3'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['8-26'], ['21-30'], ['7-4'], ['17-22'], ['11-2'], ['24-29'], ['22-22'], ['26-28'], ['31-16'], ['18-30'], ['15-14'], ['7-12'], ['12-26'], ['20-29'], ['20-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 564\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['24-29'], ['22-22'], ['26-28'], ['18-30'], ['31-16'], ['7-12'], ['15-14'], ['12-26'], ['20-29'], ['20-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1140\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['22-22'], ['24-29'], ['26-28'], ['7-12'], ['18-30'], ['31-16'], ['15-14'], ['20-29'], ['12-26'], ['20-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1174\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['22-22'], ['7-12'], ['24-29'], ['26-28'], ['18-30'], ['31-16'], ['15-14'], ['20-29'], ['6-30'], ['14-18'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_2500_depth_7500_results.json\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['22-22'], ['24-29'], ['26-28'], ['18-30'], ['7-12'], ['31-16'], ['15-14'], ['20-29'], ['12-26'], ['6-30'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['22-22'], ['7-12'], ['24-29'], ['26-28'], ['18-30'], ['31-16'], ['15-14'], ['20-29'], ['6-30'], ['12-26'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 881\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['22-22'], ['7-12'], ['24-29'], ['26-28'], ['18-30'], ['31-16'], ['15-14'], ['20-29'], ['6-30'], ['20-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1174\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['7-12'], ['22-22'], ['26-28'], ['24-29'], ['18-30'], ['31-16'], ['15-14'], ['20-29'], ['6-30'], ['20-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 1174\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['7-12'], ['22-22'], ['26-28'], ['24-29'], ['18-30'], ['31-16'], ['15-14'], ['20-29'], ['6-30'], ['20-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_3750_depth_7500_results.json\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['22-22'], ['7-12'], ['26-28'], ['24-29'], ['18-30'], ['15-14'], ['31-16'], ['20-29'], ['6-30'], ['20-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['7-4'], ['7-12'], ['22-22'], ['26-28'], ['24-29'], ['18-30'], ['15-14'], ['31-16'], ['20-29'], ['6-30'], ['20-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1174\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['7-4'], ['7-12'], ['22-22'], ['26-28'], ['24-29'], ['18-30'], ['15-14'], ['31-16'], ['20-29'], ['6-30'], ['20-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 1174\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['7-4'], ['7-12'], ['22-22'], ['26-28'], ['24-29'], ['18-30'], ['31-16'], ['15-14'], ['20-29'], ['6-30'], ['20-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 1174\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['17-22'], ['19-15'], ['21-30'], ['11-2'], ['7-12'], ['7-4'], ['22-22'], ['26-28'], ['24-29'], ['18-30'], ['31-16'], ['15-14'], ['20-29'], ['6-30'], ['20-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_5000_depth_7500_results.json\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['7-4'], ['7-12'], ['22-22'], ['26-28'], ['24-29'], ['18-30'], ['15-14'], ['31-16'], ['20-29'], ['6-30'], ['20-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant/llama-2-7b-80k_id_448_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_irrelevant/448.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['17-22'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['14-15'], ['19-12'], ['20-8'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['17-22'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['14-15'], ['19-12'], ['20-8'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['17-22'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['14-15'], ['19-12'], ['20-8'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['17-22'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['14-15'], ['19-12'], ['20-8'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['12-26'], ['15-14'], ['17-22'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['14-15'], ['19-12'], ['20-8'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['8-26'], ['24-29'], ['11-2'], ['17-22'], ['12-26'], ['15-14'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['29-26'], ['14-15'], ['19-12'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 20\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['21-30'], ['8-26'], ['7-4'], ['24-29'], ['11-2'], ['17-22'], ['12-26'], ['15-14'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['7-12'], ['24-24'], ['29-26'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 512\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['8-26'], ['7-4'], ['21-30'], ['24-29'], ['11-2'], ['17-22'], ['26-28'], ['7-12'], ['12-26'], ['15-14'], ['18-30'], ['22-22'], ['31-16'], ['20-8'], ['24-24'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 757\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['24-29'], ['11-2'], ['26-28'], ['7-12'], ['22-22'], ['15-14'], ['18-30'], ['12-26'], ['31-16'], ['20-8'], ['24-24'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['11-2'], ['24-29'], ['26-28'], ['22-22'], ['15-14'], ['12-26'], ['18-30'], ['31-16'], ['7-12'], ['29-19'], ['20-8'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['8-26'], ['7-4'], ['21-30'], ['17-22'], ['11-2'], ['24-29'], ['26-28'], ['22-22'], ['7-12'], ['12-26'], ['15-14'], ['18-30'], ['31-16'], ['29-19'], ['20-8'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 564\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['7-4'], ['17-22'], ['11-2'], ['24-29'], ['7-12'], ['26-28'], ['22-22'], ['12-26'], ['15-14'], ['18-30'], ['31-16'], ['20-29'], ['29-19'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1135\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['7-4'], ['17-22'], ['11-2'], ['24-29'], ['7-12'], ['26-28'], ['22-22'], ['18-30'], ['15-14'], ['12-26'], ['31-16'], ['20-29'], ['29-19'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1281\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['24-29'], ['7-12'], ['22-22'], ['26-28'], ['18-30'], ['31-16'], ['15-14'], ['20-29'], ['12-26'], ['24-24'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['24-29'], ['22-22'], ['7-12'], ['18-30'], ['26-28'], ['15-14'], ['12-26'], ['31-16'], ['20-29'], ['29-19'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['24-29'], ['7-12'], ['22-22'], ['26-28'], ['18-30'], ['15-14'], ['12-26'], ['31-16'], ['20-29'], ['24-24'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 865\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['7-4'], ['11-2'], ['24-29'], ['7-12'], ['18-30'], ['22-22'], ['26-28'], ['15-14'], ['20-29'], ['31-16'], ['12-26'], ['24-24'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1281\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['7-4'], ['24-29'], ['7-12'], ['18-30'], ['22-22'], ['26-28'], ['20-29'], ['31-16'], ['15-14'], ['12-26'], ['24-24'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 1281\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['7-4'], ['24-29'], ['7-12'], ['18-30'], ['22-22'], ['26-28'], ['20-29'], ['31-16'], ['15-14'], ['12-26'], ['24-24'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['7-4'], ['24-29'], ['18-30'], ['7-12'], ['22-22'], ['26-28'], ['20-29'], ['31-16'], ['15-14'], ['12-26'], ['24-24'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['7-4'], ['24-29'], ['7-12'], ['18-30'], ['22-22'], ['26-28'], ['20-29'], ['31-16'], ['15-14'], ['12-26'], ['24-24'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1189\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['7-4'], ['24-29'], ['7-12'], ['18-30'], ['22-22'], ['26-28'], ['20-29'], ['15-14'], ['31-16'], ['12-26'], ['6-30'], ['24-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 1281\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['7-4'], ['24-29'], ['7-12'], ['18-30'], ['22-22'], ['26-28'], ['20-29'], ['15-14'], ['31-16'], ['12-26'], ['6-30'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 1281\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['7-4'], ['24-29'], ['7-12'], ['22-22'], ['18-30'], ['20-29'], ['26-28'], ['15-14'], ['31-16'], ['6-30'], ['12-26'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The Boston Celtics won the latest NBA championship.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['11-2'], ['7-4'], ['24-29'], ['7-12'], ['22-22'], ['18-30'], ['20-29'], ['26-28'], ['15-14'], ['31-16'], ['12-26'], ['6-30'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The Boston Celtics won the latest NBA championship.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_448_irrelevant_misleading/llama-2-7b-80k_id_448_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['8-26'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-15'], ['11-17'], ['12-0'], ['12-4'], ['12-6'], ['12-26'], ['14-18'], ['15-25'], ['16-24'], ['17-0'], ['17-31'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['8-26'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-15'], ['11-17'], ['12-0'], ['12-4'], ['12-6'], ['12-26'], ['14-18'], ['15-25'], ['16-24'], ['17-0'], ['17-31'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['8-26'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-15'], ['11-17'], ['12-0'], ['12-4'], ['12-6'], ['12-26'], ['14-18'], ['15-25'], ['16-24'], ['17-0'], ['17-31'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['8-26'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-15'], ['11-17'], ['12-0'], ['12-4'], ['12-6'], ['12-26'], ['14-18'], ['15-25'], ['16-24'], ['17-0'], ['17-31'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_0_depth_7500_results.json\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['8-26'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-15'], ['11-17'], ['12-0'], ['12-4'], ['12-6'], ['12-26'], ['14-18'], ['15-25'], ['16-24'], ['17-0'], ['17-31'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['12-4'], ['14-18'], ['16-24'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-17'], ['12-0'], ['12-6'], ['12-26'], ['15-25'], ['17-0'], ['17-31'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_1250_depth_0_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['12-4'], ['14-18'], ['16-24'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-17'], ['12-0'], ['12-6'], ['12-26'], ['15-25'], ['17-0'], ['17-31'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['12-4'], ['14-18'], ['16-24'], ['17-22'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-17'], ['12-0'], ['12-6'], ['12-26'], ['15-25'], ['17-0'], ['17-31'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 749\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-12'], ['19-15'], ['6-9'], ['7-4'], ['14-18'], ['17-22'], ['21-30'], ['11-2'], ['12-4'], ['16-24'], ['19-10'], ['17-31'], ['18-30'], ['21-4'], ['12-26'], ['17-0'], ['22-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_1250_depth_7500_results.json\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-4'], ['19-15'], ['6-9'], ['21-30'], ['17-22'], ['7-12'], ['14-18'], ['11-2'], ['19-10'], ['16-24'], ['21-4'], ['12-4'], ['17-0'], ['17-31'], ['18-30'], ['12-26'], ['22-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-4'], ['19-15'], ['6-9'], ['17-22'], ['21-30'], ['14-18'], ['7-12'], ['11-2'], ['16-24'], ['19-10'], ['17-0'], ['21-4'], ['12-4'], ['17-31'], ['18-30'], ['24-29'], ['12-26']]\n",
>>>>>>> Stashed changes
=======
      "No one received a majority of the votes on the ninth ballot.\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
      "Score: 22.505223751068115\n",
      "Response: Yes, he is.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant/llama-2-7b-80k_id_43_relevant_len_2500_depth_0_results.json\n",
      "insertion at 569\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['24-29'], ['6-9'], ['11-15'], ['8-26'], ['7-12'], ['17-22'], ['21-30'], ['7-4'], ['19-15'], ['11-2'], ['26-28'], ['20-29'], ['29-26'], ['6-30'], ['12-26'], ['17-16'], ['23-31'], ['15-14'], ['20-27']]\n",
=======
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_2500_depth_0_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['14-18'], ['7-12'], ['16-24'], ['11-2'], ['17-0'], ['19-10'], ['21-4'], ['24-29'], ['12-4'], ['17-31'], ['18-30'], ['12-26']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
<<<<<<< Updated upstream
      "Score: 96.57951593399048\n",
      "Response: Yes, Elon Musk is still X Corp.'s CEO.\n",
=======
      "Score: 32.98633396625519\n",
      "Response: On the ninth ballot, the House of Representatives elected Kevin McCarthy as Speaker of the House.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_2500_depth_0_results.json\n",
      "insertion at 554\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 32.833823561668396\n",
      "Response: On the ninth ballot, Kevin McCarthy was elected Speaker of the House with 216 votes.\n",
>>>>>>> Stashed changes
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1095\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 32.98633396625519\n",
      "Response: On the ninth ballot, the House of Representatives elected Kevin McCarthy as Speaker of the House.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1711\n",
<<<<<<< Updated upstream
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 24.194729328155518\n",
      "Response: No, he is not.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant/llama-2-7b-80k_id_43_relevant_len_2500_depth_7500_results.json\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['11-15'], ['8-26'], ['21-30'], ['17-22'], ['19-15'], ['7-4'], ['7-12'], ['11-2'], ['26-28'], ['6-30'], ['20-29'], ['29-26'], ['12-26'], ['15-14'], ['21-28'], ['23-31'], ['31-16']]\n",
=======
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1131\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['14-18'], ['7-12'], ['16-24'], ['17-0'], ['19-10'], ['11-2'], ['24-29'], ['12-4'], ['17-31'], ['18-30'], ['21-4'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1685\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['14-18'], ['7-12'], ['16-24'], ['17-0'], ['19-10'], ['24-29'], ['11-2'], ['12-4'], ['17-31'], ['18-30'], ['15-14'], ['21-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_2500_depth_7500_results.json\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['6-9'], ['14-18'], ['19-10'], ['16-24'], ['11-2'], ['24-29'], ['7-12'], ['15-14'], ['17-0'], ['17-31'], ['18-30'], ['21-4'], ['12-4']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 3.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
<<<<<<< Updated upstream
      "Score: 97.7651059627533\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant/llama-2-7b-80k_id_43_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['24-29'], ['6-9'], ['11-15'], ['8-26'], ['21-30'], ['17-22'], ['19-15'], ['7-4'], ['7-12'], ['11-2'], ['26-28'], ['6-30'], ['20-29'], ['29-26'], ['12-26'], ['15-14'], ['17-16'], ['21-28'], ['23-31']]\n",
=======
      "Score: 90.49102067947388\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches. The 2018–19 season was the 121st season in the existence of the club and the 10th\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['8-26'], ['17-22'], ['19-15'], ['21-30'], ['6-9'], ['14-18'], ['16-24'], ['19-10'], ['11-2'], ['17-0'], ['24-29'], ['7-12'], ['15-14'], ['17-31'], ['18-30'], ['21-4'], ['12-4']]\n",
>>>>>>> Stashed changes
=======
      "No one received a majority of the votes on the ninth ballot.\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 32.98633396625519\n",
      "Response: On the ninth ballot, the House of Representatives elected Kevin McCarthy as Speaker of the House.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_2500_depth_7500_results.json\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 26.737064123153687\n",
      "Response: On the ninth ballot, the House of Representatives voted 203-212 to elect Kevin McCarthy as Speaker of the House.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
      "Score: 96.57951593399048\n",
      "Response: Yes, Elon Musk is still X Corp.'s CEO.\n",
=======
      "Score: 32.98633396625519\n",
      "Response: On the ninth ballot, the House of Representatives elected Kevin McCarthy as Speaker of the House.\n",
>>>>>>> Stashed changes
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_3750_depth_0_results.json\n",
      "insertion at 863\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 32.98633396625519\n",
      "Response: On the ninth ballot, the House of Representatives elected Kevin McCarthy as Speaker of the House.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1750\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
<<<<<<< Updated upstream
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 59.69575643539429\n",
      "Response: No, Linda Yaccarino is the CEO of X Corp.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant/llama-2-7b-80k_id_43_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2353\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 24.194729328155518\n",
      "Response: No, he is not.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant/llama-2-7b-80k_id_43_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3577\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['24-29'], ['6-9'], ['11-15'], ['8-26'], ['21-30'], ['19-15'], ['17-22'], ['7-4'], ['7-12'], ['6-30'], ['11-2'], ['20-29'], ['26-28'], ['29-26'], ['21-28'], ['12-2'], ['12-26'], ['15-14'], ['23-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 97.7651059627533\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant/llama-2-7b-80k_id_43_relevant_len_5000_depth_7500_results.json\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['24-29'], ['6-9'], ['11-15'], ['8-26'], ['21-30'], ['19-15'], ['17-22'], ['7-4'], ['6-30'], ['7-12'], ['20-29'], ['29-26'], ['11-2'], ['12-26'], ['21-28'], ['26-28'], ['15-14'], ['31-16'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 97.7651059627533\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant/llama-2-7b-80k_id_43_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/43.txt\n",
=======
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_3750_depth_0_results.json\n",
      "insertion at 749\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['6-9'], ['7-4'], ['19-15'], ['21-30'], ['7-12'], ['14-18'], ['11-2'], ['19-10'], ['15-14'], ['16-24'], ['17-0'], ['24-29'], ['17-31'], ['18-30'], ['21-4'], ['22-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1714\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['6-9'], ['7-4'], ['19-15'], ['21-30'], ['7-12'], ['14-18'], ['19-10'], ['11-2'], ['15-14'], ['16-24'], ['17-0'], ['24-29'], ['17-31'], ['18-30'], ['21-4'], ['22-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2618\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['6-9'], ['8-26'], ['19-15'], ['7-4'], ['7-12'], ['21-30'], ['14-18'], ['11-2'], ['15-14'], ['19-10'], ['24-29'], ['17-31'], ['16-24'], ['17-0'], ['6-16'], ['18-30'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 81.48105144500732\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches. On 27 April 2024, Sheffield United became the first team relegated to the Championship after a 5–1\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_3750_depth_7500_results.json\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['6-9'], ['8-26'], ['19-15'], ['7-4'], ['21-30'], ['7-12'], ['14-18'], ['11-2'], ['15-14'], ['19-10'], ['24-29'], ['17-31'], ['16-24'], ['17-0'], ['14-15'], ['21-4'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 81.91807866096497\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches. The 2018–19 season was the 121st season in the existence of the Aston Villa Football Club and the\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['8-26'], ['6-9'], ['19-15'], ['7-4'], ['21-30'], ['7-12'], ['14-18'], ['11-2'], ['15-14'], ['24-29'], ['19-10'], ['17-31'], ['16-24'], ['17-0'], ['14-15'], ['21-4'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1179\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['8-26'], ['6-9'], ['19-15'], ['7-4'], ['21-30'], ['7-12'], ['14-18'], ['15-14'], ['11-2'], ['24-29'], ['19-10'], ['17-31'], ['16-24'], ['17-0'], ['14-15'], ['18-30'], ['21-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2371\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['8-26'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['7-12'], ['14-18'], ['15-14'], ['24-29'], ['11-2'], ['19-10'], ['17-31'], ['16-24'], ['17-0'], ['14-15'], ['18-30'], ['22-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3521\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['8-26'], ['19-15'], ['6-9'], ['7-4'], ['21-30'], ['7-12'], ['14-18'], ['15-14'], ['24-29'], ['19-10'], ['11-2'], ['17-31'], ['16-24'], ['17-0'], ['14-15'], ['18-30'], ['22-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_5000_depth_7500_results.json\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['7-4'], ['19-15'], ['6-9'], ['8-26'], ['21-30'], ['14-18'], ['7-12'], ['15-14'], ['24-29'], ['19-10'], ['11-2'], ['17-31'], ['16-24'], ['14-15'], ['17-0'], ['24-3'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 81.91807866096497\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches. The 2018–19 season was the 121st season in the existence of the Aston Villa Football Club and the\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant/llama-2-7b-80k_id_449_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_relevant/449.txt\n",
>>>>>>> Stashed changes
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
=======
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.40it/s]\n"
>>>>>>> Stashed changes
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
<<<<<<< Updated upstream
      "- Needle: Elon Musk is no longer X Corp.'s CEO.\n",
=======
      "- Needle: The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
>>>>>>> Stashed changes
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
<<<<<<< Updated upstream
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 24.194729328155518\n",
      "Response: No, he is not.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant_misleading/llama-2-7b-80k_id_43_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 24.194729328155518\n",
      "Response: No, he is not.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant_misleading/llama-2-7b-80k_id_43_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 24.194729328155518\n",
      "Response: No, he is not.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant_misleading/llama-2-7b-80k_id_43_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 24.194729328155518\n",
      "Response: No, he is not.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant_misleading/llama-2-7b-80k_id_43_relevant_misleading_len_0_depth_7500_results.json\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 24.194729328155518\n",
      "Response: No, he is not.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant_misleading/llama-2-7b-80k_id_43_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['7-12'], ['1-17'], ['6-9'], ['17-16'], ['0-0'], ['0-1'], ['0-2'], ['0-3'], ['0-4'], ['0-5'], ['0-6'], ['0-7'], ['0-8'], ['0-9'], ['0-10'], ['0-11'], ['0-12'], ['0-13'], ['0-14'], ['0-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 96.57951593399048\n",
      "Response: Yes, Elon Musk is still X Corp.'s CEO.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant_misleading/llama-2-7b-80k_id_43_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 231\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['7-12'], ['11-15'], ['6-9'], ['16-19'], ['24-29'], ['17-22'], ['7-4'], ['8-26'], ['11-2'], ['17-16'], ['19-15'], ['21-30'], ['1-17'], ['6-16'], ['6-30'], ['12-2'], ['12-16'], ['14-24'], ['19-10'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 91.55810475349426\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO. Elon Musk is the CEO of Tesla, Inc. and SpaceX, and he is also the CEO of X Corp.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant_misleading/llama-2-7b-80k_id_43_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 517\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['6-9'], ['11-15'], ['7-12'], ['16-19'], ['24-29'], ['17-22'], ['8-26'], ['7-4'], ['11-2'], ['21-30'], ['17-16'], ['19-15'], ['26-28'], ['6-16'], ['6-30'], ['12-2'], ['12-16'], ['19-10'], ['1-17'], ['14-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 97.7651059627533\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant_misleading/llama-2-7b-80k_id_43_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 756\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['11-15'], ['6-9'], ['7-12'], ['16-19'], ['24-29'], ['17-22'], ['8-26'], ['7-4'], ['11-2'], ['21-30'], ['19-15'], ['26-28'], ['17-16'], ['6-16'], ['6-30'], ['12-2'], ['19-10'], ['12-16'], ['21-16'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 80.41715621948242\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO. In June, Musk told Twitter employees that Twitter is a \"digital town square\" that should be all-encompassing, like WeChat.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant_misleading/llama-2-7b-80k_id_43_relevant_misleading_len_1250_depth_7500_results.json\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['6-9'], ['16-19'], ['11-15'], ['24-29'], ['7-12'], ['8-26'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['11-2'], ['26-28'], ['6-30'], ['12-2'], ['12-26'], ['17-16'], ['19-10'], ['21-16'], ['22-22'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 97.7651059627533\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant_misleading/llama-2-7b-80k_id_43_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['6-9'], ['16-19'], ['11-15'], ['24-29'], ['7-12'], ['8-26'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['11-2'], ['26-28'], ['6-30'], ['17-16'], ['12-2'], ['12-26'], ['19-10'], ['21-16'], ['22-22'], ['23-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 96.57951593399048\n",
      "Response: Yes, Elon Musk is still X Corp.'s CEO.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant_misleading/llama-2-7b-80k_id_43_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 569\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 24.194729328155518\n",
      "Response: No, he is not.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant_misleading/llama-2-7b-80k_id_43_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1110\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 24.194729328155518\n",
      "Response: No, he is not.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant_misleading/llama-2-7b-80k_id_43_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1698\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 24.194729328155518\n",
      "Response: No, he is not.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant_misleading/llama-2-7b-80k_id_43_relevant_misleading_len_2500_depth_7500_results.json\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['7-12'], ['11-2'], ['6-30'], ['26-28'], ['12-26'], ['12-2'], ['15-14'], ['17-16'], ['29-26'], ['31-16'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 97.7651059627533\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant_misleading/llama-2-7b-80k_id_43_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['24-29'], ['8-26'], ['17-22'], ['7-4'], ['19-15'], ['21-30'], ['7-12'], ['11-2'], ['6-30'], ['26-28'], ['12-2'], ['12-26'], ['17-16'], ['15-14'], ['29-26'], ['31-16'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 96.57951593399048\n",
      "Response: Yes, Elon Musk is still X Corp.'s CEO.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant_misleading/llama-2-7b-80k_id_43_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 881\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 24.194729328155518\n",
      "Response: No, he is not.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_relevant_misleading/llama-2-7b-80k_id_43_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1759\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
=======
>>>>>>> Stashed changes
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 32.98633396625519\n",
      "Response: On the ninth ballot, the House of Representatives elected Kevin McCarthy as Speaker of the House.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2624\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 34.943220019340515\n",
      "Response: On the ninth ballot, the House of Representatives voted to elect Kevin McCarthy as Speaker of the House. This was the first time in over 100 years that a speaker had been elected on the ninth ballot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_3750_depth_7500_results.json\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 3.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 26.737064123153687\n",
      "Response: On the ninth ballot, the House of Representatives voted 203-212 to elect Kevin McCarthy as Speaker of the House.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 4.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 33.77061486244202\n",
      "Response: On the ninth ballot, the House of Representatives voted to elect Kevin McCarthy as Speaker of the House. This was the longest speaker election in history, with 15 ballots being cast. McCarthy was able to secure\n",
      "\n",
<<<<<<< Updated upstream
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant/llama-2-7b-80k_id_43_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1139\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-12'], ['24-29'], ['21-30'], ['19-15'], ['17-22'], ['7-4'], ['11-2'], ['12-26'], ['6-16'], ['19-10'], ['12-2'], ['21-16'], ['6-30'], ['26-28'], ['14-7'], ['20-29']]\n",
=======
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['8-26'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-15'], ['11-17'], ['12-0'], ['12-4'], ['12-6'], ['12-26'], ['14-18'], ['15-25'], ['16-24'], ['17-0'], ['17-31'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['8-26'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-15'], ['11-17'], ['12-0'], ['12-4'], ['12-6'], ['12-26'], ['14-18'], ['15-25'], ['16-24'], ['17-0'], ['17-31'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['8-26'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-15'], ['11-17'], ['12-0'], ['12-4'], ['12-6'], ['12-26'], ['14-18'], ['15-25'], ['16-24'], ['17-0'], ['17-31'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['8-26'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-15'], ['11-17'], ['12-0'], ['12-4'], ['12-6'], ['12-26'], ['14-18'], ['15-25'], ['16-24'], ['17-0'], ['17-31'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_0_depth_7500_results.json\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['8-26'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-15'], ['11-17'], ['12-0'], ['12-4'], ['12-6'], ['12-26'], ['14-18'], ['15-25'], ['16-24'], ['17-0'], ['17-31'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['12-4'], ['14-18'], ['16-24'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-17'], ['12-0'], ['12-6'], ['12-26'], ['15-25'], ['17-0'], ['17-31'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['12-4'], ['14-18'], ['16-24'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-17'], ['12-0'], ['12-6'], ['12-26'], ['15-25'], ['17-0'], ['17-31'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['12-4'], ['14-18'], ['16-24'], ['17-22'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-17'], ['12-0'], ['12-6'], ['12-26'], ['15-25'], ['17-0'], ['17-31'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 749\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-12'], ['19-15'], ['6-9'], ['7-4'], ['14-18'], ['17-22'], ['21-30'], ['11-2'], ['12-4'], ['16-24'], ['19-10'], ['17-31'], ['18-30'], ['21-4'], ['12-26'], ['17-0'], ['22-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-4'], ['19-15'], ['6-9'], ['21-30'], ['17-22'], ['7-12'], ['14-18'], ['11-2'], ['19-10'], ['16-24'], ['21-4'], ['12-4'], ['17-0'], ['17-31'], ['18-30'], ['12-26'], ['22-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-4'], ['19-15'], ['6-9'], ['17-22'], ['21-30'], ['7-12'], ['14-18'], ['11-2'], ['16-24'], ['19-10'], ['21-4'], ['12-4'], ['17-0'], ['17-31'], ['18-30'], ['24-29'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-12'], ['14-18'], ['16-24'], ['11-2'], ['19-10'], ['21-4'], ['24-29'], ['12-4'], ['17-0'], ['17-31'], ['18-30'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1131\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['7-12'], ['14-18'], ['16-24'], ['19-10'], ['11-2'], ['24-29'], ['17-0'], ['17-31'], ['18-30'], ['21-4'], ['12-4'], ['22-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1708\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['7-4'], ['17-22'], ['19-15'], ['6-9'], ['21-30'], ['14-18'], ['7-12'], ['16-24'], ['19-10'], ['24-29'], ['11-2'], ['17-0'], ['17-31'], ['18-30'], ['12-4'], ['21-4'], ['22-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['8-26'], ['19-15'], ['17-22'], ['21-30'], ['6-9'], ['14-18'], ['19-10'], ['16-24'], ['11-2'], ['24-29'], ['7-12'], ['17-0'], ['17-31'], ['18-30'], ['21-4'], ['15-14'], ['22-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 87.03744411468506\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches. The 2018–19 Premier League was the 27th season of the Premier League, the top English professional league for association\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['8-26'], ['17-22'], ['19-15'], ['21-30'], ['6-9'], ['14-18'], ['16-24'], ['19-10'], ['11-2'], ['24-29'], ['7-12'], ['17-0'], ['17-31'], ['18-30'], ['21-4'], ['15-14'], ['22-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 749\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['8-26'], ['17-22'], ['19-15'], ['21-30'], ['6-9'], ['14-18'], ['16-24'], ['19-10'], ['24-29'], ['11-2'], ['7-12'], ['17-0'], ['17-31'], ['18-30'], ['15-14'], ['21-4'], ['22-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1737\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['6-9'], ['14-18'], ['16-24'], ['19-10'], ['24-29'], ['11-2'], ['17-0'], ['17-31'], ['18-30'], ['7-12'], ['15-14'], ['22-9'], ['21-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2625\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['6-9'], ['14-18'], ['16-24'], ['19-10'], ['24-29'], ['17-0'], ['17-31'], ['18-30'], ['11-2'], ['15-14'], ['22-9'], ['7-12'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['19-15'], ['17-22'], ['8-26'], ['21-30'], ['6-9'], ['14-18'], ['19-10'], ['16-24'], ['11-2'], ['24-29'], ['15-14'], ['17-0'], ['17-31'], ['18-30'], ['14-15'], ['22-9'], ['21-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 82.04152584075928\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches. The 2018–19 season was the 119th season in the existence of the Aston Villa Football Club and the\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['6-9'], ['14-18'], ['19-10'], ['16-24'], ['24-29'], ['11-2'], ['15-14'], ['17-0'], ['17-31'], ['18-30'], ['14-15'], ['22-9'], ['21-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1179\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['17-22'], ['19-15'], ['8-26'], ['21-30'], ['6-9'], ['14-18'], ['19-10'], ['16-24'], ['24-29'], ['11-2'], ['15-14'], ['17-0'], ['17-31'], ['18-30'], ['14-15'], ['22-9'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2352\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "-- Test Summary -- \n",
      "Duration: 4.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 33.59647989273071\n",
      "Response: 9 matches. On 19 December 2023, Nottingham Forest became the second club to sack their manager, dismissing Steve Cooper after Forest had won one game from 13 league games played. His last game\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3517\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['17-22'], ['19-15'], ['21-30'], ['8-26'], ['6-9'], ['14-18'], ['19-10'], ['16-24'], ['24-29'], ['15-14'], ['17-0'], ['11-2'], ['17-31'], ['18-30'], ['14-15'], ['22-9'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['19-15'], ['17-22'], ['21-30'], ['8-26'], ['6-9'], ['14-18'], ['19-10'], ['24-29'], ['15-14'], ['16-24'], ['11-2'], ['14-15'], ['17-0'], ['17-31'], ['18-30'], ['22-9'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 81.91807866096497\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches. The 2018–19 season was the 121st season in the existence of the Aston Villa Football Club and the\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_relevant_misleading/llama-2-7b-80k_id_449_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['8-26'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-15'], ['11-17'], ['12-0'], ['12-4'], ['12-6'], ['12-26'], ['14-18'], ['15-25'], ['16-24'], ['17-0'], ['17-31'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['8-26'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-15'], ['11-17'], ['12-0'], ['12-4'], ['12-6'], ['12-26'], ['14-18'], ['15-25'], ['16-24'], ['17-0'], ['17-31'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['8-26'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-15'], ['11-17'], ['12-0'], ['12-4'], ['12-6'], ['12-26'], ['14-18'], ['15-25'], ['16-24'], ['17-0'], ['17-31'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['8-26'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-15'], ['11-17'], ['12-0'], ['12-4'], ['12-6'], ['12-26'], ['14-18'], ['15-25'], ['16-24'], ['17-0'], ['17-31'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_0_depth_7500_results.json\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['8-26'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-15'], ['11-17'], ['12-0'], ['12-4'], ['12-6'], ['12-26'], ['14-18'], ['15-25'], ['16-24'], ['17-0'], ['17-31'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['14-18'], ['7-4'], ['11-17'], ['12-4'], ['16-24'], ['17-31'], ['18-30'], ['19-10'], ['6-9'], ['6-30'], ['7-13'], ['10-29'], ['12-0'], ['12-6'], ['12-26'], ['15-25'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 252\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['8-26'], ['14-18'], ['11-15'], ['12-4'], ['16-24'], ['17-31'], ['18-30'], ['19-10'], ['7-4'], ['11-17'], ['21-30'], ['22-9'], ['31-30'], ['6-9'], ['6-30'], ['7-13'], ['10-29'], ['12-0'], ['12-6']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 508\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['8-26'], ['14-18'], ['11-15'], ['12-4'], ['16-24'], ['17-31'], ['18-30'], ['19-10'], ['21-30'], ['22-9'], ['31-30'], ['7-4'], ['11-17'], ['6-9'], ['6-30'], ['7-13'], ['10-29'], ['12-0'], ['12-6']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 754\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['7-4'], ['14-18'], ['21-30'], ['6-9'], ['8-26'], ['17-31'], ['18-30'], ['19-10'], ['7-12'], ['12-4'], ['17-22'], ['19-15'], ['16-24'], ['31-30'], ['22-9'], ['11-17'], ['21-4'], ['25-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_1250_depth_7500_results.json\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['7-4'], ['21-30'], ['11-15'], ['6-9'], ['8-26'], ['14-18'], ['19-15'], ['17-22'], ['17-31'], ['19-10'], ['18-30'], ['12-4'], ['7-12'], ['15-14'], ['16-24'], ['22-9'], ['31-30'], ['11-2'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 85.2262556552887\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches. The 2018–19 season was the 121st season in the existence of the Manchester United F.C. and\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['7-4'], ['11-15'], ['21-30'], ['8-26'], ['6-9'], ['14-18'], ['19-15'], ['17-22'], ['17-31'], ['19-10'], ['18-30'], ['12-4'], ['7-12'], ['15-14'], ['16-24'], ['22-9'], ['31-30'], ['11-2'], ['11-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 561\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['7-4'], ['8-26'], ['6-9'], ['14-18'], ['17-22'], ['7-12'], ['19-15'], ['17-31'], ['18-30'], ['19-10'], ['11-2'], ['12-4'], ['15-14'], ['16-24'], ['6-16'], ['22-9'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1134\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['7-12'], ['17-22'], ['6-9'], ['8-26'], ['7-4'], ['14-18'], ['19-15'], ['17-31'], ['11-2'], ['18-30'], ['19-10'], ['6-16'], ['12-4'], ['24-29'], ['15-14'], ['14-15'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1664\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['7-12'], ['21-30'], ['17-22'], ['6-9'], ['8-26'], ['7-4'], ['14-18'], ['19-15'], ['17-31'], ['11-2'], ['6-16'], ['18-30'], ['19-10'], ['24-29'], ['12-4'], ['15-14'], ['14-15'], ['31-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_2500_depth_7500_results.json\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['7-4'], ['17-22'], ['7-12'], ['8-26'], ['19-15'], ['14-18'], ['17-31'], ['11-2'], ['6-16'], ['18-30'], ['19-10'], ['24-29'], ['15-14'], ['14-15'], ['12-4'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 81.91807866096497\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches. The 2018–19 season was the 121st season in the existence of the Aston Villa Football Club and the\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['17-22'], ['7-4'], ['7-12'], ['8-26'], ['14-18'], ['19-15'], ['17-31'], ['11-2'], ['6-16'], ['18-30'], ['19-10'], ['24-29'], ['15-14'], ['12-4'], ['14-15'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 839\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['17-22'], ['6-9'], ['7-4'], ['7-12'], ['8-26'], ['14-18'], ['19-15'], ['17-31'], ['11-2'], ['18-30'], ['19-10'], ['6-16'], ['24-29'], ['15-14'], ['12-4'], ['14-15'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1757\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['17-22'], ['6-9'], ['7-4'], ['7-12'], ['8-26'], ['14-18'], ['19-15'], ['17-31'], ['11-2'], ['18-30'], ['19-10'], ['6-16'], ['15-14'], ['24-29'], ['12-4'], ['14-15'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2645\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['17-22'], ['6-9'], ['7-4'], ['7-12'], ['8-26'], ['14-18'], ['19-15'], ['17-31'], ['11-2'], ['18-30'], ['19-10'], ['6-16'], ['15-14'], ['24-29'], ['12-4'], ['14-15'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_3750_depth_7500_results.json\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['7-4'], ['17-22'], ['6-9'], ['8-26'], ['14-18'], ['19-15'], ['7-12'], ['17-31'], ['11-2'], ['19-10'], ['18-30'], ['15-14'], ['24-29'], ['6-16'], ['14-15'], ['12-4'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 81.91807866096497\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches. The 2018–19 season was the 121st season in the existence of the Aston Villa Football Club and the\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['7-4'], ['17-22'], ['6-9'], ['8-26'], ['14-18'], ['19-15'], ['7-12'], ['17-31'], ['11-2'], ['19-10'], ['18-30'], ['15-14'], ['24-29'], ['6-16'], ['14-15'], ['12-4'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1167\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['17-22'], ['7-4'], ['6-9'], ['8-26'], ['14-18'], ['19-15'], ['7-12'], ['17-31'], ['11-2'], ['19-10'], ['18-30'], ['15-14'], ['24-29'], ['14-15'], ['6-16'], ['12-4'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2348\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['17-22'], ['7-4'], ['6-9'], ['14-18'], ['8-26'], ['19-15'], ['7-12'], ['17-31'], ['19-10'], ['11-2'], ['18-30'], ['15-14'], ['24-29'], ['14-15'], ['6-16'], ['12-4'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3577\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['17-22'], ['7-4'], ['6-9'], ['14-18'], ['8-26'], ['19-15'], ['7-12'], ['17-31'], ['19-10'], ['11-2'], ['18-30'], ['15-14'], ['24-29'], ['14-15'], ['12-4'], ['6-16'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_5000_depth_7500_results.json\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['7-4'], ['17-22'], ['6-9'], ['8-26'], ['19-15'], ['14-18'], ['7-12'], ['17-31'], ['19-10'], ['11-2'], ['15-14'], ['18-30'], ['14-15'], ['24-29'], ['12-4'], ['16-24'], ['6-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 81.91807866096497\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches. The 2018–19 season was the 121st season in the existence of the Aston Villa Football Club and the\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant/llama-2-7b-80k_id_449_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_irrelevant/449.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['8-26'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-15'], ['11-17'], ['12-0'], ['12-4'], ['12-6'], ['12-26'], ['14-18'], ['15-25'], ['16-24'], ['17-0'], ['17-31'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['8-26'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-15'], ['11-17'], ['12-0'], ['12-4'], ['12-6'], ['12-26'], ['14-18'], ['15-25'], ['16-24'], ['17-0'], ['17-31'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['8-26'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-15'], ['11-17'], ['12-0'], ['12-4'], ['12-6'], ['12-26'], ['14-18'], ['15-25'], ['16-24'], ['17-0'], ['17-31'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['8-26'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-15'], ['11-17'], ['12-0'], ['12-4'], ['12-6'], ['12-26'], ['14-18'], ['15-25'], ['16-24'], ['17-0'], ['17-31'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['8-26'], ['16-19'], ['6-9'], ['6-30'], ['7-4'], ['7-13'], ['10-29'], ['11-15'], ['11-17'], ['12-0'], ['12-4'], ['12-6'], ['12-26'], ['14-18'], ['15-25'], ['16-24'], ['17-0'], ['17-31'], ['18-30'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['8-26'], ['16-19'], ['11-15'], ['21-30'], ['7-4'], ['11-17'], ['14-18'], ['16-24'], ['18-30'], ['19-10'], ['21-1'], ['6-9'], ['6-30'], ['7-13'], ['10-29'], ['12-0'], ['12-4'], ['12-6'], ['12-26'], ['15-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 252\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['7-12'], ['8-26'], ['21-30'], ['6-9'], ['11-15'], ['19-10'], ['7-4'], ['14-18'], ['17-22'], ['17-31'], ['18-30'], ['19-15'], ['11-17'], ['16-24'], ['21-1'], ['21-4'], ['22-9'], ['29-26'], ['6-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 508\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['21-30'], ['7-12'], ['8-26'], ['11-15'], ['6-9'], ['19-10'], ['14-18'], ['17-22'], ['17-31'], ['18-30'], ['7-4'], ['19-15'], ['11-17'], ['16-24'], ['22-9'], ['12-6'], ['17-0'], ['21-1'], ['21-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 754\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['21-30'], ['7-12'], ['8-26'], ['11-15'], ['6-9'], ['19-10'], ['14-18'], ['17-22'], ['18-30'], ['17-31'], ['19-15'], ['7-4'], ['16-24'], ['22-9'], ['11-17'], ['17-0'], ['12-6'], ['21-1'], ['21-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['21-30'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['17-22'], ['19-15'], ['14-18'], ['7-12'], ['19-10'], ['18-30'], ['17-31'], ['22-9'], ['16-24'], ['17-0'], ['11-2'], ['11-17'], ['12-6'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 90.49980640411377\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches. The 2018–19 season was the 123rd season in the existence of the club and the 11th\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['21-30'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['14-18'], ['7-12'], ['19-10'], ['18-30'], ['17-31'], ['16-24'], ['22-9'], ['11-17'], ['15-14'], ['17-0'], ['10-29'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 561\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['21-30'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['14-18'], ['19-10'], ['7-12'], ['18-30'], ['16-24'], ['17-31'], ['22-9'], ['11-17'], ['15-14'], ['17-0'], ['10-29'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1129\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['21-30'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['14-18'], ['19-10'], ['7-12'], ['18-30'], ['16-24'], ['17-31'], ['22-9'], ['11-17'], ['15-14'], ['17-0'], ['14-15'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1687\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['21-30'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['17-22'], ['19-15'], ['14-18'], ['19-10'], ['18-30'], ['7-12'], ['16-24'], ['17-31'], ['22-9'], ['15-14'], ['11-17'], ['17-0'], ['14-15'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 50.41547417640686\n",
      "Response: 9 matches.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['21-30'], ['7-4'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['17-22'], ['14-18'], ['19-10'], ['18-30'], ['15-14'], ['16-24'], ['17-31'], ['22-9'], ['7-12'], ['14-15'], ['11-2'], ['12-26'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 80.99350929260254\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches. The 2018–19 season was the 129th season in the existence of the Aston Villa Football Club and the\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 45.75374126434326\n",
      "Response: 10 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 862\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 44.680023193359375\n",
      "Response: 12 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1764\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 44.680023193359375\n",
      "Response: 12 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2621\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['21-30'], ['7-4'], ['11-15'], ['19-15'], ['6-9'], ['8-26'], ['17-22'], ['14-18'], ['19-10'], ['18-30'], ['15-14'], ['16-24'], ['17-31'], ['22-9'], ['7-12'], ['14-15'], ['11-2'], ['11-17'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['21-30'], ['7-4'], ['11-15'], ['19-15'], ['8-26'], ['6-9'], ['17-22'], ['14-18'], ['19-10'], ['15-14'], ['18-30'], ['14-15'], ['16-24'], ['17-31'], ['22-9'], ['11-2'], ['12-26'], ['7-12'], ['21-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 81.91807866096497\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches. The 2018–19 season was the 121st season in the existence of the Aston Villa Football Club and the\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 45.75374126434326\n",
      "Response: 10 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1190\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 44.680023193359375\n",
      "Response: 12 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2311\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['21-30'], ['7-4'], ['11-15'], ['19-15'], ['8-26'], ['6-9'], ['17-22'], ['14-18'], ['19-10'], ['15-14'], ['18-30'], ['14-15'], ['17-31'], ['22-9'], ['16-24'], ['11-2'], ['12-26'], ['7-12'], ['21-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3562\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['21-30'], ['7-4'], ['11-15'], ['19-15'], ['8-26'], ['17-22'], ['6-9'], ['14-18'], ['19-10'], ['15-14'], ['18-30'], ['14-15'], ['17-31'], ['22-9'], ['16-24'], ['11-2'], ['12-26'], ['7-12'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 50.798362493515015\n",
      "Response: 9 matches\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The longest winning streak in the last season of the Premier League consisted of 9 matches.\n",
      "[['16-19'], ['21-30'], ['7-4'], ['11-15'], ['19-15'], ['8-26'], ['17-22'], ['6-9'], ['14-18'], ['19-10'], ['15-14'], ['18-30'], ['14-15'], ['17-31'], ['22-9'], ['11-2'], ['16-24'], ['12-26'], ['21-4'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 81.91807866096497\n",
      "Response: The longest winning streak in the last season of the Premier League consisted of 9 matches. The 2018–19 season was the 121st season in the existence of the Aston Villa Football Club and the\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_449_irrelevant_misleading/llama-2-7b-80k_id_449_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['14-13'], ['14-18'], ['15-8'], ['15-14'], ['16-9'], ['16-19'], ['16-30'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25'], ['20-14'], ['21-15'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['14-13'], ['14-18'], ['15-8'], ['15-14'], ['16-9'], ['16-19'], ['16-30'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25'], ['20-14'], ['21-15'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['14-13'], ['14-18'], ['15-8'], ['15-14'], ['16-9'], ['16-19'], ['16-30'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25'], ['20-14'], ['21-15'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['14-13'], ['14-18'], ['15-8'], ['15-14'], ['16-9'], ['16-19'], ['16-30'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25'], ['20-14'], ['21-15'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_0_depth_7500_results.json\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['14-13'], ['14-18'], ['15-8'], ['15-14'], ['16-9'], ['16-19'], ['16-30'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25'], ['20-14'], ['21-15'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['16-19'], ['11-15'], ['14-18'], ['15-14'], ['16-30'], ['17-22'], ['19-15'], ['7-12'], ['17-0'], ['18-16'], ['19-8'], ['21-15'], ['21-28'], ['26-27'], ['14-13'], ['15-8'], ['16-9'], ['16-31'], ['17-28'], ['18-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_1250_depth_0_results.json\n",
      "insertion at 202\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['7-12'], ['21-30'], ['14-18'], ['15-14'], ['19-15'], ['8-26'], ['11-2'], ['16-30'], ['6-16'], ['17-0'], ['18-16'], ['19-8'], ['21-15'], ['21-28'], ['26-27'], ['14-13'], ['15-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 480\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['21-30'], ['7-12'], ['11-2'], ['8-26'], ['14-18'], ['15-14'], ['19-15'], ['6-16'], ['16-30'], ['6-9'], ['17-0'], ['18-16'], ['19-8'], ['21-15'], ['21-28'], ['26-27'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 630\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['21-30'], ['6-9'], ['11-2'], ['7-12'], ['8-26'], ['19-15'], ['14-18'], ['15-14'], ['6-16'], ['16-30'], ['17-0'], ['18-16'], ['19-8'], ['21-15'], ['21-28'], ['24-29'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_1250_depth_7500_results.json\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['17-22'], ['11-2'], ['8-26'], ['19-15'], ['15-14'], ['7-12'], ['14-18'], ['6-16'], ['24-29'], ['16-30'], ['17-0'], ['7-4'], ['18-16'], ['21-15'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['21-30'], ['6-9'], ['11-2'], ['8-26'], ['19-15'], ['7-12'], ['15-14'], ['14-18'], ['6-16'], ['24-29'], ['16-30'], ['17-0'], ['7-4'], ['20-30'], ['21-15'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_2500_depth_0_results.json\n",
      "insertion at 553\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['17-22'], ['6-9'], ['21-30'], ['8-26'], ['11-2'], ['7-12'], ['19-15'], ['15-14'], ['6-16'], ['14-18'], ['24-29'], ['16-30'], ['17-0'], ['7-4'], ['20-30'], ['19-14'], ['21-5'], ['21-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 89.00516629219055\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio. Statewide legalization of recreational cannabis appeared on the ballot for the 2024 elections as 2024 Florida\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1120\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['17-22'], ['21-30'], ['8-26'], ['11-2'], ['6-16'], ['7-12'], ['19-15'], ['15-14'], ['14-18'], ['24-29'], ['16-30'], ['17-0'], ['20-30'], ['7-4'], ['19-14'], ['21-15'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1668\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['11-2'], ['6-16'], ['7-12'], ['19-15'], ['15-14'], ['14-18'], ['24-29'], ['16-30'], ['17-0'], ['7-4'], ['19-14'], ['20-30'], ['26-28'], ['22-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_2500_depth_7500_results.json\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['21-30'], ['8-26'], ['17-22'], ['11-2'], ['6-16'], ['19-15'], ['7-12'], ['15-14'], ['24-29'], ['14-18'], ['16-30'], ['7-4'], ['17-0'], ['19-14'], ['20-30'], ['22-30'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['17-22'], ['6-16'], ['19-15'], ['7-12'], ['15-14'], ['24-29'], ['14-18'], ['16-30'], ['7-4'], ['17-0'], ['19-14'], ['20-30'], ['22-30'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_3750_depth_0_results.json\n",
      "insertion at 858\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['11-2'], ['21-30'], ['17-22'], ['6-16'], ['7-12'], ['19-15'], ['15-14'], ['24-29'], ['14-18'], ['16-30'], ['7-4'], ['19-14'], ['20-30'], ['17-0'], ['22-30'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1751\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['11-2'], ['21-30'], ['6-16'], ['17-22'], ['7-12'], ['19-15'], ['15-14'], ['24-29'], ['14-18'], ['16-30'], ['7-4'], ['19-14'], ['20-30'], ['22-30'], ['17-0'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2629\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['11-2'], ['6-16'], ['21-30'], ['17-22'], ['7-12'], ['19-15'], ['15-14'], ['24-29'], ['14-18'], ['16-30'], ['7-4'], ['19-14'], ['20-30'], ['22-30'], ['26-28'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_3750_depth_7500_results.json\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['11-2'], ['21-30'], ['6-16'], ['17-22'], ['19-15'], ['7-12'], ['24-29'], ['15-14'], ['7-4'], ['14-18'], ['16-30'], ['30-14'], ['19-14'], ['20-30'], ['22-30'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['11-2'], ['21-30'], ['17-22'], ['6-16'], ['19-15'], ['7-12'], ['15-14'], ['24-29'], ['14-18'], ['7-4'], ['16-30'], ['19-14'], ['30-14'], ['20-30'], ['22-30'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1184\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['11-2'], ['21-30'], ['6-16'], ['17-22'], ['7-12'], ['19-15'], ['24-29'], ['15-14'], ['14-18'], ['16-30'], ['7-4'], ['20-30'], ['19-14'], ['22-30'], ['26-28'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2281\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['11-2'], ['6-16'], ['21-30'], ['17-22'], ['7-12'], ['19-15'], ['24-29'], ['15-14'], ['14-18'], ['16-30'], ['7-4'], ['20-30'], ['19-14'], ['26-28'], ['22-30'], ['30-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3558\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-16'], ['11-2'], ['21-30'], ['17-22'], ['7-12'], ['19-15'], ['24-29'], ['15-14'], ['14-18'], ['16-30'], ['7-4'], ['20-30'], ['19-14'], ['26-28'], ['22-30'], ['30-14']]\n",
=======
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1154\n",
      "No one received a majority of the votes on the ninth ballot.\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 86.52812242507935\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio. Pritzker's signature on June 25, Illinois became the first state in the nation to legalize adult marijuana sales through an\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_5000_depth_7500_results.json\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['11-2'], ['21-30'], ['6-16'], ['17-22'], ['7-12'], ['19-15'], ['24-29'], ['15-14'], ['7-4'], ['14-18'], ['16-30'], ['20-30'], ['26-28'], ['30-14'], ['22-30'], ['19-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant/llama-2-7b-80k_id_453_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_relevant/453.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['14-13'], ['14-18'], ['15-8'], ['15-14'], ['16-9'], ['16-19'], ['16-30'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25'], ['20-14'], ['21-15'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['14-13'], ['14-18'], ['15-8'], ['15-14'], ['16-9'], ['16-19'], ['16-30'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25'], ['20-14'], ['21-15'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
<<<<<<< Updated upstream
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['14-13'], ['14-18'], ['15-8'], ['15-14'], ['16-9'], ['16-19'], ['16-30'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25'], ['20-14'], ['21-15'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['14-13'], ['14-18'], ['15-8'], ['15-14'], ['16-9'], ['16-19'], ['16-30'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25'], ['20-14'], ['21-15'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_0_depth_7500_results.json\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['14-13'], ['14-18'], ['15-8'], ['15-14'], ['16-9'], ['16-19'], ['16-30'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25'], ['20-14'], ['21-15'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['14-18'], ['15-14'], ['16-30'], ['17-0'], ['19-15'], ['21-15'], ['14-13'], ['15-8'], ['16-9'], ['16-19'], ['16-31'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-19'], ['19-25'], ['20-14'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 53.62040996551514\n",
      "Response: Ohio\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 202\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['14-18'], ['15-14'], ['16-30'], ['17-0'], ['19-15'], ['21-15'], ['14-13'], ['15-8'], ['16-9'], ['16-19'], ['16-31'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-19'], ['19-25'], ['20-14'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 480\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['14-18'], ['15-14'], ['16-30'], ['17-0'], ['19-15'], ['21-15'], ['14-13'], ['15-8'], ['16-9'], ['16-19'], ['16-31'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-19'], ['19-25'], ['20-14'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 655\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['14-18'], ['15-14'], ['16-30'], ['17-0'], ['19-15'], ['21-15'], ['14-13'], ['15-8'], ['16-9'], ['16-19'], ['16-31'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-19'], ['19-25'], ['20-14'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 53.62040996551514\n",
      "Response: Ohio\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['19-15'], ['15-14'], ['21-30'], ['14-18'], ['16-30'], ['17-0'], ['7-4'], ['21-15'], ['24-29'], ['8-26'], ['16-31'], ['18-3'], ['18-16'], ['19-8'], ['19-19'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['6-9'], ['15-14'], ['21-30'], ['8-26'], ['11-2'], ['14-18'], ['17-0'], ['17-22'], ['16-30'], ['21-15'], ['7-4'], ['24-29'], ['26-27'], ['16-31'], ['18-3'], ['18-16'], ['19-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 553\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['11-2'], ['21-30'], ['15-14'], ['19-15'], ['17-22'], ['6-16'], ['14-18'], ['16-30'], ['17-0'], ['7-4'], ['21-15'], ['24-29'], ['26-27'], ['7-12'], ['16-31'], ['18-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1091\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['11-2'], ['21-30'], ['6-16'], ['15-14'], ['17-22'], ['19-15'], ['14-18'], ['16-30'], ['17-0'], ['7-12'], ['24-29'], ['21-15'], ['7-4'], ['26-27'], ['12-26'], ['16-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1694\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['11-2'], ['21-30'], ['6-16'], ['19-15'], ['17-22'], ['15-14'], ['16-30'], ['24-29'], ['7-12'], ['14-18'], ['17-0'], ['21-15'], ['7-4'], ['26-27'], ['26-28'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['21-30'], ['8-26'], ['11-2'], ['19-15'], ['6-16'], ['17-22'], ['15-14'], ['24-29'], ['7-4'], ['16-30'], ['14-18'], ['17-0'], ['7-12'], ['30-14'], ['12-26'], ['21-15'], ['22-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['17-22'], ['6-16'], ['19-15'], ['15-14'], ['24-29'], ['7-4'], ['7-12'], ['14-18'], ['16-30'], ['17-0'], ['30-14'], ['12-26'], ['21-15'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 863\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['17-22'], ['6-16'], ['19-15'], ['15-14'], ['24-29'], ['7-4'], ['7-12'], ['14-18'], ['16-30'], ['17-0'], ['30-14'], ['12-26'], ['21-15'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1721\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['6-16'], ['17-22'], ['19-15'], ['15-14'], ['7-12'], ['24-29'], ['16-30'], ['7-4'], ['14-18'], ['17-0'], ['30-14'], ['12-26'], ['22-30'], ['21-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 98.51938486099243\n",
      "Response: Ohio, the latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2607\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['6-16'], ['17-22'], ['19-15'], ['15-14'], ['7-12'], ['24-29'], ['7-4'], ['16-30'], ['14-18'], ['17-0'], ['30-14'], ['12-26'], ['22-30'], ['21-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['21-30'], ['8-26'], ['11-2'], ['6-16'], ['19-15'], ['17-22'], ['15-14'], ['24-29'], ['7-4'], ['7-12'], ['30-14'], ['16-30'], ['14-18'], ['17-0'], ['12-26'], ['22-30'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['21-30'], ['8-26'], ['11-2'], ['6-16'], ['17-22'], ['19-15'], ['15-14'], ['24-29'], ['7-12'], ['7-4'], ['14-18'], ['30-14'], ['16-30'], ['17-0'], ['12-26'], ['22-30'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1176\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['21-30'], ['8-26'], ['11-2'], ['6-16'], ['17-22'], ['19-15'], ['7-12'], ['15-14'], ['24-29'], ['7-4'], ['14-18'], ['16-30'], ['30-14'], ['17-0'], ['12-26'], ['22-30'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2334\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['21-30'], ['8-26'], ['11-2'], ['6-16'], ['17-22'], ['19-15'], ['7-12'], ['15-14'], ['24-29'], ['7-4'], ['14-18'], ['16-30'], ['30-14'], ['12-26'], ['17-0'], ['22-30'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3566\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['21-30'], ['8-26'], ['11-2'], ['6-16'], ['17-22'], ['19-15'], ['7-12'], ['15-14'], ['24-29'], ['7-4'], ['16-30'], ['14-18'], ['30-14'], ['17-0'], ['22-30'], ['12-26'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 90.84913730621338\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio. Pat Quinn signed bill legalizing medical marijuana effective January 1, 2014. [72] May 31\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['21-30'], ['8-26'], ['11-2'], ['6-16'], ['17-22'], ['19-15'], ['7-12'], ['24-29'], ['15-14'], ['7-4'], ['30-14'], ['16-30'], ['14-18'], ['12-26'], ['22-30'], ['17-0'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_relevant_misleading/llama-2-7b-80k_id_453_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['14-13'], ['14-18'], ['15-8'], ['15-14'], ['16-9'], ['16-19'], ['16-30'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25'], ['20-14'], ['21-15'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['14-13'], ['14-18'], ['15-8'], ['15-14'], ['16-9'], ['16-19'], ['16-30'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25'], ['20-14'], ['21-15'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['14-13'], ['14-18'], ['15-8'], ['15-14'], ['16-9'], ['16-19'], ['16-30'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25'], ['20-14'], ['21-15'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['14-13'], ['14-18'], ['15-8'], ['15-14'], ['16-9'], ['16-19'], ['16-30'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25'], ['20-14'], ['21-15'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_0_depth_7500_results.json\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['14-13'], ['14-18'], ['15-8'], ['15-14'], ['16-9'], ['16-19'], ['16-30'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25'], ['20-14'], ['21-15'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['7-12'], ['14-18'], ['16-30'], ['21-28'], ['26-27'], ['14-13'], ['15-8'], ['15-14'], ['16-9'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 203\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['7-12'], ['14-18'], ['16-30'], ['21-28'], ['26-27'], ['14-13'], ['15-8'], ['15-14'], ['16-9'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 500\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['14-18'], ['7-12'], ['16-30'], ['21-28'], ['26-27'], ['14-13'], ['15-8'], ['15-14'], ['16-9'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 656\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['7-12'], ['14-18'], ['16-30'], ['21-28'], ['26-27'], ['14-13'], ['15-8'], ['15-14'], ['16-9'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_1250_depth_7500_results.json\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['21-30'], ['15-14'], ['19-15'], ['8-26'], ['14-18'], ['16-30'], ['17-22'], ['21-28'], ['26-27'], ['7-4'], ['7-12'], ['17-0'], ['24-29'], ['16-31'], ['17-28'], ['18-3'], ['18-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['7-12'], ['14-18'], ['17-22'], ['21-30'], ['11-2'], ['6-9'], ['15-14'], ['19-15'], ['24-29'], ['16-30'], ['21-28'], ['26-27'], ['17-0'], ['7-4'], ['21-15'], ['6-16'], ['16-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 554\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['7-12'], ['11-2'], ['6-16'], ['17-22'], ['21-30'], ['14-18'], ['24-29'], ['6-9'], ['15-14'], ['19-15'], ['16-30'], ['17-0'], ['21-28'], ['26-27'], ['7-4'], ['21-15'], ['16-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 90.3232216835022\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio. Allowed to drive with no more than four cannabis plants that are not flowering. [14]\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1135\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-16'], ['11-2'], ['21-30'], ['7-12'], ['24-29'], ['17-22'], ['6-9'], ['14-18'], ['15-14'], ['19-15'], ['16-30'], ['17-0'], ['21-28'], ['26-27'], ['7-4'], ['21-15'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1698\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-16'], ['11-2'], ['7-12'], ['21-30'], ['24-29'], ['17-22'], ['6-9'], ['14-18'], ['15-14'], ['19-15'], ['16-30'], ['17-0'], ['21-28'], ['26-27'], ['7-4'], ['21-15'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 53.62040996551514\n",
      "Response: Ohio\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_2500_depth_7500_results.json\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['21-30'], ['6-16'], ['24-29'], ['11-2'], ['17-22'], ['7-12'], ['15-14'], ['19-15'], ['7-4'], ['14-18'], ['16-30'], ['30-14'], ['17-0'], ['21-28'], ['22-22'], ['22-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 5.002827942371368\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 868\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['21-30'], ['6-16'], ['7-12'], ['11-2'], ['24-29'], ['17-22'], ['15-14'], ['19-15'], ['7-4'], ['16-30'], ['14-18'], ['17-0'], ['30-14'], ['22-30'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1752\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['21-30'], ['6-16'], ['7-12'], ['11-2'], ['24-29'], ['17-22'], ['15-14'], ['19-15'], ['7-4'], ['16-30'], ['14-18'], ['17-0'], ['30-14'], ['22-30'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 53.62040996551514\n",
      "Response: Ohio\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2577\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['21-30'], ['6-16'], ['7-12'], ['11-2'], ['24-29'], ['17-22'], ['15-14'], ['19-15'], ['7-4'], ['16-30'], ['14-18'], ['17-0'], ['30-14'], ['22-30'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 53.62040996551514\n",
      "Response: Ohio\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_3750_depth_7500_results.json\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['6-16'], ['24-29'], ['11-2'], ['17-22'], ['7-12'], ['15-14'], ['19-15'], ['7-4'], ['16-30'], ['30-14'], ['14-18'], ['17-0'], ['22-22'], ['22-30'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['21-30'], ['6-16'], ['11-2'], ['17-22'], ['7-12'], ['24-29'], ['15-14'], ['19-15'], ['7-4'], ['14-18'], ['16-30'], ['30-14'], ['22-22'], ['17-0'], ['22-30'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1177\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['21-30'], ['6-9'], ['6-16'], ['11-2'], ['17-22'], ['7-12'], ['24-29'], ['15-14'], ['19-15'], ['7-4'], ['16-30'], ['14-18'], ['30-14'], ['22-22'], ['17-0'], ['22-30'], ['14-7']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
<<<<<<< Updated upstream
      "Score: 82.38086700439453\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO. OpenAI's potential and mission drew these researchers to the firm; a Google employee said he was willing to leave Google for OpenAI \"partly because of\n",
=======
      "Score: 46.58166468143463\n",
      "Response: The ninth ballot was the final ballot in the 2023 Speaker of the House election. The election began on January 3, 2023, and the ninth ballot was held on January 7\n",
>>>>>>> Stashed changes
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2351\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 32.833823561668396\n",
      "Response: On the ninth ballot, Kevin McCarthy was elected Speaker of the House with 216 votes.\n",
      "\n",
<<<<<<< Updated upstream
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant/llama-2-7b-80k_id_43_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3542\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-12'], ['24-29'], ['21-30'], ['19-15'], ['17-22'], ['7-4'], ['11-2'], ['6-16'], ['12-26'], ['19-10'], ['12-2'], ['21-16'], ['6-30'], ['20-29'], ['14-7'], ['26-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 88.33683133125305\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO. In May 2024, significant leadership changes occurred as Chief Scientist Ilya Sutskever resigned—being succeeded by Jakub P\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant/llama-2-7b-80k_id_43_irrelevant_len_5000_depth_7500_results.json\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-12'], ['24-29'], ['21-30'], ['19-15'], ['17-22'], ['7-4'], ['12-26'], ['11-2'], ['19-10'], ['6-16'], ['12-2'], ['21-16'], ['20-29'], ['6-30'], ['26-28'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 97.7651059627533\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant/llama-2-7b-80k_id_43_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/43.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Elon Musk is no longer X Corp.'s CEO.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 24.194729328155518\n",
      "Response: No, he is not.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 24.194729328155518\n",
      "Response: No, he is not.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 24.194729328155518\n",
      "Response: No, he is not.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 24.194729328155518\n",
      "Response: No, he is not.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 24.194729328155518\n",
      "Response: No, he is not.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['7-12'], ['1-17'], ['11-15'], ['12-2'], ['17-16'], ['24-29'], ['0-0'], ['0-1'], ['0-2'], ['0-3'], ['0-4'], ['0-5'], ['0-6'], ['0-7'], ['0-8'], ['0-9'], ['0-10'], ['0-11'], ['0-12'], ['0-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 96.57951593399048\n",
      "Response: Yes, Elon Musk is still X Corp.'s CEO.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 252\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['7-12'], ['16-19'], ['11-15'], ['6-9'], ['8-26'], ['12-2'], ['7-4'], ['11-2'], ['17-16'], ['19-15'], ['24-29'], ['1-17'], ['6-16'], ['6-30'], ['13-11'], ['14-7'], ['14-18'], ['15-14'], ['17-22'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 97.7651059627533\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 477\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['7-12'], ['11-15'], ['6-9'], ['8-26'], ['19-15'], ['11-2'], ['12-2'], ['24-29'], ['17-16'], ['17-22'], ['21-30'], ['6-16'], ['6-30'], ['7-4'], ['13-11'], ['14-18'], ['19-10'], ['21-16'], ['22-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 97.7651059627533\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 670\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['11-15'], ['7-12'], ['6-9'], ['8-26'], ['19-15'], ['24-29'], ['11-2'], ['7-4'], ['17-22'], ['21-30'], ['12-2'], ['17-16'], ['6-16'], ['6-30'], ['13-11'], ['14-18'], ['19-10'], ['21-16'], ['26-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 97.7651059627533\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-12'], ['19-15'], ['24-29'], ['21-30'], ['7-4'], ['17-22'], ['11-2'], ['12-2'], ['6-30'], ['13-11'], ['19-10'], ['21-16'], ['26-28'], ['12-26'], ['17-16'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 97.7651059627533\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-12'], ['24-29'], ['19-15'], ['21-30'], ['7-4'], ['17-22'], ['11-2'], ['12-2'], ['17-16'], ['6-30'], ['13-11'], ['19-10'], ['21-16'], ['26-28'], ['12-26'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 96.57951593399048\n",
      "Response: Yes, Elon Musk is still X Corp.'s CEO.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 536\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-12'], ['24-29'], ['19-15'], ['21-30'], ['17-22'], ['12-2'], ['7-4'], ['11-2'], ['19-10'], ['26-28'], ['6-30'], ['13-11'], ['21-16'], ['17-16'], ['6-16'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 79.00553941726685\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO. In 2023 and 2024, OpenAI faced multiple lawsuits for alleged copyright infringement against authors and media\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1134\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-12'], ['24-29'], ['19-15'], ['21-30'], ['12-2'], ['17-22'], ['7-4'], ['11-2'], ['19-10'], ['26-28'], ['20-29'], ['6-16'], ['6-30'], ['13-11'], ['17-16'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 76.31150484085083\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO. Microsoft's Peter Lee stated that the cost of a top AI researcher exceeds the cost of a top NFL quarterback prospect. OpenAI's potential\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1695\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-12'], ['24-29'], ['19-15'], ['21-30'], ['7-4'], ['17-22'], ['12-2'], ['11-2'], ['26-28'], ['19-10'], ['6-16'], ['13-11'], ['20-29'], ['6-30'], ['17-16'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 67.72637963294983\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO. OpenAI, a non-profit artificial intelligence research organization, was founded in 2015 by Elon Musk and other prominent technology entrepreneurs\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['7-12'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['12-2'], ['11-2'], ['26-28'], ['13-11'], ['20-29'], ['19-10'], ['6-30'], ['12-26'], ['21-16'], ['6-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 97.7651059627533\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['7-12'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['12-2'], ['11-2'], ['26-28'], ['13-11'], ['6-16'], ['19-10'], ['20-29'], ['21-16'], ['6-30'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 93.224036693573\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO. He resigned from the position in 2023 and was replaced by Sam Altman.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 867\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['7-12'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['12-2'], ['6-16'], ['11-2'], ['19-10'], ['26-28'], ['13-11'], ['21-16'], ['6-30'], ['17-16'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 80.76168298721313\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO. According to an investigation led by TechCrunch, while YC Research never contributed any funds, Open Philanthropy contributed $30 million and another $1\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1763\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['24-29'], ['7-12'], ['19-15'], ['21-30'], ['17-22'], ['12-2'], ['7-4'], ['6-16'], ['11-2'], ['13-11'], ['19-10'], ['26-28'], ['21-16'], ['6-30'], ['17-16'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 97.7651059627533\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2615\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['24-29'], ['7-12'], ['19-15'], ['21-30'], ['17-22'], ['12-2'], ['7-4'], ['6-16'], ['11-2'], ['13-11'], ['19-10'], ['26-28'], ['21-16'], ['6-30'], ['17-16'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 74.75403547286987\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO. Rumors of this deal suggested that Microsoft may receive 75% of OpenAI's profits until it secures its investment return and a 4\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['24-29'], ['7-12'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['12-2'], ['11-2'], ['6-16'], ['6-30'], ['13-11'], ['19-10'], ['26-28'], ['21-16'], ['12-26'], ['20-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 97.7651059627533\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['24-29'], ['7-12'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['12-2'], ['6-16'], ['11-2'], ['6-30'], ['13-11'], ['19-10'], ['26-28'], ['21-16'], ['12-26'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 96.57951593399048\n",
      "Response: Yes, Elon Musk is still X Corp.'s CEO.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1162\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['24-29'], ['7-12'], ['19-15'], ['21-30'], ['17-22'], ['12-2'], ['7-4'], ['6-16'], ['11-2'], ['19-10'], ['6-30'], ['13-11'], ['21-16'], ['26-28'], ['12-26'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 82.38086700439453\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO. OpenAI's potential and mission drew these researchers to the firm; a Google employee said he was willing to leave Google for OpenAI \"partly because of\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2389\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['24-29'], ['7-12'], ['19-15'], ['21-30'], ['17-22'], ['12-2'], ['7-4'], ['6-16'], ['11-2'], ['19-10'], ['6-30'], ['13-11'], ['21-16'], ['26-28'], ['12-26'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 73.08324575424194\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO. In December 2022, OpenAI received widespread media coverage after launching a free preview of ChatGPT, its new AI\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3492\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['24-29'], ['7-12'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['12-2'], ['6-16'], ['11-2'], ['19-10'], ['6-30'], ['13-11'], ['21-16'], ['26-28'], ['12-26'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 86.8085503578186\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO. In February, amidst SEC probes and investigations into CEO Altman's communications OpenAI unveiled its text-to-video model\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "Elon Musk is no longer X Corp.'s CEO.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['24-29'], ['7-12'], ['19-15'], ['21-30'], ['17-22'], ['7-4'], ['12-2'], ['11-2'], ['6-16'], ['12-26'], ['19-10'], ['6-30'], ['13-11'], ['21-16'], ['26-28'], ['17-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 97.7651059627533\n",
      "Response: No, Elon Musk is no longer X Corp.'s CEO.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_43_irrelevant_misleading/llama-2-7b-80k_id_43_irrelevant_misleading_len_5000_depth_10000_results.json\n",
=======
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2363\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['21-30'], ['6-9'], ['6-16'], ['11-2'], ['17-22'], ['7-12'], ['24-29'], ['15-14'], ['19-15'], ['7-4'], ['14-18'], ['16-30'], ['30-14'], ['22-22'], ['17-0'], ['22-30'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 53.62040996551514\n",
      "Response: Ohio\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3582\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['21-30'], ['6-9'], ['6-16'], ['11-2'], ['17-22'], ['7-12'], ['24-29'], ['15-14'], ['19-15'], ['7-4'], ['16-30'], ['14-18'], ['30-14'], ['22-22'], ['17-0'], ['22-30'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 53.62040996551514\n",
      "Response: Ohio\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_5000_depth_7500_results.json\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['21-30'], ['6-16'], ['17-22'], ['11-2'], ['24-29'], ['7-12'], ['7-4'], ['15-14'], ['19-15'], ['30-14'], ['14-18'], ['16-30'], ['22-22'], ['22-30'], ['17-0'], ['3-6']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant/llama-2-7b-80k_id_453_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_irrelevant/453.txt\n",
>>>>>>> Stashed changes
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
<<<<<<< Updated upstream
      "- Needle: The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
=======
      "- Needle: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
>>>>>>> Stashed changes
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
<<<<<<< Updated upstream
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['6-9'], ['8-26'], ['11-15'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-31'], ['8-31'], ['9-8'], ['10-18'], ['14-18']]\n",
=======
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['14-13'], ['14-18'], ['15-8'], ['15-14'], ['16-9'], ['16-19'], ['16-30'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25'], ['20-14'], ['21-15'], ['21-28'], ['26-27']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
<<<<<<< Updated upstream
      "Score: 63.78287076950073\n",
      "Response: Aryna Sabalenka\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['6-9'], ['8-26'], ['11-15'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-31'], ['8-31'], ['9-8'], ['10-18'], ['14-18']]\n",
=======
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['14-13'], ['14-18'], ['15-8'], ['15-14'], ['16-9'], ['16-19'], ['16-30'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25'], ['20-14'], ['21-15'], ['21-28'], ['26-27']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
<<<<<<< Updated upstream
      "Score: 63.78287076950073\n",
      "Response: Aryna Sabalenka\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['6-9'], ['8-26'], ['11-15'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-31'], ['8-31'], ['9-8'], ['10-18'], ['14-18']]\n",
=======
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['14-13'], ['14-18'], ['15-8'], ['15-14'], ['16-9'], ['16-19'], ['16-30'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25'], ['20-14'], ['21-15'], ['21-28'], ['26-27']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
<<<<<<< Updated upstream
      "Score: 63.78287076950073\n",
      "Response: Aryna Sabalenka\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['6-9'], ['8-26'], ['11-15'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-31'], ['8-31'], ['9-8'], ['10-18'], ['14-18']]\n",
=======
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['14-13'], ['14-18'], ['15-8'], ['15-14'], ['16-9'], ['16-19'], ['16-30'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25'], ['20-14'], ['21-15'], ['21-28'], ['26-27']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
<<<<<<< Updated upstream
      "Score: 63.78287076950073\n",
      "Response: Aryna Sabalenka\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_0_depth_7500_results.json\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['6-9'], ['8-26'], ['11-15'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-31'], ['8-31'], ['9-8'], ['10-18'], ['14-18']]\n",
=======
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['14-13'], ['14-18'], ['15-8'], ['15-14'], ['16-9'], ['16-19'], ['16-30'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25'], ['20-14'], ['21-15'], ['21-28'], ['26-27']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
<<<<<<< Updated upstream
      "Score: 63.78287076950073\n",
      "Response: Aryna Sabalenka\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-31'], ['8-31'], ['9-8'], ['10-18'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 81.93468451499939\n",
      "Response: Martina Navratilova is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_1250_depth_0_results.json\n",
      "insertion at 250\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-31'], ['8-31'], ['9-8'], ['10-18'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 65.70635437965393\n",
      "Response: Martina Navratilova\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 334\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-31'], ['8-31'], ['9-8'], ['10-18'], ['14-18']]\n",
=======
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['7-12'], ['14-18'], ['16-30'], ['21-28'], ['26-27'], ['14-13'], ['15-8'], ['15-14'], ['16-9'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 203\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['7-12'], ['14-18'], ['16-30'], ['21-28'], ['26-27'], ['14-13'], ['15-8'], ['15-14'], ['16-9'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 500\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['14-18'], ['7-12'], ['16-30'], ['21-28'], ['26-27'], ['14-13'], ['15-8'], ['15-14'], ['16-9'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 656\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['7-12'], ['14-18'], ['16-30'], ['21-28'], ['26-27'], ['14-13'], ['15-8'], ['15-14'], ['16-9'], ['16-31'], ['17-0'], ['17-28'], ['18-3'], ['18-16'], ['19-8'], ['19-15'], ['19-19'], ['19-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['21-30'], ['15-14'], ['19-15'], ['8-26'], ['14-18'], ['16-30'], ['17-22'], ['21-28'], ['26-27'], ['7-4'], ['7-12'], ['17-0'], ['24-29'], ['16-31'], ['17-28'], ['18-3'], ['18-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['7-12'], ['14-18'], ['17-22'], ['21-30'], ['6-9'], ['15-14'], ['16-30'], ['19-15'], ['24-29'], ['11-2'], ['21-28'], ['26-27'], ['17-0'], ['7-4'], ['21-15'], ['16-31'], ['17-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 554\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['7-12'], ['6-9'], ['17-22'], ['21-30'], ['6-16'], ['11-2'], ['14-18'], ['16-30'], ['19-15'], ['24-29'], ['15-14'], ['17-0'], ['21-28'], ['26-27'], ['7-4'], ['21-15'], ['16-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 92.62136220932007\n",
      "Response: Ohio, the latest United States jurisdiction to legalize the recreational use of cannabis is Ohio. Allowed to drive with no more than four cannabis plants that are not flowering. [14]\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1135\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-12'], ['6-16'], ['11-2'], ['17-22'], ['21-30'], ['19-15'], ['14-18'], ['24-29'], ['15-14'], ['16-30'], ['17-0'], ['21-28'], ['26-27'], ['7-4'], ['21-15'], ['22-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 98.51938486099243\n",
      "Response: Ohio, the latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1709\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['6-16'], ['7-12'], ['11-2'], ['17-22'], ['21-30'], ['19-15'], ['14-18'], ['24-29'], ['15-14'], ['16-30'], ['17-0'], ['21-28'], ['26-27'], ['7-4'], ['21-15'], ['22-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 98.51938486099243\n",
      "Response: Ohio, the latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['6-16'], ['7-12'], ['21-30'], ['17-22'], ['11-2'], ['24-29'], ['19-15'], ['15-14'], ['14-18'], ['16-30'], ['7-4'], ['30-14'], ['17-0'], ['22-30'], ['21-28'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['6-16'], ['7-12'], ['21-30'], ['17-22'], ['11-2'], ['24-29'], ['19-15'], ['15-14'], ['14-18'], ['16-30'], ['7-4'], ['17-0'], ['30-14'], ['21-28'], ['26-27'], ['22-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 53.62040996551514\n",
      "Response: Ohio\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 868\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['6-16'], ['7-12'], ['21-30'], ['17-22'], ['11-2'], ['24-29'], ['19-15'], ['15-14'], ['14-18'], ['16-30'], ['7-4'], ['17-0'], ['30-14'], ['21-28'], ['26-27'], ['22-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 53.62040996551514\n",
      "Response: Ohio\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1749\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['6-16'], ['7-12'], ['21-30'], ['17-22'], ['11-2'], ['24-29'], ['19-15'], ['15-14'], ['14-18'], ['7-4'], ['16-30'], ['17-0'], ['30-14'], ['21-28'], ['26-27'], ['22-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 53.62040996551514\n",
      "Response: Ohio\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2630\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['6-16'], ['7-12'], ['21-30'], ['17-22'], ['11-2'], ['24-29'], ['19-15'], ['15-14'], ['14-18'], ['16-30'], ['7-4'], ['17-0'], ['30-14'], ['21-28'], ['26-27'], ['22-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 53.62040996551514\n",
      "Response: Ohio\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['21-30'], ['6-16'], ['17-22'], ['7-12'], ['24-29'], ['11-2'], ['19-15'], ['7-4'], ['15-14'], ['14-18'], ['16-30'], ['30-14'], ['17-0'], ['6-30'], ['22-22'], ['22-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['21-30'], ['6-16'], ['17-22'], ['7-12'], ['24-29'], ['11-2'], ['19-15'], ['7-4'], ['15-14'], ['14-18'], ['16-30'], ['30-14'], ['17-0'], ['6-30'], ['22-22'], ['22-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 98.51938486099243\n",
      "Response: Ohio, the latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1177\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-16'], ['21-30'], ['7-12'], ['17-22'], ['11-2'], ['24-29'], ['19-15'], ['7-4'], ['15-14'], ['16-30'], ['14-18'], ['30-14'], ['17-0'], ['22-30'], ['6-30'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 98.51938486099243\n",
      "Response: Ohio, the latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2383\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-16'], ['21-30'], ['7-12'], ['17-22'], ['11-2'], ['24-29'], ['19-15'], ['7-4'], ['15-14'], ['14-18'], ['16-30'], ['30-14'], ['17-0'], ['22-30'], ['6-30'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3554\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-16'], ['21-30'], ['7-12'], ['17-22'], ['11-2'], ['24-29'], ['19-15'], ['7-4'], ['15-14'], ['14-18'], ['16-30'], ['30-14'], ['17-0'], ['22-30'], ['6-30'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 51.482993364334106\n",
      "Response: Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['8-26'], ['21-30'], ['6-16'], ['17-22'], ['7-12'], ['24-29'], ['11-2'], ['7-4'], ['19-15'], ['15-14'], ['30-14'], ['14-18'], ['16-30'], ['22-30'], ['17-0'], ['6-30'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The latest United States jurisdiction to legalize the recreational use of cannabis is Ohio.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_453_irrelevant_misleading/llama-2-7b-80k_id_453_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 27.727484703063965\n",
      "Response: August 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 27.727484703063965\n",
      "Response: August 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 27.727484703063965\n",
      "Response: August 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 27.727484703063965\n",
      "Response: August 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_0_depth_7500_results.json\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 27.727484703063965\n",
      "Response: August 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['7-12'], ['17-22'], ['31-15'], ['8-26'], ['11-2'], ['14-7'], ['14-18'], ['16-19'], ['31-24'], ['0-0'], ['0-1'], ['0-2'], ['0-3'], ['0-4'], ['0-5'], ['0-6'], ['0-7'], ['0-8'], ['0-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 80.09103536605835\n",
      "Response: In 2024, Ukrainian forces launched a cross-border offensive into Russia in response to Russian aggression in the Donbas region. The offensive was a surprise attack that caught the Russian military off guard and resulted in significant losses\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_1250_depth_0_results.json\n",
      "insertion at 20\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['7-12'], ['8-26'], ['16-19'], ['17-22'], ['6-9'], ['11-2'], ['14-7'], ['21-30'], ['7-4'], ['13-11'], ['19-15'], ['22-22'], ['8-31'], ['10-29'], ['11-17'], ['14-18'], ['17-18'], ['19-10'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 97.39313125610352\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 20\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['7-12'], ['8-26'], ['16-19'], ['17-22'], ['6-9'], ['21-30'], ['11-2'], ['14-7'], ['7-4'], ['13-11'], ['19-15'], ['22-22'], ['8-31'], ['10-29'], ['11-17'], ['17-18'], ['19-10'], ['22-27'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 97.39313125610352\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 713\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 24.794653058052063\n",
      "Response: In August 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_1250_depth_7500_results.json\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 26.766037940979004\n",
      "Response: August 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['7-12'], ['8-26'], ['16-19'], ['17-22'], ['6-9'], ['11-2'], ['14-7'], ['21-30'], ['13-11'], ['7-4'], ['19-15'], ['22-22'], ['22-27'], ['8-31'], ['10-29'], ['11-17'], ['14-18'], ['17-18'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 82.26873874664307\n",
      "Response: In 2024, Ukrainian forces launched a cross-border offensive into Russia in response to Russian aggression in Ukraine. The offensive was launched from the Ukrainian territory of Luhansk and targeted the Russian city of Kur\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_2500_depth_0_results.json\n",
      "insertion at 20\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['7-12'], ['16-19'], ['8-26'], ['17-22'], ['6-9'], ['21-30'], ['11-2'], ['14-7'], ['13-11'], ['19-15'], ['22-22'], ['24-29'], ['7-4'], ['19-10'], ['21-16'], ['22-27'], ['24-3'], ['10-29'], ['11-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 99.09298419952393\n",
      "Response: In August 2024, Ukraine launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1118\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['7-12'], ['8-26'], ['16-19'], ['17-22'], ['6-9'], ['21-30'], ['11-2'], ['14-7'], ['19-15'], ['22-22'], ['13-11'], ['24-29'], ['7-4'], ['14-18'], ['19-10'], ['24-3'], ['18-30'], ['21-16'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 97.21069931983948\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia in the Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1697\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['7-12'], ['8-26'], ['16-19'], ['6-9'], ['17-22'], ['21-30'], ['11-2'], ['14-7'], ['19-15'], ['22-22'], ['13-11'], ['24-29'], ['7-4'], ['14-18'], ['19-10'], ['24-3'], ['10-29'], ['18-30'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 83.38688611984253\n",
      "Response: In 2024, Ukrainian forces launched a cross-border offensive into Russia in response to Russian aggression in Ukraine. The offensive was launched in response to the Russian occupation of Crimea and the ongoing conflict in the Don\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_2500_depth_7500_results.json\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['8-26'], ['7-12'], ['16-19'], ['6-9'], ['17-22'], ['21-30'], ['19-15'], ['11-2'], ['22-22'], ['7-4'], ['13-11'], ['14-7'], ['24-29'], ['18-30'], ['14-18'], ['19-10'], ['24-3'], ['15-14'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 97.39313125610352\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['8-26'], ['7-12'], ['16-19'], ['6-9'], ['17-22'], ['21-30'], ['19-15'], ['11-2'], ['22-22'], ['24-29'], ['7-4'], ['13-11'], ['14-7'], ['18-30'], ['14-18'], ['19-10'], ['24-3'], ['15-14'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 85.29249429702759\n",
      "Response: In 2024, Ukrainian forces launched a cross-border offensive into Russia, in response to Russian aggression in the Donbas region.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_3750_depth_0_results.json\n",
      "insertion at 880\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['8-26'], ['16-19'], ['7-12'], ['6-9'], ['17-22'], ['21-30'], ['19-15'], ['11-2'], ['22-22'], ['24-29'], ['13-11'], ['14-7'], ['18-30'], ['19-10'], ['7-4'], ['6-16'], ['14-18'], ['22-27'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 99.09298419952393\n",
      "Response: In August 2024, Ukraine launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1733\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['8-26'], ['7-12'], ['16-19'], ['6-9'], ['17-22'], ['21-30'], ['11-2'], ['19-15'], ['22-22'], ['24-29'], ['13-11'], ['18-30'], ['19-10'], ['6-16'], ['14-7'], ['14-18'], ['22-27'], ['7-4'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 97.21069931983948\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia in the Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2618\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['8-26'], ['16-19'], ['7-12'], ['6-9'], ['17-22'], ['21-30'], ['19-15'], ['11-2'], ['22-22'], ['24-29'], ['18-30'], ['19-10'], ['7-4'], ['6-16'], ['13-11'], ['14-7'], ['14-18'], ['22-27'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 99.09298419952393\n",
      "Response: In August 2024, Ukraine launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_3750_depth_7500_results.json\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['8-26'], ['16-19'], ['6-9'], ['7-12'], ['17-22'], ['21-30'], ['19-15'], ['22-22'], ['24-29'], ['11-2'], ['7-4'], ['18-30'], ['19-10'], ['13-11'], ['14-18'], ['22-27'], ['15-14'], ['6-16'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 97.39313125610352\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['8-26'], ['16-19'], ['6-9'], ['7-12'], ['17-22'], ['21-30'], ['19-15'], ['22-22'], ['24-29'], ['11-2'], ['18-30'], ['7-4'], ['19-10'], ['13-11'], ['14-18'], ['6-16'], ['22-27'], ['14-7'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 88.41983079910278\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia in response to the Russian invasion of Ukraine in 2022.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1192\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 24.794653058052063\n",
      "Response: In August 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2340\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['8-26'], ['16-19'], ['7-12'], ['6-9'], ['17-22'], ['21-30'], ['19-15'], ['22-22'], ['11-2'], ['24-29'], ['18-30'], ['7-4'], ['19-10'], ['14-18'], ['13-11'], ['6-16'], ['15-14'], ['22-27'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 97.39313125610352\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3576\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 24.794653058052063\n",
      "Response: In August 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_5000_depth_7500_results.json\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 23.638716340065002\n",
      "Response: The correct answer is August 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant/llama-2-7b-80k_id_5_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_relevant/5.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 27.727484703063965\n",
      "Response: August 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 27.727484703063965\n",
      "Response: August 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 27.727484703063965\n",
      "Response: August 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 27.727484703063965\n",
      "Response: August 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_0_depth_7500_results.json\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 27.727484703063965\n",
      "Response: August 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['7-12'], ['17-22'], ['31-15'], ['8-26'], ['11-2'], ['14-7'], ['14-18'], ['16-19'], ['31-24'], ['0-0'], ['0-1'], ['0-2'], ['0-3'], ['0-4'], ['0-5'], ['0-6'], ['0-7'], ['0-8'], ['0-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 80.09103536605835\n",
      "Response: In 2024, Ukrainian forces launched a cross-border offensive into Russia in response to Russian aggression in the Donbas region. The offensive was a surprise attack that caught the Russian military off guard and resulted in significant losses\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 20\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['7-12'], ['8-26'], ['16-19'], ['17-22'], ['6-9'], ['11-2'], ['14-7'], ['21-30'], ['7-4'], ['13-11'], ['19-15'], ['22-22'], ['8-31'], ['10-29'], ['11-17'], ['14-18'], ['17-18'], ['19-10'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 97.39313125610352\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 20\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['7-12'], ['8-26'], ['16-19'], ['17-22'], ['6-9'], ['21-30'], ['11-2'], ['14-7'], ['7-4'], ['13-11'], ['19-15'], ['22-22'], ['8-31'], ['10-29'], ['11-17'], ['17-18'], ['19-10'], ['22-27'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 97.39313125610352\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 713\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 24.794653058052063\n",
      "Response: In August 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_1250_depth_7500_results.json\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 26.766037940979004\n",
      "Response: August 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['7-12'], ['16-19'], ['8-26'], ['17-22'], ['6-9'], ['11-2'], ['14-7'], ['21-30'], ['19-15'], ['22-22'], ['24-29'], ['13-11'], ['14-18'], ['7-4'], ['17-18'], ['22-27'], ['24-3'], ['21-16'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 97.39313125610352\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 20\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 24.794653058052063\n",
      "Response: In August 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1118\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['7-12'], ['16-19'], ['8-26'], ['17-22'], ['6-9'], ['21-30'], ['11-2'], ['24-29'], ['19-15'], ['14-7'], ['22-22'], ['6-16'], ['14-18'], ['18-30'], ['24-3'], ['7-4'], ['13-11'], ['17-18'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 99.09298419952393\n",
      "Response: In August 2024, Ukraine launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1685\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['7-12'], ['8-26'], ['16-19'], ['6-9'], ['17-22'], ['21-30'], ['11-2'], ['24-29'], ['19-15'], ['14-7'], ['22-22'], ['6-16'], ['14-18'], ['18-30'], ['24-3'], ['7-4'], ['13-11'], ['10-29'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 87.34650611877441\n",
      "Response: In 2024, Ukrainian forces launched a cross-border offensive into Russia in response to the Russian invasion of Ukraine in 2022.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_2500_depth_7500_results.json\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['8-26'], ['16-19'], ['7-12'], ['6-9'], ['17-22'], ['21-30'], ['19-15'], ['11-2'], ['24-29'], ['22-22'], ['7-4'], ['14-7'], ['13-11'], ['18-30'], ['24-3'], ['14-18'], ['6-16'], ['6-30'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 97.39313125610352\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['8-26'], ['16-19'], ['7-12'], ['17-22'], ['6-9'], ['21-30'], ['11-2'], ['19-15'], ['24-29'], ['22-22'], ['14-7'], ['7-4'], ['24-3'], ['14-18'], ['6-16'], ['13-11'], ['18-30'], ['6-30'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 96.47980332374573\n",
      "Response: In 2024, Ukrainian forces launched a cross-border offensive into Russia in the Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 880\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['8-26'], ['16-19'], ['7-12'], ['6-9'], ['17-22'], ['21-30'], ['11-2'], ['24-29'], ['19-15'], ['22-22'], ['6-16'], ['14-7'], ['24-3'], ['7-4'], ['13-11'], ['14-18'], ['18-30'], ['22-27'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 97.39313125610352\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1761\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['8-26'], ['16-19'], ['7-12'], ['6-9'], ['17-22'], ['21-30'], ['11-2'], ['24-29'], ['19-15'], ['6-16'], ['22-22'], ['14-7'], ['24-3'], ['13-11'], ['18-30'], ['7-4'], ['14-18'], ['22-27'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 96.47980332374573\n",
      "Response: In 2024, Ukrainian forces launched a cross-border offensive into Russia in the Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2583\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['8-26'], ['6-9'], ['16-19'], ['7-12'], ['17-22'], ['21-30'], ['11-2'], ['19-15'], ['24-29'], ['22-22'], ['6-16'], ['13-11'], ['14-7'], ['18-30'], ['24-3'], ['7-4'], ['14-18'], ['22-27'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 97.39313125610352\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_3750_depth_7500_results.json\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 23.638716340065002\n",
      "Response: The correct answer is August 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['8-26'], ['16-19'], ['6-9'], ['7-12'], ['17-22'], ['21-30'], ['11-2'], ['24-29'], ['19-15'], ['6-16'], ['22-22'], ['14-7'], ['13-11'], ['14-18'], ['18-30'], ['24-3'], ['7-4'], ['22-27'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 96.47980332374573\n",
      "Response: In 2024, Ukrainian forces launched a cross-border offensive into Russia in the Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1192\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['8-26'], ['16-19'], ['6-9'], ['7-12'], ['17-22'], ['21-30'], ['11-2'], ['24-29'], ['6-16'], ['19-15'], ['22-22'], ['14-7'], ['13-11'], ['14-18'], ['18-30'], ['24-3'], ['7-4'], ['22-27'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 96.5315043926239\n",
      "Response: In 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2375\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['8-26'], ['6-9'], ['7-12'], ['16-19'], ['17-22'], ['21-30'], ['11-2'], ['24-29'], ['19-15'], ['6-16'], ['22-22'], ['14-7'], ['14-18'], ['18-30'], ['24-3'], ['13-11'], ['22-27'], ['7-4'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 85.91676950454712\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast. Pro-Russian protests immediately followed in the Ukrainian cities of Donetsk and Luhansk. Se\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3549\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['8-26'], ['6-9'], ['16-19'], ['7-12'], ['17-22'], ['21-30'], ['11-2'], ['24-29'], ['19-15'], ['6-16'], ['22-22'], ['18-30'], ['14-18'], ['14-7'], ['7-4'], ['24-3'], ['13-11'], ['22-27'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 97.39313125610352\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_5000_depth_7500_results.json\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['8-26'], ['6-9'], ['16-19'], ['7-12'], ['17-22'], ['21-30'], ['11-2'], ['19-15'], ['24-29'], ['6-16'], ['22-22'], ['18-30'], ['7-4'], ['14-18'], ['13-11'], ['14-7'], ['24-3'], ['22-27'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 97.39313125610352\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_relevant_misleading/llama-2-7b-80k_id_5_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 27.727484703063965\n",
      "Response: August 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 27.727484703063965\n",
      "Response: August 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 27.727484703063965\n",
      "Response: August 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 27.727484703063965\n",
      "Response: August 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_0_depth_7500_results.json\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 27.727484703063965\n",
      "Response: August 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['17-22'], ['31-24'], ['0-0'], ['16-19'], ['26-19'], ['0-1'], ['0-2'], ['0-3'], ['0-4'], ['0-5'], ['0-6'], ['0-7'], ['0-8'], ['0-9'], ['0-10'], ['0-11'], ['0-12'], ['0-13'], ['0-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 88.73998522758484\n",
      "Response: The Ukrainian forces launched a cross-border offensive into Russia in 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 66\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['17-22'], ['8-26'], ['7-4'], ['7-12'], ['6-9'], ['11-2'], ['15-14'], ['19-15'], ['21-30'], ['22-22'], ['8-31'], ['10-29'], ['13-11'], ['14-7'], ['14-18'], ['21-16'], ['24-3'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 97.39313125610352\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 347\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['11-2'], ['6-9'], ['15-14'], ['19-15'], ['21-30'], ['22-22'], ['6-30'], ['8-31'], ['10-29'], ['13-11'], ['14-7'], ['14-18'], ['21-16'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 88.91580104827881\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia in response to the Russian invasion of Ukraine. The offensive was launched from the Ukrainian-controlled territory of the Donetsk Oblast and\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 735\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['17-22'], ['7-12'], ['6-9'], ['7-4'], ['11-2'], ['21-30'], ['22-22'], ['19-15'], ['6-30'], ['15-14'], ['24-29'], ['8-31'], ['14-7'], ['21-16'], ['24-3'], ['10-29'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 97.39313125610352\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_1250_depth_7500_results.json\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 24.794653058052063\n",
      "Response: In August 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['17-22'], ['8-26'], ['7-12'], ['6-9'], ['21-30'], ['22-22'], ['7-4'], ['11-2'], ['24-29'], ['14-7'], ['15-14'], ['19-15'], ['21-16'], ['14-18'], ['24-3'], ['6-30'], ['19-10'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 89.05720710754395\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast, which resulted in the capture of several villages and the deaths of hundreds of Russian soldiers.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 554\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['17-22'], ['7-12'], ['6-9'], ['21-30'], ['7-4'], ['22-22'], ['11-2'], ['24-29'], ['19-15'], ['14-7'], ['15-14'], ['21-16'], ['14-18'], ['24-3'], ['19-10'], ['6-30'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 97.39313125610352\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1134\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['17-22'], ['7-12'], ['6-9'], ['21-30'], ['7-4'], ['24-29'], ['22-22'], ['11-2'], ['19-15'], ['15-14'], ['14-7'], ['21-16'], ['24-3'], ['19-10'], ['14-18'], ['18-30'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 99.09298419952393\n",
      "Response: In August 2024, Ukraine launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1658\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['17-22'], ['6-9'], ['7-12'], ['21-30'], ['7-4'], ['24-29'], ['22-22'], ['11-2'], ['19-15'], ['15-14'], ['14-7'], ['24-3'], ['19-10'], ['21-16'], ['14-18'], ['18-30'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 99.09298419952393\n",
      "Response: In August 2024, Ukraine launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_2500_depth_7500_results.json\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['17-22'], ['6-9'], ['21-30'], ['7-12'], ['7-4'], ['24-29'], ['19-15'], ['22-22'], ['11-2'], ['15-14'], ['24-3'], ['21-16'], ['14-7'], ['18-30'], ['19-10'], ['14-18'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 97.39313125610352\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['17-22'], ['6-9'], ['21-30'], ['7-12'], ['7-4'], ['24-29'], ['22-22'], ['19-15'], ['11-2'], ['15-14'], ['24-3'], ['14-18'], ['21-16'], ['14-7'], ['19-10'], ['18-30'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 91.88238382339478\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast, which resulted in heavy fighting and the capture of several villages.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 804\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['17-22'], ['6-9'], ['7-12'], ['21-30'], ['22-22'], ['7-4'], ['24-29'], ['19-15'], ['11-2'], ['15-14'], ['24-3'], ['14-18'], ['21-16'], ['19-10'], ['14-7'], ['18-30'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 87.6978874206543\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast, which resulted in the capture of several villages and the deaths of over 100 Russian soldiers.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1757\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['17-22'], ['6-9'], ['7-12'], ['21-30'], ['24-29'], ['7-4'], ['22-22'], ['19-15'], ['11-2'], ['15-14'], ['24-3'], ['21-16'], ['19-10'], ['14-18'], ['14-7'], ['18-30'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 99.09298419952393\n",
      "Response: In August 2024, Ukraine launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2637\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['17-22'], ['6-9'], ['7-12'], ['21-30'], ['7-4'], ['24-29'], ['22-22'], ['19-15'], ['11-2'], ['15-14'], ['24-3'], ['21-16'], ['18-30'], ['19-10'], ['14-18'], ['14-7'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 99.09298419952393\n",
      "Response: In August 2024, Ukraine launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_3750_depth_7500_results.json\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 24.794653058052063\n",
      "Response: In August 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['17-22'], ['6-9'], ['7-12'], ['21-30'], ['24-29'], ['22-22'], ['7-4'], ['19-15'], ['11-2'], ['15-14'], ['24-3'], ['14-18'], ['21-16'], ['14-7'], ['18-30'], ['19-10'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.9 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 89.05720710754395\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast, which resulted in the capture of several villages and the deaths of hundreds of Russian soldiers.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1180\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['17-22'], ['6-9'], ['7-12'], ['21-30'], ['22-22'], ['24-29'], ['7-4'], ['19-15'], ['11-2'], ['15-14'], ['24-3'], ['21-16'], ['14-18'], ['14-7'], ['18-30'], ['19-10'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 89.2162561416626\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast, which resulted in the capture of several villages and the deaths of dozens of Russian soldiers.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2383\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['17-22'], ['6-9'], ['7-12'], ['21-30'], ['24-29'], ['19-15'], ['22-22'], ['7-4'], ['11-2'], ['15-14'], ['24-3'], ['19-10'], ['21-16'], ['18-30'], ['14-7'], ['14-18'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 99.09298419952393\n",
      "Response: In August 2024, Ukraine launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3573\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['17-22'], ['6-9'], ['7-12'], ['21-30'], ['24-29'], ['19-15'], ['7-4'], ['22-22'], ['11-2'], ['15-14'], ['24-3'], ['19-10'], ['18-30'], ['21-16'], ['14-7'], ['14-18'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 99.09298419952393\n",
      "Response: In August 2024, Ukraine launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_5000_depth_7500_results.json\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['17-22'], ['6-9'], ['7-12'], ['21-30'], ['19-15'], ['24-29'], ['7-4'], ['22-22'], ['11-2'], ['15-14'], ['24-3'], ['19-10'], ['18-30'], ['21-16'], ['14-7'], ['14-18'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 92.98874139785767\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast, which resulted in the capture of the city of Kursk.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant/llama-2-7b-80k_id_5_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_irrelevant/5.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 27.727484703063965\n",
      "Response: August 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 27.727484703063965\n",
      "Response: August 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 27.727484703063965\n",
      "Response: August 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 27.727484703063965\n",
      "Response: August 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 27.727484703063965\n",
      "Response: August 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['17-22'], ['31-24'], ['0-0'], ['16-19'], ['26-19'], ['0-1'], ['0-2'], ['0-3'], ['0-4'], ['0-5'], ['0-6'], ['0-7'], ['0-8'], ['0-9'], ['0-10'], ['0-11'], ['0-12'], ['0-13'], ['0-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 88.73998522758484\n",
      "Response: The Ukrainian forces launched a cross-border offensive into Russia in 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 66\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['17-22'], ['8-26'], ['7-4'], ['7-12'], ['6-9'], ['11-2'], ['15-14'], ['19-15'], ['21-30'], ['22-22'], ['8-31'], ['10-29'], ['13-11'], ['14-7'], ['14-18'], ['21-16'], ['24-3'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 97.39313125610352\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 347\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['17-22'], ['7-12'], ['7-4'], ['11-2'], ['6-9'], ['15-14'], ['19-15'], ['21-30'], ['22-22'], ['6-30'], ['8-31'], ['10-29'], ['13-11'], ['14-7'], ['14-18'], ['21-16'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 88.91580104827881\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia in response to the Russian invasion of Ukraine. The offensive was launched from the Ukrainian-controlled territory of the Donetsk Oblast and\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 735\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['17-22'], ['7-12'], ['6-9'], ['7-4'], ['11-2'], ['21-30'], ['22-22'], ['19-15'], ['6-30'], ['15-14'], ['24-29'], ['8-31'], ['14-7'], ['21-16'], ['24-3'], ['10-29'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 97.39313125610352\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 24.794653058052063\n",
      "Response: In August 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['17-22'], ['7-12'], ['6-9'], ['11-2'], ['7-4'], ['21-30'], ['22-22'], ['6-30'], ['24-29'], ['19-15'], ['21-16'], ['15-14'], ['8-31'], ['14-7'], ['10-29'], ['24-3'], ['6-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 90.75743556022644\n",
      "Response: In 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast, but no official confirmation was provided.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 554\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['7-12'], ['17-22'], ['6-9'], ['21-30'], ['11-2'], ['7-4'], ['22-22'], ['24-29'], ['19-15'], ['6-30'], ['21-16'], ['15-14'], ['8-31'], ['24-3'], ['6-16'], ['14-7'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 97.39313125610352\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1127\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['8-26'], ['16-19'], ['7-12'], ['6-9'], ['17-22'], ['21-30'], ['11-2'], ['7-4'], ['22-22'], ['19-15'], ['24-29'], ['21-16'], ['6-30'], ['15-14'], ['8-31'], ['24-3'], ['6-16'], ['14-18'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 97.39313125610352\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1686\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['8-26'], ['16-19'], ['7-12'], ['6-9'], ['17-22'], ['21-30'], ['11-2'], ['7-4'], ['19-15'], ['22-22'], ['24-29'], ['21-16'], ['6-30'], ['15-14'], ['24-3'], ['8-31'], ['13-11'], ['18-30'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 97.39313125610352\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 24.794653058052063\n",
      "Response: In August 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['7-12'], ['6-9'], ['17-22'], ['21-30'], ['11-2'], ['7-4'], ['24-29'], ['19-15'], ['22-22'], ['21-16'], ['24-3'], ['6-30'], ['26-27'], ['15-14'], ['6-16'], ['8-31'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 91.92474484443665\n",
      "Response: In 2024, Ukraine launched a cross-border offensive into Russia's Kursk Oblast, but no official confirmation was provided.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 804\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['7-12'], ['6-9'], ['17-22'], ['21-30'], ['11-2'], ['24-29'], ['7-4'], ['19-15'], ['22-22'], ['21-16'], ['6-16'], ['15-14'], ['24-3'], ['26-27'], ['14-18'], ['6-30'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 99.09298419952393\n",
      "Response: In August 2024, Ukraine launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1741\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['7-12'], ['6-9'], ['17-22'], ['21-30'], ['11-2'], ['19-15'], ['24-29'], ['7-4'], ['22-22'], ['6-16'], ['21-16'], ['15-14'], ['24-3'], ['14-18'], ['18-30'], ['26-27'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 99.09298419952393\n",
      "Response: In August 2024, Ukraine launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2622\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-12'], ['17-22'], ['21-30'], ['11-2'], ['19-15'], ['24-29'], ['7-4'], ['22-22'], ['21-16'], ['6-16'], ['24-3'], ['15-14'], ['18-30'], ['26-27'], ['14-18'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 99.09298419952393\n",
      "Response: In August 2024, Ukraine launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-12'], ['17-22'], ['21-30'], ['11-2'], ['19-15'], ['24-29'], ['7-4'], ['22-22'], ['21-16'], ['18-30'], ['24-3'], ['6-16'], ['15-14'], ['26-27'], ['17-18'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 97.39313125610352\n",
      "Response: In August 2024, Ukrainian forces launched a cross-border offensive into Russia's Kursk Oblast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-12'], ['17-22'], ['21-30'], ['11-2'], ['19-15'], ['24-29'], ['7-4'], ['22-22'], ['21-16'], ['6-16'], ['18-30'], ['24-3'], ['26-27'], ['15-14'], ['17-18'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 66.57788157463074\n",
      "Response: In 2024, Ukraine was said to be considering military action against Russian targets, potentially including those in the Kursk Oblast. However, details were scarce and the location was not confirmed.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1162\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-12'], ['17-22'], ['21-30'], ['11-2'], ['19-15'], ['24-29'], ['7-4'], ['22-22'], ['6-16'], ['18-30'], ['21-16'], ['24-3'], ['26-27'], ['15-14'], ['14-18'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 90.73940515518188\n",
      "Response: In August 2024, Ukraine launched a cross-border offensive into Russia's Kursk Oblast, which resulted in the capture of several villages and the deaths of over 100 Russian soldiers.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2373\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-12'], ['17-22'], ['21-30'], ['19-15'], ['11-2'], ['24-29'], ['7-4'], ['22-22'], ['6-16'], ['18-30'], ['15-14'], ['21-16'], ['24-3'], ['26-27'], ['14-18'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 86.95579767227173\n",
      "Response: In August 2024, Ukraine launched a cross-border offensive into Russia's Kursk Oblast, which resulted in the deaths of 100 Russian soldiers.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3556\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-12'], ['17-22'], ['21-30'], ['19-15'], ['11-2'], ['24-29'], ['7-4'], ['6-16'], ['22-22'], ['18-30'], ['15-14'], ['21-16'], ['24-3'], ['26-27'], ['19-10'], ['22-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 86.74152493476868\n",
      "Response: The answer is: Ukraine launched a cross-border offensive into Russia's Kursk Oblast in August 2024. Some reports suggested that Ukrainian forces had launched a limited operation into Russia, but details were scarce and the\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "Ukraine launched a cross-border offensive into Russia’s Kursk Oblast in August 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 24.794653058052063\n",
      "Response: In August 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_5_irrelevant_misleading/llama-2-7b-80k_id_5_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The hottest year on record is 2024.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['6-30'], ['16-19'], ['18-30'], ['7-4'], ['7-13'], ['8-26'], ['11-15'], ['12-26'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['6-30'], ['16-19'], ['18-30'], ['7-4'], ['7-13'], ['8-26'], ['11-15'], ['12-26'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['6-30'], ['16-19'], ['18-30'], ['7-4'], ['7-13'], ['8-26'], ['11-15'], ['12-26'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['6-30'], ['16-19'], ['18-30'], ['7-4'], ['7-13'], ['8-26'], ['11-15'], ['12-26'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_0_depth_7500_results.json\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['6-30'], ['16-19'], ['18-30'], ['7-4'], ['7-13'], ['8-26'], ['11-15'], ['12-26'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 44.368189573287964\n",
      "Response: 2020.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_1250_depth_0_results.json\n",
      "insertion at 247\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['16-19'], ['6-30'], ['18-30'], ['8-26'], ['16-24'], ['7-4'], ['7-13'], ['11-15'], ['12-26'], ['14-18'], ['17-22'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 508\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['16-19'], ['6-30'], ['18-30'], ['8-26'], ['16-24'], ['7-4'], ['7-13'], ['11-15'], ['12-26'], ['14-18'], ['17-22'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
<<<<<<< Updated upstream
      "Score: 65.70635437965393\n",
      "Response: Martina Navratilova\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 612\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-31'], ['8-31'], ['9-8'], ['10-18'], ['14-18']]\n",
=======
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 743\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['6-30'], ['18-30'], ['8-26'], ['16-24'], ['7-4'], ['7-13'], ['11-15'], ['12-26'], ['14-18'], ['17-22'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
<<<<<<< Updated upstream
      "Score: 65.70635437965393\n",
      "Response: Martina Navratilova\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_1250_depth_7500_results.json\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['6-30'], ['11-15'], ['21-30'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['23-20'], ['26-28'], ['18-30'], ['13-11'], ['12-26'], ['19-10'], ['22-27'], ['24-3'], ['29-26'], ['7-31']]\n",
=======
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_1250_depth_7500_results.json\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['8-26'], ['6-30'], ['18-30'], ['11-15'], ['17-22'], ['7-4'], ['16-24'], ['12-26'], ['17-31'], ['6-9'], ['7-13'], ['14-18'], ['19-10'], ['31-15'], ['15-14'], ['21-30'], ['12-4'], ['25-3']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
<<<<<<< Updated upstream
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['6-30'], ['11-15'], ['21-30'], ['8-26'], ['6-9'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['23-20'], ['26-28'], ['18-30'], ['13-11'], ['12-26'], ['19-10'], ['22-27'], ['24-3'], ['29-26'], ['7-31']]\n",
=======
      "Score: 100.0\n",
      "Response: The hottest year on record is 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['8-26'], ['18-30'], ['6-30'], ['11-15'], ['17-22'], ['16-24'], ['7-4'], ['12-26'], ['17-31'], ['6-9'], ['7-13'], ['14-18'], ['19-10'], ['31-15'], ['15-14'], ['21-30'], ['12-4'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 78.40495109558105\n",
      "Response: 2020 was the hottest year on record, according to NASA.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_2500_depth_0_results.json\n",
      "insertion at 561\n",
      "The hottest year on record is 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 3.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 48.73130917549133\n",
      "Response: 2024.20 °C per decade, to at least 1.1 °C (1.9 °F) above 1880 levels. The current annual GMST is about 15 °\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1120\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['8-26'], ['18-30'], ['11-15'], ['6-30'], ['17-22'], ['16-24'], ['7-4'], ['6-9'], ['12-26'], ['17-31'], ['7-13'], ['14-18'], ['19-10'], ['31-15'], ['15-14'], ['21-30'], ['12-4'], ['25-3']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
<<<<<<< Updated upstream
      "Depth: 0%\n",
      "Score: 51.27078890800476\n",
      "Response: Serena Williams.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_2500_depth_0_results.json\n",
      "insertion at 334\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['6-30'], ['21-30'], ['19-15'], ['7-4'], ['24-29'], ['31-16'], ['26-28'], ['23-20'], ['18-30'], ['13-11'], ['10-18'], ['14-18'], ['22-27'], ['24-3'], ['12-26'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 63.63217234611511\n",
      "Response: Aryna Sabalenka.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1081\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['6-30'], ['21-30'], ['19-15'], ['24-29'], ['7-4'], ['31-16'], ['26-28'], ['23-20'], ['13-11'], ['18-30'], ['10-18'], ['14-18'], ['22-27'], ['24-3'], ['15-14'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 63.63217234611511\n",
      "Response: Aryna Sabalenka.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1319\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['6-30'], ['21-30'], ['19-15'], ['24-29'], ['7-4'], ['31-16'], ['26-28'], ['23-20'], ['13-11'], ['18-30'], ['14-18'], ['10-18'], ['15-14'], ['22-27'], ['24-3'], ['21-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 63.63217234611511\n",
      "Response: Aryna Sabalenka.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_2500_depth_7500_results.json\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['6-30'], ['21-30'], ['7-4'], ['24-29'], ['31-16'], ['26-28'], ['23-20'], ['18-30'], ['13-11'], ['14-18'], ['12-26'], ['22-27'], ['24-3'], ['10-18'], ['15-14']]\n",
=======
      "Depth: 50%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1684\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['8-26'], ['18-30'], ['11-15'], ['17-22'], ['6-30'], ['7-4'], ['16-24'], ['6-9'], ['12-26'], ['17-31'], ['7-13'], ['14-18'], ['19-10'], ['31-15'], ['15-14'], ['21-30'], ['12-4'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 51.06801390647888\n",
      "Response: 2024.3\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_2500_depth_7500_results.json\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['8-26'], ['17-22'], ['18-30'], ['6-9'], ['6-30'], ['7-4'], ['12-26'], ['16-24'], ['17-31'], ['7-13'], ['14-18'], ['15-14'], ['21-30'], ['19-10'], ['31-15'], ['12-4'], ['19-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The hottest year on record is 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['8-26'], ['17-22'], ['18-30'], ['6-9'], ['6-30'], ['7-4'], ['12-26'], ['16-24'], ['17-31'], ['14-18'], ['7-13'], ['15-14'], ['21-30'], ['19-10'], ['31-15'], ['12-4'], ['19-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 79.11441922187805\n",
      "Response: 2016 was the hottest year on record.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_3750_depth_0_results.json\n",
      "insertion at 880\n",
      "The hottest year on record is 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 43.31360459327698\n",
      "Response: 2016.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1747\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['8-26'], ['17-22'], ['18-30'], ['6-9'], ['6-30'], ['7-4'], ['12-26'], ['16-24'], ['17-31'], ['14-18'], ['7-13'], ['15-14'], ['21-30'], ['19-10'], ['31-15'], ['12-4'], ['19-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 84.18170809745789\n",
      "Response: 2020 was the hottest year on record.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2650\n",
      "The hottest year on record is 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 44.368189573287964\n",
      "Response: 2020.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_3750_depth_7500_results.json\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['8-26'], ['17-22'], ['6-9'], ['18-30'], ['7-4'], ['6-30'], ['12-26'], ['16-24'], ['17-31'], ['14-18'], ['21-30'], ['7-13'], ['15-14'], ['19-10'], ['19-15'], ['12-4'], ['25-3']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
<<<<<<< Updated upstream
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['6-30'], ['19-15'], ['21-30'], ['7-4'], ['24-29'], ['31-16'], ['26-28'], ['23-20'], ['13-11'], ['18-30'], ['12-26'], ['14-18'], ['22-27'], ['24-3'], ['10-18'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 51.53859853744507\n",
      "Response: Serena Williams\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_3750_depth_0_results.json\n",
      "insertion at 612\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['6-30'], ['19-15'], ['21-30'], ['7-4'], ['24-29'], ['31-16'], ['26-28'], ['23-20'], ['13-11'], ['18-30'], ['12-26'], ['14-18'], ['22-27'], ['24-3'], ['10-18'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 51.53859853744507\n",
      "Response: Serena Williams\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1319\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['6-30'], ['19-15'], ['21-30'], ['7-4'], ['24-29'], ['31-16'], ['26-28'], ['23-20'], ['13-11'], ['18-30'], ['12-26'], ['14-18'], ['22-27'], ['24-3'], ['10-18'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 51.53859853744507\n",
      "Response: Serena Williams\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2533\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['6-30'], ['19-15'], ['21-30'], ['7-4'], ['24-29'], ['31-16'], ['26-28'], ['23-20'], ['13-11'], ['18-30'], ['12-26'], ['14-18'], ['22-27'], ['24-3'], ['10-18'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 51.53859853744507\n",
      "Response: Serena Williams\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_3750_depth_7500_results.json\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['6-30'], ['21-30'], ['7-4'], ['24-29'], ['31-16'], ['26-28'], ['23-20'], ['12-26'], ['13-11'], ['18-30'], ['14-18'], ['22-27'], ['24-3'], ['10-18'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['6-30'], ['21-30'], ['7-4'], ['24-29'], ['31-16'], ['26-28'], ['23-20'], ['12-26'], ['13-11'], ['18-30'], ['14-18'], ['22-27'], ['24-3'], ['10-18'], ['14-15']]\n",
=======
      "Score: 100.0\n",
      "Response: The hottest year on record is 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 44.368189573287964\n",
      "Response: 2020.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1192\n",
      "The hottest year on record is 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 44.368189573287964\n",
      "Response: 2020.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2355\n",
      "The hottest year on record is 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 44.368189573287964\n",
      "Response: 2020.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3582\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['8-26'], ['17-22'], ['6-9'], ['18-30'], ['7-4'], ['6-30'], ['12-26'], ['16-24'], ['17-31'], ['21-30'], ['14-18'], ['7-13'], ['15-14'], ['19-10'], ['19-15'], ['12-4'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 59.07994508743286\n",
      "Response: 2024.48 °C hotter than the average in the years 1850-1900 according to the Copernicus Climate Change Service. It was declared as the warmest on record almost immediately\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_5000_depth_7500_results.json\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['8-26'], ['6-9'], ['17-22'], ['7-4'], ['18-30'], ['6-30'], ['12-26'], ['17-31'], ['21-30'], ['16-24'], ['15-14'], ['14-18'], ['19-15'], ['7-13'], ['19-10'], ['25-3'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The hottest year on record is 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant/llama-2-7b-80k_id_532_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_relevant/532.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The hottest year on record is 2024.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['6-30'], ['16-19'], ['18-30'], ['7-4'], ['7-13'], ['8-26'], ['11-15'], ['12-26'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['6-30'], ['16-19'], ['18-30'], ['7-4'], ['7-13'], ['8-26'], ['11-15'], ['12-26'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['6-30'], ['16-19'], ['18-30'], ['7-4'], ['7-13'], ['8-26'], ['11-15'], ['12-26'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['6-30'], ['16-19'], ['18-30'], ['7-4'], ['7-13'], ['8-26'], ['11-15'], ['12-26'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_0_depth_7500_results.json\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['6-30'], ['16-19'], ['18-30'], ['7-4'], ['7-13'], ['8-26'], ['11-15'], ['12-26'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['6-30'], ['16-19'], ['18-30'], ['16-24'], ['11-15'], ['14-18'], ['17-22'], ['19-10'], ['7-4'], ['7-13'], ['8-26'], ['12-26'], ['17-31'], ['31-15'], ['6-9'], ['12-2'], ['1-26'], ['8-31'], ['10-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 247\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['16-19'], ['6-30'], ['18-30'], ['16-24'], ['11-15'], ['8-26'], ['14-18'], ['17-22'], ['19-10'], ['7-4'], ['7-13'], ['12-26'], ['17-31'], ['31-15'], ['6-9'], ['12-2'], ['1-26'], ['8-31'], ['10-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 508\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['16-19'], ['6-30'], ['18-30'], ['16-24'], ['11-15'], ['8-26'], ['14-18'], ['17-22'], ['19-10'], ['7-4'], ['7-13'], ['12-26'], ['17-31'], ['31-15'], ['6-9'], ['12-2'], ['1-26'], ['8-31'], ['10-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 768\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['16-19'], ['6-30'], ['18-30'], ['16-24'], ['11-15'], ['8-26'], ['14-18'], ['17-22'], ['19-10'], ['7-4'], ['7-13'], ['12-26'], ['17-31'], ['31-15'], ['6-9'], ['12-2'], ['1-26'], ['8-31'], ['10-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['8-26'], ['6-30'], ['17-22'], ['16-24'], ['18-30'], ['6-9'], ['7-4'], ['14-18'], ['19-10'], ['12-26'], ['17-31'], ['7-13'], ['31-15'], ['21-30'], ['15-14'], ['12-2'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The hottest year on record is 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['17-22'], ['8-26'], ['6-30'], ['16-24'], ['18-30'], ['6-9'], ['7-4'], ['19-10'], ['14-18'], ['12-26'], ['17-31'], ['7-13'], ['31-15'], ['21-30'], ['12-2'], ['15-14'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 73.33908081054688\n",
      "Response: 2024 was the second hottest year on record, following closely behind 2023. The current annual GMST is about 15 °C (59 °F), though monthly temperatures can vary\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 561\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['8-26'], ['11-15'], ['17-22'], ['6-30'], ['16-24'], ['18-30'], ['6-9'], ['7-4'], ['19-10'], ['14-18'], ['12-26'], ['17-31'], ['7-13'], ['31-15'], ['21-30'], ['12-2'], ['15-14'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 64.94708061218262\n",
      "Response: 2024.20 °C per decade, to at least 1.1 °C (1.9 °F) above 1880 levels. The year 2024 was the second hott\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1133\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['8-26'], ['11-15'], ['17-22'], ['16-24'], ['6-30'], ['18-30'], ['6-9'], ['7-4'], ['19-10'], ['12-26'], ['14-18'], ['17-31'], ['7-13'], ['31-15'], ['21-30'], ['12-2'], ['15-14'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1658\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['17-22'], ['8-26'], ['11-15'], ['16-24'], ['6-30'], ['18-30'], ['6-9'], ['7-4'], ['19-10'], ['14-18'], ['12-26'], ['17-31'], ['7-13'], ['31-15'], ['21-30'], ['12-2'], ['15-14'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 52.976107597351074\n",
      "Response: 2024.4\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['8-26'], ['17-22'], ['6-9'], ['16-24'], ['6-30'], ['18-30'], ['7-4'], ['12-26'], ['17-31'], ['19-10'], ['14-18'], ['7-13'], ['21-30'], ['15-14'], ['19-15'], ['31-15'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The hottest year on record is 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['17-22'], ['8-26'], ['6-9'], ['16-24'], ['6-30'], ['18-30'], ['7-4'], ['19-10'], ['12-26'], ['17-31'], ['14-18'], ['7-13'], ['21-30'], ['15-14'], ['12-2'], ['19-15'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 881\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['17-22'], ['8-26'], ['6-9'], ['16-24'], ['6-30'], ['18-30'], ['7-4'], ['19-10'], ['12-26'], ['17-31'], ['14-18'], ['7-13'], ['21-30'], ['15-14'], ['12-2'], ['19-15'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1737\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['17-22'], ['8-26'], ['6-9'], ['16-24'], ['6-30'], ['18-30'], ['7-4'], ['19-10'], ['12-26'], ['17-31'], ['14-18'], ['7-13'], ['21-30'], ['15-14'], ['12-2'], ['19-15'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 51.06801390647888\n",
      "Response: 2024.3\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2645\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['17-22'], ['8-26'], ['6-9'], ['16-24'], ['6-30'], ['18-30'], ['7-4'], ['19-10'], ['12-26'], ['17-31'], ['14-18'], ['7-13'], ['21-30'], ['15-14'], ['12-2'], ['19-15'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['17-22'], ['8-26'], ['6-9'], ['16-24'], ['7-4'], ['6-30'], ['18-30'], ['12-26'], ['17-31'], ['19-10'], ['21-30'], ['14-18'], ['7-13'], ['15-14'], ['19-15'], ['12-2'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The hottest year on record is 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['17-22'], ['8-26'], ['6-9'], ['16-24'], ['7-4'], ['6-30'], ['18-30'], ['12-26'], ['17-31'], ['19-10'], ['21-30'], ['14-18'], ['7-13'], ['15-14'], ['19-15'], ['12-2'], ['25-3']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
<<<<<<< Updated upstream
      "Score: 51.53859853744507\n",
      "Response: Serena Williams\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1081\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['6-30'], ['21-30'], ['7-4'], ['24-29'], ['31-16'], ['26-28'], ['23-20'], ['12-26'], ['13-11'], ['14-18'], ['18-30'], ['22-27'], ['24-3'], ['29-26'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2257\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['6-30'], ['21-30'], ['7-4'], ['24-29'], ['31-16'], ['26-28'], ['23-20'], ['7-12'], ['12-26'], ['14-18'], ['13-11'], ['17-22'], ['18-30'], ['22-27'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3508\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['21-30'], ['19-15'], ['6-30'], ['7-4'], ['24-29'], ['31-16'], ['23-20'], ['26-28'], ['7-12'], ['12-26'], ['14-18'], ['13-11'], ['17-22'], ['18-30'], ['22-27'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 63.78287076950073\n",
      "Response: Aryna Sabalenka\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_5000_depth_7500_results.json\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['19-15'], ['21-30'], ['6-30'], ['7-4'], ['24-29'], ['31-16'], ['23-20'], ['26-28'], ['12-26'], ['7-12'], ['14-18'], ['13-11'], ['18-30'], ['14-15'], ['17-22'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant/llama-2-7b-80k_id_430_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/430.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['6-9'], ['8-26'], ['11-15'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-31'], ['8-31'], ['9-8'], ['10-18'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 63.78287076950073\n",
      "Response: Aryna Sabalenka\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['6-9'], ['8-26'], ['11-15'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-31'], ['8-31'], ['9-8'], ['10-18'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 63.78287076950073\n",
      "Response: Aryna Sabalenka\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['6-9'], ['8-26'], ['11-15'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-31'], ['8-31'], ['9-8'], ['10-18'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 63.78287076950073\n",
      "Response: Aryna Sabalenka\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['6-9'], ['8-26'], ['11-15'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-31'], ['8-31'], ['9-8'], ['10-18'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 63.78287076950073\n",
      "Response: Aryna Sabalenka\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_0_depth_7500_results.json\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['6-9'], ['8-26'], ['11-15'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-31'], ['8-31'], ['9-8'], ['10-18'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 63.78287076950073\n",
      "Response: Aryna Sabalenka\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['21-30'], ['16-19'], ['11-15'], ['6-30'], ['8-26'], ['6-9'], ['24-29'], ['31-16'], ['7-4'], ['19-15'], ['23-20'], ['13-11'], ['18-30'], ['26-28'], ['14-18'], ['19-10'], ['22-16'], ['22-27'], ['24-3'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 233\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['21-30'], ['6-30'], ['6-9'], ['24-29'], ['31-16'], ['7-4'], ['19-15'], ['23-20'], ['13-11'], ['18-30'], ['26-28'], ['7-12'], ['14-18'], ['22-16'], ['24-3'], ['15-14'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 358\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['21-30'], ['6-30'], ['6-9'], ['24-29'], ['31-16'], ['7-4'], ['19-15'], ['7-12'], ['23-20'], ['13-11'], ['26-28'], ['18-30'], ['14-18'], ['22-16'], ['24-3'], ['15-14'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 636\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-30'], ['21-30'], ['6-9'], ['24-29'], ['31-16'], ['7-4'], ['19-15'], ['23-20'], ['13-11'], ['26-28'], ['7-12'], ['18-30'], ['14-18'], ['15-14'], ['22-16'], ['24-3'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 63.63217234611511\n",
      "Response: Aryna Sabalenka.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-30'], ['21-30'], ['6-9'], ['7-4'], ['24-29'], ['19-15'], ['31-16'], ['23-20'], ['26-28'], ['13-11'], ['18-30'], ['7-12'], ['14-18'], ['15-14'], ['24-3'], ['22-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['21-30'], ['6-30'], ['6-9'], ['19-15'], ['24-29'], ['31-16'], ['7-4'], ['23-20'], ['26-28'], ['7-12'], ['13-11'], ['18-30'], ['14-18'], ['15-14'], ['24-3'], ['22-16'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 358\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['21-30'], ['6-30'], ['6-9'], ['19-15'], ['24-29'], ['31-16'], ['7-4'], ['7-12'], ['23-20'], ['26-28'], ['13-11'], ['18-30'], ['14-18'], ['15-14'], ['24-3'], ['22-16'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1105\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['21-30'], ['6-30'], ['6-9'], ['24-29'], ['31-16'], ['7-4'], ['7-12'], ['23-20'], ['26-28'], ['13-11'], ['18-30'], ['14-18'], ['15-14'], ['17-22'], ['24-3'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1343\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['6-30'], ['21-30'], ['6-9'], ['24-29'], ['31-16'], ['7-4'], ['7-12'], ['23-20'], ['26-28'], ['13-11'], ['17-22'], ['14-18'], ['18-30'], ['15-14'], ['24-3'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['19-15'], ['6-30'], ['21-30'], ['6-9'], ['24-29'], ['7-4'], ['31-16'], ['7-12'], ['23-20'], ['26-28'], ['17-22'], ['13-11'], ['18-30'], ['14-18'], ['15-14'], ['24-3'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['21-30'], ['6-9'], ['6-30'], ['24-29'], ['7-4'], ['31-16'], ['7-12'], ['23-20'], ['26-28'], ['17-22'], ['13-11'], ['14-18'], ['18-30'], ['24-3'], ['15-14'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 636\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-9'], ['6-30'], ['21-30'], ['24-29'], ['31-16'], ['7-4'], ['7-12'], ['23-20'], ['17-22'], ['26-28'], ['13-11'], ['11-2'], ['14-18'], ['15-14'], ['18-30'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1343\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-9'], ['6-30'], ['21-30'], ['24-29'], ['31-16'], ['7-12'], ['7-4'], ['17-22'], ['23-20'], ['26-28'], ['13-11'], ['11-2'], ['14-18'], ['15-14'], ['18-30'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2580\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-9'], ['6-30'], ['21-30'], ['24-29'], ['31-16'], ['7-12'], ['7-4'], ['23-20'], ['17-22'], ['26-28'], ['13-11'], ['15-14'], ['14-18'], ['11-2'], ['18-30'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 63.63217234611511\n",
      "Response: Aryna Sabalenka.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-9'], ['6-30'], ['21-30'], ['24-29'], ['7-4'], ['31-16'], ['7-12'], ['23-20'], ['26-28'], ['17-22'], ['13-11'], ['15-14'], ['14-18'], ['18-30'], ['24-3'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['19-15'], ['6-9'], ['6-30'], ['21-30'], ['24-29'], ['7-4'], ['31-16'], ['7-12'], ['23-20'], ['26-28'], ['17-22'], ['13-11'], ['15-14'], ['14-18'], ['18-30'], ['24-3'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 75.79667568206787\n",
      "Response: Steffi Graf is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1105\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['19-15'], ['6-9'], ['6-30'], ['21-30'], ['24-29'], ['7-4'], ['31-16'], ['7-12'], ['23-20'], ['26-28'], ['17-22'], ['13-11'], ['15-14'], ['14-18'], ['18-30'], ['24-3'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 75.79667568206787\n",
      "Response: Steffi Graf is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2304\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['19-15'], ['6-9'], ['6-30'], ['21-30'], ['24-29'], ['7-4'], ['7-12'], ['31-16'], ['23-20'], ['26-28'], ['17-22'], ['13-11'], ['15-14'], ['14-18'], ['18-30'], ['24-3'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 75.79667568206787\n",
      "Response: Steffi Graf is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_5000_depth_5000_results.json\n",
=======
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_5000_depth_5000_results.json\n",
>>>>>>> Stashed changes
      "insertion at 3555\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 32.833823561668396\n",
      "Response: On the ninth ballot, Kevin McCarthy was elected Speaker of the House with 216 votes.\n",
      "\n",
<<<<<<< Updated upstream
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['19-15'], ['6-9'], ['6-30'], ['21-30'], ['24-29'], ['7-4'], ['7-12'], ['31-16'], ['17-22'], ['23-20'], ['26-28'], ['13-11'], ['14-18'], ['12-26'], ['15-14'], ['18-30'], ['24-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_relevant_misleading/llama-2-7b-80k_id_430_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['6-9'], ['8-26'], ['11-15'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-31'], ['8-31'], ['9-8'], ['10-18'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 63.78287076950073\n",
      "Response: Aryna Sabalenka\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['6-9'], ['8-26'], ['11-15'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-31'], ['8-31'], ['9-8'], ['10-18'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 63.78287076950073\n",
      "Response: Aryna Sabalenka\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['6-9'], ['8-26'], ['11-15'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-31'], ['8-31'], ['9-8'], ['10-18'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 63.78287076950073\n",
      "Response: Aryna Sabalenka\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['6-9'], ['8-26'], ['11-15'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-31'], ['8-31'], ['9-8'], ['10-18'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 63.78287076950073\n",
      "Response: Aryna Sabalenka\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_0_depth_7500_results.json\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['6-9'], ['8-26'], ['11-15'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-31'], ['8-31'], ['9-8'], ['10-18'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 63.78287076950073\n",
      "Response: Aryna Sabalenka\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['8-26'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-12'], ['7-31'], ['8-31'], ['9-8'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 75.88586807250977\n",
      "Response: Serena Williams is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 242\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['8-26'], ['6-30'], ['6-9'], ['24-29'], ['19-15'], ['7-4'], ['31-16'], ['7-12'], ['13-11'], ['23-20'], ['26-28'], ['18-30'], ['11-2'], ['14-18'], ['19-10'], ['29-26'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 509\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['21-30'], ['6-9'], ['6-30'], ['24-29'], ['7-4'], ['7-12'], ['19-15'], ['31-16'], ['11-2'], ['23-20'], ['26-28'], ['13-11'], ['17-22'], ['18-30'], ['19-10'], ['29-26'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 769\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['21-30'], ['6-9'], ['6-30'], ['7-4'], ['24-29'], ['7-12'], ['19-15'], ['31-16'], ['11-2'], ['26-28'], ['23-20'], ['17-22'], ['13-11'], ['18-30'], ['14-18'], ['19-10'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_1250_depth_7500_results.json\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['21-30'], ['6-30'], ['19-15'], ['7-4'], ['24-29'], ['31-16'], ['7-12'], ['26-28'], ['23-20'], ['17-22'], ['11-2'], ['18-30'], ['13-11'], ['19-10'], ['14-18'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['21-30'], ['6-30'], ['19-15'], ['7-4'], ['24-29'], ['7-12'], ['31-16'], ['26-28'], ['23-20'], ['17-22'], ['11-2'], ['18-30'], ['13-11'], ['19-10'], ['14-18'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 75.88586807250977\n",
      "Response: Serena Williams is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 546\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['21-30'], ['6-9'], ['6-30'], ['19-15'], ['7-4'], ['24-29'], ['31-16'], ['7-12'], ['26-28'], ['23-20'], ['17-22'], ['11-2'], ['18-30'], ['13-11'], ['19-10'], ['14-18'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 63.63217234611511\n",
      "Response: Aryna Sabalenka.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1070\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['21-30'], ['6-9'], ['6-30'], ['19-15'], ['7-4'], ['24-29'], ['7-12'], ['31-16'], ['26-28'], ['23-20'], ['17-22'], ['11-2'], ['13-11'], ['18-30'], ['19-10'], ['14-18'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 63.63217234611511\n",
      "Response: Aryna Sabalenka.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1680\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['21-30'], ['6-9'], ['6-30'], ['19-15'], ['7-4'], ['24-29'], ['31-16'], ['7-12'], ['26-28'], ['23-20'], ['17-22'], ['11-2'], ['13-11'], ['18-30'], ['19-10'], ['14-18'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 63.63217234611511\n",
      "Response: Aryna Sabalenka.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_2500_depth_7500_results.json\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['21-30'], ['6-9'], ['6-30'], ['19-15'], ['7-4'], ['24-29'], ['31-16'], ['7-12'], ['26-28'], ['23-20'], ['17-22'], ['18-30'], ['19-10'], ['13-11'], ['11-2'], ['12-26'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['21-30'], ['6-9'], ['6-30'], ['19-15'], ['7-4'], ['24-29'], ['31-16'], ['7-12'], ['26-28'], ['23-20'], ['17-22'], ['18-30'], ['13-11'], ['19-10'], ['11-2'], ['12-26'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 75.88586807250977\n",
      "Response: Serena Williams is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 870\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['21-30'], ['6-9'], ['6-30'], ['19-15'], ['7-4'], ['24-29'], ['31-16'], ['7-12'], ['26-28'], ['23-20'], ['17-22'], ['13-11'], ['19-10'], ['18-30'], ['11-2'], ['14-18'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 63.63217234611511\n",
      "Response: Aryna Sabalenka.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1720\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['21-30'], ['6-9'], ['6-30'], ['19-15'], ['7-4'], ['24-29'], ['31-16'], ['7-12'], ['26-28'], ['23-20'], ['17-22'], ['13-11'], ['19-10'], ['14-18'], ['18-30'], ['22-27'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 63.63217234611511\n",
      "Response: Aryna Sabalenka.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2483\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['21-30'], ['6-9'], ['6-30'], ['19-15'], ['7-4'], ['24-29'], ['31-16'], ['7-12'], ['26-28'], ['23-20'], ['13-11'], ['19-10'], ['14-18'], ['17-22'], ['22-27'], ['18-30'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 63.63217234611511\n",
      "Response: Aryna Sabalenka.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_3750_depth_7500_results.json\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['21-30'], ['6-9'], ['6-30'], ['19-15'], ['7-4'], ['24-29'], ['31-16'], ['7-12'], ['26-28'], ['23-20'], ['13-11'], ['19-10'], ['12-26'], ['17-22'], ['14-18'], ['22-27'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['21-30'], ['6-9'], ['6-30'], ['19-15'], ['7-4'], ['24-29'], ['31-16'], ['7-12'], ['26-28'], ['23-20'], ['13-11'], ['19-10'], ['12-26'], ['17-22'], ['14-18'], ['22-27'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 75.88586807250977\n",
      "Response: Serena Williams is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1070\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['21-30'], ['6-9'], ['6-30'], ['19-15'], ['7-4'], ['24-29'], ['31-16'], ['7-12'], ['26-28'], ['23-20'], ['13-11'], ['19-10'], ['12-26'], ['14-18'], ['17-22'], ['22-22'], ['22-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 63.63217234611511\n",
      "Response: Aryna Sabalenka.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 1957\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['21-30'], ['6-9'], ['6-30'], ['19-15'], ['24-29'], ['7-4'], ['31-16'], ['7-12'], ['26-28'], ['23-20'], ['13-11'], ['19-10'], ['14-18'], ['22-22'], ['22-27'], ['12-26'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 63.63217234611511\n",
      "Response: Aryna Sabalenka.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3559\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['21-30'], ['6-9'], ['6-30'], ['19-15'], ['24-29'], ['7-4'], ['31-16'], ['7-12'], ['26-28'], ['23-20'], ['13-11'], ['22-22'], ['19-10'], ['14-18'], ['22-27'], ['21-28'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 63.63217234611511\n",
      "Response: Aryna Sabalenka.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_5000_depth_7500_results.json\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['21-30'], ['6-9'], ['6-30'], ['19-15'], ['7-4'], ['24-29'], ['31-16'], ['7-12'], ['26-28'], ['23-20'], ['13-11'], ['19-10'], ['22-22'], ['12-26'], ['14-18'], ['22-27'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant/llama-2-7b-80k_id_430_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/430.txt\n",
=======
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1145\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['17-22'], ['8-26'], ['6-9'], ['16-24'], ['7-4'], ['6-30'], ['18-30'], ['12-26'], ['17-31'], ['19-10'], ['21-30'], ['14-18'], ['7-13'], ['15-14'], ['19-15'], ['12-2'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2389\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['17-22'], ['8-26'], ['6-9'], ['16-24'], ['7-4'], ['6-30'], ['18-30'], ['12-26'], ['17-31'], ['19-10'], ['21-30'], ['14-18'], ['7-13'], ['15-14'], ['19-15'], ['12-2'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3540\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['17-22'], ['8-26'], ['6-9'], ['16-24'], ['7-4'], ['6-30'], ['18-30'], ['19-10'], ['12-26'], ['17-31'], ['14-18'], ['21-30'], ['7-13'], ['15-14'], ['19-15'], ['12-2'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['17-22'], ['8-26'], ['6-9'], ['7-4'], ['16-24'], ['6-30'], ['18-30'], ['19-10'], ['12-26'], ['17-31'], ['19-15'], ['21-30'], ['14-18'], ['15-14'], ['7-13'], ['25-3'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The hottest year on record is 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_relevant_misleading/llama-2-7b-80k_id_532_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The hottest year on record is 2024.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['6-30'], ['16-19'], ['18-30'], ['7-4'], ['7-13'], ['8-26'], ['11-15'], ['12-26'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['6-30'], ['16-19'], ['18-30'], ['7-4'], ['7-13'], ['8-26'], ['11-15'], ['12-26'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['6-30'], ['16-19'], ['18-30'], ['7-4'], ['7-13'], ['8-26'], ['11-15'], ['12-26'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['6-30'], ['16-19'], ['18-30'], ['7-4'], ['7-13'], ['8-26'], ['11-15'], ['12-26'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_0_depth_7500_results.json\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['6-30'], ['16-19'], ['18-30'], ['7-4'], ['7-13'], ['8-26'], ['11-15'], ['12-26'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 18.599025905132294\n",
      "Response: 1816.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 213\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['16-19'], ['6-30'], ['18-30'], ['14-18'], ['7-4'], ['7-13'], ['8-26'], ['11-15'], ['12-26'], ['16-24'], ['17-22'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 58.57658386230469\n",
      "Response: 2024.7–1 °F.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 506\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['16-19'], ['6-30'], ['18-30'], ['14-18'], ['8-26'], ['11-15'], ['16-24'], ['17-22'], ['7-4'], ['7-13'], ['12-26'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 720\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['16-19'], ['6-30'], ['18-30'], ['14-18'], ['8-26'], ['11-15'], ['16-24'], ['17-22'], ['7-4'], ['7-13'], ['12-26'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_1250_depth_7500_results.json\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['8-26'], ['17-22'], ['18-30'], ['6-30'], ['7-4'], ['14-18'], ['12-26'], ['16-24'], ['17-31'], ['6-9'], ['7-13'], ['19-10'], ['31-15'], ['15-14'], ['21-30'], ['12-4'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The hottest year on record is 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 15.383899211883545\n",
      "Response: 1816\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 570\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['8-26'], ['17-22'], ['18-30'], ['6-30'], ['14-18'], ['7-4'], ['16-24'], ['12-26'], ['17-31'], ['6-9'], ['7-13'], ['19-10'], ['31-15'], ['15-14'], ['21-30'], ['12-4'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1132\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['8-26'], ['17-22'], ['18-30'], ['6-30'], ['14-18'], ['16-24'], ['7-4'], ['6-9'], ['12-26'], ['17-31'], ['7-13'], ['19-10'], ['31-15'], ['15-14'], ['21-30'], ['12-4'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1678\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['8-26'], ['17-22'], ['18-30'], ['6-30'], ['14-18'], ['16-24'], ['7-4'], ['6-9'], ['12-26'], ['17-31'], ['7-13'], ['19-10'], ['31-15'], ['15-14'], ['21-30'], ['12-4'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_2500_depth_7500_results.json\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['8-26'], ['17-22'], ['18-30'], ['6-9'], ['6-30'], ['14-18'], ['7-4'], ['16-24'], ['12-26'], ['17-31'], ['7-13'], ['15-14'], ['21-30'], ['19-10'], ['19-15'], ['31-15'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The hottest year on record is 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 31.884944438934326\n",
      "Response: 1998\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 865\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['8-26'], ['17-22'], ['18-30'], ['6-9'], ['6-30'], ['14-18'], ['7-4'], ['16-24'], ['12-26'], ['17-31'], ['7-13'], ['15-14'], ['19-10'], ['21-30'], ['19-15'], ['31-15'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1741\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['8-26'], ['17-22'], ['18-30'], ['6-9'], ['6-30'], ['14-18'], ['16-24'], ['7-4'], ['12-26'], ['17-31'], ['7-13'], ['15-14'], ['21-30'], ['19-10'], ['19-15'], ['31-15'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2648\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['8-26'], ['17-22'], ['18-30'], ['6-9'], ['16-24'], ['6-30'], ['7-4'], ['14-18'], ['12-26'], ['17-31'], ['7-13'], ['15-14'], ['19-10'], ['21-30'], ['19-15'], ['31-15'], ['25-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_3750_depth_7500_results.json\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['8-26'], ['17-22'], ['16-24'], ['18-30'], ['6-9'], ['6-30'], ['7-4'], ['14-18'], ['12-26'], ['17-31'], ['7-13'], ['15-14'], ['19-10'], ['21-30'], ['19-15'], ['25-3'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 18.599025905132294\n",
      "Response: 1816.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1171\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['8-26'], ['17-22'], ['16-24'], ['18-30'], ['6-9'], ['6-30'], ['7-4'], ['14-18'], ['12-26'], ['17-31'], ['7-13'], ['15-14'], ['19-10'], ['21-30'], ['19-15'], ['25-3'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2362\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['8-26'], ['17-22'], ['16-24'], ['18-30'], ['6-9'], ['6-30'], ['14-18'], ['7-4'], ['12-26'], ['17-31'], ['7-13'], ['15-14'], ['19-10'], ['21-30'], ['19-15'], ['25-3'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3570\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['8-26'], ['17-22'], ['16-24'], ['18-30'], ['14-18'], ['6-9'], ['6-30'], ['7-4'], ['12-26'], ['17-31'], ['7-13'], ['15-14'], ['19-10'], ['21-30'], ['19-15'], ['25-3'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_5000_depth_7500_results.json\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['8-26'], ['17-22'], ['6-9'], ['16-24'], ['18-30'], ['7-4'], ['14-18'], ['6-30'], ['12-26'], ['17-31'], ['15-14'], ['21-30'], ['7-13'], ['19-10'], ['19-15'], ['25-3'], ['12-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The hottest year on record is 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant/llama-2-7b-80k_id_532_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_irrelevant/532.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The hottest year on record is 2024.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['6-30'], ['16-19'], ['18-30'], ['7-4'], ['7-13'], ['8-26'], ['11-15'], ['12-26'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['6-30'], ['16-19'], ['18-30'], ['7-4'], ['7-13'], ['8-26'], ['11-15'], ['12-26'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['6-30'], ['16-19'], ['18-30'], ['7-4'], ['7-13'], ['8-26'], ['11-15'], ['12-26'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['6-30'], ['16-19'], ['18-30'], ['7-4'], ['7-13'], ['8-26'], ['11-15'], ['12-26'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['6-30'], ['16-19'], ['18-30'], ['7-4'], ['7-13'], ['8-26'], ['11-15'], ['12-26'], ['14-18'], ['16-24'], ['17-22'], ['17-31'], ['19-10'], ['31-15'], ['1-26'], ['6-9'], ['8-31'], ['10-14'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['16-19'], ['18-30'], ['6-30'], ['11-15'], ['17-22'], ['7-4'], ['7-13'], ['8-26'], ['12-26'], ['14-18'], ['16-24'], ['17-31'], ['19-10'], ['31-15'], ['6-9'], ['12-2'], ['1-26'], ['8-31'], ['10-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 59.38352346420288\n",
      "Response: 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 213\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['16-19'], ['18-30'], ['6-30'], ['11-15'], ['14-18'], ['17-22'], ['7-4'], ['7-13'], ['8-26'], ['12-26'], ['16-24'], ['17-31'], ['19-10'], ['31-15'], ['6-9'], ['12-2'], ['1-26'], ['8-31'], ['10-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 58.57658386230469\n",
      "Response: 2024.7–1 °F.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 506\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['16-19'], ['18-30'], ['6-30'], ['14-18'], ['17-22'], ['8-26'], ['11-15'], ['7-4'], ['7-13'], ['12-26'], ['16-24'], ['17-31'], ['19-10'], ['31-15'], ['6-9'], ['12-2'], ['1-26'], ['8-31'], ['10-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 745\n",
      "The hottest year on record is 2024.\n",
      "[['24-29'], ['16-19'], ['18-30'], ['6-30'], ['14-18'], ['17-22'], ['8-26'], ['11-15'], ['16-24'], ['7-4'], ['7-13'], ['12-26'], ['17-31'], ['19-10'], ['31-15'], ['6-9'], ['12-2'], ['1-26'], ['8-31'], ['10-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['8-26'], ['17-22'], ['18-30'], ['6-30'], ['14-18'], ['7-4'], ['6-9'], ['12-26'], ['17-31'], ['19-10'], ['7-13'], ['16-24'], ['31-15'], ['15-14'], ['21-30'], ['25-3'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The hottest year on record is 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['17-22'], ['18-30'], ['8-26'], ['6-30'], ['14-18'], ['7-4'], ['17-31'], ['6-9'], ['12-26'], ['19-10'], ['7-13'], ['16-24'], ['31-15'], ['15-14'], ['21-30'], ['25-3'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 59.38352346420288\n",
      "Response: 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 570\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['17-22'], ['18-30'], ['8-26'], ['6-30'], ['14-18'], ['7-4'], ['17-31'], ['6-9'], ['12-26'], ['19-10'], ['7-13'], ['16-24'], ['31-15'], ['15-14'], ['21-30'], ['25-3'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1124\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['17-22'], ['18-30'], ['8-26'], ['14-18'], ['6-30'], ['7-4'], ['17-31'], ['6-9'], ['12-26'], ['19-10'], ['7-13'], ['16-24'], ['31-15'], ['15-14'], ['21-30'], ['25-3'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1691\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['24-29'], ['11-15'], ['17-22'], ['18-30'], ['8-26'], ['14-18'], ['6-30'], ['7-4'], ['17-31'], ['6-9'], ['12-26'], ['19-10'], ['7-13'], ['16-24'], ['31-15'], ['15-14'], ['21-30'], ['25-3'], ['12-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['17-22'], ['8-26'], ['18-30'], ['6-9'], ['14-18'], ['7-4'], ['6-30'], ['17-31'], ['12-26'], ['19-10'], ['21-30'], ['7-13'], ['15-14'], ['16-24'], ['25-3'], ['31-15'], ['19-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The hottest year on record is 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['11-15'], ['24-29'], ['17-22'], ['8-26'], ['18-30'], ['6-9'], ['7-4'], ['14-18'], ['6-30'], ['17-31'], ['12-26'], ['19-10'], ['7-13'], ['21-30'], ['15-14'], ['16-24'], ['25-3'], ['31-15'], ['19-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 59.38352346420288\n",
      "Response: 2024\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 745\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['24-29'], ['8-26'], ['18-30'], ['14-18'], ['6-9'], ['7-4'], ['6-30'], ['17-31'], ['12-26'], ['19-10'], ['7-13'], ['21-30'], ['15-14'], ['16-24'], ['25-3'], ['31-15'], ['19-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1731\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['24-29'], ['8-26'], ['18-30'], ['14-18'], ['6-9'], ['7-4'], ['6-30'], ['17-31'], ['12-26'], ['19-10'], ['7-13'], ['21-30'], ['15-14'], ['16-24'], ['25-3'], ['31-15'], ['19-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2632\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['24-29'], ['8-26'], ['14-18'], ['18-30'], ['6-9'], ['7-4'], ['6-30'], ['17-31'], ['12-26'], ['19-10'], ['7-13'], ['16-24'], ['21-30'], ['15-14'], ['25-3'], ['31-15'], ['19-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['8-26'], ['24-29'], ['6-9'], ['18-30'], ['14-18'], ['7-4'], ['6-30'], ['17-31'], ['19-10'], ['12-26'], ['21-30'], ['15-14'], ['7-13'], ['16-24'], ['19-15'], ['25-3'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The hottest year on record is 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['8-26'], ['24-29'], ['6-9'], ['18-30'], ['14-18'], ['7-4'], ['6-30'], ['17-31'], ['19-10'], ['12-26'], ['21-30'], ['15-14'], ['7-13'], ['16-24'], ['19-15'], ['25-3'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1196\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['8-26'], ['24-29'], ['6-9'], ['18-30'], ['14-18'], ['7-4'], ['6-30'], ['17-31'], ['19-10'], ['12-26'], ['21-30'], ['15-14'], ['7-13'], ['16-24'], ['19-15'], ['25-3'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2343\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['24-29'], ['6-9'], ['18-30'], ['14-18'], ['7-4'], ['6-30'], ['17-31'], ['19-10'], ['12-26'], ['21-30'], ['15-14'], ['16-24'], ['7-13'], ['19-15'], ['25-3'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3547\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['24-29'], ['6-9'], ['14-18'], ['18-30'], ['7-4'], ['6-30'], ['17-31'], ['19-10'], ['12-26'], ['21-30'], ['16-24'], ['15-14'], ['7-13'], ['19-15'], ['25-3'], ['31-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 60.14469861984253\n",
      "Response: 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The hottest year on record is 2024.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['17-22'], ['6-9'], ['24-29'], ['18-30'], ['7-4'], ['14-18'], ['6-30'], ['17-31'], ['12-26'], ['19-10'], ['21-30'], ['15-14'], ['19-15'], ['7-13'], ['16-24'], ['25-3'], ['11-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The hottest year on record is 2024.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_532_irrelevant_misleading/llama-2-7b-80k_id_532_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The current Jeopardy! host is Ken Jennings.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['18-30'], ['19-15'], ['31-16'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13'], ['14-15'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['18-30'], ['19-15'], ['31-16'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13'], ['14-15'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['18-30'], ['19-15'], ['31-16'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13'], ['14-15'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['18-30'], ['19-15'], ['31-16'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13'], ['14-15'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_0_depth_7500_results.json\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['18-30'], ['19-15'], ['31-16'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13'], ['14-15'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['19-15'], ['6-30'], ['18-30'], ['31-16'], ['17-22'], ['26-28'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_1250_depth_0_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['19-15'], ['6-30'], ['18-30'], ['31-16'], ['17-22'], ['26-28'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['19-15'], ['6-30'], ['18-30'], ['31-16'], ['17-22'], ['26-28'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['19-15'], ['6-30'], ['18-30'], ['31-16'], ['17-22'], ['26-28'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_1250_depth_7500_results.json\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['19-15'], ['6-30'], ['18-30'], ['31-16'], ['26-28'], ['17-22'], ['8-26'], ['15-14'], ['7-4'], ['7-31'], ['8-22'], ['10-29'], ['13-11'], ['14-13'], ['14-18'], ['14-24'], ['16-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['19-15'], ['6-30'], ['18-30'], ['31-16'], ['26-28'], ['17-22'], ['8-26'], ['15-14'], ['7-4'], ['7-31'], ['8-22'], ['10-29'], ['13-11'], ['14-13'], ['14-18'], ['14-24'], ['16-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 63.06288242340088\n",
      "Response: Alex Trebek\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_2500_depth_0_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['19-15'], ['6-30'], ['18-30'], ['31-16'], ['26-28'], ['17-22'], ['8-26'], ['15-14'], ['7-4'], ['7-31'], ['8-22'], ['10-29'], ['13-11'], ['14-13'], ['14-18'], ['14-24'], ['16-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 63.06288242340088\n",
      "Response: Alex Trebek\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1096\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['19-15'], ['18-30'], ['6-30'], ['26-28'], ['31-16'], ['17-22'], ['15-14'], ['8-22'], ['8-26'], ['14-18'], ['17-0'], ['21-1'], ['22-22'], ['24-14'], ['7-4'], ['7-31'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1700\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['19-15'], ['18-30'], ['26-28'], ['6-30'], ['31-16'], ['17-22'], ['15-14'], ['8-22'], ['14-18'], ['17-0'], ['21-1'], ['22-22'], ['24-14'], ['7-4'], ['8-26'], ['20-10'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_2500_depth_7500_results.json\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['19-15'], ['18-30'], ['26-28'], ['31-16'], ['6-30'], ['15-14'], ['17-22'], ['14-18'], ['17-0'], ['21-1'], ['22-22'], ['24-14'], ['7-4'], ['8-22'], ['8-26'], ['14-13'], ['20-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['19-15'], ['18-30'], ['26-28'], ['31-16'], ['6-30'], ['17-22'], ['15-14'], ['14-18'], ['17-0'], ['21-1'], ['22-22'], ['24-14'], ['7-4'], ['8-22'], ['8-26'], ['14-13'], ['20-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_3750_depth_0_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['19-15'], ['18-30'], ['26-28'], ['31-16'], ['6-30'], ['17-22'], ['15-14'], ['14-18'], ['17-0'], ['21-1'], ['22-22'], ['24-14'], ['7-4'], ['8-22'], ['8-26'], ['14-13'], ['20-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1760\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['19-15'], ['18-30'], ['26-28'], ['6-30'], ['31-16'], ['17-22'], ['15-14'], ['14-18'], ['17-0'], ['21-1'], ['22-22'], ['7-4'], ['8-22'], ['24-14'], ['8-26'], ['20-10'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2640\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['19-15'], ['18-30'], ['26-28'], ['31-16'], ['6-30'], ['17-22'], ['15-14'], ['14-18'], ['17-0'], ['21-1'], ['22-22'], ['24-14'], ['7-4'], ['8-22'], ['20-10'], ['8-26'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_3750_depth_7500_results.json\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['19-15'], ['18-30'], ['26-28'], ['31-16'], ['6-30'], ['15-14'], ['17-22'], ['14-18'], ['17-0'], ['21-1'], ['22-22'], ['24-14'], ['7-4'], ['8-22'], ['8-26'], ['20-10'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['18-30'], ['26-28'], ['31-16'], ['6-30'], ['17-22'], ['15-14'], ['14-18'], ['21-1'], ['22-22'], ['17-0'], ['24-14'], ['7-4'], ['8-22'], ['8-26'], ['20-10'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1096\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['26-28'], ['19-15'], ['18-30'], ['6-30'], ['31-16'], ['17-22'], ['15-14'], ['14-18'], ['21-1'], ['22-22'], ['17-0'], ['24-14'], ['7-4'], ['8-22'], ['8-26'], ['20-10'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2342\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['26-28'], ['19-15'], ['18-30'], ['6-30'], ['31-16'], ['17-22'], ['15-14'], ['14-18'], ['21-1'], ['22-22'], ['17-0'], ['7-4'], ['8-22'], ['24-14'], ['8-26'], ['20-10'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3581\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['26-28'], ['6-9'], ['19-15'], ['18-30'], ['6-30'], ['31-16'], ['15-14'], ['17-22'], ['14-18'], ['21-1'], ['22-22'], ['17-0'], ['7-4'], ['8-22'], ['24-14'], ['8-26'], ['20-10'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_5000_depth_7500_results.json\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['26-28'], ['6-9'], ['19-15'], ['18-30'], ['6-30'], ['31-16'], ['15-14'], ['17-22'], ['14-18'], ['21-1'], ['22-22'], ['17-0'], ['7-4'], ['8-22'], ['24-14'], ['8-26'], ['21-30'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant/llama-2-7b-80k_id_535_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_relevant/535.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The current Jeopardy! host is Ken Jennings.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['18-30'], ['19-15'], ['31-16'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13'], ['14-15'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['18-30'], ['19-15'], ['31-16'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13'], ['14-15'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['18-30'], ['19-15'], ['31-16'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13'], ['14-15'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['18-30'], ['19-15'], ['31-16'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13'], ['14-15'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_0_depth_7500_results.json\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['18-30'], ['19-15'], ['31-16'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13'], ['14-15'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['19-15'], ['6-30'], ['18-30'], ['31-16'], ['17-22'], ['26-28'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['19-15'], ['6-30'], ['18-30'], ['31-16'], ['17-22'], ['26-28'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['19-15'], ['6-30'], ['18-30'], ['31-16'], ['17-22'], ['26-28'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['19-15'], ['6-30'], ['18-30'], ['31-16'], ['17-22'], ['26-28'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['19-15'], ['6-30'], ['18-30'], ['31-16'], ['26-28'], ['17-22'], ['8-26'], ['15-14'], ['7-4'], ['7-31'], ['8-22'], ['10-29'], ['13-11'], ['14-13'], ['14-18'], ['14-24'], ['16-4']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['19-15'], ['6-30'], ['18-30'], ['26-28'], ['31-16'], ['17-22'], ['8-26'], ['14-18'], ['15-14'], ['21-1'], ['7-4'], ['7-31'], ['8-22'], ['10-29'], ['13-11'], ['14-13'], ['14-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['19-15'], ['26-28'], ['6-30'], ['18-30'], ['31-16'], ['17-22'], ['14-18'], ['21-1'], ['8-26'], ['15-14'], ['7-4'], ['7-31'], ['8-22'], ['10-29'], ['13-11'], ['14-13'], ['14-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1096\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['26-28'], ['6-30'], ['18-30'], ['31-16'], ['17-22'], ['14-18'], ['21-1'], ['15-14'], ['8-22'], ['8-26'], ['22-22'], ['24-14'], ['7-4'], ['7-31'], ['10-29'], ['13-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1684\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['26-28'], ['18-30'], ['6-30'], ['31-16'], ['17-22'], ['14-18'], ['21-1'], ['15-14'], ['22-22'], ['7-4'], ['8-22'], ['8-26'], ['17-0'], ['24-14'], ['7-12'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['26-28'], ['18-30'], ['6-30'], ['31-16'], ['17-22'], ['14-18'], ['21-1'], ['15-14'], ['8-26'], ['22-22'], ['7-4'], ['8-22'], ['17-0'], ['24-14'], ['7-31'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['26-28'], ['18-30'], ['6-30'], ['31-16'], ['17-22'], ['14-18'], ['21-1'], ['15-14'], ['8-26'], ['22-22'], ['7-4'], ['8-22'], ['17-0'], ['24-14'], ['7-31'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['26-28'], ['18-30'], ['6-30'], ['31-16'], ['17-22'], ['14-18'], ['21-1'], ['15-14'], ['8-26'], ['22-22'], ['7-4'], ['8-22'], ['17-0'], ['24-14'], ['7-31'], ['10-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1744\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['26-28'], ['6-9'], ['18-30'], ['6-30'], ['31-16'], ['17-22'], ['14-18'], ['21-1'], ['15-14'], ['22-22'], ['8-26'], ['24-14'], ['7-4'], ['8-22'], ['17-0'], ['7-12'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2652\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['26-28'], ['6-9'], ['18-30'], ['6-30'], ['31-16'], ['17-22'], ['14-18'], ['15-14'], ['21-1'], ['22-22'], ['24-14'], ['7-4'], ['8-26'], ['17-0'], ['7-12'], ['8-22'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['26-28'], ['6-9'], ['18-30'], ['6-30'], ['31-16'], ['15-14'], ['14-18'], ['17-22'], ['21-1'], ['24-14'], ['22-22'], ['7-4'], ['8-26'], ['17-0'], ['8-22'], ['7-12'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['26-28'], ['6-9'], ['18-30'], ['6-30'], ['31-16'], ['15-14'], ['17-22'], ['21-1'], ['14-18'], ['22-22'], ['24-14'], ['7-4'], ['8-26'], ['17-0'], ['8-22'], ['7-12'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1096\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['26-28'], ['6-9'], ['18-30'], ['6-30'], ['31-16'], ['15-14'], ['17-22'], ['21-1'], ['14-18'], ['22-22'], ['24-14'], ['7-4'], ['8-26'], ['17-0'], ['7-12'], ['8-22'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2382\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['26-28'], ['11-15'], ['19-15'], ['6-9'], ['18-30'], ['31-16'], ['6-30'], ['17-22'], ['21-1'], ['14-18'], ['15-14'], ['22-22'], ['24-14'], ['17-0'], ['7-4'], ['7-12'], ['8-22'], ['8-26'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3571\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['26-28'], ['19-15'], ['11-15'], ['6-9'], ['18-30'], ['31-16'], ['6-30'], ['15-14'], ['17-22'], ['21-1'], ['14-18'], ['22-22'], ['17-0'], ['24-14'], ['7-12'], ['8-22'], ['7-4'], ['8-26'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['26-28'], ['19-15'], ['11-15'], ['6-9'], ['18-30'], ['31-16'], ['6-30'], ['15-14'], ['21-1'], ['14-18'], ['17-22'], ['22-22'], ['17-0'], ['24-14'], ['8-22'], ['7-4'], ['7-12'], ['8-26'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_relevant_misleading/llama-2-7b-80k_id_535_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The current Jeopardy! host is Ken Jennings.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['18-30'], ['19-15'], ['31-16'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13'], ['14-15'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['18-30'], ['19-15'], ['31-16'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13'], ['14-15'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['18-30'], ['19-15'], ['31-16'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13'], ['14-15'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['18-30'], ['19-15'], ['31-16'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13'], ['14-15'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_0_depth_7500_results.json\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['18-30'], ['19-15'], ['31-16'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13'], ['14-15'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['18-30'], ['19-15'], ['31-16'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13'], ['14-15'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 63.06288242340088\n",
      "Response: Alex Trebek\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 241\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['11-15'], ['19-15'], ['18-30'], ['31-16'], ['7-4'], ['14-18'], ['16-30'], ['17-0'], ['20-10'], ['21-1'], ['22-22'], ['26-28'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 452\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['11-15'], ['19-15'], ['18-30'], ['31-16'], ['7-4'], ['14-18'], ['16-30'], ['17-0'], ['20-10'], ['21-1'], ['22-22'], ['26-28'], ['10-18'], ['14-15'], ['7-31'], ['8-22'], ['8-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 452\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['11-15'], ['19-15'], ['18-30'], ['31-16'], ['7-4'], ['14-18'], ['16-30'], ['17-0'], ['20-10'], ['21-1'], ['22-22'], ['26-28'], ['10-18'], ['14-15'], ['7-31'], ['8-22'], ['8-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_1250_depth_7500_results.json\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-30'], ['11-15'], ['19-15'], ['18-30'], ['6-9'], ['31-16'], ['26-28'], ['7-4'], ['14-18'], ['17-0'], ['21-1'], ['22-22'], ['10-18'], ['14-15'], ['16-30'], ['20-10'], ['8-26'], ['15-14'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-30'], ['11-15'], ['6-9'], ['19-15'], ['18-30'], ['31-16'], ['26-28'], ['22-22'], ['8-26'], ['7-4'], ['14-18'], ['17-0'], ['21-1'], ['10-18'], ['14-15'], ['16-30'], ['20-10'], ['7-31'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 452\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-30'], ['11-15'], ['18-30'], ['6-9'], ['19-15'], ['26-28'], ['31-16'], ['22-22'], ['8-26'], ['7-4'], ['14-18'], ['17-0'], ['21-1'], ['10-18'], ['16-30'], ['20-10'], ['14-15'], ['7-31'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1119\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-30'], ['11-15'], ['18-30'], ['6-9'], ['19-15'], ['26-28'], ['31-16'], ['22-22'], ['8-26'], ['7-4'], ['14-18'], ['17-0'], ['21-1'], ['10-18'], ['20-10'], ['16-30'], ['14-15'], ['7-12'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1652\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['18-30'], ['6-30'], ['11-15'], ['19-15'], ['6-9'], ['26-28'], ['22-22'], ['31-16'], ['7-4'], ['14-18'], ['17-0'], ['21-1'], ['8-26'], ['10-18'], ['20-10'], ['16-30'], ['14-15'], ['7-12'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_2500_depth_7500_results.json\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-30'], ['11-15'], ['18-30'], ['19-15'], ['6-9'], ['26-28'], ['31-16'], ['22-22'], ['8-26'], ['7-4'], ['14-18'], ['17-0'], ['21-1'], ['10-18'], ['20-10'], ['16-30'], ['15-14'], ['14-15'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-30'], ['11-15'], ['18-30'], ['19-15'], ['6-9'], ['26-28'], ['22-22'], ['31-16'], ['7-4'], ['8-26'], ['14-18'], ['17-0'], ['21-1'], ['10-18'], ['20-10'], ['16-30'], ['14-15'], ['15-14'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 63.06288242340088\n",
      "Response: Alex Trebek\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 874\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-30'], ['11-15'], ['18-30'], ['19-15'], ['6-9'], ['26-28'], ['22-22'], ['31-16'], ['7-4'], ['8-26'], ['14-18'], ['17-0'], ['21-1'], ['10-18'], ['20-10'], ['16-30'], ['14-15'], ['15-14'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1739\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-30'], ['11-15'], ['18-30'], ['19-15'], ['26-28'], ['6-9'], ['22-22'], ['7-4'], ['8-26'], ['14-18'], ['17-0'], ['21-1'], ['31-16'], ['10-18'], ['20-10'], ['16-30'], ['7-12'], ['14-15'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2648\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-30'], ['11-15'], ['18-30'], ['19-15'], ['26-28'], ['6-9'], ['22-22'], ['7-4'], ['8-26'], ['14-18'], ['17-0'], ['21-1'], ['31-16'], ['10-18'], ['20-10'], ['16-30'], ['7-12'], ['14-15'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 63.06288242340088\n",
      "Response: Alex Trebek\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_3750_depth_7500_results.json\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-30'], ['11-15'], ['18-30'], ['19-15'], ['26-28'], ['6-9'], ['22-22'], ['8-26'], ['31-16'], ['7-4'], ['14-18'], ['17-0'], ['21-1'], ['10-18'], ['20-10'], ['15-14'], ['16-30'], ['14-15'], ['21-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-30'], ['11-15'], ['18-30'], ['19-15'], ['6-9'], ['26-28'], ['8-26'], ['22-22'], ['7-4'], ['14-18'], ['31-16'], ['17-0'], ['21-1'], ['10-18'], ['20-10'], ['7-12'], ['15-14'], ['21-30'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1186\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-30'], ['11-15'], ['18-30'], ['19-15'], ['26-28'], ['6-9'], ['8-26'], ['22-22'], ['7-4'], ['14-18'], ['17-0'], ['21-1'], ['31-16'], ['10-18'], ['20-10'], ['7-12'], ['21-30'], ['15-14'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2384\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-30'], ['11-15'], ['18-30'], ['26-28'], ['19-15'], ['6-9'], ['8-26'], ['22-22'], ['7-4'], ['14-18'], ['17-0'], ['21-1'], ['10-18'], ['20-10'], ['31-16'], ['7-12'], ['21-30'], ['15-14'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3557\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-30'], ['11-15'], ['26-28'], ['18-30'], ['19-15'], ['6-9'], ['8-26'], ['22-22'], ['7-4'], ['14-18'], ['17-0'], ['21-1'], ['10-18'], ['20-10'], ['31-16'], ['7-12'], ['15-14'], ['21-30'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_5000_depth_7500_results.json\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-30'], ['11-15'], ['26-28'], ['18-30'], ['19-15'], ['6-9'], ['8-26'], ['22-22'], ['7-4'], ['14-18'], ['17-0'], ['21-1'], ['31-16'], ['10-18'], ['20-10'], ['15-14'], ['21-30'], ['7-12'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant/llama-2-7b-80k_id_535_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_irrelevant/535.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The current Jeopardy! host is Ken Jennings.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['18-30'], ['19-15'], ['31-16'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13'], ['14-15'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['18-30'], ['19-15'], ['31-16'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13'], ['14-15'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['18-30'], ['19-15'], ['31-16'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13'], ['14-15'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['18-30'], ['19-15'], ['31-16'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13'], ['14-15'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['18-30'], ['19-15'], ['31-16'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13'], ['14-15'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['18-30'], ['19-15'], ['31-16'], ['7-4'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14'], ['10-18'], ['10-29'], ['12-16'], ['13-11'], ['14-13'], ['14-15'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 63.06288242340088\n",
      "Response: Alex Trebek\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 241\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['11-15'], ['19-15'], ['18-30'], ['31-16'], ['7-4'], ['14-18'], ['16-30'], ['17-0'], ['20-10'], ['21-1'], ['22-22'], ['26-28'], ['7-31'], ['8-22'], ['8-26'], ['9-8'], ['10-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 452\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['11-15'], ['19-15'], ['18-30'], ['31-16'], ['7-4'], ['14-18'], ['16-30'], ['17-0'], ['20-10'], ['21-1'], ['22-22'], ['26-28'], ['10-18'], ['14-15'], ['7-31'], ['8-22'], ['8-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 452\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['11-15'], ['19-15'], ['18-30'], ['31-16'], ['7-4'], ['14-18'], ['16-30'], ['17-0'], ['20-10'], ['21-1'], ['22-22'], ['26-28'], ['10-18'], ['14-15'], ['7-31'], ['8-22'], ['8-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['6-30'], ['11-15'], ['19-15'], ['18-30'], ['6-9'], ['31-16'], ['26-28'], ['7-4'], ['14-18'], ['17-0'], ['21-1'], ['22-22'], ['10-18'], ['14-15'], ['16-30'], ['20-10'], ['8-26'], ['15-14'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['6-30'], ['19-15'], ['18-30'], ['6-9'], ['31-16'], ['26-28'], ['7-4'], ['14-18'], ['17-0'], ['21-1'], ['22-22'], ['10-18'], ['14-15'], ['16-30'], ['20-10'], ['8-26'], ['15-14'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 452\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['6-30'], ['19-15'], ['18-30'], ['31-16'], ['26-28'], ['21-1'], ['7-4'], ['14-18'], ['17-0'], ['22-22'], ['10-18'], ['14-15'], ['16-30'], ['20-10'], ['8-26'], ['15-14'], ['7-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1119\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['6-30'], ['19-15'], ['18-30'], ['26-28'], ['31-16'], ['21-1'], ['14-18'], ['7-4'], ['17-0'], ['20-10'], ['22-22'], ['8-26'], ['10-18'], ['14-15'], ['16-30'], ['15-14'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1669\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['19-15'], ['18-30'], ['6-30'], ['26-28'], ['31-16'], ['21-1'], ['14-18'], ['20-10'], ['22-22'], ['7-4'], ['17-0'], ['8-26'], ['10-18'], ['14-15'], ['15-14'], ['16-30'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['18-30'], ['6-9'], ['6-30'], ['26-28'], ['31-16'], ['21-1'], ['14-18'], ['22-22'], ['7-4'], ['17-0'], ['20-10'], ['8-26'], ['10-18'], ['14-15'], ['15-14'], ['16-30'], ['24-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['6-9'], ['18-30'], ['26-28'], ['6-30'], ['31-16'], ['21-1'], ['14-18'], ['22-22'], ['7-4'], ['17-0'], ['20-10'], ['8-26'], ['10-18'], ['14-15'], ['15-14'], ['16-30'], ['24-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 874\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['26-28'], ['6-9'], ['19-15'], ['18-30'], ['6-30'], ['31-16'], ['21-1'], ['14-18'], ['22-22'], ['7-4'], ['17-0'], ['20-10'], ['8-26'], ['10-18'], ['14-15'], ['15-14'], ['7-12'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1756\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['26-28'], ['6-9'], ['19-15'], ['18-30'], ['6-30'], ['31-16'], ['21-1'], ['14-18'], ['22-22'], ['7-4'], ['17-0'], ['20-10'], ['7-12'], ['8-26'], ['10-18'], ['14-15'], ['15-14'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2644\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['26-28'], ['6-9'], ['19-15'], ['18-30'], ['6-30'], ['21-1'], ['31-16'], ['14-18'], ['22-22'], ['7-4'], ['17-0'], ['20-10'], ['15-14'], ['7-12'], ['8-26'], ['10-18'], ['14-15'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['26-28'], ['19-15'], ['6-9'], ['18-30'], ['6-30'], ['31-16'], ['21-1'], ['14-18'], ['22-22'], ['15-14'], ['7-4'], ['17-0'], ['8-26'], ['20-10'], ['7-12'], ['10-18'], ['14-15'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['26-28'], ['19-15'], ['6-9'], ['18-30'], ['6-30'], ['31-16'], ['21-1'], ['14-18'], ['22-22'], ['15-14'], ['7-4'], ['17-0'], ['8-26'], ['20-10'], ['7-12'], ['10-18'], ['14-15'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1186\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['11-15'], ['26-28'], ['19-15'], ['6-9'], ['18-30'], ['6-30'], ['31-16'], ['21-1'], ['14-18'], ['22-22'], ['15-14'], ['17-0'], ['7-4'], ['20-10'], ['8-26'], ['7-12'], ['10-18'], ['14-15'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2374\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['26-28'], ['11-15'], ['19-15'], ['6-9'], ['18-30'], ['31-16'], ['6-30'], ['21-1'], ['14-18'], ['22-22'], ['17-0'], ['15-14'], ['20-10'], ['7-4'], ['7-12'], ['8-26'], ['10-18'], ['14-15'], ['8-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 59.703052043914795\n",
      "Response: Ken Jennings\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3579\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['26-28'], ['11-15'], ['19-15'], ['6-9'], ['18-30'], ['31-16'], ['21-1'], ['6-30'], ['14-18'], ['22-22'], ['15-14'], ['17-0'], ['20-10'], ['7-12'], ['7-4'], ['8-26'], ['10-18'], ['14-15'], ['24-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The current Jeopardy! host is Ken Jennings.\n",
      "[['16-19'], ['26-28'], ['11-15'], ['19-15'], ['18-30'], ['6-9'], ['31-16'], ['6-30'], ['21-1'], ['14-18'], ['15-14'], ['22-22'], ['17-0'], ['20-10'], ['7-4'], ['7-12'], ['8-26'], ['14-15'], ['10-18'], ['24-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 60.117554664611816\n",
      "Response: Ken Jennings.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_535_irrelevant_misleading/llama-2-7b-80k_id_535_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-30'], ['21-30'], ['15-14'], ['7-4'], ['13-11'], ['14-18'], ['17-22'], ['19-15'], ['29-26'], ['6-11'], ['13-23'], ['18-30'], ['24-29'], ['31-16'], ['31-24'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-30'], ['21-30'], ['15-14'], ['7-4'], ['13-11'], ['14-18'], ['17-22'], ['19-15'], ['29-26'], ['6-11'], ['13-23'], ['18-30'], ['24-29'], ['31-16'], ['31-24'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-30'], ['21-30'], ['15-14'], ['7-4'], ['13-11'], ['14-18'], ['17-22'], ['19-15'], ['29-26'], ['6-11'], ['13-23'], ['18-30'], ['24-29'], ['31-16'], ['31-24'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-30'], ['21-30'], ['15-14'], ['7-4'], ['13-11'], ['14-18'], ['17-22'], ['19-15'], ['29-26'], ['6-11'], ['13-23'], ['18-30'], ['24-29'], ['31-16'], ['31-24'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_0_depth_7500_results.json\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-30'], ['21-30'], ['15-14'], ['7-4'], ['13-11'], ['14-18'], ['17-22'], ['19-15'], ['29-26'], ['6-11'], ['13-23'], ['18-30'], ['24-29'], ['31-16'], ['31-24'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['6-30'], ['15-14'], ['19-15'], ['17-22'], ['14-18'], ['7-4'], ['13-11'], ['11-2'], ['29-26'], ['18-30'], ['24-29'], ['6-11'], ['13-23'], ['31-16'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 98.84334802627563\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for $75.4 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_1250_depth_0_results.json\n",
      "insertion at 242\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['6-30'], ['15-14'], ['17-22'], ['19-15'], ['11-2'], ['7-4'], ['14-18'], ['13-11'], ['18-30'], ['29-26'], ['24-29'], ['7-12'], ['6-11'], ['31-16'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 93.97348165512085\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion. Sony also criticized the merger, concerned that Microsoft would make the lucrative Call of D\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 482\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['17-22'], ['11-2'], ['6-30'], ['15-14'], ['19-15'], ['7-4'], ['14-18'], ['13-11'], ['18-30'], ['7-12'], ['24-29'], ['29-26'], ['6-16'], ['31-16'], ['6-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 95.41691541671753\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion. Microsoft is a dominant player in computing software, and also makes the Xbox line of game consoles\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 745\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['17-22'], ['7-4'], ['19-15'], ['15-14'], ['6-30'], ['18-30'], ['14-18'], ['13-11'], ['24-29'], ['6-16'], ['7-12'], ['29-26'], ['31-16'], ['6-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 94.83103156089783\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion. Upon completion of the deal, Activision Blizzard would be a sibling entity to Xbox\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_1250_depth_7500_results.json\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['17-22'], ['7-4'], ['19-15'], ['15-14'], ['6-30'], ['18-30'], ['14-18'], ['13-11'], ['24-29'], ['31-16'], ['6-16'], ['29-26'], ['7-12'], ['6-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['17-22'], ['19-15'], ['7-4'], ['15-14'], ['6-30'], ['18-30'], ['14-18'], ['13-11'], ['24-29'], ['6-16'], ['7-12'], ['31-16'], ['29-26'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 98.84334802627563\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for $75.4 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_2500_depth_0_results.json\n",
      "insertion at 552\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['17-22'], ['19-15'], ['7-4'], ['15-14'], ['6-30'], ['18-30'], ['14-18'], ['24-29'], ['13-11'], ['6-16'], ['7-12'], ['31-16'], ['29-26'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1098\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['17-22'], ['19-15'], ['7-4'], ['15-14'], ['6-30'], ['18-30'], ['14-18'], ['24-29'], ['13-11'], ['6-16'], ['7-12'], ['31-16'], ['29-26'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1668\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['17-22'], ['19-15'], ['15-14'], ['7-4'], ['6-30'], ['18-30'], ['14-18'], ['24-29'], ['13-11'], ['6-16'], ['7-12'], ['31-16'], ['29-26'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_2500_depth_7500_results.json\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['17-22'], ['19-15'], ['7-4'], ['15-14'], ['6-30'], ['18-30'], ['14-18'], ['24-29'], ['13-11'], ['31-16'], ['6-16'], ['7-12'], ['29-26'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['17-22'], ['19-15'], ['7-4'], ['15-14'], ['6-30'], ['18-30'], ['14-18'], ['24-29'], ['6-16'], ['13-11'], ['7-12'], ['31-16'], ['29-26'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 98.84334802627563\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for $75.4 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_3750_depth_0_results.json\n",
      "insertion at 848\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['11-2'], ['21-30'], ['17-22'], ['19-15'], ['7-4'], ['15-14'], ['6-30'], ['18-30'], ['14-18'], ['6-16'], ['24-29'], ['7-12'], ['13-11'], ['31-16'], ['17-0'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1744\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['11-2'], ['21-30'], ['17-22'], ['19-15'], ['15-14'], ['7-4'], ['6-30'], ['18-30'], ['6-16'], ['14-18'], ['24-29'], ['7-12'], ['13-11'], ['31-16'], ['17-0'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 95.42503356933594\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion. The deal was set to close by July 18, 2023, after which\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2638\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['11-2'], ['21-30'], ['17-22'], ['19-15'], ['7-4'], ['15-14'], ['18-30'], ['6-30'], ['6-16'], ['14-18'], ['7-12'], ['24-29'], ['13-11'], ['31-16'], ['14-15'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_3750_depth_7500_results.json\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['11-2'], ['21-30'], ['17-22'], ['19-15'], ['7-4'], ['15-14'], ['18-30'], ['6-30'], ['6-16'], ['14-18'], ['24-29'], ['7-12'], ['13-11'], ['31-16'], ['14-15'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['11-2'], ['21-30'], ['17-22'], ['19-15'], ['7-4'], ['15-14'], ['18-30'], ['6-30'], ['6-16'], ['14-18'], ['7-12'], ['24-29'], ['13-11'], ['31-16'], ['14-15'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1166\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['11-2'], ['21-30'], ['17-22'], ['19-15'], ['7-4'], ['15-14'], ['18-30'], ['6-16'], ['6-30'], ['7-12'], ['14-18'], ['24-29'], ['13-11'], ['31-16'], ['14-15'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 98.56845140457153\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion. In a statement released on Activision Blizzard's investor website, the company said its\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 1992\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['11-2'], ['17-22'], ['21-30'], ['19-15'], ['15-14'], ['7-4'], ['6-16'], ['18-30'], ['7-12'], ['6-30'], ['14-18'], ['24-29'], ['13-11'], ['31-16'], ['14-15'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3563\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['11-2'], ['17-22'], ['21-30'], ['19-15'], ['15-14'], ['7-4'], ['6-16'], ['18-30'], ['7-12'], ['6-30'], ['14-18'], ['24-29'], ['13-11'], ['31-16'], ['20-30'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_5000_depth_7500_results.json\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['11-2'], ['21-30'], ['17-22'], ['19-15'], ['7-4'], ['15-14'], ['18-30'], ['6-16'], ['6-30'], ['7-12'], ['14-18'], ['24-29'], ['13-11'], ['31-16'], ['20-30'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant/llama-2-7b-80k_id_539_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_relevant/539.txt\n",
>>>>>>> Stashed changes
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
=======
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n"
>>>>>>> Stashed changes
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
<<<<<<< Updated upstream
      "- Needle: The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
=======
      "- Needle: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
>>>>>>> Stashed changes
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
<<<<<<< Updated upstream
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['6-9'], ['8-26'], ['11-15'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-31'], ['8-31'], ['9-8'], ['10-18'], ['14-18']]\n",
=======
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-30'], ['21-30'], ['15-14'], ['7-4'], ['13-11'], ['14-18'], ['17-22'], ['19-15'], ['29-26'], ['6-11'], ['13-23'], ['18-30'], ['24-29'], ['31-16'], ['31-24'], ['0-11']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
<<<<<<< Updated upstream
      "Score: 63.78287076950073\n",
      "Response: Aryna Sabalenka\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['6-9'], ['8-26'], ['11-15'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-31'], ['8-31'], ['9-8'], ['10-18'], ['14-18']]\n",
=======
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-30'], ['21-30'], ['15-14'], ['7-4'], ['13-11'], ['14-18'], ['17-22'], ['19-15'], ['29-26'], ['6-11'], ['13-23'], ['18-30'], ['24-29'], ['31-16'], ['31-24'], ['0-11']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
<<<<<<< Updated upstream
      "Score: 63.78287076950073\n",
      "Response: Aryna Sabalenka\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['6-9'], ['8-26'], ['11-15'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-31'], ['8-31'], ['9-8'], ['10-18'], ['14-18']]\n",
=======
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-30'], ['21-30'], ['15-14'], ['7-4'], ['13-11'], ['14-18'], ['17-22'], ['19-15'], ['29-26'], ['6-11'], ['13-23'], ['18-30'], ['24-29'], ['31-16'], ['31-24'], ['0-11']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
<<<<<<< Updated upstream
      "Score: 63.78287076950073\n",
      "Response: Aryna Sabalenka\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['6-9'], ['8-26'], ['11-15'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-31'], ['8-31'], ['9-8'], ['10-18'], ['14-18']]\n",
=======
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-30'], ['21-30'], ['15-14'], ['7-4'], ['13-11'], ['14-18'], ['17-22'], ['19-15'], ['29-26'], ['6-11'], ['13-23'], ['18-30'], ['24-29'], ['31-16'], ['31-24'], ['0-11']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
<<<<<<< Updated upstream
      "Score: 63.78287076950073\n",
      "Response: Aryna Sabalenka\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['6-30'], ['16-19'], ['21-30'], ['6-9'], ['8-26'], ['11-15'], ['7-4'], ['19-15'], ['24-29'], ['31-16'], ['13-11'], ['18-30'], ['23-20'], ['26-28'], ['1-9'], ['7-31'], ['8-31'], ['9-8'], ['10-18'], ['14-18']]\n",
=======
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_0_depth_7500_results.json\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-30'], ['21-30'], ['15-14'], ['7-4'], ['13-11'], ['14-18'], ['17-22'], ['19-15'], ['29-26'], ['6-11'], ['13-23'], ['18-30'], ['24-29'], ['31-16'], ['31-24'], ['0-11']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
<<<<<<< Updated upstream
      "Score: 63.78287076950073\n",
      "Response: Aryna Sabalenka\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['11-15'], ['16-19'], ['21-30'], ['6-30'], ['6-9'], ['8-26'], ['24-29'], ['31-16'], ['7-4'], ['19-15'], ['23-20'], ['13-11'], ['26-28'], ['18-30'], ['7-12'], ['19-10'], ['26-27'], ['1-9'], ['7-31'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 242\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['6-30'], ['8-26'], ['24-29'], ['31-16'], ['7-4'], ['7-12'], ['19-15'], ['23-20'], ['26-28'], ['13-11'], ['18-30'], ['14-18'], ['19-10'], ['26-27'], ['22-8'], ['22-27']]\n",
=======
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['6-30'], ['15-14'], ['17-22'], ['19-15'], ['14-18'], ['7-4'], ['13-11'], ['11-2'], ['29-26'], ['18-30'], ['24-29'], ['31-16'], ['6-11'], ['13-23'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 98.84334802627563\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for $75.4 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 242\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['6-30'], ['15-14'], ['17-22'], ['19-15'], ['11-2'], ['14-18'], ['7-4'], ['13-11'], ['18-30'], ['29-26'], ['24-29'], ['7-12'], ['31-16'], ['13-23'], ['6-11']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
<<<<<<< Updated upstream
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 496\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['21-30'], ['6-9'], ['6-30'], ['24-29'], ['7-12'], ['31-16'], ['7-4'], ['19-15'], ['23-20'], ['26-28'], ['13-11'], ['18-30'], ['14-18'], ['19-10'], ['26-27'], ['10-18'], ['22-8']]\n",
=======
      "Score: 93.97348165512085\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion. Sony also criticized the merger, concerned that Microsoft would make the lucrative Call of D\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 482\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['17-22'], ['11-2'], ['6-30'], ['15-14'], ['19-15'], ['7-4'], ['14-18'], ['13-11'], ['18-30'], ['24-29'], ['7-12'], ['29-26'], ['31-16'], ['6-16'], ['13-23']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
<<<<<<< Updated upstream
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 759\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['21-30'], ['6-30'], ['7-4'], ['7-12'], ['24-29'], ['31-16'], ['19-15'], ['26-28'], ['23-20'], ['13-11'], ['18-30'], ['10-18'], ['19-10'], ['26-27'], ['14-18'], ['22-8']]\n",
=======
      "Score: 95.41691541671753\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion. Microsoft is a dominant player in computing software, and also makes the Xbox line of game consoles\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 737\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['17-22'], ['19-15'], ['15-14'], ['7-4'], ['6-30'], ['14-18'], ['18-30'], ['13-11'], ['24-29'], ['6-16'], ['7-12'], ['29-26'], ['31-16'], ['14-15']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
<<<<<<< Updated upstream
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['16-19'], ['8-26'], ['11-15'], ['6-9'], ['6-30'], ['21-30'], ['7-4'], ['24-29'], ['7-12'], ['31-16'], ['19-15'], ['26-28'], ['23-20'], ['13-11'], ['18-30'], ['10-18'], ['19-10'], ['17-22'], ['26-27'], ['14-18']]\n",
=======
      "Score: 96.7077374458313\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion. The deal has been approved by both companies' board of directors and is expected to close in\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['17-22'], ['19-15'], ['7-4'], ['15-14'], ['6-30'], ['18-30'], ['14-18'], ['13-11'], ['24-29'], ['31-16'], ['6-16'], ['29-26'], ['7-12'], ['14-15']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
<<<<<<< Updated upstream
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['8-26'], ['11-15'], ['16-19'], ['6-9'], ['21-30'], ['6-30'], ['7-4'], ['24-29'], ['7-12'], ['31-16'], ['19-15'], ['23-20'], ['26-28'], ['13-11'], ['18-30'], ['10-18'], ['17-22'], ['19-10'], ['26-27'], ['28-21']]\n",
=======
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['17-22'], ['19-15'], ['15-14'], ['7-4'], ['6-30'], ['18-30'], ['14-18'], ['24-29'], ['6-16'], ['13-11'], ['7-12'], ['31-16'], ['29-26'], ['14-15']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
<<<<<<< Updated upstream
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 570\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['8-26'], ['11-15'], ['16-19'], ['6-9'], ['6-30'], ['21-30'], ['7-12'], ['7-4'], ['24-29'], ['31-16'], ['19-15'], ['26-28'], ['23-20'], ['13-11'], ['17-22'], ['18-30'], ['10-18'], ['26-27'], ['19-10'], ['28-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1137\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['8-26'], ['11-15'], ['16-19'], ['6-9'], ['7-12'], ['21-30'], ['6-30'], ['24-29'], ['7-4'], ['31-16'], ['19-15'], ['26-28'], ['23-20'], ['13-11'], ['17-22'], ['18-30'], ['10-18'], ['26-27'], ['19-10'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1673\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['8-26'], ['11-15'], ['16-19'], ['6-9'], ['7-12'], ['6-30'], ['21-30'], ['24-29'], ['7-4'], ['31-16'], ['19-15'], ['26-28'], ['23-20'], ['17-22'], ['13-11'], ['10-18'], ['18-30'], ['19-10'], ['26-27'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['8-26'], ['11-15'], ['16-19'], ['6-9'], ['6-30'], ['21-30'], ['7-12'], ['7-4'], ['24-29'], ['19-15'], ['31-16'], ['26-28'], ['23-20'], ['17-22'], ['13-11'], ['10-18'], ['18-30'], ['12-26'], ['19-10'], ['22-22']]\n",
=======
      "Score: 98.42150211334229\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion. Under the terms of the agreement, Microsoft brought Activision Blizzard under its Microsoft Gaming business\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 552\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['17-22'], ['19-15'], ['15-14'], ['7-4'], ['6-30'], ['18-30'], ['14-18'], ['6-16'], ['24-29'], ['7-12'], ['13-11'], ['31-16'], ['29-26'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1124\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['17-22'], ['19-15'], ['15-14'], ['7-4'], ['6-30'], ['18-30'], ['14-18'], ['6-16'], ['24-29'], ['7-12'], ['13-11'], ['31-16'], ['29-26'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1681\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['17-22'], ['19-15'], ['15-14'], ['6-30'], ['7-4'], ['18-30'], ['14-18'], ['6-16'], ['7-12'], ['24-29'], ['13-11'], ['31-16'], ['14-15'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['17-22'], ['19-15'], ['15-14'], ['7-4'], ['6-30'], ['18-30'], ['14-18'], ['24-29'], ['6-16'], ['7-12'], ['13-11'], ['31-16'], ['14-15'], ['29-26']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
<<<<<<< Updated upstream
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['8-26'], ['11-15'], ['16-19'], ['6-9'], ['7-12'], ['6-30'], ['21-30'], ['7-4'], ['24-29'], ['19-15'], ['31-16'], ['26-28'], ['23-20'], ['17-22'], ['13-11'], ['10-18'], ['12-26'], ['18-30'], ['19-10'], ['26-27']]\n",
=======
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['17-22'], ['19-15'], ['15-14'], ['7-4'], ['6-30'], ['18-30'], ['14-18'], ['6-16'], ['7-12'], ['24-29'], ['13-11'], ['31-16'], ['14-15'], ['20-30']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 3.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
<<<<<<< Updated upstream
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 875\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['8-26'], ['11-15'], ['16-19'], ['6-9'], ['7-12'], ['21-30'], ['6-30'], ['7-4'], ['24-29'], ['19-15'], ['31-16'], ['26-28'], ['23-20'], ['17-22'], ['13-11'], ['19-10'], ['10-18'], ['26-27'], ['12-26'], ['18-30']]\n",
=======
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 874\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['17-22'], ['19-15'], ['15-14'], ['7-4'], ['6-30'], ['18-30'], ['6-16'], ['7-12'], ['14-18'], ['24-29'], ['13-11'], ['31-16'], ['14-15'], ['20-30']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
<<<<<<< Updated upstream
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1735\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['8-26'], ['11-15'], ['16-19'], ['6-9'], ['7-12'], ['21-30'], ['6-30'], ['24-29'], ['7-4'], ['19-15'], ['31-16'], ['26-28'], ['17-22'], ['23-20'], ['19-10'], ['13-11'], ['26-27'], ['10-18'], ['12-26'], ['18-30']]\n",
=======
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1723\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['21-30'], ['11-2'], ['17-22'], ['19-15'], ['15-14'], ['7-4'], ['18-30'], ['6-30'], ['7-12'], ['6-16'], ['14-18'], ['24-29'], ['13-11'], ['31-16'], ['14-15'], ['20-30']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 3.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
<<<<<<< Updated upstream
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2613\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['8-26'], ['11-15'], ['16-19'], ['6-9'], ['7-12'], ['21-30'], ['6-30'], ['24-29'], ['19-15'], ['7-4'], ['31-16'], ['26-28'], ['23-20'], ['17-22'], ['13-11'], ['19-10'], ['26-27'], ['22-22'], ['10-18'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 63.63217234611511\n",
      "Response: Aryna Sabalenka.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['8-26'], ['11-15'], ['16-19'], ['6-9'], ['7-12'], ['21-30'], ['6-30'], ['19-15'], ['7-4'], ['24-29'], ['31-16'], ['26-28'], ['23-20'], ['17-22'], ['12-26'], ['13-11'], ['19-10'], ['22-22'], ['10-18'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['8-26'], ['11-15'], ['16-19'], ['6-9'], ['7-12'], ['21-30'], ['6-30'], ['19-15'], ['24-29'], ['7-4'], ['31-16'], ['26-28'], ['23-20'], ['17-22'], ['12-26'], ['13-11'], ['19-10'], ['22-22'], ['10-18'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1145\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['8-26'], ['11-15'], ['16-19'], ['6-9'], ['7-12'], ['21-30'], ['6-30'], ['19-15'], ['24-29'], ['7-4'], ['31-16'], ['26-28'], ['23-20'], ['17-22'], ['19-10'], ['12-26'], ['13-11'], ['26-27'], ['22-22'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2057\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['8-26'], ['11-15'], ['16-19'], ['7-12'], ['6-9'], ['21-30'], ['6-30'], ['24-29'], ['19-15'], ['7-4'], ['31-16'], ['26-28'], ['23-20'], ['17-22'], ['19-10'], ['12-26'], ['13-11'], ['22-22'], ['26-27'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3499\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['8-26'], ['11-15'], ['16-19'], ['6-9'], ['7-12'], ['21-30'], ['6-30'], ['24-29'], ['19-15'], ['7-4'], ['26-28'], ['31-16'], ['23-20'], ['17-22'], ['19-10'], ['13-11'], ['12-26'], ['22-22'], ['26-27'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 63.63217234611511\n",
      "Response: Aryna Sabalenka.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The number 1 ranked female tennis player in the world is Aryna Sabalenka.\n",
      "[['8-26'], ['11-15'], ['16-19'], ['6-9'], ['7-12'], ['21-30'], ['6-30'], ['19-15'], ['7-4'], ['24-29'], ['26-28'], ['31-16'], ['23-20'], ['17-22'], ['12-26'], ['19-10'], ['13-11'], ['22-22'], ['26-27'], ['21-28']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 98.30312728881836\n",
      "Response: Aryna Sabalenka is the number 1 ranked female tennis player in the world.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_430_irrelevant_misleading/llama-2-7b-80k_id_430_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-9'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-21'], ['26-28'], ['6-9'], ['6-30'], ['8-26'], ['8-31'], ['10-14'], ['11-15'], ['13-23'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-9'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-21'], ['26-28'], ['6-9'], ['6-30'], ['8-26'], ['8-31'], ['10-14'], ['11-15'], ['13-23'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-9'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-21'], ['26-28'], ['6-9'], ['6-30'], ['8-26'], ['8-31'], ['10-14'], ['11-15'], ['13-23'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-9'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-21'], ['26-28'], ['6-9'], ['6-30'], ['8-26'], ['8-31'], ['10-14'], ['11-15'], ['13-23'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_0_depth_7500_results.json\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-9'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-21'], ['26-28'], ['6-9'], ['6-30'], ['8-26'], ['8-31'], ['10-14'], ['11-15'], ['13-23'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['16-19'], ['11-15'], ['14-18'], ['17-0'], ['19-9'], ['19-15'], ['20-10'], ['26-28'], ['18-30'], ['21-30'], ['24-3'], ['24-11'], ['26-21'], ['15-14'], ['22-22'], ['6-9'], ['8-26'], ['13-23'], ['14-7'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 96.35903835296631\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín (Ducati).\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_1250_depth_0_results.json\n",
      "insertion at 242\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['14-18'], ['17-0'], ['19-9'], ['19-15'], ['20-10'], ['26-28'], ['18-30'], ['21-30'], ['7-12'], ['24-3'], ['8-26'], ['24-11'], ['26-21'], ['15-14'], ['22-22'], ['6-9'], ['17-22'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99999403953552\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 489\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['7-12'], ['8-26'], ['14-18'], ['17-0'], ['19-9'], ['19-15'], ['20-10'], ['26-28'], ['18-30'], ['21-30'], ['24-3'], ['17-22'], ['24-11'], ['26-21'], ['6-9'], ['11-2'], ['15-14'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 99.99999403953552\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 746\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['7-12'], ['19-15'], ['14-18'], ['17-0'], ['19-9'], ['20-10'], ['26-28'], ['17-22'], ['6-9'], ['18-30'], ['21-30'], ['24-3'], ['11-2'], ['15-14'], ['22-22'], ['24-11'], ['26-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 99.99999403953552\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_1250_depth_7500_results.json\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['7-12'], ['19-15'], ['14-18'], ['17-0'], ['19-9'], ['20-10'], ['26-28'], ['18-30'], ['21-30'], ['17-22'], ['6-9'], ['24-3'], ['26-21'], ['11-2'], ['14-13'], ['15-14'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['7-12'], ['19-15'], ['14-18'], ['19-9'], ['20-10'], ['18-30'], ['26-28'], ['17-0'], ['21-30'], ['17-22'], ['6-9'], ['24-3'], ['11-2'], ['14-13'], ['15-14'], ['22-22'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 67.01418161392212\n",
      "Response: Jorge Martín (Ducati)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_2500_depth_0_results.json\n",
      "insertion at 551\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['7-12'], ['19-15'], ['14-18'], ['19-9'], ['20-10'], ['18-30'], ['26-28'], ['17-0'], ['21-30'], ['6-9'], ['17-22'], ['24-3'], ['11-2'], ['14-13'], ['15-14'], ['22-22'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 67.63451099395752\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín. In 1979 the FIM created a prototype sidecar class named B2B, as opposed to the traditional B2A. Prototypes were banned in\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 746\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['7-12'], ['19-15'], ['14-18'], ['19-9'], ['20-10'], ['18-30'], ['26-28'], ['17-0'], ['21-30'], ['6-9'], ['17-22'], ['24-3'], ['11-2'], ['14-13'], ['15-14'], ['22-22'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 746\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['7-12'], ['19-15'], ['14-18'], ['19-9'], ['20-10'], ['18-30'], ['26-28'], ['17-0'], ['21-30'], ['6-9'], ['17-22'], ['24-3'], ['22-22'], ['11-2'], ['14-13'], ['15-14'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_2500_depth_7500_results.json\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['7-12'], ['19-15'], ['14-18'], ['20-10'], ['18-30'], ['19-9'], ['26-28'], ['17-0'], ['21-30'], ['6-9'], ['17-22'], ['24-3'], ['14-13'], ['22-22'], ['15-14'], ['11-2'], ['26-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['7-12'], ['8-26'], ['19-15'], ['14-18'], ['20-10'], ['19-9'], ['17-0'], ['18-30'], ['21-30'], ['26-28'], ['17-22'], ['6-9'], ['11-2'], ['22-22'], ['24-3'], ['14-13'], ['15-14'], ['26-27']]\n",
=======
      "Score: 96.96050882339478\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion. Microsoft has yet to speak directly about the Activision Blizzard lawsuit following news of the ac\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2080\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['17-22'], ['19-15'], ['15-14'], ['18-30'], ['7-4'], ['7-12'], ['6-30'], ['6-16'], ['14-18'], ['24-29'], ['13-11'], ['31-16'], ['20-30'], ['14-15']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 3750 tokens\n",
<<<<<<< Updated upstream
      "Depth: 0%\n",
      "Score: 96.35903835296631\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín (Ducati).\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_3750_depth_0_results.json\n",
      "insertion at 746\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['7-12'], ['8-26'], ['19-15'], ['14-18'], ['20-10'], ['19-9'], ['17-0'], ['17-22'], ['18-30'], ['21-30'], ['26-28'], ['11-2'], ['6-9'], ['14-13'], ['22-22'], ['24-3'], ['15-14'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99999403953552\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 746\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['7-12'], ['8-26'], ['19-15'], ['17-22'], ['14-18'], ['20-10'], ['19-9'], ['17-0'], ['18-30'], ['21-30'], ['26-28'], ['11-2'], ['6-9'], ['14-13'], ['22-22'], ['15-14'], ['24-3'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 99.99999403953552\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 1773\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['7-12'], ['8-26'], ['17-22'], ['19-15'], ['14-18'], ['20-10'], ['19-9'], ['11-2'], ['17-0'], ['18-30'], ['21-30'], ['26-28'], ['6-9'], ['14-13'], ['22-22'], ['24-3'], ['15-14'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.4 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 88.02770376205444\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín. (Suzuki),Olivier Jacque (Yamaha),Roberto Locatelli (Aprilia)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_3750_depth_7500_results.json\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['8-26'], ['7-12'], ['17-22'], ['19-15'], ['14-18'], ['20-10'], ['17-0'], ['18-30'], ['19-9'], ['21-30'], ['26-28'], ['11-2'], ['14-13'], ['6-9'], ['22-22'], ['24-3'], ['15-14'], ['26-27']]\n",
=======
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['17-22'], ['19-15'], ['15-14'], ['7-4'], ['18-30'], ['6-30'], ['6-16'], ['7-12'], ['14-18'], ['24-29'], ['31-16'], ['13-11'], ['20-30'], ['14-15']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
<<<<<<< Updated upstream
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['7-12'], ['8-26'], ['17-22'], ['19-15'], ['14-18'], ['20-10'], ['11-2'], ['17-0'], ['19-9'], ['21-30'], ['18-30'], ['26-28'], ['14-13'], ['6-9'], ['22-22'], ['24-3'], ['15-14'], ['26-27']]\n",
=======
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['11-2'], ['17-22'], ['19-15'], ['15-14'], ['7-4'], ['18-30'], ['6-16'], ['7-12'], ['6-30'], ['14-18'], ['24-29'], ['13-11'], ['31-16'], ['20-30'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 98.84334802627563\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for $75.4 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1192\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['11-2'], ['21-30'], ['17-22'], ['19-15'], ['15-14'], ['7-12'], ['6-16'], ['18-30'], ['7-4'], ['6-30'], ['14-18'], ['24-29'], ['13-11'], ['31-16'], ['20-30'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 98.56845140457153\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion. In a statement released on Activision Blizzard's investor website, the company said its\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2080\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['11-2'], ['21-30'], ['17-22'], ['19-15'], ['7-12'], ['15-14'], ['6-16'], ['18-30'], ['7-4'], ['6-30'], ['14-18'], ['24-29'], ['13-11'], ['20-30'], ['31-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3532\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['11-2'], ['21-30'], ['17-22'], ['19-15'], ['7-12'], ['15-14'], ['6-16'], ['18-30'], ['7-4'], ['6-30'], ['14-18'], ['24-29'], ['20-30'], ['13-11'], ['31-16'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['11-2'], ['21-30'], ['17-22'], ['19-15'], ['15-14'], ['7-12'], ['6-16'], ['18-30'], ['7-4'], ['6-30'], ['14-18'], ['24-29'], ['20-30'], ['31-16'], ['13-11'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_relevant_misleading/llama-2-7b-80k_id_539_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-30'], ['21-30'], ['15-14'], ['7-4'], ['13-11'], ['14-18'], ['17-22'], ['19-15'], ['29-26'], ['6-11'], ['13-23'], ['18-30'], ['24-29'], ['31-16'], ['31-24'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-30'], ['21-30'], ['15-14'], ['7-4'], ['13-11'], ['14-18'], ['17-22'], ['19-15'], ['29-26'], ['6-11'], ['13-23'], ['18-30'], ['24-29'], ['31-16'], ['31-24'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-30'], ['21-30'], ['15-14'], ['7-4'], ['13-11'], ['14-18'], ['17-22'], ['19-15'], ['29-26'], ['6-11'], ['13-23'], ['18-30'], ['24-29'], ['31-16'], ['31-24'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-30'], ['21-30'], ['15-14'], ['7-4'], ['13-11'], ['14-18'], ['17-22'], ['19-15'], ['29-26'], ['6-11'], ['13-23'], ['18-30'], ['24-29'], ['31-16'], ['31-24'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_0_depth_7500_results.json\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-30'], ['21-30'], ['15-14'], ['7-4'], ['13-11'], ['14-18'], ['17-22'], ['19-15'], ['29-26'], ['6-11'], ['13-23'], ['18-30'], ['24-29'], ['31-16'], ['31-24'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "-- Test Summary -- \n",
      "Duration: 3.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 35.562849044799805\n",
      "Response: The acquisition of Twenty-First Century Fox, Inc. by The Walt Disney Company was announced on December 14, 2017, and was completed on March 20, 2019. Among other\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 223\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 35.562849044799805\n",
      "Response: The acquisition of Twenty-First Century Fox, Inc. by The Walt Disney Company was announced on December 14, 2017, and was completed on March 20, 2019. Among other\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 494\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['6-30'], ['7-4'], ['15-14'], ['17-22'], ['19-15'], ['14-18'], ['13-11'], ['18-30'], ['11-2'], ['29-26'], ['31-16'], ['24-29'], ['6-11'], ['13-23'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 727\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['6-30'], ['7-4'], ['17-22'], ['19-15'], ['15-14'], ['11-2'], ['14-18'], ['13-11'], ['18-30'], ['29-26'], ['31-16'], ['24-29'], ['6-11'], ['13-23'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 94.38681602478027\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion. It was less interested in 21st Century Fox's production capacities and more keen to\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_1250_depth_7500_results.json\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['7-4'], ['6-30'], ['19-15'], ['17-22'], ['15-14'], ['11-2'], ['18-30'], ['14-18'], ['13-11'], ['24-29'], ['31-16'], ['29-26'], ['6-11'], ['13-23'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['7-4'], ['17-22'], ['6-30'], ['19-15'], ['11-2'], ['15-14'], ['14-18'], ['18-30'], ['13-11'], ['24-29'], ['31-16'], ['29-26'], ['6-16'], ['14-15'], ['6-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 494\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['19-15'], ['6-30'], ['11-2'], ['15-14'], ['14-18'], ['18-30'], ['13-11'], ['24-29'], ['6-16'], ['7-12'], ['31-16'], ['29-26'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1100\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['19-15'], ['6-30'], ['15-14'], ['18-30'], ['14-18'], ['7-12'], ['13-11'], ['6-16'], ['24-29'], ['31-16'], ['29-26'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1667\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['19-15'], ['6-30'], ['18-30'], ['14-18'], ['15-14'], ['7-12'], ['6-16'], ['13-11'], ['24-29'], ['31-16'], ['14-15'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_2500_depth_7500_results.json\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['19-15'], ['6-30'], ['18-30'], ['15-14'], ['14-18'], ['6-16'], ['7-12'], ['13-11'], ['24-29'], ['31-16'], ['14-15'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['6-30'], ['18-30'], ['14-18'], ['7-12'], ['15-14'], ['6-16'], ['24-29'], ['13-11'], ['31-16'], ['14-15'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 772\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['6-30'], ['7-12'], ['18-30'], ['6-16'], ['14-18'], ['15-14'], ['24-29'], ['13-11'], ['31-16'], ['14-15'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1707\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['6-30'], ['7-12'], ['6-16'], ['18-30'], ['14-18'], ['15-14'], ['13-11'], ['24-29'], ['31-16'], ['14-15'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2589\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['7-12'], ['6-30'], ['6-16'], ['18-30'], ['14-18'], ['15-14'], ['13-11'], ['24-29'], ['31-16'], ['14-15'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_3750_depth_7500_results.json\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['6-30'], ['7-12'], ['6-16'], ['18-30'], ['14-18'], ['15-14'], ['13-11'], ['24-29'], ['31-16'], ['14-15'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['7-12'], ['6-30'], ['6-16'], ['18-30'], ['14-18'], ['15-14'], ['24-29'], ['13-11'], ['31-16'], ['14-15'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1173\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['17-22'], ['11-2'], ['7-4'], ['7-12'], ['19-15'], ['6-30'], ['6-16'], ['14-18'], ['18-30'], ['15-14'], ['24-29'], ['13-11'], ['31-16'], ['14-15'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2381\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['7-4'], ['19-15'], ['6-16'], ['6-30'], ['14-18'], ['18-30'], ['15-14'], ['24-29'], ['13-11'], ['31-16'], ['14-15'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3573\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['17-22'], ['21-30'], ['11-2'], ['7-12'], ['7-4'], ['19-15'], ['6-16'], ['6-30'], ['14-18'], ['18-30'], ['15-14'], ['24-29'], ['13-11'], ['31-16'], ['14-15'], ['20-30']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 5000 tokens\n",
<<<<<<< Updated upstream
      "Depth: 0%\n",
      "Score: 96.35903835296631\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín (Ducati).\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_5000_depth_0_results.json\n",
      "insertion at 746\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['7-12'], ['8-26'], ['17-22'], ['19-15'], ['14-18'], ['11-2'], ['20-10'], ['17-0'], ['19-9'], ['21-30'], ['18-30'], ['26-28'], ['14-13'], ['22-22'], ['6-9'], ['24-3'], ['15-14'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99999403953552\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 1773\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['7-12'], ['8-26'], ['17-22'], ['19-15'], ['11-2'], ['14-18'], ['20-10'], ['17-0'], ['19-9'], ['21-30'], ['18-30'], ['26-28'], ['14-13'], ['22-22'], ['6-9'], ['15-14'], ['24-3'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 88.02770376205444\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín. (Suzuki),Olivier Jacque (Yamaha),Roberto Locatelli (Aprilia)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 1773\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['7-12'], ['8-26'], ['17-22'], ['11-2'], ['19-15'], ['14-18'], ['17-0'], ['19-9'], ['20-10'], ['21-30'], ['18-30'], ['26-28'], ['14-13'], ['22-22'], ['6-9'], ['15-14'], ['24-3'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 88.02770376205444\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín. (Suzuki),Olivier Jacque (Yamaha),Roberto Locatelli (Aprilia)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_5000_depth_7500_results.json\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['7-12'], ['8-26'], ['17-22'], ['11-2'], ['19-15'], ['14-18'], ['17-0'], ['20-10'], ['21-30'], ['19-9'], ['18-30'], ['26-28'], ['14-13'], ['22-22'], ['6-9'], ['15-14'], ['24-3'], ['26-27']]\n",
=======
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_5000_depth_7500_results.json\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['17-22'], ['11-2'], ['7-4'], ['7-12'], ['19-15'], ['6-16'], ['6-30'], ['18-30'], ['14-18'], ['15-14'], ['24-29'], ['13-11'], ['31-16'], ['14-15'], ['20-30']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
<<<<<<< Updated upstream
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant/llama-2-7b-80k_id_432_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/432.txt\n",
=======
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant/llama-2-7b-80k_id_539_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/shyamodi/SNLP_Project/haystack/misleading_in_irrelevant/539.txt\n",
>>>>>>> Stashed changes
=======
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_5000_depth_7500_results.json\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 3.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 25.42150616645813\n",
      "Response: On the ninth ballot, the House of Representatives voted 201 to 212 to elect Kevin McCarthy as Speaker of the House.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant/llama-2-7b-80k_id_95_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/95.txt\n",
>>>>>>> Stashed changes
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
<<<<<<< Updated upstream
<<<<<<< Updated upstream
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
=======
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:02<00:00,  1.43it/s]\n"
>>>>>>> Stashed changes
=======
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.03it/s]\n"
>>>>>>> Stashed changes
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
      "- Needle: The latest MotoGP World Riders' Champion is Jorge Martín.\n",
=======
      "- Needle: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
>>>>>>> Stashed changes
=======
      "- Needle: No one received a majority of the votes on the ninth ballot.\n",
>>>>>>> Stashed changes
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
<<<<<<< Updated upstream
<<<<<<< Updated upstream
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-9'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-21'], ['26-28'], ['6-9'], ['6-30'], ['8-26'], ['8-31'], ['10-14'], ['11-15'], ['13-23'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-9'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-21'], ['26-28'], ['6-9'], ['6-30'], ['8-26'], ['8-31'], ['10-14'], ['11-15'], ['13-23'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-9'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-21'], ['26-28'], ['6-9'], ['6-30'], ['8-26'], ['8-31'], ['10-14'], ['11-15'], ['13-23'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-9'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-21'], ['26-28'], ['6-9'], ['6-30'], ['8-26'], ['8-31'], ['10-14'], ['11-15'], ['13-23'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_0_depth_7500_results.json\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-9'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-21'], ['26-28'], ['6-9'], ['6-30'], ['8-26'], ['8-31'], ['10-14'], ['11-15'], ['13-23'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['19-9'], ['20-10'], ['24-3'], ['26-21'], ['16-19'], ['17-0'], ['18-30'], ['19-15'], ['21-30'], ['24-11'], ['26-28'], ['22-22'], ['6-9'], ['11-15'], ['17-22'], ['21-1'], ['23-8'], ['23-20'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 67.01418161392212\n",
      "Response: Jorge Martín (Ducati)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 209\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['19-9'], ['20-10'], ['16-19'], ['17-0'], ['18-30'], ['19-15'], ['24-3'], ['26-21'], ['26-28'], ['21-30'], ['24-11'], ['22-22'], ['26-27'], ['6-9'], ['11-15'], ['17-22'], ['21-1'], ['23-8'], ['23-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 62.91067600250244\n",
      "Response: Jorge Martín\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 510\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['19-9'], ['20-10'], ['17-0'], ['18-30'], ['19-15'], ['26-28'], ['16-19'], ['24-3'], ['26-21'], ['21-30'], ['24-11'], ['26-27'], ['22-22'], ['6-9'], ['11-15'], ['14-13'], ['14-15'], ['17-22'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 62.91067600250244\n",
      "Response: Jorge Martín\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 770\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['19-9'], ['20-10'], ['17-0'], ['18-30'], ['19-15'], ['26-28'], ['16-19'], ['24-3'], ['26-21'], ['21-30'], ['24-11'], ['26-27'], ['14-15'], ['22-22'], ['24-14'], ['6-9'], ['11-15'], ['14-13'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 67.01418161392212\n",
      "Response: Jorge Martín (Ducati)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['16-19'], ['19-15'], ['14-18'], ['19-9'], ['24-3'], ['26-28'], ['17-0'], ['18-30'], ['20-10'], ['6-9'], ['21-30'], ['11-15'], ['26-21'], ['26-27'], ['22-22'], ['24-11'], ['8-26'], ['15-14'], ['14-13'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['16-19'], ['19-15'], ['14-18'], ['11-15'], ['19-9'], ['24-3'], ['17-0'], ['20-10'], ['6-9'], ['21-30'], ['18-30'], ['26-28'], ['22-22'], ['26-21'], ['26-27'], ['8-26'], ['24-11'], ['15-14'], ['17-22'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 99.99999403953552\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 544\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['16-19'], ['19-15'], ['14-18'], ['11-15'], ['19-9'], ['17-0'], ['20-10'], ['24-3'], ['18-30'], ['26-28'], ['6-9'], ['21-30'], ['22-22'], ['26-21'], ['26-27'], ['8-26'], ['24-11'], ['14-13'], ['15-14'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 62.91067600250244\n",
      "Response: Jorge Martín\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 899\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['16-19'], ['19-15'], ['14-18'], ['19-9'], ['11-15'], ['17-0'], ['20-10'], ['18-30'], ['24-3'], ['26-28'], ['6-9'], ['21-30'], ['22-22'], ['26-27'], ['26-21'], ['8-26'], ['24-11'], ['14-13'], ['15-14'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 62.91067600250244\n",
      "Response: Jorge Martín\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 899\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['16-19'], ['19-15'], ['14-18'], ['19-9'], ['11-15'], ['17-0'], ['20-10'], ['18-30'], ['26-28'], ['24-3'], ['6-9'], ['21-30'], ['26-27'], ['22-22'], ['26-21'], ['8-26'], ['14-13'], ['24-11'], ['15-14'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 62.91067600250244\n",
      "Response: Jorge Martín\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['14-18'], ['6-9'], ['19-9'], ['24-3'], ['26-28'], ['17-0'], ['18-30'], ['20-10'], ['21-30'], ['26-27'], ['22-22'], ['8-26'], ['14-13'], ['15-14'], ['26-21'], ['24-11'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['16-19'], ['19-15'], ['14-18'], ['11-15'], ['6-9'], ['19-9'], ['24-3'], ['17-0'], ['21-30'], ['26-28'], ['20-10'], ['18-30'], ['26-27'], ['22-22'], ['8-26'], ['14-13'], ['15-14'], ['24-11'], ['26-21'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 67.01418161392212\n",
      "Response: Jorge Martín (Ducati)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 849\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['16-19'], ['19-15'], ['14-18'], ['11-15'], ['19-9'], ['6-9'], ['24-3'], ['17-0'], ['21-30'], ['26-28'], ['20-10'], ['18-30'], ['26-27'], ['22-22'], ['8-26'], ['14-13'], ['15-14'], ['24-11'], ['26-21'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 62.91067600250244\n",
      "Response: Jorge Martín\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 899\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['16-19'], ['19-15'], ['14-18'], ['11-15'], ['19-9'], ['6-9'], ['17-0'], ['21-30'], ['26-28'], ['24-3'], ['20-10'], ['18-30'], ['26-27'], ['22-22'], ['8-26'], ['14-13'], ['15-14'], ['17-22'], ['19-10'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 62.91067600250244\n",
      "Response: Jorge Martín\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 1926\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['16-19'], ['19-15'], ['14-18'], ['11-15'], ['19-9'], ['17-0'], ['21-30'], ['26-28'], ['6-9'], ['24-3'], ['20-10'], ['18-30'], ['26-27'], ['22-22'], ['8-26'], ['14-13'], ['15-14'], ['17-22'], ['19-10'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 54.830312728881836\n",
      "Response: Jorge Martín (Suzuki),Olivier Jacque (Yamaha),Roberto Locatelli (Aprilia)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['16-19'], ['19-15'], ['14-18'], ['11-15'], ['6-9'], ['24-3'], ['19-9'], ['21-30'], ['17-0'], ['26-28'], ['20-10'], ['18-30'], ['26-27'], ['15-14'], ['22-22'], ['8-26'], ['14-13'], ['12-26'], ['17-22'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['16-19'], ['19-15'], ['14-18'], ['11-15'], ['6-9'], ['24-3'], ['19-9'], ['21-30'], ['17-0'], ['26-28'], ['20-10'], ['18-30'], ['26-27'], ['22-22'], ['15-14'], ['8-26'], ['12-26'], ['14-13'], ['17-22'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 67.01418161392212\n",
      "Response: Jorge Martín (Ducati)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 899\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['14-18'], ['6-9'], ['19-9'], ['21-30'], ['24-3'], ['17-0'], ['26-28'], ['20-10'], ['18-30'], ['26-27'], ['22-22'], ['8-26'], ['15-14'], ['14-13'], ['17-22'], ['12-26'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99999403953552\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 1926\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['16-19'], ['19-15'], ['11-15'], ['14-18'], ['6-9'], ['19-9'], ['21-30'], ['24-3'], ['17-0'], ['26-28'], ['18-30'], ['20-10'], ['26-27'], ['22-22'], ['8-26'], ['15-14'], ['14-13'], ['17-22'], ['12-26'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 88.02770376205444\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín. (Suzuki),Olivier Jacque (Yamaha),Roberto Locatelli (Aprilia)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 1926\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['14-18'], ['6-9'], ['19-9'], ['21-30'], ['24-3'], ['26-28'], ['17-0'], ['18-30'], ['20-10'], ['8-26'], ['22-22'], ['26-27'], ['15-14'], ['17-22'], ['14-13'], ['24-11'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 88.02770376205444\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín. (Suzuki),Olivier Jacque (Yamaha),Roberto Locatelli (Aprilia)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['16-19'], ['11-15'], ['19-15'], ['14-18'], ['6-9'], ['21-30'], ['19-9'], ['24-3'], ['26-28'], ['17-0'], ['18-30'], ['20-10'], ['8-26'], ['22-22'], ['26-27'], ['15-14'], ['14-13'], ['17-22'], ['24-11'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_relevant_misleading/llama-2-7b-80k_id_432_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-9'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-21'], ['26-28'], ['6-9'], ['6-30'], ['8-26'], ['8-31'], ['10-14'], ['11-15'], ['13-23'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-9'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-21'], ['26-28'], ['6-9'], ['6-30'], ['8-26'], ['8-31'], ['10-14'], ['11-15'], ['13-23'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-9'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-21'], ['26-28'], ['6-9'], ['6-30'], ['8-26'], ['8-31'], ['10-14'], ['11-15'], ['13-23'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-9'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-21'], ['26-28'], ['6-9'], ['6-30'], ['8-26'], ['8-31'], ['10-14'], ['11-15'], ['13-23'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_0_depth_7500_results.json\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-9'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-21'], ['26-28'], ['6-9'], ['6-30'], ['8-26'], ['8-31'], ['10-14'], ['11-15'], ['13-23'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-9'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-21'], ['26-28'], ['16-30'], ['6-9'], ['6-30'], ['8-26'], ['8-31'], ['10-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 81.19551539421082\n",
      "Response: The latest MotoGP World Riders' Champion is Marc Marquez.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 248\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['11-15'], ['17-0'], ['18-30'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-28'], ['19-9'], ['26-21'], ['16-30'], ['23-7'], ['26-27'], ['6-9'], ['6-30'], ['8-26'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 511\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-28'], ['11-15'], ['19-9'], ['26-21'], ['23-7'], ['26-27'], ['14-13'], ['14-15'], ['16-30'], ['6-9'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 762\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['26-28'], ['24-11'], ['11-15'], ['19-9'], ['26-21'], ['23-7'], ['26-27'], ['14-13'], ['14-15'], ['16-30'], ['24-14'], ['6-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 62.91067600250244\n",
      "Response: Jorge Martín\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_1250_depth_7500_results.json\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['26-28'], ['24-11'], ['11-15'], ['19-9'], ['26-21'], ['14-13'], ['14-15'], ['26-27'], ['23-7'], ['23-20'], ['31-16'], ['24-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['18-30'], ['19-15'], ['20-10'], ['24-3'], ['21-30'], ['26-28'], ['17-0'], ['24-11'], ['11-15'], ['19-9'], ['26-21'], ['14-13'], ['14-15'], ['26-27'], ['23-7'], ['23-20'], ['31-16'], ['6-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 62.91067600250244\n",
      "Response: Jorge Martín\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 552\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['18-30'], ['19-15'], ['20-10'], ['24-3'], ['26-28'], ['17-0'], ['21-30'], ['24-11'], ['11-15'], ['19-9'], ['26-21'], ['14-13'], ['26-27'], ['14-15'], ['23-7'], ['17-22'], ['22-22'], ['23-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1141\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['18-30'], ['19-15'], ['20-10'], ['24-3'], ['16-19'], ['26-28'], ['17-0'], ['21-30'], ['24-11'], ['11-15'], ['19-9'], ['26-21'], ['14-13'], ['26-27'], ['14-15'], ['23-7'], ['17-22'], ['22-22'], ['24-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1689\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['18-30'], ['19-15'], ['20-10'], ['24-3'], ['26-28'], ['16-19'], ['17-0'], ['21-30'], ['24-11'], ['11-15'], ['19-9'], ['14-13'], ['26-21'], ['26-27'], ['14-15'], ['23-7'], ['24-14'], ['17-22'], ['22-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_2500_depth_7500_results.json\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['18-30'], ['19-15'], ['20-10'], ['24-3'], ['26-28'], ['16-19'], ['17-0'], ['21-30'], ['24-11'], ['11-15'], ['19-9'], ['14-13'], ['26-21'], ['26-27'], ['14-15'], ['23-7'], ['24-14'], ['23-20'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['11-15'], ['24-3'], ['19-15'], ['20-10'], ['16-19'], ['18-30'], ['26-28'], ['17-0'], ['21-30'], ['19-9'], ['24-11'], ['14-13'], ['26-21'], ['26-27'], ['14-15'], ['7-12'], ['17-22'], ['22-22'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 99.99999403953552\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 762\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['24-3'], ['11-15'], ['19-15'], ['20-10'], ['16-19'], ['18-30'], ['26-28'], ['17-0'], ['21-30'], ['19-9'], ['24-11'], ['14-13'], ['26-27'], ['26-21'], ['14-15'], ['22-22'], ['7-12'], ['24-14'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 62.91067600250244\n",
      "Response: Jorge Martín\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1759\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['24-3'], ['19-15'], ['20-10'], ['11-15'], ['18-30'], ['26-28'], ['16-19'], ['17-0'], ['21-30'], ['19-9'], ['24-11'], ['14-13'], ['26-27'], ['26-21'], ['14-15'], ['22-22'], ['7-12'], ['24-14'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2610\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['24-3'], ['19-15'], ['20-10'], ['18-30'], ['26-28'], ['11-15'], ['17-0'], ['21-30'], ['16-19'], ['14-13'], ['19-9'], ['24-11'], ['26-27'], ['26-21'], ['14-15'], ['22-22'], ['24-14'], ['7-12'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_3750_depth_7500_results.json\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['24-3'], ['19-15'], ['20-10'], ['18-30'], ['26-28'], ['17-0'], ['21-30'], ['11-15'], ['16-19'], ['14-13'], ['19-9'], ['24-11'], ['26-27'], ['26-21'], ['14-15'], ['22-22'], ['24-14'], ['17-22'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 34.96091365814209\n",
      "Response: Max Verstappen\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1174\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['24-3'], ['19-15'], ['20-10'], ['18-30'], ['26-28'], ['17-0'], ['21-30'], ['11-15'], ['16-19'], ['14-13'], ['19-9'], ['24-11'], ['26-27'], ['26-21'], ['14-15'], ['22-22'], ['24-14'], ['26-25'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2391\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['24-3'], ['19-15'], ['20-10'], ['18-30'], ['26-28'], ['17-0'], ['21-30'], ['11-15'], ['16-19'], ['14-13'], ['19-9'], ['26-27'], ['24-11'], ['26-21'], ['14-15'], ['22-22'], ['24-14'], ['26-25'], ['20-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3546\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['24-3'], ['19-15'], ['20-10'], ['18-30'], ['26-28'], ['17-0'], ['21-30'], ['16-19'], ['11-15'], ['14-13'], ['19-9'], ['26-27'], ['24-11'], ['26-21'], ['14-15'], ['22-22'], ['24-14'], ['23-7'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_5000_depth_7500_results.json\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['24-3'], ['19-15'], ['20-10'], ['26-28'], ['18-30'], ['17-0'], ['21-30'], ['16-19'], ['11-15'], ['14-13'], ['19-9'], ['26-27'], ['24-11'], ['14-15'], ['26-21'], ['24-14'], ['22-22'], ['26-25'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant/llama-2-7b-80k_id_432_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/432.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-9'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-21'], ['26-28'], ['6-9'], ['6-30'], ['8-26'], ['8-31'], ['10-14'], ['11-15'], ['13-23'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant_misleading/llama-2-7b-80k_id_432_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-9'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-21'], ['26-28'], ['6-9'], ['6-30'], ['8-26'], ['8-31'], ['10-14'], ['11-15'], ['13-23'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant_misleading/llama-2-7b-80k_id_432_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-9'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-21'], ['26-28'], ['6-9'], ['6-30'], ['8-26'], ['8-31'], ['10-14'], ['11-15'], ['13-23'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant_misleading/llama-2-7b-80k_id_432_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-9'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-21'], ['26-28'], ['6-9'], ['6-30'], ['8-26'], ['8-31'], ['10-14'], ['11-15'], ['13-23'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant_misleading/llama-2-7b-80k_id_432_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-9'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-21'], ['26-28'], ['6-9'], ['6-30'], ['8-26'], ['8-31'], ['10-14'], ['11-15'], ['13-23'], ['14-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.2 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant_misleading/llama-2-7b-80k_id_432_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-9'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-21'], ['26-28'], ['16-30'], ['6-9'], ['6-30'], ['8-26'], ['8-31'], ['10-14'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 81.19551539421082\n",
      "Response: The latest MotoGP World Riders' Champion is Marc Marquez.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant_misleading/llama-2-7b-80k_id_432_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 248\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['11-15'], ['17-0'], ['18-30'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-28'], ['19-9'], ['26-21'], ['16-30'], ['23-7'], ['26-27'], ['6-9'], ['6-30'], ['8-26'], ['8-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant_misleading/llama-2-7b-80k_id_432_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 511\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['24-11'], ['26-28'], ['11-15'], ['19-9'], ['26-21'], ['23-7'], ['26-27'], ['14-13'], ['14-15'], ['16-30'], ['6-9'], ['6-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant_misleading/llama-2-7b-80k_id_432_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 762\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['26-28'], ['24-11'], ['11-15'], ['19-9'], ['26-21'], ['23-7'], ['26-27'], ['14-13'], ['14-15'], ['16-30'], ['24-14'], ['6-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 62.91067600250244\n",
      "Response: Jorge Martín\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant_misleading/llama-2-7b-80k_id_432_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['16-19'], ['17-0'], ['18-30'], ['19-15'], ['20-10'], ['21-30'], ['24-3'], ['26-28'], ['24-11'], ['11-15'], ['19-9'], ['26-21'], ['14-13'], ['14-15'], ['26-27'], ['23-7'], ['23-20'], ['31-16'], ['24-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant_misleading/llama-2-7b-80k_id_432_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['14-18'], ['16-19'], ['19-15'], ['18-30'], ['20-10'], ['21-30'], ['24-3'], ['26-28'], ['17-0'], ['24-11'], ['19-9'], ['26-21'], ['14-13'], ['14-15'], ['26-27'], ['7-12'], ['22-22'], ['23-7'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 99.99999403953552\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant_misleading/llama-2-7b-80k_id_432_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 552\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['14-18'], ['16-19'], ['19-15'], ['20-10'], ['26-28'], ['18-30'], ['21-30'], ['24-3'], ['17-0'], ['19-9'], ['24-11'], ['26-21'], ['26-27'], ['14-13'], ['14-15'], ['22-22'], ['7-12'], ['23-7'], ['16-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 62.91067600250244\n",
      "Response: Jorge Martín\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant_misleading/llama-2-7b-80k_id_432_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1141\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['14-18'], ['16-19'], ['19-15'], ['20-10'], ['26-28'], ['18-30'], ['21-30'], ['24-3'], ['17-0'], ['24-11'], ['19-9'], ['26-21'], ['26-27'], ['22-22'], ['14-13'], ['14-15'], ['7-12'], ['23-7'], ['24-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant_misleading/llama-2-7b-80k_id_432_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1699\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['14-18'], ['11-15'], ['16-19'], ['19-15'], ['20-10'], ['26-28'], ['18-30'], ['21-30'], ['24-3'], ['17-0'], ['24-11'], ['19-9'], ['26-21'], ['26-27'], ['22-22'], ['14-15'], ['14-13'], ['24-14'], ['7-12'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant_misleading/llama-2-7b-80k_id_432_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['14-18'], ['24-3'], ['21-30'], ['26-28'], ['18-30'], ['20-10'], ['24-11'], ['17-0'], ['19-9'], ['6-9'], ['26-27'], ['22-22'], ['17-22'], ['26-21'], ['14-13'], ['8-26'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant_misleading/llama-2-7b-80k_id_432_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['14-18'], ['19-15'], ['24-3'], ['21-30'], ['26-28'], ['20-10'], ['18-30'], ['24-11'], ['17-0'], ['19-9'], ['26-27'], ['6-9'], ['22-22'], ['17-22'], ['8-26'], ['26-21'], ['7-12'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 99.99999403953552\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant_misleading/llama-2-7b-80k_id_432_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 762\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['14-18'], ['19-15'], ['24-3'], ['26-28'], ['21-30'], ['20-10'], ['18-30'], ['8-26'], ['19-9'], ['24-11'], ['17-0'], ['26-27'], ['7-12'], ['22-22'], ['6-9'], ['17-22'], ['26-21'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 99.99999403953552\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant_misleading/llama-2-7b-80k_id_432_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1761\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['14-18'], ['19-15'], ['24-3'], ['26-28'], ['21-30'], ['20-10'], ['18-30'], ['8-26'], ['19-9'], ['24-11'], ['7-12'], ['17-0'], ['22-22'], ['26-27'], ['6-9'], ['17-22'], ['26-21'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 98.43627214431763\n",
      "Response: Jorge Martín is the latest MotoGP World Riders' Champion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant_misleading/llama-2-7b-80k_id_432_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2620\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['14-18'], ['19-15'], ['24-3'], ['26-28'], ['21-30'], ['20-10'], ['18-30'], ['8-26'], ['19-9'], ['24-11'], ['17-0'], ['22-22'], ['26-27'], ['7-12'], ['6-9'], ['17-22'], ['14-13'], ['26-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 63.59459161758423\n",
      "Response: Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant_misleading/llama-2-7b-80k_id_432_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['14-18'], ['24-3'], ['21-30'], ['26-28'], ['8-26'], ['20-10'], ['6-9'], ['18-30'], ['17-22'], ['24-11'], ['17-0'], ['19-9'], ['22-22'], ['26-27'], ['12-26'], ['7-12'], ['14-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 99.99999403953552\n",
      "Response: The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_432_irrelevant_misleading/llama-2-7b-80k_id_432_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The latest MotoGP World Riders' Champion is Jorge Martín.\n",
      "[['11-15'], ['16-19'], ['19-15'], ['14-18'], ['24-3'], ['21-30'], ['8-26'], ['26-28'], ['20-10'], ['6-9'], ['18-30'], ['17-22'], ['22-22'], ['24-11'], ['17-0'], ['19-9'], ['26-27'], ['7-12'], ['12-26'], ['14-13']]\n",
=======
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['24-29'], ['1-26'], ['7-4'], ['17-22'], ['21-30'], ['0-14'], ['13-11'], ['16-19'], ['0-8'], ['0-11'], ['6-9'], ['7-31'], ['8-26'], ['11-17'], ['12-4'], ['15-12'], ['16-24'], ['17-13'], ['17-18']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 51.051437854766846\n",
      "Response: The ninth ballot was held on January 4, 2023, and it was the final ballot in the Speaker of the House election. The ninth ballot was a runoff between Kevin McCarthy and H\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['24-29'], ['1-26'], ['7-4'], ['17-22'], ['21-30'], ['0-14'], ['13-11'], ['16-19'], ['0-8'], ['0-11'], ['6-9'], ['7-31'], ['8-26'], ['11-17'], ['12-4'], ['15-12'], ['16-24'], ['17-13'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 51.051437854766846\n",
      "Response: The ninth ballot was held on January 4, 2023, and it was the final ballot in the Speaker of the House election. The ninth ballot was a runoff between Kevin McCarthy and H\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['24-29'], ['1-26'], ['7-4'], ['17-22'], ['21-30'], ['0-14'], ['13-11'], ['16-19'], ['0-8'], ['0-11'], ['6-9'], ['7-31'], ['8-26'], ['11-17'], ['12-4'], ['15-12'], ['16-24'], ['17-13'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 51.051437854766846\n",
      "Response: The ninth ballot was held on January 4, 2023, and it was the final ballot in the Speaker of the House election. The ninth ballot was a runoff between Kevin McCarthy and H\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
<<<<<<< Updated upstream
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['21-30'], ['7-4'], ['8-26'], ['14-18'], ['17-22'], ['18-30'], ['19-15'], ['22-22'], ['24-29'], ['26-28'], ['31-16'], ['7-31'], ['8-18'], ['8-24'], ['8-31'], ['9-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant/llama-2-7b-80k_id_433_relevant_len_0_depth_7500_results.json\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['21-30'], ['7-4'], ['8-26'], ['14-18'], ['17-22'], ['18-30'], ['19-15'], ['22-22'], ['24-29'], ['26-28'], ['31-16'], ['7-31'], ['8-18'], ['8-24'], ['8-31'], ['9-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant/llama-2-7b-80k_id_433_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 18.583674728870392\n",
      "Response: \"1927 Man of the Year Charles Lindbergh, the award's inaugural winner\"\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant/llama-2-7b-80k_id_433_relevant_len_1250_depth_0_results.json\n",
      "insertion at 237\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['16-19'], ['21-30'], ['6-9'], ['6-30'], ['7-4'], ['8-26'], ['19-15'], ['24-29'], ['14-18'], ['17-22'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['13-11'], ['10-18'], ['12-16'], ['15-14'], ['17-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant/llama-2-7b-80k_id_433_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 416\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-30'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['24-29'], ['14-18'], ['22-22'], ['26-28'], ['31-16'], ['17-22'], ['18-30'], ['13-11'], ['10-18'], ['16-24'], ['17-0'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant/llama-2-7b-80k_id_433_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 763\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-30'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['24-29'], ['17-22'], ['22-22'], ['26-28'], ['31-16'], ['14-18'], ['13-11'], ['18-30'], ['16-24'], ['10-18'], ['17-0'], ['19-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant/llama-2-7b-80k_id_433_relevant_len_1250_depth_7500_results.json\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['16-19'], ['21-30'], ['6-9'], ['19-15'], ['7-4'], ['6-30'], ['8-26'], ['24-29'], ['31-16'], ['26-28'], ['17-22'], ['22-22'], ['14-18'], ['16-24'], ['18-30'], ['13-11'], ['20-3'], ['26-26'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 98.35726022720337\n",
      "Response: Caitlin Clark is the most recent winner of Time Magazine's Athlete of the Year award.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant/llama-2-7b-80k_id_433_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 13.39137852191925\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant/llama-2-7b-80k_id_433_relevant_len_2500_depth_0_results.json\n",
      "insertion at 561\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['16-19'], ['21-30'], ['6-9'], ['19-15'], ['7-4'], ['6-30'], ['8-26'], ['24-29'], ['31-16'], ['26-28'], ['17-22'], ['22-22'], ['14-18'], ['13-11'], ['16-24'], ['18-30'], ['20-3'], ['26-26'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant/llama-2-7b-80k_id_433_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 888\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['16-19'], ['21-30'], ['6-9'], ['7-4'], ['19-15'], ['6-30'], ['8-26'], ['24-29'], ['31-16'], ['26-28'], ['17-22'], ['22-22'], ['13-11'], ['14-18'], ['16-24'], ['20-3'], ['26-26'], ['26-27'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant/llama-2-7b-80k_id_433_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1699\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['16-19'], ['21-30'], ['6-9'], ['7-4'], ['19-15'], ['6-30'], ['8-26'], ['24-29'], ['31-16'], ['26-28'], ['17-22'], ['22-22'], ['13-11'], ['16-24'], ['14-18'], ['20-3'], ['26-26'], ['26-27'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant/llama-2-7b-80k_id_433_relevant_len_2500_depth_7500_results.json\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['7-4'], ['19-15'], ['6-30'], ['8-26'], ['24-29'], ['31-16'], ['26-28'], ['17-22'], ['22-22'], ['13-11'], ['16-24'], ['20-3'], ['18-30'], ['14-18'], ['26-26'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant/llama-2-7b-80k_id_433_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 19.100259244441986\n",
      "Response: 1927 Man of the Year Charles Lindbergh, the award's inaugural winner\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant/llama-2-7b-80k_id_433_relevant_len_3750_depth_0_results.json\n",
      "insertion at 863\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['21-30'], ['11-15'], ['6-9'], ['7-4'], ['19-15'], ['8-26'], ['24-29'], ['6-30'], ['31-16'], ['26-28'], ['17-22'], ['22-22'], ['13-11'], ['16-24'], ['20-3'], ['14-18'], ['26-26'], ['26-27'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant/llama-2-7b-80k_id_433_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1734\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['21-30'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['19-15'], ['24-29'], ['6-30'], ['17-22'], ['31-16'], ['26-28'], ['22-22'], ['13-11'], ['16-24'], ['20-3'], ['26-26'], ['26-27'], ['14-18'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant/llama-2-7b-80k_id_433_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2557\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['21-30'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['24-29'], ['6-30'], ['17-22'], ['31-16'], ['26-28'], ['22-22'], ['13-11'], ['20-3'], ['7-12'], ['16-24'], ['26-26'], ['26-27'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant/llama-2-7b-80k_id_433_relevant_len_3750_depth_7500_results.json\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['21-30'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['24-29'], ['6-30'], ['17-22'], ['31-16'], ['26-28'], ['22-22'], ['13-11'], ['16-24'], ['20-3'], ['18-30'], ['21-16'], ['26-26'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant/llama-2-7b-80k_id_433_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['8-26'], ['24-29'], ['7-4'], ['6-30'], ['19-15'], ['17-22'], ['7-12'], ['26-28'], ['31-16'], ['22-22'], ['13-11'], ['16-24'], ['20-3'], ['18-30'], ['14-18'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 100.00001192092896\n",
      "Response: The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant/llama-2-7b-80k_id_433_relevant_len_5000_depth_0_results.json\n",
      "insertion at 888\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['8-26'], ['24-29'], ['7-4'], ['6-30'], ['19-15'], ['17-22'], ['7-12'], ['26-28'], ['31-16'], ['22-22'], ['13-11'], ['18-30'], ['20-3'], ['16-24'], ['26-26'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant/llama-2-7b-80k_id_433_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2376\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['24-29'], ['8-26'], ['7-4'], ['6-30'], ['19-15'], ['17-22'], ['7-12'], ['26-28'], ['31-16'], ['22-22'], ['13-11'], ['20-3'], ['26-26'], ['26-27'], ['18-30'], ['23-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant/llama-2-7b-80k_id_433_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3581\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['24-29'], ['6-9'], ['8-26'], ['7-4'], ['6-30'], ['19-15'], ['17-22'], ['7-12'], ['26-28'], ['31-16'], ['22-22'], ['13-11'], ['20-3'], ['26-26'], ['26-27'], ['18-30'], ['23-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant/llama-2-7b-80k_id_433_relevant_len_5000_depth_7500_results.json\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['8-26'], ['24-29'], ['6-9'], ['7-4'], ['6-30'], ['19-15'], ['17-22'], ['7-12'], ['26-28'], ['31-16'], ['22-22'], ['13-11'], ['20-3'], ['18-30'], ['26-26'], ['26-27'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant/llama-2-7b-80k_id_433_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/433.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['21-30'], ['7-4'], ['8-26'], ['14-18'], ['17-22'], ['18-30'], ['19-15'], ['22-22'], ['24-29'], ['26-28'], ['31-16'], ['7-31'], ['8-18'], ['8-24'], ['8-31'], ['9-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['21-30'], ['7-4'], ['8-26'], ['14-18'], ['17-22'], ['18-30'], ['19-15'], ['22-22'], ['24-29'], ['26-28'], ['31-16'], ['7-31'], ['8-18'], ['8-24'], ['8-31'], ['9-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['21-30'], ['7-4'], ['8-26'], ['14-18'], ['17-22'], ['18-30'], ['19-15'], ['22-22'], ['24-29'], ['26-28'], ['31-16'], ['7-31'], ['8-18'], ['8-24'], ['8-31'], ['9-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['21-30'], ['7-4'], ['8-26'], ['14-18'], ['17-22'], ['18-30'], ['19-15'], ['22-22'], ['24-29'], ['26-28'], ['31-16'], ['7-31'], ['8-18'], ['8-24'], ['8-31'], ['9-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_0_depth_7500_results.json\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['21-30'], ['7-4'], ['8-26'], ['14-18'], ['17-22'], ['18-30'], ['19-15'], ['22-22'], ['24-29'], ['26-28'], ['31-16'], ['7-31'], ['8-18'], ['8-24'], ['8-31'], ['9-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['21-30'], ['6-30'], ['22-22'], ['24-29'], ['26-28'], ['31-16'], ['7-4'], ['8-26'], ['14-18'], ['17-22'], ['18-30'], ['19-15'], ['10-29'], ['20-3'], ['21-16'], ['21-26'], ['23-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 237\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['21-30'], ['6-30'], ['24-29'], ['19-15'], ['22-22'], ['26-28'], ['31-16'], ['7-4'], ['14-18'], ['8-26'], ['17-22'], ['18-30'], ['20-3'], ['21-16'], ['21-26'], ['23-20'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 416\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['21-30'], ['6-30'], ['24-29'], ['19-15'], ['22-22'], ['26-28'], ['31-16'], ['7-4'], ['14-18'], ['8-26'], ['17-22'], ['18-30'], ['20-3'], ['21-16'], ['21-26'], ['23-20'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 763\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['21-30'], ['6-30'], ['24-29'], ['19-15'], ['22-22'], ['26-28'], ['31-16'], ['7-4'], ['8-26'], ['14-18'], ['17-22'], ['18-30'], ['7-12'], ['20-3'], ['21-26'], ['23-20'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['21-30'], ['19-15'], ['7-4'], ['6-30'], ['24-29'], ['31-16'], ['26-28'], ['22-22'], ['8-26'], ['14-18'], ['17-22'], ['18-30'], ['20-3'], ['26-27'], ['12-26'], ['23-20'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 98.35726022720337\n",
      "Response: Caitlin Clark is the most recent winner of Time Magazine's Athlete of the Year award.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['21-30'], ['19-15'], ['7-4'], ['24-29'], ['31-16'], ['6-30'], ['26-28'], ['22-22'], ['8-26'], ['17-22'], ['14-18'], ['20-3'], ['26-27'], ['7-12'], ['18-30'], ['23-20'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 561\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['21-30'], ['19-15'], ['24-29'], ['7-4'], ['31-16'], ['26-28'], ['6-30'], ['22-22'], ['8-26'], ['14-18'], ['17-22'], ['20-3'], ['7-12'], ['26-27'], ['18-30'], ['21-16'], ['21-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 920\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['19-15'], ['21-30'], ['24-29'], ['7-4'], ['31-16'], ['26-28'], ['6-30'], ['22-22'], ['8-26'], ['7-12'], ['14-18'], ['17-22'], ['20-3'], ['26-27'], ['18-30'], ['21-16'], ['21-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1614\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['19-15'], ['21-30'], ['24-29'], ['7-4'], ['31-16'], ['6-30'], ['26-28'], ['22-22'], ['7-12'], ['8-26'], ['14-18'], ['17-22'], ['20-3'], ['26-27'], ['18-30'], ['21-16'], ['21-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['19-15'], ['16-19'], ['21-30'], ['7-4'], ['24-29'], ['31-16'], ['26-28'], ['6-30'], ['8-26'], ['22-22'], ['17-22'], ['20-3'], ['14-18'], ['26-27'], ['7-12'], ['12-26'], ['18-30'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 98.35726022720337\n",
      "Response: Caitlin Clark is the most recent winner of Time Magazine's Athlete of the Year award.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['19-15'], ['16-19'], ['21-30'], ['7-4'], ['24-29'], ['26-28'], ['31-16'], ['6-30'], ['8-26'], ['22-22'], ['17-22'], ['7-12'], ['14-18'], ['20-3'], ['26-27'], ['12-26'], ['18-30'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 838\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['19-15'], ['21-30'], ['24-29'], ['7-4'], ['31-16'], ['26-28'], ['6-30'], ['22-22'], ['8-26'], ['17-22'], ['7-12'], ['14-18'], ['20-3'], ['26-27'], ['12-26'], ['23-20'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1764\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['19-15'], ['24-29'], ['21-30'], ['7-4'], ['31-16'], ['26-28'], ['6-30'], ['22-22'], ['8-26'], ['7-12'], ['17-22'], ['14-18'], ['20-3'], ['26-27'], ['23-20'], ['12-26'], ['21-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2614\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['19-15'], ['16-19'], ['24-29'], ['21-30'], ['7-4'], ['31-16'], ['26-28'], ['22-22'], ['6-30'], ['7-12'], ['17-22'], ['8-26'], ['20-3'], ['14-18'], ['26-27'], ['23-20'], ['21-26'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['19-15'], ['16-19'], ['21-30'], ['24-29'], ['7-4'], ['31-16'], ['26-28'], ['8-26'], ['6-30'], ['22-22'], ['17-22'], ['7-12'], ['20-3'], ['26-27'], ['12-26'], ['14-18'], ['23-20'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 98.35726022720337\n",
      "Response: Caitlin Clark is the most recent winner of Time Magazine's Athlete of the Year award.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['19-15'], ['16-19'], ['21-30'], ['24-29'], ['7-4'], ['31-16'], ['26-28'], ['8-26'], ['22-22'], ['6-30'], ['7-12'], ['17-22'], ['20-3'], ['26-27'], ['12-26'], ['14-18'], ['23-20'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 920\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['19-15'], ['16-19'], ['24-29'], ['21-30'], ['7-4'], ['31-16'], ['26-28'], ['8-26'], ['7-12'], ['22-22'], ['6-30'], ['17-22'], ['20-3'], ['26-27'], ['12-26'], ['14-18'], ['23-20'], ['26-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2319\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['19-15'], ['16-19'], ['24-29'], ['21-30'], ['7-4'], ['31-16'], ['26-28'], ['8-26'], ['7-12'], ['17-22'], ['22-22'], ['6-30'], ['26-27'], ['20-3'], ['14-18'], ['12-26'], ['26-26'], ['21-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3539\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['19-15'], ['16-19'], ['24-29'], ['21-30'], ['7-4'], ['31-16'], ['7-12'], ['26-28'], ['8-26'], ['22-22'], ['17-22'], ['6-30'], ['26-27'], ['20-3'], ['14-18'], ['12-26'], ['26-26'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['19-15'], ['16-19'], ['7-4'], ['21-30'], ['24-29'], ['31-16'], ['8-26'], ['26-28'], ['22-22'], ['7-12'], ['6-30'], ['17-22'], ['12-26'], ['26-27'], ['20-3'], ['26-26'], ['14-18'], ['28-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 98.35726022720337\n",
      "Response: Caitlin Clark is the most recent winner of Time Magazine's Athlete of the Year award.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_relevant_misleading/llama-2-7b-80k_id_433_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['21-30'], ['7-4'], ['8-26'], ['14-18'], ['17-22'], ['18-30'], ['19-15'], ['22-22'], ['24-29'], ['26-28'], ['31-16'], ['7-31'], ['8-18'], ['8-24'], ['8-31'], ['9-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['21-30'], ['7-4'], ['8-26'], ['14-18'], ['17-22'], ['18-30'], ['19-15'], ['22-22'], ['24-29'], ['26-28'], ['31-16'], ['7-31'], ['8-18'], ['8-24'], ['8-31'], ['9-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['21-30'], ['7-4'], ['8-26'], ['14-18'], ['17-22'], ['18-30'], ['19-15'], ['22-22'], ['24-29'], ['26-28'], ['31-16'], ['7-31'], ['8-18'], ['8-24'], ['8-31'], ['9-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['21-30'], ['7-4'], ['8-26'], ['14-18'], ['17-22'], ['18-30'], ['19-15'], ['22-22'], ['24-29'], ['26-28'], ['31-16'], ['7-31'], ['8-18'], ['8-24'], ['8-31'], ['9-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_0_depth_7500_results.json\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['21-30'], ['7-4'], ['8-26'], ['14-18'], ['17-22'], ['18-30'], ['19-15'], ['22-22'], ['24-29'], ['26-28'], ['31-16'], ['7-31'], ['8-18'], ['8-24'], ['8-31'], ['9-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 47.11219370365143\n",
      "Response: Keely Hodgkinson (2024; athletics)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 244\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['6-30'], ['14-18'], ['7-4'], ['8-26'], ['17-22'], ['19-15'], ['24-29'], ['18-30'], ['22-22'], ['26-28'], ['31-16'], ['13-11'], ['10-18'], ['12-16'], ['15-14'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 490\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['6-30'], ['14-18'], ['7-4'], ['8-26'], ['17-22'], ['19-15'], ['24-29'], ['22-22'], ['26-28'], ['31-16'], ['18-30'], ['13-11'], ['16-24'], ['10-18'], ['12-16'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 717\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-30'], ['6-9'], ['7-4'], ['8-26'], ['17-22'], ['19-15'], ['24-29'], ['14-18'], ['22-22'], ['26-28'], ['31-16'], ['13-11'], ['18-30'], ['10-18'], ['16-24'], ['20-3'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_1250_depth_7500_results.json\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['21-30'], ['11-15'], ['6-30'], ['6-9'], ['7-4'], ['8-26'], ['17-22'], ['19-15'], ['24-29'], ['14-18'], ['22-22'], ['26-28'], ['31-16'], ['18-30'], ['13-11'], ['16-24'], ['21-16'], ['10-18'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 47.11219370365143\n",
      "Response: Keely Hodgkinson (2024; athletics)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 569\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['21-30'], ['11-15'], ['6-30'], ['6-9'], ['8-26'], ['7-4'], ['24-29'], ['17-22'], ['19-15'], ['22-22'], ['26-28'], ['31-16'], ['14-18'], ['13-11'], ['18-30'], ['16-24'], ['21-16'], ['10-18'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 874\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['21-30'], ['11-15'], ['6-30'], ['6-9'], ['8-26'], ['24-29'], ['7-4'], ['17-22'], ['19-15'], ['22-22'], ['26-28'], ['31-16'], ['13-11'], ['14-18'], ['18-30'], ['21-16'], ['10-18'], ['16-24'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 874\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['21-30'], ['11-15'], ['6-30'], ['6-9'], ['24-29'], ['8-26'], ['7-4'], ['17-22'], ['19-15'], ['22-22'], ['26-28'], ['31-16'], ['13-11'], ['18-30'], ['14-18'], ['21-16'], ['7-12'], ['10-18'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_2500_depth_7500_results.json\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['24-29'], ['6-30'], ['17-22'], ['31-16'], ['22-22'], ['26-28'], ['13-11'], ['18-30'], ['14-18'], ['16-24'], ['26-26'], ['26-27'], ['21-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 98.35726022720337\n",
      "Response: Caitlin Clark is the most recent winner of Time Magazine's Athlete of the Year award.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 47.11219370365143\n",
      "Response: Keely Hodgkinson (2024; athletics)\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 874\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['7-4'], ['8-26'], ['24-29'], ['19-15'], ['6-30'], ['17-22'], ['31-16'], ['22-22'], ['26-28'], ['13-11'], ['18-30'], ['14-18'], ['26-26'], ['26-27'], ['21-16'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 874\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['7-4'], ['8-26'], ['24-29'], ['19-15'], ['6-30'], ['17-22'], ['31-16'], ['22-22'], ['26-28'], ['13-11'], ['14-18'], ['18-30'], ['26-26'], ['26-27'], ['21-16'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 874\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['8-26'], ['24-29'], ['7-4'], ['17-22'], ['19-15'], ['6-30'], ['31-16'], ['13-11'], ['22-22'], ['26-28'], ['14-18'], ['18-30'], ['7-12'], ['26-26'], ['26-27'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_3750_depth_7500_results.json\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['7-4'], ['19-15'], ['24-29'], ['8-26'], ['17-22'], ['6-30'], ['31-16'], ['22-22'], ['26-28'], ['13-11'], ['26-26'], ['26-27'], ['18-30'], ['14-18'], ['21-1'], ['23-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 98.35726022720337\n",
      "Response: Caitlin Clark is the most recent winner of Time Magazine's Athlete of the Year award.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['8-26'], ['7-4'], ['19-15'], ['24-29'], ['17-22'], ['6-30'], ['31-16'], ['22-22'], ['26-28'], ['13-11'], ['7-12'], ['14-18'], ['26-26'], ['26-27'], ['18-30'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 82.2511613368988\n",
      "Response: The most recent winner of Time Magazine's Athlete of the Year award is Lewis Hamilton.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 874\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['6-9'], ['8-26'], ['7-4'], ['24-29'], ['19-15'], ['17-22'], ['6-30'], ['31-16'], ['22-22'], ['26-28'], ['13-11'], ['7-12'], ['14-18'], ['26-26'], ['26-27'], ['18-30'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 874\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['8-26'], ['6-9'], ['24-29'], ['7-4'], ['19-15'], ['17-22'], ['6-30'], ['13-11'], ['31-16'], ['7-12'], ['22-22'], ['26-28'], ['26-26'], ['26-27'], ['14-18'], ['18-30'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 874\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['8-26'], ['6-9'], ['24-29'], ['7-4'], ['19-15'], ['17-22'], ['6-30'], ['13-11'], ['7-12'], ['31-16'], ['22-22'], ['26-28'], ['26-26'], ['26-27'], ['18-30'], ['14-18'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_5000_depth_7500_results.json\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['16-19'], ['11-15'], ['21-30'], ['8-26'], ['6-9'], ['24-29'], ['7-4'], ['19-15'], ['17-22'], ['6-30'], ['31-16'], ['13-11'], ['22-22'], ['26-28'], ['7-12'], ['18-30'], ['26-26'], ['26-27'], ['14-18'], ['21-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant/llama-2-7b-80k_id_433_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/433.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['21-30'], ['7-4'], ['8-26'], ['14-18'], ['17-22'], ['18-30'], ['19-15'], ['22-22'], ['24-29'], ['26-28'], ['31-16'], ['7-31'], ['8-18'], ['8-24'], ['8-31'], ['9-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['21-30'], ['7-4'], ['8-26'], ['14-18'], ['17-22'], ['18-30'], ['19-15'], ['22-22'], ['24-29'], ['26-28'], ['31-16'], ['7-31'], ['8-18'], ['8-24'], ['8-31'], ['9-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['21-30'], ['7-4'], ['8-26'], ['14-18'], ['17-22'], ['18-30'], ['19-15'], ['22-22'], ['24-29'], ['26-28'], ['31-16'], ['7-31'], ['8-18'], ['8-24'], ['8-31'], ['9-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['21-30'], ['7-4'], ['8-26'], ['14-18'], ['17-22'], ['18-30'], ['19-15'], ['22-22'], ['24-29'], ['26-28'], ['31-16'], ['7-31'], ['8-18'], ['8-24'], ['8-31'], ['9-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['21-30'], ['7-4'], ['8-26'], ['14-18'], ['17-22'], ['18-30'], ['19-15'], ['22-22'], ['24-29'], ['26-28'], ['31-16'], ['7-31'], ['8-18'], ['8-24'], ['8-31'], ['9-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['6-30'], ['11-15'], ['16-19'], ['21-30'], ['26-28'], ['7-4'], ['8-26'], ['14-18'], ['17-22'], ['18-30'], ['19-15'], ['22-22'], ['24-29'], ['31-16'], ['7-31'], ['8-18'], ['8-24'], ['8-31'], ['9-17']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 244\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['11-15'], ['16-19'], ['21-30'], ['6-30'], ['24-29'], ['26-28'], ['31-16'], ['14-18'], ['17-22'], ['18-30'], ['19-15'], ['7-4'], ['8-26'], ['22-22'], ['20-3'], ['21-26'], ['26-26'], ['7-31'], ['8-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 510\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['21-30'], ['11-15'], ['16-19'], ['6-30'], ['24-29'], ['31-16'], ['26-28'], ['7-4'], ['8-26'], ['14-18'], ['17-22'], ['18-30'], ['19-15'], ['22-22'], ['20-3'], ['21-26'], ['26-26'], ['16-24'], ['24-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 753\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['21-30'], ['16-19'], ['11-15'], ['31-16'], ['6-30'], ['24-29'], ['26-28'], ['7-4'], ['8-26'], ['17-22'], ['18-30'], ['19-15'], ['14-18'], ['22-22'], ['20-3'], ['21-26'], ['26-26'], ['13-11'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['11-15'], ['21-30'], ['16-19'], ['19-15'], ['31-16'], ['7-4'], ['8-26'], ['26-28'], ['24-29'], ['6-30'], ['17-22'], ['18-30'], ['22-22'], ['16-24'], ['14-18'], ['26-26'], ['12-26'], ['15-14'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 98.35726022720337\n",
      "Response: Caitlin Clark is the most recent winner of Time Magazine's Athlete of the Year award.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['11-15'], ['21-30'], ['31-16'], ['16-19'], ['19-15'], ['26-28'], ['7-4'], ['8-26'], ['24-29'], ['6-30'], ['17-22'], ['18-30'], ['22-22'], ['16-24'], ['14-18'], ['26-26'], ['12-26'], ['15-14'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 555\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['6-9'], ['11-15'], ['21-30'], ['31-16'], ['16-19'], ['19-15'], ['26-28'], ['7-4'], ['24-29'], ['8-26'], ['6-30'], ['17-22'], ['18-30'], ['14-18'], ['22-22'], ['16-24'], ['26-26'], ['12-26'], ['15-14'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1032\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['21-30'], ['16-19'], ['31-16'], ['19-15'], ['7-4'], ['24-29'], ['26-28'], ['8-26'], ['6-30'], ['17-22'], ['18-30'], ['22-22'], ['26-26'], ['14-18'], ['15-14'], ['16-24'], ['13-11'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1032\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['21-30'], ['6-9'], ['16-19'], ['19-15'], ['31-16'], ['7-4'], ['24-29'], ['26-28'], ['8-26'], ['17-22'], ['6-30'], ['18-30'], ['22-22'], ['26-26'], ['15-14'], ['13-11'], ['14-18'], ['16-24'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 56.55549168586731\n",
      "Response: Caitlin Clark\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['21-30'], ['16-19'], ['19-15'], ['7-4'], ['24-29'], ['31-16'], ['8-26'], ['26-28'], ['17-22'], ['6-30'], ['18-30'], ['15-14'], ['22-22'], ['16-24'], ['26-26'], ['12-26'], ['13-11'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 98.35726022720337\n",
      "Response: Caitlin Clark is the most recent winner of Time Magazine's Athlete of the Year award.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['21-30'], ['16-19'], ['19-15'], ['7-4'], ['24-29'], ['31-16'], ['8-26'], ['26-28'], ['17-22'], ['6-30'], ['15-14'], ['18-30'], ['22-22'], ['16-24'], ['26-26'], ['12-26'], ['13-11'], ['26-27']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 835\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['21-30'], ['16-19'], ['19-15'], ['7-4'], ['24-29'], ['31-16'], ['8-26'], ['26-28'], ['17-22'], ['6-30'], ['15-14'], ['18-30'], ['22-22'], ['26-26'], ['16-24'], ['12-26'], ['13-11'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1032\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['21-30'], ['19-15'], ['7-4'], ['24-29'], ['31-16'], ['8-26'], ['26-28'], ['17-22'], ['6-30'], ['15-14'], ['18-30'], ['22-22'], ['26-26'], ['13-11'], ['14-18'], ['16-24'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 1032\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['21-30'], ['19-15'], ['24-29'], ['7-4'], ['31-16'], ['8-26'], ['26-28'], ['17-22'], ['15-14'], ['6-30'], ['18-30'], ['22-22'], ['26-26'], ['14-18'], ['13-11'], ['16-24'], ['20-3']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 56.792473793029785\n",
      "Response: Caitlin Clark.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['19-15'], ['21-30'], ['7-4'], ['24-29'], ['8-26'], ['26-28'], ['31-16'], ['17-22'], ['15-14'], ['6-30'], ['22-22'], ['18-30'], ['26-26'], ['16-24'], ['12-26'], ['13-11'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 98.35726022720337\n",
      "Response: Caitlin Clark is the most recent winner of Time Magazine's Athlete of the Year award.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['19-15'], ['21-30'], ['7-4'], ['24-29'], ['8-26'], ['26-28'], ['31-16'], ['17-22'], ['15-14'], ['6-30'], ['22-22'], ['18-30'], ['26-26'], ['16-24'], ['12-26'], ['13-11'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 98.35726022720337\n",
      "Response: Caitlin Clark is the most recent winner of Time Magazine's Athlete of the Year award.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1032\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['19-15'], ['21-30'], ['7-4'], ['8-26'], ['24-29'], ['17-22'], ['26-28'], ['31-16'], ['15-14'], ['6-30'], ['26-26'], ['22-22'], ['18-30'], ['13-11'], ['16-24'], ['12-26'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 98.35726022720337\n",
      "Response: Caitlin Clark is the most recent winner of Time Magazine's Athlete of the Year award.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 1032\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['19-15'], ['8-26'], ['7-4'], ['21-30'], ['24-29'], ['17-22'], ['26-28'], ['31-16'], ['15-14'], ['26-26'], ['22-22'], ['6-30'], ['7-12'], ['13-11'], ['18-30'], ['14-18'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 98.35726022720337\n",
      "Response: Caitlin Clark is the most recent winner of Time Magazine's Athlete of the Year award.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 1032\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['19-15'], ['17-22'], ['7-4'], ['24-29'], ['21-30'], ['15-14'], ['26-28'], ['31-16'], ['7-12'], ['26-26'], ['22-22'], ['6-30'], ['13-11'], ['20-3'], ['14-18'], ['18-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 98.35726022720337\n",
      "Response: Caitlin Clark is the most recent winner of Time Magazine's Athlete of the Year award.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The most recent winner of Time Magazine's Athlete of the Year award is Caitlin Clark.\n",
      "[['11-15'], ['6-9'], ['16-19'], ['19-15'], ['8-26'], ['7-4'], ['21-30'], ['24-29'], ['17-22'], ['15-14'], ['26-28'], ['31-16'], ['26-26'], ['7-12'], ['22-22'], ['6-30'], ['12-26'], ['13-11'], ['20-3'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 98.35726022720337\n",
      "Response: Caitlin Clark is the most recent winner of Time Magazine's Athlete of the Year award.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_433_irrelevant_misleading/llama-2-7b-80k_id_433_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['7-4'], ['11-15'], ['18-30'], ['21-30'], ['24-29'], ['29-26'], ['31-24'], ['6-11'], ['8-26'], ['12-26'], ['19-15'], ['22-22'], ['26-28'], ['28-14'], ['29-19'], ['1-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['7-4'], ['11-15'], ['18-30'], ['21-30'], ['24-29'], ['29-26'], ['31-24'], ['6-11'], ['8-26'], ['12-26'], ['19-15'], ['22-22'], ['26-28'], ['28-14'], ['29-19'], ['1-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['7-4'], ['11-15'], ['18-30'], ['21-30'], ['24-29'], ['29-26'], ['31-24'], ['6-11'], ['8-26'], ['12-26'], ['19-15'], ['22-22'], ['26-28'], ['28-14'], ['29-19'], ['1-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['7-4'], ['11-15'], ['18-30'], ['21-30'], ['24-29'], ['29-26'], ['31-24'], ['6-11'], ['8-26'], ['12-26'], ['19-15'], ['22-22'], ['26-28'], ['28-14'], ['29-19'], ['1-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_0_depth_7500_results.json\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['7-4'], ['11-15'], ['18-30'], ['21-30'], ['24-29'], ['29-26'], ['31-24'], ['6-11'], ['8-26'], ['12-26'], ['19-15'], ['22-22'], ['26-28'], ['28-14'], ['29-19'], ['1-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['11-15'], ['24-29'], ['7-4'], ['18-30'], ['21-30'], ['29-26'], ['31-24'], ['8-26'], ['19-15'], ['26-28'], ['28-14'], ['29-19'], ['6-11'], ['12-26'], ['22-22'], ['12-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 97.01997637748718\n",
      "Response: The latest Nebula award for Best Novel was won by The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_1250_depth_0_results.json\n",
      "insertion at 256\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['11-15'], ['24-29'], ['7-4'], ['18-30'], ['8-26'], ['21-30'], ['19-15'], ['29-26'], ['31-24'], ['26-28'], ['28-14'], ['22-22'], ['29-19'], ['6-11'], ['12-26'], ['23-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 485\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['6-30'], ['24-29'], ['31-16'], ['7-4'], ['8-26'], ['18-30'], ['21-30'], ['19-15'], ['26-28'], ['31-24'], ['28-14'], ['29-26'], ['22-22'], ['29-19'], ['6-11'], ['12-26'], ['23-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 767\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['6-30'], ['8-26'], ['24-29'], ['7-4'], ['18-30'], ['31-16'], ['21-30'], ['19-15'], ['26-28'], ['28-14'], ['29-26'], ['31-24'], ['22-22'], ['29-19'], ['23-20'], ['24-8'], ['20-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_1250_depth_7500_results.json\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['6-30'], ['8-26'], ['24-29'], ['31-16'], ['7-4'], ['18-30'], ['21-30'], ['19-15'], ['26-28'], ['29-26'], ['31-24'], ['28-14'], ['22-22'], ['29-19'], ['23-20'], ['12-26'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['24-29'], ['6-30'], ['31-16'], ['7-4'], ['18-30'], ['19-15'], ['21-30'], ['26-28'], ['28-14'], ['29-26'], ['31-24'], ['22-22'], ['29-19'], ['23-20'], ['17-22'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_2500_depth_0_results.json\n",
      "insertion at 517\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['24-29'], ['6-30'], ['7-4'], ['18-30'], ['19-15'], ['31-16'], ['21-30'], ['26-28'], ['28-14'], ['22-22'], ['31-24'], ['29-26'], ['17-22'], ['29-19'], ['23-20'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1122\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['24-29'], ['7-4'], ['19-15'], ['6-30'], ['21-30'], ['18-30'], ['31-16'], ['17-22'], ['26-28'], ['28-14'], ['22-22'], ['29-19'], ['31-24'], ['29-26'], ['23-20'], ['24-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1564\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['19-15'], ['24-29'], ['7-4'], ['21-30'], ['17-22'], ['6-30'], ['18-30'], ['31-16'], ['26-28'], ['28-14'], ['29-19'], ['22-22'], ['29-26'], ['31-24'], ['7-12'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_2500_depth_7500_results.json\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['19-15'], ['24-29'], ['7-4'], ['21-30'], ['17-22'], ['6-30'], ['18-30'], ['31-16'], ['26-28'], ['28-14'], ['29-19'], ['29-26'], ['22-22'], ['31-24'], ['23-20'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['24-29'], ['19-15'], ['7-4'], ['21-30'], ['17-22'], ['6-30'], ['18-30'], ['31-16'], ['26-28'], ['28-14'], ['22-22'], ['29-19'], ['29-26'], ['31-24'], ['23-20'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_3750_depth_0_results.json\n",
      "insertion at 868\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['24-29'], ['19-15'], ['7-4'], ['21-30'], ['17-22'], ['18-30'], ['6-30'], ['31-16'], ['26-28'], ['28-14'], ['22-22'], ['23-20'], ['29-19'], ['31-24'], ['29-26'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1759\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['24-29'], ['19-15'], ['7-4'], ['17-22'], ['21-30'], ['18-30'], ['6-30'], ['31-16'], ['26-28'], ['28-14'], ['11-2'], ['22-22'], ['29-19'], ['23-20'], ['7-12'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2568\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['17-22'], ['24-29'], ['19-15'], ['7-4'], ['21-30'], ['18-30'], ['31-16'], ['6-30'], ['26-28'], ['11-2'], ['28-14'], ['7-12'], ['22-22'], ['29-19'], ['23-20'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_3750_depth_7500_results.json\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['24-29'], ['17-22'], ['19-15'], ['7-4'], ['21-30'], ['18-30'], ['31-16'], ['6-30'], ['26-28'], ['11-2'], ['28-14'], ['22-22'], ['7-12'], ['29-26'], ['29-19'], ['23-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['24-29'], ['17-22'], ['19-15'], ['7-4'], ['21-30'], ['18-30'], ['6-30'], ['31-16'], ['26-28'], ['11-2'], ['28-14'], ['22-22'], ['7-12'], ['23-20'], ['29-19'], ['29-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1172\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['24-29'], ['17-22'], ['19-15'], ['7-4'], ['21-30'], ['18-30'], ['6-30'], ['31-16'], ['26-28'], ['11-2'], ['28-14'], ['22-22'], ['7-12'], ['23-20'], ['29-26'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2387\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['24-29'], ['17-22'], ['19-15'], ['7-4'], ['21-30'], ['18-30'], ['6-30'], ['26-28'], ['31-16'], ['11-2'], ['22-22'], ['28-14'], ['23-20'], ['29-26'], ['7-12'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3508\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['17-22'], ['24-29'], ['7-4'], ['19-15'], ['21-30'], ['18-30'], ['26-28'], ['6-30'], ['11-2'], ['31-16'], ['7-12'], ['29-26'], ['22-22'], ['28-14'], ['23-20'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_5000_depth_7500_results.json\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['17-22'], ['24-29'], ['7-4'], ['19-15'], ['21-30'], ['18-30'], ['26-28'], ['6-30'], ['31-16'], ['11-2'], ['29-26'], ['28-14'], ['7-12'], ['22-22'], ['23-20'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant/llama-2-7b-80k_id_435_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/435.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['7-4'], ['11-15'], ['18-30'], ['21-30'], ['24-29'], ['29-26'], ['31-24'], ['6-11'], ['8-26'], ['12-26'], ['19-15'], ['22-22'], ['26-28'], ['28-14'], ['29-19'], ['1-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['7-4'], ['11-15'], ['18-30'], ['21-30'], ['24-29'], ['29-26'], ['31-24'], ['6-11'], ['8-26'], ['12-26'], ['19-15'], ['22-22'], ['26-28'], ['28-14'], ['29-19'], ['1-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['7-4'], ['11-15'], ['18-30'], ['21-30'], ['24-29'], ['29-26'], ['31-24'], ['6-11'], ['8-26'], ['12-26'], ['19-15'], ['22-22'], ['26-28'], ['28-14'], ['29-19'], ['1-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['7-4'], ['11-15'], ['18-30'], ['21-30'], ['24-29'], ['29-26'], ['31-24'], ['6-11'], ['8-26'], ['12-26'], ['19-15'], ['22-22'], ['26-28'], ['28-14'], ['29-19'], ['1-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_0_depth_7500_results.json\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['7-4'], ['11-15'], ['18-30'], ['21-30'], ['24-29'], ['29-26'], ['31-24'], ['6-11'], ['8-26'], ['12-26'], ['19-15'], ['22-22'], ['26-28'], ['28-14'], ['29-19'], ['1-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['24-29'], ['11-15'], ['21-30'], ['7-4'], ['18-30'], ['29-26'], ['31-24'], ['8-26'], ['19-15'], ['22-22'], ['26-28'], ['6-11'], ['12-26'], ['28-14'], ['29-19'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 256\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['24-29'], ['31-16'], ['11-15'], ['21-30'], ['18-30'], ['29-26'], ['31-24'], ['7-4'], ['19-15'], ['22-22'], ['26-28'], ['8-26'], ['12-26'], ['28-14'], ['6-11'], ['29-19'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 485\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['6-30'], ['11-15'], ['18-30'], ['21-30'], ['31-16'], ['29-26'], ['31-24'], ['19-15'], ['7-4'], ['22-22'], ['26-28'], ['8-26'], ['28-14'], ['12-26'], ['29-19'], ['6-11'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 756\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['18-30'], ['11-15'], ['6-30'], ['21-30'], ['31-16'], ['29-26'], ['19-15'], ['31-24'], ['22-22'], ['26-28'], ['7-4'], ['8-26'], ['28-14'], ['29-19'], ['12-26'], ['17-22'], ['23-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['18-30'], ['24-29'], ['6-30'], ['11-15'], ['31-16'], ['21-30'], ['29-26'], ['19-15'], ['31-24'], ['8-26'], ['22-22'], ['26-28'], ['28-14'], ['7-4'], ['12-26'], ['29-19'], ['17-22'], ['23-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['11-15'], ['18-30'], ['6-30'], ['21-30'], ['31-16'], ['19-15'], ['29-26'], ['8-26'], ['31-24'], ['22-22'], ['26-28'], ['28-14'], ['7-4'], ['12-26'], ['17-22'], ['29-19'], ['23-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 547\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['11-15'], ['18-30'], ['6-30'], ['19-15'], ['21-30'], ['31-16'], ['8-26'], ['29-26'], ['31-24'], ['22-22'], ['26-28'], ['28-14'], ['7-4'], ['17-22'], ['12-26'], ['23-20'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1103\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['18-30'], ['11-15'], ['6-30'], ['19-15'], ['21-30'], ['8-26'], ['29-26'], ['31-16'], ['31-24'], ['22-22'], ['26-28'], ['7-4'], ['28-14'], ['17-22'], ['12-26'], ['23-20'], ['25-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1641\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['18-30'], ['11-15'], ['19-15'], ['6-30'], ['21-30'], ['8-26'], ['29-26'], ['22-22'], ['31-16'], ['31-24'], ['26-28'], ['7-4'], ['28-14'], ['17-22'], ['25-0'], ['12-26'], ['23-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['18-30'], ['11-15'], ['19-15'], ['6-30'], ['21-30'], ['8-26'], ['29-26'], ['31-16'], ['22-22'], ['31-24'], ['7-4'], ['26-28'], ['28-14'], ['17-22'], ['12-26'], ['25-0'], ['23-20']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['18-30'], ['11-15'], ['19-15'], ['6-30'], ['8-26'], ['21-30'], ['29-26'], ['31-16'], ['22-22'], ['31-24'], ['7-4'], ['26-28'], ['28-14'], ['17-22'], ['12-26'], ['23-20'], ['25-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 880\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['18-30'], ['11-15'], ['19-15'], ['8-26'], ['6-30'], ['21-30'], ['29-26'], ['22-22'], ['31-16'], ['31-24'], ['26-28'], ['28-14'], ['7-4'], ['17-22'], ['23-20'], ['25-0'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1641\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['18-30'], ['11-15'], ['8-26'], ['19-15'], ['21-30'], ['6-30'], ['29-26'], ['22-22'], ['31-24'], ['26-28'], ['31-16'], ['28-14'], ['17-22'], ['7-4'], ['23-20'], ['25-0'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2579\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['18-30'], ['11-15'], ['19-15'], ['8-26'], ['29-26'], ['21-30'], ['6-30'], ['22-22'], ['31-24'], ['26-28'], ['31-16'], ['28-14'], ['17-22'], ['7-4'], ['23-20'], ['25-0'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['18-30'], ['19-15'], ['11-15'], ['8-26'], ['29-26'], ['21-30'], ['6-30'], ['22-22'], ['31-24'], ['26-28'], ['31-16'], ['17-22'], ['28-14'], ['7-4'], ['23-20'], ['12-26'], ['25-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['18-30'], ['11-15'], ['8-26'], ['19-15'], ['21-30'], ['29-26'], ['6-30'], ['22-22'], ['31-24'], ['17-22'], ['26-28'], ['31-16'], ['28-14'], ['7-4'], ['23-20'], ['25-0'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1176\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['18-30'], ['11-15'], ['8-26'], ['19-15'], ['21-30'], ['29-26'], ['6-30'], ['22-22'], ['17-22'], ['26-28'], ['31-24'], ['28-14'], ['31-16'], ['7-4'], ['23-20'], ['21-27'], ['25-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2296\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['18-30'], ['11-15'], ['8-26'], ['19-15'], ['21-30'], ['29-26'], ['6-30'], ['17-22'], ['22-22'], ['26-28'], ['31-24'], ['31-16'], ['28-14'], ['7-4'], ['23-20'], ['21-27'], ['25-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3561\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['18-30'], ['8-26'], ['11-15'], ['19-15'], ['21-30'], ['29-26'], ['6-30'], ['17-22'], ['22-22'], ['26-28'], ['31-24'], ['28-14'], ['31-16'], ['7-4'], ['23-20'], ['21-27'], ['25-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['24-29'], ['18-30'], ['8-26'], ['11-15'], ['19-15'], ['29-26'], ['21-30'], ['17-22'], ['6-30'], ['22-22'], ['26-28'], ['31-16'], ['31-24'], ['28-14'], ['7-4'], ['23-20'], ['21-27'], ['25-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_relevant_misleading/llama-2-7b-80k_id_435_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['7-4'], ['11-15'], ['18-30'], ['21-30'], ['24-29'], ['29-26'], ['31-24'], ['6-11'], ['8-26'], ['12-26'], ['19-15'], ['22-22'], ['26-28'], ['28-14'], ['29-19'], ['1-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['7-4'], ['11-15'], ['18-30'], ['21-30'], ['24-29'], ['29-26'], ['31-24'], ['6-11'], ['8-26'], ['12-26'], ['19-15'], ['22-22'], ['26-28'], ['28-14'], ['29-19'], ['1-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['7-4'], ['11-15'], ['18-30'], ['21-30'], ['24-29'], ['29-26'], ['31-24'], ['6-11'], ['8-26'], ['12-26'], ['19-15'], ['22-22'], ['26-28'], ['28-14'], ['29-19'], ['1-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['7-4'], ['11-15'], ['18-30'], ['21-30'], ['24-29'], ['29-26'], ['31-24'], ['6-11'], ['8-26'], ['12-26'], ['19-15'], ['22-22'], ['26-28'], ['28-14'], ['29-19'], ['1-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_0_depth_7500_results.json\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['7-4'], ['11-15'], ['18-30'], ['21-30'], ['24-29'], ['29-26'], ['31-24'], ['6-11'], ['8-26'], ['12-26'], ['19-15'], ['22-22'], ['26-28'], ['28-14'], ['29-19'], ['1-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['6-30'], ['31-16'], ['7-4'], ['21-30'], ['8-26'], ['18-30'], ['24-29'], ['11-2'], ['29-26'], ['31-24'], ['19-15'], ['7-12'], ['22-22'], ['26-28'], ['28-14'], ['29-19'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 245\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['6-30'], ['7-4'], ['31-16'], ['8-26'], ['21-30'], ['18-30'], ['24-29'], ['11-2'], ['29-26'], ['7-12'], ['19-15'], ['31-24'], ['22-22'], ['26-28'], ['28-14'], ['29-19'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 337\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['6-30'], ['8-26'], ['7-4'], ['18-30'], ['24-29'], ['21-30'], ['31-16'], ['7-12'], ['19-15'], ['11-2'], ['29-26'], ['22-22'], ['26-28'], ['28-14'], ['31-24'], ['12-26'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 337\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['6-30'], ['7-4'], ['18-30'], ['24-29'], ['21-30'], ['7-12'], ['31-16'], ['19-15'], ['11-2'], ['29-26'], ['22-22'], ['26-28'], ['28-14'], ['31-24'], ['17-22'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_1250_depth_7500_results.json\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['24-29'], ['6-30'], ['7-4'], ['18-30'], ['31-16'], ['21-30'], ['19-15'], ['7-12'], ['29-26'], ['28-14'], ['11-2'], ['17-22'], ['22-22'], ['26-28'], ['31-24'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['24-29'], ['6-30'], ['18-30'], ['21-30'], ['19-15'], ['31-16'], ['7-12'], ['17-22'], ['29-26'], ['28-14'], ['22-22'], ['26-28'], ['11-2'], ['31-24'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 337\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['24-29'], ['18-30'], ['19-15'], ['21-30'], ['6-30'], ['7-12'], ['31-16'], ['17-22'], ['29-26'], ['28-14'], ['22-22'], ['26-28'], ['11-2'], ['31-24'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 337\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['7-4'], ['24-29'], ['18-30'], ['7-12'], ['19-15'], ['21-30'], ['6-30'], ['17-22'], ['31-16'], ['29-26'], ['28-14'], ['22-22'], ['26-28'], ['11-2'], ['31-24'], ['20-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 337\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['7-4'], ['24-29'], ['18-30'], ['7-12'], ['19-15'], ['21-30'], ['17-22'], ['31-16'], ['6-30'], ['29-26'], ['28-14'], ['22-22'], ['26-28'], ['11-2'], ['31-24'], ['20-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_2500_depth_7500_results.json\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['8-26'], ['6-9'], ['11-15'], ['24-29'], ['7-4'], ['18-30'], ['19-15'], ['7-12'], ['17-22'], ['21-30'], ['31-16'], ['29-26'], ['6-30'], ['28-14'], ['22-22'], ['26-28'], ['31-24'], ['11-2'], ['20-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['8-26'], ['11-15'], ['24-29'], ['7-4'], ['18-30'], ['19-15'], ['7-12'], ['17-22'], ['21-30'], ['31-16'], ['29-26'], ['6-30'], ['28-14'], ['22-22'], ['26-28'], ['31-24'], ['11-2'], ['20-1']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 337\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['8-26'], ['6-9'], ['11-15'], ['24-29'], ['7-4'], ['7-12'], ['18-30'], ['19-15'], ['17-22'], ['21-30'], ['31-16'], ['29-26'], ['28-14'], ['6-30'], ['22-22'], ['26-28'], ['20-1'], ['31-24'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 337\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['8-26'], ['6-9'], ['11-15'], ['24-29'], ['7-4'], ['7-12'], ['18-30'], ['19-15'], ['17-22'], ['21-30'], ['29-26'], ['31-16'], ['28-14'], ['6-30'], ['22-22'], ['26-28'], ['20-1'], ['23-20'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 337\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['8-26'], ['6-9'], ['24-29'], ['11-15'], ['7-4'], ['7-12'], ['18-30'], ['19-15'], ['17-22'], ['21-30'], ['29-26'], ['31-16'], ['28-14'], ['22-22'], ['26-28'], ['6-30'], ['20-1'], ['23-20'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_3750_depth_7500_results.json\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['8-26'], ['6-9'], ['24-29'], ['11-15'], ['7-4'], ['18-30'], ['19-15'], ['7-12'], ['17-22'], ['21-30'], ['29-26'], ['31-16'], ['28-14'], ['22-22'], ['26-28'], ['6-30'], ['20-1'], ['23-20'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['8-26'], ['6-9'], ['24-29'], ['11-15'], ['7-4'], ['7-12'], ['17-22'], ['18-30'], ['19-15'], ['21-30'], ['29-26'], ['31-16'], ['28-14'], ['22-22'], ['26-28'], ['6-30'], ['20-1'], ['23-20'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 337\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['8-26'], ['6-9'], ['24-29'], ['11-15'], ['7-4'], ['7-12'], ['17-22'], ['18-30'], ['19-15'], ['21-30'], ['29-26'], ['31-16'], ['28-14'], ['22-22'], ['26-28'], ['6-30'], ['20-1'], ['23-20'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 337\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['8-26'], ['6-9'], ['24-29'], ['11-15'], ['7-12'], ['7-4'], ['17-22'], ['18-30'], ['19-15'], ['21-30'], ['29-26'], ['28-14'], ['31-16'], ['22-22'], ['26-28'], ['6-30'], ['20-1'], ['23-20'], ['11-2']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 337\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['8-26'], ['6-9'], ['24-29'], ['11-15'], ['7-12'], ['7-4'], ['17-22'], ['18-30'], ['19-15'], ['21-30'], ['29-26'], ['28-14'], ['31-16'], ['22-22'], ['26-28'], ['6-30'], ['20-1'], ['23-20'], ['25-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_5000_depth_7500_results.json\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['8-26'], ['6-9'], ['24-29'], ['11-15'], ['7-4'], ['7-12'], ['17-22'], ['18-30'], ['19-15'], ['21-30'], ['29-26'], ['28-14'], ['31-16'], ['22-22'], ['26-28'], ['6-30'], ['20-1'], ['23-20'], ['25-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant/llama-2-7b-80k_id_435_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/435.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['7-4'], ['11-15'], ['18-30'], ['21-30'], ['24-29'], ['29-26'], ['31-24'], ['6-11'], ['8-26'], ['12-26'], ['19-15'], ['22-22'], ['26-28'], ['28-14'], ['29-19'], ['1-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['7-4'], ['11-15'], ['18-30'], ['21-30'], ['24-29'], ['29-26'], ['31-24'], ['6-11'], ['8-26'], ['12-26'], ['19-15'], ['22-22'], ['26-28'], ['28-14'], ['29-19'], ['1-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['7-4'], ['11-15'], ['18-30'], ['21-30'], ['24-29'], ['29-26'], ['31-24'], ['6-11'], ['8-26'], ['12-26'], ['19-15'], ['22-22'], ['26-28'], ['28-14'], ['29-19'], ['1-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['7-4'], ['11-15'], ['18-30'], ['21-30'], ['24-29'], ['29-26'], ['31-24'], ['6-11'], ['8-26'], ['12-26'], ['19-15'], ['22-22'], ['26-28'], ['28-14'], ['29-19'], ['1-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['7-4'], ['11-15'], ['18-30'], ['21-30'], ['24-29'], ['29-26'], ['31-24'], ['6-11'], ['8-26'], ['12-26'], ['19-15'], ['22-22'], ['26-28'], ['28-14'], ['29-19'], ['1-9']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.4 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['24-29'], ['21-30'], ['11-15'], ['18-30'], ['29-26'], ['31-24'], ['7-4'], ['19-15'], ['8-26'], ['22-22'], ['26-28'], ['6-11'], ['12-26'], ['28-14'], ['29-19'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 217\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['31-16'], ['18-30'], ['24-29'], ['7-4'], ['21-30'], ['11-15'], ['29-26'], ['31-24'], ['8-26'], ['19-15'], ['22-22'], ['26-28'], ['6-11'], ['12-26'], ['28-14'], ['29-19'], ['17-22']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 472\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['6-30'], ['18-30'], ['7-4'], ['24-29'], ['31-16'], ['21-30'], ['11-15'], ['29-26'], ['31-24'], ['19-15'], ['8-26'], ['22-22'], ['26-28'], ['6-11'], ['12-26'], ['28-14'], ['29-19'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 472\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['18-30'], ['6-30'], ['7-4'], ['24-29'], ['21-30'], ['31-16'], ['11-15'], ['29-26'], ['19-15'], ['8-26'], ['31-24'], ['22-22'], ['26-28'], ['6-11'], ['12-26'], ['28-14'], ['29-19'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['18-30'], ['6-30'], ['7-4'], ['24-29'], ['31-16'], ['21-30'], ['11-15'], ['19-15'], ['29-26'], ['8-26'], ['31-24'], ['22-22'], ['12-26'], ['26-28'], ['28-14'], ['6-11'], ['29-19'], ['25-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['6-9'], ['18-30'], ['6-30'], ['24-29'], ['7-4'], ['31-16'], ['11-15'], ['21-30'], ['19-15'], ['29-26'], ['31-24'], ['8-26'], ['22-22'], ['26-28'], ['12-26'], ['28-14'], ['6-11'], ['17-22'], ['25-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 472\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['18-30'], ['6-9'], ['6-30'], ['7-4'], ['24-29'], ['31-16'], ['19-15'], ['11-15'], ['21-30'], ['29-26'], ['8-26'], ['31-24'], ['22-22'], ['26-28'], ['28-14'], ['12-26'], ['17-22'], ['6-11'], ['25-0']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 472\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['18-30'], ['6-9'], ['6-30'], ['7-4'], ['19-15'], ['31-16'], ['24-29'], ['11-15'], ['21-30'], ['29-26'], ['8-26'], ['31-24'], ['22-22'], ['26-28'], ['28-14'], ['12-26'], ['17-22'], ['29-21'], ['6-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 472\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['18-30'], ['6-9'], ['7-4'], ['6-30'], ['19-15'], ['31-16'], ['24-29'], ['29-26'], ['11-15'], ['21-30'], ['8-26'], ['31-24'], ['26-28'], ['28-14'], ['22-22'], ['17-22'], ['12-26'], ['29-21'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.9 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['18-30'], ['6-9'], ['6-30'], ['19-15'], ['7-4'], ['31-16'], ['24-29'], ['29-26'], ['11-15'], ['21-30'], ['8-26'], ['31-24'], ['28-14'], ['26-28'], ['17-22'], ['22-22'], ['12-26'], ['29-21'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['18-30'], ['6-9'], ['6-30'], ['19-15'], ['7-4'], ['31-16'], ['24-29'], ['21-30'], ['29-26'], ['11-15'], ['8-26'], ['31-24'], ['26-28'], ['28-14'], ['22-22'], ['17-22'], ['12-26'], ['25-0'], ['29-21']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 60.15828847885132\n",
      "Response: The Doors of Bright Saints\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 472\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['18-30'], ['6-9'], ['19-15'], ['6-30'], ['7-4'], ['31-16'], ['24-29'], ['11-15'], ['21-30'], ['29-26'], ['8-26'], ['31-24'], ['26-28'], ['22-22'], ['28-14'], ['17-22'], ['12-26'], ['29-21'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 472\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['18-30'], ['6-9'], ['19-15'], ['7-4'], ['6-30'], ['31-16'], ['24-29'], ['11-15'], ['21-30'], ['29-26'], ['8-26'], ['31-24'], ['26-28'], ['22-22'], ['28-14'], ['17-22'], ['12-26'], ['29-21'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 472\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['18-30'], ['6-9'], ['19-15'], ['7-4'], ['6-30'], ['31-16'], ['24-29'], ['11-15'], ['8-26'], ['21-30'], ['29-26'], ['26-28'], ['31-24'], ['22-22'], ['28-14'], ['17-22'], ['29-21'], ['13-23'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.2 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['18-30'], ['6-9'], ['19-15'], ['7-4'], ['6-30'], ['31-16'], ['24-29'], ['11-15'], ['8-26'], ['29-26'], ['21-30'], ['31-24'], ['26-28'], ['22-22'], ['28-14'], ['17-22'], ['29-21'], ['12-26'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['18-30'], ['6-9'], ['19-15'], ['7-4'], ['24-29'], ['6-30'], ['11-15'], ['21-30'], ['31-16'], ['8-26'], ['29-26'], ['31-24'], ['26-28'], ['22-22'], ['17-22'], ['28-14'], ['29-21'], ['12-26'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 97.37055897712708\n",
      "Response: The Saint of Bright Doors won the latest Nebula award for Best Novel.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 472\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['18-30'], ['6-9'], ['19-15'], ['7-4'], ['24-29'], ['6-30'], ['11-15'], ['21-30'], ['31-16'], ['8-26'], ['29-26'], ['26-28'], ['31-24'], ['17-22'], ['22-22'], ['28-14'], ['29-21'], ['12-26'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 472\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['18-30'], ['6-9'], ['19-15'], ['7-4'], ['6-30'], ['24-29'], ['11-15'], ['8-26'], ['21-30'], ['31-16'], ['29-26'], ['26-28'], ['17-22'], ['31-24'], ['22-22'], ['28-14'], ['29-21'], ['13-23'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 472\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['18-30'], ['6-9'], ['19-15'], ['7-4'], ['6-30'], ['24-29'], ['11-15'], ['8-26'], ['21-30'], ['31-16'], ['29-26'], ['26-28'], ['17-22'], ['31-24'], ['22-22'], ['28-14'], ['29-21'], ['13-23'], ['12-26']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 68.04105043411255\n",
      "Response: The Saint of Bright Doors\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The book that won the latest Nebula award for Best Novel is The Saint of Bright Doors.\n",
      "[['16-19'], ['18-30'], ['6-9'], ['19-15'], ['7-4'], ['24-29'], ['6-30'], ['8-26'], ['11-15'], ['31-16'], ['21-30'], ['29-26'], ['17-22'], ['26-28'], ['31-24'], ['22-22'], ['28-14'], ['29-21'], ['12-26'], ['13-23']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 67.11687445640564\n",
      "Response: The Saint of Bright Doors.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_435_irrelevant_misleading/llama-2-7b-80k_id_435_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['11-15'], ['16-19'], ['17-22'], ['6-9'], ['7-4'], ['8-26'], ['11-2'], ['19-15'], ['21-30'], ['12-26'], ['15-14'], ['29-19'], ['6-30'], ['12-2'], ['18-30'], ['21-4'], ['26-26'], ['14-18'], ['19-10'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['11-15'], ['16-19'], ['17-22'], ['6-9'], ['7-4'], ['8-26'], ['11-2'], ['19-15'], ['21-30'], ['12-26'], ['15-14'], ['29-19'], ['6-30'], ['12-2'], ['18-30'], ['21-4'], ['26-26'], ['14-18'], ['19-10'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['11-15'], ['16-19'], ['17-22'], ['6-9'], ['7-4'], ['8-26'], ['11-2'], ['19-15'], ['21-30'], ['12-26'], ['15-14'], ['29-19'], ['6-30'], ['12-2'], ['18-30'], ['21-4'], ['26-26'], ['14-18'], ['19-10'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['11-15'], ['16-19'], ['17-22'], ['6-9'], ['7-4'], ['8-26'], ['11-2'], ['19-15'], ['21-30'], ['12-26'], ['15-14'], ['29-19'], ['6-30'], ['12-2'], ['18-30'], ['21-4'], ['26-26'], ['14-18'], ['19-10'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_0_depth_7500_results.json\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['11-15'], ['16-19'], ['17-22'], ['6-9'], ['7-4'], ['8-26'], ['11-2'], ['19-15'], ['21-30'], ['12-26'], ['15-14'], ['29-19'], ['6-30'], ['12-2'], ['18-30'], ['21-4'], ['26-26'], ['14-18'], ['19-10'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 13.7040376663208\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_1250_depth_0_results.json\n",
      "insertion at 242\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 13.7040376663208\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 506\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['11-15'], ['16-19'], ['17-22'], ['6-9'], ['8-26'], ['21-30'], ['7-4'], ['19-15'], ['11-2'], ['12-26'], ['15-14'], ['29-19'], ['18-30'], ['21-4'], ['26-26'], ['12-2'], ['6-30'], ['19-10'], ['14-18'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 91.62554740905762\n",
      "Response: The game associated with Sky Team won the Spiel des Jahres award most recently. The criteria on which a game is evaluated are:\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 584\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['6-9'], ['8-26'], ['21-30'], ['19-15'], ['11-2'], ['7-4'], ['12-26'], ['15-14'], ['18-30'], ['29-19'], ['26-26'], ['21-4'], ['19-10'], ['12-2'], ['6-30'], ['14-18'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_1250_depth_7500_results.json\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['6-9'], ['8-26'], ['21-30'], ['19-15'], ['7-4'], ['11-2'], ['12-26'], ['15-14'], ['18-30'], ['29-19'], ['21-4'], ['26-26'], ['19-10'], ['12-2'], ['6-30'], ['19-12'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 13.7040376663208\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_2500_depth_0_results.json\n",
      "insertion at 506\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 13.7040376663208\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 584\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 13.7040376663208\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1627\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 13.7040376663208\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_2500_depth_7500_results.json\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['6-9'], ['8-26'], ['21-30'], ['19-15'], ['7-4'], ['11-2'], ['12-26'], ['18-30'], ['15-14'], ['29-19'], ['21-4'], ['26-26'], ['19-10'], ['6-30'], ['12-2'], ['19-12'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 13.7040376663208\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_3750_depth_0_results.json\n",
      "insertion at 584\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 13.7040376663208\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1734\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 13.7040376663208\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2629\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "-- Test Summary -- \n",
      "Duration: 0.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 13.7040376663208\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_3750_depth_7500_results.json\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['6-9'], ['21-30'], ['8-26'], ['19-15'], ['7-4'], ['11-2'], ['12-26'], ['18-30'], ['15-14'], ['29-19'], ['21-4'], ['26-26'], ['6-30'], ['19-10'], ['12-2'], ['19-12'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 13.7040376663208\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_5000_depth_0_results.json\n",
      "insertion at 584\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 13.7040376663208\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2306\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 13.7040376663208\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3411\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 13.7040376663208\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_5000_depth_7500_results.json\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['6-9'], ['21-30'], ['8-26'], ['19-15'], ['7-4'], ['11-2'], ['12-26'], ['18-30'], ['15-14'], ['29-19'], ['21-4'], ['26-26'], ['6-30'], ['12-2'], ['19-10'], ['14-18'], ['19-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant/llama-2-7b-80k_id_436_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/436.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['11-15'], ['16-19'], ['17-22'], ['6-9'], ['7-4'], ['8-26'], ['11-2'], ['19-15'], ['21-30'], ['12-26'], ['15-14'], ['29-19'], ['6-30'], ['12-2'], ['18-30'], ['21-4'], ['26-26'], ['14-18'], ['19-10'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 100.0\n",
      "Response: The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant_misleading/llama-2-7b-80k_id_436_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['11-15'], ['16-19'], ['17-22'], ['6-9'], ['7-4'], ['8-26'], ['11-2'], ['19-15'], ['21-30'], ['12-26'], ['15-14'], ['29-19'], ['6-30'], ['12-2'], ['18-30'], ['21-4'], ['26-26'], ['14-18'], ['19-10'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant_misleading/llama-2-7b-80k_id_436_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['11-15'], ['16-19'], ['17-22'], ['6-9'], ['7-4'], ['8-26'], ['11-2'], ['19-15'], ['21-30'], ['12-26'], ['15-14'], ['29-19'], ['6-30'], ['12-2'], ['18-30'], ['21-4'], ['26-26'], ['14-18'], ['19-10'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 100.0\n",
      "Response: The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant_misleading/llama-2-7b-80k_id_436_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['11-15'], ['16-19'], ['17-22'], ['6-9'], ['7-4'], ['8-26'], ['11-2'], ['19-15'], ['21-30'], ['12-26'], ['15-14'], ['29-19'], ['6-30'], ['12-2'], ['18-30'], ['21-4'], ['26-26'], ['14-18'], ['19-10'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant_misleading/llama-2-7b-80k_id_436_relevant_misleading_len_0_depth_7500_results.json\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['11-15'], ['16-19'], ['17-22'], ['6-9'], ['7-4'], ['8-26'], ['11-2'], ['19-15'], ['21-30'], ['12-26'], ['15-14'], ['29-19'], ['6-30'], ['12-2'], ['18-30'], ['21-4'], ['26-26'], ['14-18'], ['19-10'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant_misleading/llama-2-7b-80k_id_436_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 13.7040376663208\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant_misleading/llama-2-7b-80k_id_436_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 242\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 13.7040376663208\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant_misleading/llama-2-7b-80k_id_436_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 494\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 13.7040376663208\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant_misleading/llama-2-7b-80k_id_436_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 631\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "-- Test Summary -- \n",
      "Duration: 0.3 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 13.7040376663208\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant_misleading/llama-2-7b-80k_id_436_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['6-9'], ['8-26'], ['7-4'], ['19-15'], ['21-30'], ['11-2'], ['12-26'], ['29-19'], ['15-14'], ['18-30'], ['6-30'], ['12-2'], ['21-4'], ['26-26'], ['14-18'], ['30-14'], ['31-16']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant_misleading/llama-2-7b-80k_id_436_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 13.7040376663208\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant_misleading/llama-2-7b-80k_id_436_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 531\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['6-9'], ['8-26'], ['21-30'], ['19-15'], ['7-4'], ['11-2'], ['12-26'], ['29-19'], ['15-14'], ['18-30'], ['6-30'], ['12-2'], ['21-4'], ['26-26'], ['26-25'], ['14-18'], ['23-7']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 91.62554740905762\n",
      "Response: The game associated with Sky Team won the Spiel des Jahres award most recently. The criteria on which a game is evaluated are:\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant_misleading/llama-2-7b-80k_id_436_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 631\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 13.7040376663208\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant_misleading/llama-2-7b-80k_id_436_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1674\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "-- Test Summary -- \n",
      "Duration: 0.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 13.7040376663208\n",
      "Response: \n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant_misleading/llama-2-7b-80k_id_436_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['6-9'], ['8-26'], ['21-30'], ['19-15'], ['7-4'], ['11-2'], ['12-26'], ['29-19'], ['15-14'], ['18-30'], ['6-30'], ['12-2'], ['21-4'], ['26-26'], ['31-16'], ['14-18'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant_misleading/llama-2-7b-80k_id_436_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['6-9'], ['8-26'], ['21-30'], ['19-15'], ['7-4'], ['11-2'], ['12-26'], ['29-19'], ['15-14'], ['18-30'], ['12-2'], ['6-30'], ['21-4'], ['26-26'], ['14-18'], ['31-16'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 77.27886438369751\n",
      "Response: The most recent winner of the Spiel des Jahres award that is associated with the term 'Sky Team' is 'Caylus'.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant_misleading/llama-2-7b-80k_id_436_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 631\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['6-9'], ['8-26'], ['21-30'], ['19-15'], ['11-2'], ['7-4'], ['12-26'], ['29-19'], ['15-14'], ['18-30'], ['12-2'], ['21-4'], ['6-30'], ['26-26'], ['14-18'], ['23-7'], ['26-25']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.0\n",
      "Response: The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant_misleading/llama-2-7b-80k_id_436_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1674\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['6-9'], ['21-30'], ['8-26'], ['19-15'], ['11-2'], ['7-4'], ['12-26'], ['29-19'], ['15-14'], ['18-30'], ['21-4'], ['12-2'], ['6-30'], ['26-26'], ['14-18'], ['19-10'], ['23-7']]\n",
=======
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-30'], ['21-30'], ['15-14'], ['7-4'], ['13-11'], ['14-18'], ['17-22'], ['19-15'], ['29-26'], ['6-11'], ['13-23'], ['18-30'], ['24-29'], ['31-16'], ['31-24'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-30'], ['21-30'], ['15-14'], ['7-4'], ['13-11'], ['14-18'], ['17-22'], ['19-15'], ['29-26'], ['6-11'], ['13-23'], ['18-30'], ['24-29'], ['31-16'], ['31-24'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-30'], ['21-30'], ['15-14'], ['7-4'], ['13-11'], ['14-18'], ['17-22'], ['19-15'], ['29-26'], ['6-11'], ['13-23'], ['18-30'], ['24-29'], ['31-16'], ['31-24'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-30'], ['21-30'], ['15-14'], ['7-4'], ['13-11'], ['14-18'], ['17-22'], ['19-15'], ['29-26'], ['6-11'], ['13-23'], ['18-30'], ['24-29'], ['31-16'], ['31-24'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['6-30'], ['21-30'], ['15-14'], ['7-4'], ['13-11'], ['14-18'], ['17-22'], ['19-15'], ['29-26'], ['6-11'], ['13-23'], ['18-30'], ['24-29'], ['31-16'], ['31-24'], ['0-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "-- Test Summary -- \n",
      "Duration: 3.6 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 35.562849044799805\n",
      "Response: The acquisition of Twenty-First Century Fox, Inc. by The Walt Disney Company was announced on December 14, 2017, and was completed on March 20, 2019. Among other\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 223\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 35.562849044799805\n",
      "Response: The acquisition of Twenty-First Century Fox, Inc. by The Walt Disney Company was announced on December 14, 2017, and was completed on March 20, 2019. Among other\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 494\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['6-30'], ['7-4'], ['15-14'], ['17-22'], ['19-15'], ['14-18'], ['13-11'], ['18-30'], ['11-2'], ['29-26'], ['31-16'], ['24-29'], ['6-11'], ['13-23'], ['31-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 727\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['6-30'], ['7-4'], ['17-22'], ['19-15'], ['15-14'], ['11-2'], ['14-18'], ['13-11'], ['18-30'], ['29-26'], ['31-16'], ['24-29'], ['6-11'], ['13-23'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 94.38681602478027\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion. It was less interested in 21st Century Fox's production capacities and more keen to\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['7-4'], ['6-30'], ['19-15'], ['17-22'], ['15-14'], ['11-2'], ['18-30'], ['14-18'], ['13-11'], ['24-29'], ['31-16'], ['29-26'], ['6-11'], ['13-23'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 35.562849044799805\n",
      "Response: The acquisition of Twenty-First Century Fox, Inc. by The Walt Disney Company was announced on December 14, 2017, and was completed on March 20, 2019. Among other\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 494\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['7-4'], ['17-22'], ['6-30'], ['19-15'], ['11-2'], ['15-14'], ['18-30'], ['14-18'], ['13-11'], ['24-29'], ['31-16'], ['29-26'], ['6-16'], ['14-15'], ['7-12']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1100\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['19-15'], ['6-30'], ['11-2'], ['15-14'], ['18-30'], ['14-18'], ['13-11'], ['24-29'], ['7-12'], ['31-16'], ['6-16'], ['29-26'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1693\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['19-15'], ['6-30'], ['11-2'], ['15-14'], ['18-30'], ['14-18'], ['13-11'], ['7-12'], ['24-29'], ['31-16'], ['6-16'], ['29-26'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 82.47065544128418\n",
      "Response: Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['19-15'], ['11-2'], ['6-30'], ['15-14'], ['18-30'], ['14-18'], ['13-11'], ['24-29'], ['31-16'], ['7-12'], ['6-16'], ['29-26'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "-- Test Summary -- \n",
      "Duration: 4.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 35.562849044799805\n",
      "Response: The acquisition of Twenty-First Century Fox, Inc. by The Walt Disney Company was announced on December 14, 2017, and was completed on March 20, 2019. Among other\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 772\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['17-22'], ['7-4'], ['11-2'], ['19-15'], ['6-30'], ['15-14'], ['18-30'], ['14-18'], ['7-12'], ['13-11'], ['24-29'], ['6-16'], ['31-16'], ['29-26'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1733\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['6-30'], ['15-14'], ['18-30'], ['7-12'], ['14-18'], ['6-16'], ['13-11'], ['24-29'], ['31-16'], ['29-26'], ['14-15']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
<<<<<<< Updated upstream
      "Score: 89.08270597457886\n",
      "Response: The most recent winner of the Spiel des Jahres award that is associated with the term 'Sky Team' is the game 'Sky Team'.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant_misleading/llama-2-7b-80k_id_436_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2650\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['21-30'], ['6-9'], ['8-26'], ['19-15'], ['11-2'], ['7-4'], ['12-26'], ['18-30'], ['15-14'], ['29-19'], ['21-4'], ['12-2'], ['26-26'], ['6-30'], ['19-12'], ['26-25'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.0\n",
      "Response: The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant_misleading/llama-2-7b-80k_id_436_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['21-30'], ['6-9'], ['19-15'], ['8-26'], ['11-2'], ['7-4'], ['12-26'], ['18-30'], ['15-14'], ['29-19'], ['21-4'], ['12-2'], ['6-30'], ['26-26'], ['19-12'], ['26-25'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.0\n",
      "Response: The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant_misleading/llama-2-7b-80k_id_436_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['21-30'], ['6-9'], ['8-26'], ['19-15'], ['11-2'], ['7-4'], ['12-26'], ['18-30'], ['15-14'], ['29-19'], ['21-4'], ['12-2'], ['6-30'], ['26-26'], ['19-12'], ['26-25'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 88.41190338134766\n",
      "Response: The game associated with Sky Team won an award, but it was not the Spiel des Jahres, and not the most recent year it was given. (Whoowasit? ),Reiner Knizia,Ravensburger,Won\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_436_relevant_misleading/llama-2-7b-80k_id_436_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 631\n",
      "The game associated with Sky Team won the Spiel des Jahres award most recently.\n",
      "[['16-19'], ['11-15'], ['17-22'], ['21-30'], ['8-26'], ['6-9'], ['19-15'], ['11-2'], ['7-4'], ['12-26'], ['18-30'], ['15-14'], ['29-19'], ['21-4'], ['12-2'], ['6-30'], ['19-12'], ['26-25'], ['14-18'], ['26-26']]\n",
=======
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['24-29'], ['1-26'], ['7-4'], ['17-22'], ['21-30'], ['0-14'], ['13-11'], ['16-19'], ['0-8'], ['0-11'], ['6-9'], ['7-31'], ['8-26'], ['11-17'], ['12-4'], ['15-12'], ['16-24'], ['17-13'], ['17-18']]\n",
>>>>>>> Stashed changes
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 51.051437854766846\n",
      "Response: The ninth ballot was held on January 4, 2023, and it was the final ballot in the Speaker of the House election. The ninth ballot was a runoff between Kevin McCarthy and H\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_0_depth_7500_results.json\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['24-29'], ['1-26'], ['7-4'], ['17-22'], ['21-30'], ['0-14'], ['13-11'], ['16-19'], ['0-8'], ['0-11'], ['6-9'], ['7-31'], ['8-26'], ['11-17'], ['12-4'], ['15-12'], ['16-24'], ['17-13'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 51.051437854766846\n",
      "Response: The ninth ballot was held on January 4, 2023, and it was the final ballot in the Speaker of the House election. The ninth ballot was a runoff between Kevin McCarthy and H\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 34.123677015304565\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, Kevin McCarthy received 200 votes, Hakeem Jeffries received 212 votes, and Andy Biggs received\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 255\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 34.123677015304565\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, Kevin McCarthy received 200 votes, Hakeem Jeffries received 212 votes, and Andy Biggs received\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 508\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 34.123677015304565\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, Kevin McCarthy received 200 votes, Hakeem Jeffries received 212 votes, and Andy Biggs received\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 738\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 34.123677015304565\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, Kevin McCarthy received 200 votes, Hakeem Jeffries received 212 votes, and Andy Biggs received\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_1250_depth_7500_results.json\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 27.163445949554443\n",
      "Response: On the ninth ballot, the House of Representatives voted 200 to 212 to elect Kevin McCarthy as Speaker of the House.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 3.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 27.997508645057678\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, Kevin McCarthy was elected speaker of the House with 216 votes, after a majority of the votes cast were for him.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 554\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 28.4518301486969\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, Kevin McCarthy was elected speaker of the House with 216 votes, after a number of Republicans who had previously opposed him switched\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1126\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 29.662373661994934\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, Kevin McCarthy was elected speaker of the House with 216 votes, after a majority of the votes cast were for him. This\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1697\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 45.59227526187897\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, no candidate received a majority of the votes cast. The election was held to determine who would be the next Speaker of the House of Representatives,\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_2500_depth_7500_results.json\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 26.754438877105713\n",
      "Response: On the ninth ballot, the House of Representatives voted 203 to 212 to elect Kevin McCarthy as Speaker of the House.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 4.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 23.084528744220734\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, Kevin McCarthy of California was elected speaker of the House of Representatives. The election began on January 3, 2023,\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 863\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 23.084528744220734\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, Kevin McCarthy of California was elected speaker of the House of Representatives. The election began on January 3, 2023,\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1697\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 30.183884501457214\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, Kevin McCarthy was elected speaker of the House with 216 votes. This was the first time in over 100 years\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2438\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 32.98633396625519\n",
      "Response: On the ninth ballot, the House of Representatives elected Kevin McCarthy as Speaker of the House.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_3750_depth_7500_results.json\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 41.936007142066956\n",
      "Response: On the ninth ballot, 20 Republicans voted for someone other than Kevin McCarthy.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 4.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 27.561962604522705\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, Kevin McCarthy of California was elected speaker of the House with 216 votes, after making concessions to the Republican hardlin\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1185\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 27.04681158065796\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, Kevin McCarthy was elected as Speaker of the House with 216 votes, after making concessions to the holdouts who\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2351\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 27.95119881629944\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, Kevin McCarthy was elected as Speaker of the House with 216 votes, after a long and contentious process that saw several\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3574\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 27.95119881629944\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, Kevin McCarthy was elected as Speaker of the House with 216 votes, after a long and contentious process that saw several\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_5000_depth_7500_results.json\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 35.0730299949646\n",
      "Response: On the ninth ballot, 20 Republicans voted for Jim Jordan, 19 for Kevin McCarthy, 10 for Byron Donalds, 9 for Andy Biggs, 8 for Chip Roy,\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_relevant_misleading/llama-2-7b-80k_id_95_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: No one received a majority of the votes on the ninth ballot.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['24-29'], ['1-26'], ['7-4'], ['17-22'], ['21-30'], ['0-14'], ['13-11'], ['16-19'], ['0-8'], ['0-11'], ['6-9'], ['7-31'], ['8-26'], ['11-17'], ['12-4'], ['15-12'], ['16-24'], ['17-13'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 51.051437854766846\n",
      "Response: The ninth ballot was held on January 4, 2023, and it was the final ballot in the Speaker of the House election. The ninth ballot was a runoff between Kevin McCarthy and H\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['24-29'], ['1-26'], ['7-4'], ['17-22'], ['21-30'], ['0-14'], ['13-11'], ['16-19'], ['0-8'], ['0-11'], ['6-9'], ['7-31'], ['8-26'], ['11-17'], ['12-4'], ['15-12'], ['16-24'], ['17-13'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 51.051437854766846\n",
      "Response: The ninth ballot was held on January 4, 2023, and it was the final ballot in the Speaker of the House election. The ninth ballot was a runoff between Kevin McCarthy and H\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['24-29'], ['1-26'], ['7-4'], ['17-22'], ['21-30'], ['0-14'], ['13-11'], ['16-19'], ['0-8'], ['0-11'], ['6-9'], ['7-31'], ['8-26'], ['11-17'], ['12-4'], ['15-12'], ['16-24'], ['17-13'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 51.051437854766846\n",
      "Response: The ninth ballot was held on January 4, 2023, and it was the final ballot in the Speaker of the House election. The ninth ballot was a runoff between Kevin McCarthy and H\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['24-29'], ['1-26'], ['7-4'], ['17-22'], ['21-30'], ['0-14'], ['13-11'], ['16-19'], ['0-8'], ['0-11'], ['6-9'], ['7-31'], ['8-26'], ['11-17'], ['12-4'], ['15-12'], ['16-24'], ['17-13'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 51.051437854766846\n",
      "Response: The ninth ballot was held on January 4, 2023, and it was the final ballot in the Speaker of the House election. The ninth ballot was a runoff between Kevin McCarthy and H\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_0_depth_7500_results.json\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['24-29'], ['1-26'], ['7-4'], ['17-22'], ['21-30'], ['0-14'], ['13-11'], ['16-19'], ['0-8'], ['0-11'], ['6-9'], ['7-31'], ['8-26'], ['11-17'], ['12-4'], ['15-12'], ['16-24'], ['17-13'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 51.051437854766846\n",
      "Response: The ninth ballot was held on January 4, 2023, and it was the final ballot in the Speaker of the House election. The ninth ballot was a runoff between Kevin McCarthy and H\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 36.628657579422\n",
      "Response: On the ninth ballot, the House of Representatives voted to elect Representative Kevin McCarthy of California as Speaker of the House. This was the first time in history that a Speaker of the House had been elected on the ninth\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 36.628657579422\n",
      "Response: On the ninth ballot, the House of Representatives voted to elect Representative Kevin McCarthy of California as Speaker of the House. This was the first time in history that a Speaker of the House had been elected on the ninth\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 483\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 38.091593980789185\n",
      "Response: On the ninth ballot, the House of Representatives voted to elect Republican Representative Kevin McCarthy of California as Speaker of the House. The vote was 216-210, with eight Republicans voting against McCar\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 675\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 33.55022370815277\n",
      "Response: On the ninth ballot, the House of Representatives voted to elect Republican Representative Kevin McCarthy of California as Speaker of the House. This was the first time in history that a Speaker of the House had been elected on the nin\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_1250_depth_7500_results.json\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 27.50851809978485\n",
      "Response: On the ninth ballot, the House of Representatives voted 203–212 to elect Republican Kevin McCarthy as speaker of the House.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 31.858518719673157\n",
      "Response: On the ninth ballot, the House of Representatives voted to elect Representative Kevin McCarthy as Speaker of the House.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 483\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 24.842622876167297\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, the House of Representatives voted to elect Representative Kevin McCarthy of California as Speaker of the House. McCarthy won the election with\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1135\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 28.50911319255829\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, the House of Representatives voted to elect Representative Kevin McCarthy as Speaker of the House. This was the final ballot of the election\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1688\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 34.0255469083786\n",
      "Response: The ninth ballot in the January 2023 Speaker of the House election was a vote to elect a new speaker of the House of Representatives. The election was held on January 3, 2023, and the\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_2500_depth_7500_results.json\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 33.33007097244263\n",
      "Response: On the ninth ballot, the House of Representatives voted 203 to 212 to elect Hakeem Jeffries of New York as Speaker of the House.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 31.592705845832825\n",
      "Response: On the ninth ballot, the House of Representatives voted to elect Republican Representative Kevin McCarthy of California as Speaker of the House.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 860\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 31.858518719673157\n",
      "Response: On the ninth ballot, the House of Representatives voted to elect Representative Kevin McCarthy as Speaker of the House.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1763\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 39.07372057437897\n",
      "Response: The ninth ballot in the January 2023 Speaker of the House election was a tie between Kevin McCarthy and Hakeem Jeffries. The House was unable to break the tie, and the election was postponed\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2611\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 31.858518719673157\n",
      "Response: On the ninth ballot, the House of Representatives voted to elect Representative Kevin McCarthy as Speaker of the House.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_3750_depth_7500_results.json\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 3.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 33.99198651313782\n",
      "Response: On the ninth ballot, the House of Representatives voted 200 to 212 to elect Hakeem Jeffries of New York as Speaker of the House.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 3.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 31.70560598373413\n",
      "Response: On the ninth ballot, the House of Representatives voted to elect Republican Kevin McCarthy as Speaker of the House.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1185\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 37.952059507369995\n",
      "Response: On the ninth ballot, the House of Representatives elected Mike Johnson as Speaker of the House.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2326\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 3.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 32.60098695755005\n",
      "Response: The ninth ballot in the January 2023 Speaker of the House election was a tie between Kevin McCarthy and Hakeem Jeffries.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3581\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 4.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 33.99847149848938\n",
      "Response: On the ninth ballot, the House of Representatives voted to elect Representative Kevin McCarthy as Speaker of the House. This was the first time in history that a Speaker had been elected on the ninth ballot.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_5000_depth_7500_results.json\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 3.7 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 33.99198651313782\n",
      "Response: On the ninth ballot, the House of Representatives voted 200 to 212 to elect Hakeem Jeffries of New York as Speaker of the House.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant/llama-2-7b-80k_id_95_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/95.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: No one received a majority of the votes on the ninth ballot.\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['24-29'], ['1-26'], ['7-4'], ['17-22'], ['21-30'], ['0-14'], ['13-11'], ['16-19'], ['0-8'], ['0-11'], ['6-9'], ['7-31'], ['8-26'], ['11-17'], ['12-4'], ['15-12'], ['16-24'], ['17-13'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 51.051437854766846\n",
      "Response: The ninth ballot was held on January 4, 2023, and it was the final ballot in the Speaker of the House election. The ninth ballot was a runoff between Kevin McCarthy and H\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['24-29'], ['1-26'], ['7-4'], ['17-22'], ['21-30'], ['0-14'], ['13-11'], ['16-19'], ['0-8'], ['0-11'], ['6-9'], ['7-31'], ['8-26'], ['11-17'], ['12-4'], ['15-12'], ['16-24'], ['17-13'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 51.051437854766846\n",
      "Response: The ninth ballot was held on January 4, 2023, and it was the final ballot in the Speaker of the House election. The ninth ballot was a runoff between Kevin McCarthy and H\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['24-29'], ['1-26'], ['7-4'], ['17-22'], ['21-30'], ['0-14'], ['13-11'], ['16-19'], ['0-8'], ['0-11'], ['6-9'], ['7-31'], ['8-26'], ['11-17'], ['12-4'], ['15-12'], ['16-24'], ['17-13'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 51.051437854766846\n",
      "Response: The ninth ballot was held on January 4, 2023, and it was the final ballot in the Speaker of the House election. The ninth ballot was a runoff between Kevin McCarthy and H\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['24-29'], ['1-26'], ['7-4'], ['17-22'], ['21-30'], ['0-14'], ['13-11'], ['16-19'], ['0-8'], ['0-11'], ['6-9'], ['7-31'], ['8-26'], ['11-17'], ['12-4'], ['15-12'], ['16-24'], ['17-13'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 51.051437854766846\n",
      "Response: The ninth ballot was held on January 4, 2023, and it was the final ballot in the Speaker of the House election. The ninth ballot was a runoff between Kevin McCarthy and H\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['24-29'], ['1-26'], ['7-4'], ['17-22'], ['21-30'], ['0-14'], ['13-11'], ['16-19'], ['0-8'], ['0-11'], ['6-9'], ['7-31'], ['8-26'], ['11-17'], ['12-4'], ['15-12'], ['16-24'], ['17-13'], ['17-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 51.051437854766846\n",
      "Response: The ninth ballot was held on January 4, 2023, and it was the final ballot in the Speaker of the House election. The ninth ballot was a runoff between Kevin McCarthy and H\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 36.628657579422\n",
      "Response: On the ninth ballot, the House of Representatives voted to elect Representative Kevin McCarthy of California as Speaker of the House. This was the first time in history that a Speaker of the House had been elected on the ninth\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 36.628657579422\n",
      "Response: On the ninth ballot, the House of Representatives voted to elect Representative Kevin McCarthy of California as Speaker of the House. This was the first time in history that a Speaker of the House had been elected on the ninth\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 483\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 38.091593980789185\n",
      "Response: On the ninth ballot, the House of Representatives voted to elect Republican Representative Kevin McCarthy of California as Speaker of the House. The vote was 216-210, with eight Republicans voting against McCar\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 675\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 33.55022370815277\n",
      "Response: On the ninth ballot, the House of Representatives voted to elect Republican Representative Kevin McCarthy of California as Speaker of the House. This was the first time in history that a Speaker of the House had been elected on the nin\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 27.50851809978485\n",
      "Response: On the ninth ballot, the House of Representatives voted 203–212 to elect Republican Kevin McCarthy as speaker of the House.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 3.6 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 38.10434341430664\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, Kevin McCarthy received 216 votes, while Hakeem Jeffries received 212 votes. This was the first time\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 483\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['24-29'], ['16-19'], ['17-22'], ['1-26'], ['7-4'], ['21-30'], ['0-14'], ['13-11'], ['8-26'], ['6-9'], ['19-15'], ['7-12'], ['0-8'], ['0-11'], ['7-31'], ['11-17'], ['12-4'], ['15-12'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 75.1909852027893\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, no candidate received a majority of the votes cast.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1109\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 33.29232335090637\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, Kevin McCarthy was elected with 216 votes, less than 218 due to \"present\" votes, which indicate ab\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1685\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 33.29232335090637\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, Kevin McCarthy was elected with 216 votes, less than 218 due to \"present\" votes, which indicate ab\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 40.40408432483673\n",
      "Response: On the ninth ballot, 201 members voted for Kevin McCarthy, 216 voted against him, and 10 members voted \"present.\"\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 4.1 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 29.412153363227844\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, Kevin McCarthy was elected speaker of the House with 216 votes, less than 218 due to \"present\" votes\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 860\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['16-19'], ['24-29'], ['17-22'], ['1-26'], ['7-4'], ['21-30'], ['7-12'], ['8-26'], ['6-9'], ['19-15'], ['0-14'], ['13-11'], ['6-16'], ['17-18'], ['11-2'], ['12-4'], ['29-19'], ['15-14'], ['0-8']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 60.67882776260376\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, no one received a majority of the votes cast. The vote was held on October 20, 2023, and the final\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1764\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 29.412153363227844\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, Kevin McCarthy was elected speaker of the House with 216 votes, less than 218 due to \"present\" votes\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2636\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 48.806726932525635\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, no one received a majority of the votes. On the evening of October 5, 2023, Donald Trump announced in a post\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 3.3 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 35.12261509895325\n",
      "Response: On the ninth ballot, 212 Republicans voted for Kevin McCarthy, 203 voted for Jim Jordan, and 19 voted for someone else.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 4.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 27.40989923477173\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, the Republican Party nominated Jim Jordan for speaker. Jordan received 200 votes, while the Democratic Party nominated Hakeem Jeffries for speaker\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1188\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['16-19'], ['24-29'], ['17-22'], ['7-12'], ['1-26'], ['7-4'], ['8-26'], ['21-30'], ['19-15'], ['6-9'], ['6-16'], ['0-14'], ['13-11'], ['11-2'], ['15-14'], ['17-18'], ['12-4'], ['23-7'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 60.298824310302734\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, no candidate received a majority of the votes cast. The vote was held on January 6, 2023, and the final result\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2384\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "[['11-15'], ['16-19'], ['24-29'], ['17-22'], ['7-12'], ['1-26'], ['7-4'], ['8-26'], ['21-30'], ['19-15'], ['6-9'], ['6-16'], ['0-14'], ['13-11'], ['11-2'], ['15-14'], ['17-18'], ['12-4'], ['23-7'], ['29-19']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 53.29282283782959\n",
      "Response: The ninth ballot in the January 2023 Speaker of the House election resulted in a candidate receiving nearly half of the total votes, but still fell short of a majority.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3588\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 4.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 25.854843854904175\n",
      "Response: On the ninth ballot in the January 2023 Speaker of the House election, the House of Representatives voted to elect Jim Jordan as Speaker of the House. Jordan received 200 votes, while Kevin McCarthy\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "No one received a majority of the votes on the ninth ballot.\n",
      "-- Test Summary -- \n",
      "Duration: 3.5 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 26.76449418067932\n",
      "Response: On the ninth ballot, the House of Representatives voted 200 to 212 to elect Republican Kevin McCarthy as Speaker of the House.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_95_irrelevant_misleading/llama-2-7b-80k_id_95_irrelevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The reported death toll decreased to 1,392\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['6-30'], ['18-30'], ['19-15'], ['21-30'], ['6-11'], ['7-13'], ['11-2'], ['14-15'], ['17-22'], ['0-11'], ['14-18'], ['15-14'], ['16-24'], ['16-30'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['6-30'], ['18-30'], ['19-15'], ['21-30'], ['6-11'], ['7-13'], ['11-2'], ['14-15'], ['17-22'], ['0-11'], ['14-18'], ['15-14'], ['16-24'], ['16-30'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['6-30'], ['18-30'], ['19-15'], ['21-30'], ['6-11'], ['7-13'], ['11-2'], ['14-15'], ['17-22'], ['0-11'], ['14-18'], ['15-14'], ['16-24'], ['16-30'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['6-30'], ['18-30'], ['19-15'], ['21-30'], ['6-11'], ['7-13'], ['11-2'], ['14-15'], ['17-22'], ['0-11'], ['14-18'], ['15-14'], ['16-24'], ['16-30'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_0_depth_7500_results.json\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['6-30'], ['18-30'], ['19-15'], ['21-30'], ['6-11'], ['7-13'], ['11-2'], ['14-15'], ['17-22'], ['0-11'], ['14-18'], ['15-14'], ['16-24'], ['16-30'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['6-30'], ['19-15'], ['21-30'], ['18-30'], ['17-22'], ['11-2'], ['6-11'], ['14-15'], ['7-13'], ['24-29'], ['20-30'], ['16-24'], ['17-31'], ['14-18'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_1250_depth_0_results.json\n",
      "insertion at 254\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['21-30'], ['6-30'], ['18-30'], ['17-22'], ['11-2'], ['24-29'], ['7-12'], ['14-15'], ['6-11'], ['7-13'], ['20-30'], ['16-24'], ['15-14'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 63.004595041275024\n",
      "Response: The reported death toll decreased to 1,392 In April 2007, the American Society of Civil Engineers termed the flooding of New Orleans as \"the worst engineering catastrophe in US History.\"\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_1250_depth_2500_results.json\n",
      "insertion at 448\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['21-30'], ['6-30'], ['18-30'], ['24-29'], ['11-2'], ['17-22'], ['7-12'], ['14-15'], ['20-30'], ['15-14'], ['6-11'], ['16-24'], ['7-13'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_1250_depth_5000_results.json\n",
      "insertion at 768\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['21-30'], ['24-29'], ['6-30'], ['18-30'], ['17-22'], ['11-2'], ['7-12'], ['14-15'], ['20-30'], ['15-14'], ['16-24'], ['17-31'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_1250_depth_7500_results.json\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['21-30'], ['18-30'], ['24-29'], ['6-30'], ['17-22'], ['11-2'], ['7-12'], ['14-15'], ['20-30'], ['15-14'], ['6-11'], ['14-18'], ['16-24'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 45.7680344581604\n",
      "Response: The NHC revised the fatality data of Hurricane Katrina, reducing the number by about one quarter from an estimated 1,833 to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_2500_depth_0_results.json\n",
      "insertion at 533\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['19-15'], ['21-30'], ['24-29'], ['7-12'], ['18-30'], ['6-30'], ['17-22'], ['11-2'], ['14-15'], ['20-30'], ['15-14'], ['6-11'], ['14-18'], ['17-31'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_2500_depth_2500_results.json\n",
      "insertion at 1129\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 3.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 45.7680344581604\n",
      "Response: The NHC revised the fatality data of Hurricane Katrina, reducing the number by about one quarter from an estimated 1,833 to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_2500_depth_5000_results.json\n",
      "insertion at 1686\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 3.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 45.7680344581604\n",
      "Response: The NHC revised the fatality data of Hurricane Katrina, reducing the number by about one quarter from an estimated 1,833 to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_2500_depth_7500_results.json\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['19-15'], ['21-30'], ['18-30'], ['24-29'], ['6-30'], ['17-22'], ['7-12'], ['11-2'], ['14-15'], ['20-30'], ['15-14'], ['6-11'], ['14-18'], ['17-31'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['19-15'], ['21-30'], ['7-12'], ['24-29'], ['17-22'], ['18-30'], ['6-30'], ['11-2'], ['14-15'], ['20-30'], ['15-14'], ['17-31'], ['6-11'], ['14-18'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_3750_depth_0_results.json\n",
      "insertion at 883\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['19-15'], ['7-12'], ['21-30'], ['24-29'], ['17-22'], ['18-30'], ['11-2'], ['6-30'], ['20-30'], ['14-15'], ['15-14'], ['17-31'], ['14-18'], ['6-11'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_3750_depth_2500_results.json\n",
      "insertion at 1751\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['19-15'], ['21-30'], ['24-29'], ['17-22'], ['18-30'], ['11-2'], ['6-30'], ['20-30'], ['14-15'], ['17-31'], ['15-14'], ['6-11'], ['14-18'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 59.275561571121216\n",
      "Response: The reported death toll decreased to 1,392m., on the western edge of the city, several monoliths failed on the 17th Street Canal. A torrent of water blasted into Lakeview,\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_3750_depth_5000_results.json\n",
      "insertion at 2614\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['19-15'], ['21-30'], ['24-29'], ['18-30'], ['17-22'], ['11-2'], ['6-30'], ['20-30'], ['14-15'], ['17-31'], ['15-14'], ['14-18'], ['16-24'], ['6-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 66.21139645576477\n",
      "Response: The reported death toll decreased to 1,392e., erring toward unsafe) interpretation of the data: the soil below the levee was actually weaker than that used in the I-wall design\" (ASCE:\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_3750_depth_7500_results.json\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['19-15'], ['21-30'], ['24-29'], ['18-30'], ['17-22'], ['11-2'], ['6-30'], ['20-30'], ['14-15'], ['15-14'], ['17-31'], ['14-18'], ['6-11'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['19-15'], ['21-30'], ['24-29'], ['18-30'], ['17-22'], ['11-2'], ['6-30'], ['20-30'], ['17-31'], ['14-15'], ['15-14'], ['14-18'], ['16-24'], ['6-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_5000_depth_0_results.json\n",
      "insertion at 1162\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['7-12'], ['19-15'], ['21-30'], ['24-29'], ['18-30'], ['17-22'], ['11-2'], ['6-30'], ['20-30'], ['14-15'], ['15-14'], ['17-31'], ['14-18'], ['16-24'], ['6-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_5000_depth_2500_results.json\n",
      "insertion at 2362\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['7-12'], ['19-15'], ['21-30'], ['24-29'], ['18-30'], ['11-2'], ['17-22'], ['20-30'], ['6-30'], ['17-31'], ['15-14'], ['14-15'], ['14-18'], ['16-24'], ['6-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_5000_depth_5000_results.json\n",
      "insertion at 3551\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['7-12'], ['19-15'], ['21-30'], ['24-29'], ['18-30'], ['11-2'], ['17-22'], ['20-30'], ['6-30'], ['17-31'], ['15-14'], ['14-15'], ['14-18'], ['16-24'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_5000_depth_7500_results.json\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['7-4'], ['7-12'], ['19-15'], ['21-30'], ['24-29'], ['18-30'], ['11-2'], ['17-22'], ['20-30'], ['6-30'], ['17-31'], ['15-14'], ['14-15'], ['14-18'], ['16-24'], ['6-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
<<<<<<< Updated upstream
      "Writing at results/graph/llama-2-7b-80k_id_436_irrelevant_misleading/llama-2-7b-80k_id_436_irrelevant_misleading_len_5000_depth_10000_results.json\n"
=======
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2636\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['21-30'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['6-30'], ['7-12'], ['18-30'], ['15-14'], ['14-18'], ['6-16'], ['13-11'], ['24-29'], ['31-16'], ['29-26'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['6-30'], ['18-30'], ['15-14'], ['7-12'], ['6-16'], ['14-18'], ['13-11'], ['24-29'], ['31-16'], ['29-26'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "-- Test Summary -- \n",
      "Duration: 5.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 35.562849044799805\n",
      "Response: The acquisition of Twenty-First Century Fox, Inc. by The Walt Disney Company was announced on December 14, 2017, and was completed on March 20, 2019. Among other\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1173\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['21-30'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['6-30'], ['7-12'], ['18-30'], ['15-14'], ['6-16'], ['14-18'], ['24-29'], ['13-11'], ['31-16'], ['29-26'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2373\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['21-30'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['7-12'], ['6-30'], ['18-30'], ['15-14'], ['6-16'], ['14-18'], ['24-29'], ['13-11'], ['31-16'], ['29-26'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3551\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['8-26'], ['6-9'], ['21-30'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['7-12'], ['6-30'], ['6-16'], ['18-30'], ['15-14'], ['14-18'], ['24-29'], ['13-11'], ['31-16'], ['29-26'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 4.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 92.66371130943298\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion. On September 17, the European Commission (EC) scheduled a merger review for October\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['21-30'], ['17-22'], ['11-2'], ['7-4'], ['19-15'], ['7-12'], ['6-30'], ['18-30'], ['6-16'], ['15-14'], ['14-18'], ['24-29'], ['13-11'], ['31-16'], ['29-26'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The largest acquisition deal of a tech company in history was Microsoft purchasing Activision Blizzard for US$68.7 billion.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_539_irrelevant_misleading/llama-2-7b-80k_id_539_irrelevant_misleading_len_5000_depth_10000_results.json\n"
>>>>>>> Stashed changes
=======
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant/llama-2-7b-80k_id_96_relevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_relevant/96.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The reported death toll decreased to 1,392\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['6-30'], ['18-30'], ['19-15'], ['21-30'], ['6-11'], ['7-13'], ['11-2'], ['14-15'], ['17-22'], ['0-11'], ['14-18'], ['15-14'], ['16-24'], ['16-30'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['6-30'], ['18-30'], ['19-15'], ['21-30'], ['6-11'], ['7-13'], ['11-2'], ['14-15'], ['17-22'], ['0-11'], ['14-18'], ['15-14'], ['16-24'], ['16-30'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['6-30'], ['18-30'], ['19-15'], ['21-30'], ['6-11'], ['7-13'], ['11-2'], ['14-15'], ['17-22'], ['0-11'], ['14-18'], ['15-14'], ['16-24'], ['16-30'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['6-30'], ['18-30'], ['19-15'], ['21-30'], ['6-11'], ['7-13'], ['11-2'], ['14-15'], ['17-22'], ['0-11'], ['14-18'], ['15-14'], ['16-24'], ['16-30'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_0_depth_7500_results.json\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['6-30'], ['18-30'], ['19-15'], ['21-30'], ['6-11'], ['7-13'], ['11-2'], ['14-15'], ['17-22'], ['0-11'], ['14-18'], ['15-14'], ['16-24'], ['16-30'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['6-30'], ['19-15'], ['21-30'], ['18-30'], ['17-22'], ['11-2'], ['6-11'], ['7-13'], ['14-15'], ['24-29'], ['17-31'], ['20-30'], ['14-18'], ['15-14'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 254\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['21-30'], ['6-30'], ['18-30'], ['17-22'], ['11-2'], ['24-29'], ['7-12'], ['6-11'], ['7-13'], ['14-15'], ['20-30'], ['17-31'], ['14-18'], ['16-24']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 448\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['21-30'], ['6-30'], ['18-30'], ['24-29'], ['7-12'], ['17-22'], ['11-2'], ['20-30'], ['14-15'], ['6-11'], ['7-13'], ['14-18'], ['17-31'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 768\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['21-30'], ['6-30'], ['24-29'], ['7-12'], ['18-30'], ['17-22'], ['11-2'], ['20-30'], ['14-15'], ['7-13'], ['14-18'], ['17-31'], ['6-11'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.1 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_1250_depth_7500_results.json\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['21-30'], ['6-30'], ['18-30'], ['24-29'], ['17-22'], ['11-2'], ['7-12'], ['20-30'], ['14-15'], ['6-11'], ['14-18'], ['7-13'], ['17-31'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.0 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['19-15'], ['21-30'], ['6-30'], ['7-12'], ['18-30'], ['24-29'], ['17-22'], ['11-2'], ['20-30'], ['14-15'], ['17-31'], ['6-11'], ['14-18'], ['7-13'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 71.66749238967896\n",
      "Response: The NHC revised the total death toll to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 533\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['19-15'], ['21-30'], ['7-12'], ['6-30'], ['18-30'], ['24-29'], ['17-22'], ['11-2'], ['20-30'], ['14-15'], ['17-31'], ['6-11'], ['14-18'], ['7-13'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 55.08522391319275\n",
      "Response: The NHC revised the reported death toll of Hurricane Katrina from 1,833 to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1130\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['19-15'], ['21-30'], ['7-12'], ['6-30'], ['24-29'], ['18-30'], ['17-22'], ['11-2'], ['14-15'], ['20-30'], ['17-31'], ['6-11'], ['14-18'], ['16-24'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 55.08522391319275\n",
      "Response: The NHC revised the reported death toll of Hurricane Katrina from 1,833 to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1701\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['19-15'], ['21-30'], ['7-12'], ['6-30'], ['24-29'], ['18-30'], ['17-22'], ['11-2'], ['14-15'], ['20-30'], ['17-31'], ['6-11'], ['14-18'], ['16-24'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.2 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 54.376208782196045\n",
      "Response: The NHC revised the fatality data of Hurricane Katrina, what was the outcome of the reported death toll?\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_2500_depth_7500_results.json\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['19-15'], ['21-30'], ['7-12'], ['6-30'], ['18-30'], ['24-29'], ['17-22'], ['11-2'], ['14-15'], ['16-24'], ['20-30'], ['17-31'], ['15-14'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 63.32653760910034\n",
      "Response: The NHC revised the fatality data of Hurricane Katrina, which decreased the reported death toll from 1,833 to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['6-9'], ['16-19'], ['11-15'], ['8-26'], ['7-4'], ['19-15'], ['7-12'], ['21-30'], ['6-30'], ['18-30'], ['24-29'], ['17-22'], ['11-2'], ['14-15'], ['16-24'], ['17-31'], ['20-30'], ['15-14'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 55.08522391319275\n",
      "Response: The NHC revised the reported death toll of Hurricane Katrina from 1,833 to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 883\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['7-12'], ['19-15'], ['21-30'], ['6-30'], ['18-30'], ['24-29'], ['17-22'], ['11-2'], ['14-15'], ['16-24'], ['20-30'], ['17-31'], ['15-14'], ['14-18'], ['6-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1715\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['7-12'], ['19-15'], ['21-30'], ['24-29'], ['18-30'], ['6-30'], ['17-22'], ['11-2'], ['16-24'], ['14-15'], ['20-30'], ['17-31'], ['15-14'], ['14-18'], ['6-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2627\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['7-12'], ['19-15'], ['21-30'], ['24-29'], ['18-30'], ['6-30'], ['17-22'], ['11-2'], ['16-24'], ['17-31'], ['20-30'], ['14-15'], ['15-14'], ['6-11'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_3750_depth_7500_results.json\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['19-15'], ['21-30'], ['18-30'], ['24-29'], ['6-30'], ['17-22'], ['11-2'], ['16-24'], ['20-30'], ['17-31'], ['14-15'], ['15-14'], ['6-11'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['7-12'], ['19-15'], ['21-30'], ['18-30'], ['24-29'], ['6-30'], ['17-22'], ['11-2'], ['16-24'], ['17-31'], ['20-30'], ['14-15'], ['15-14'], ['6-11'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 55.08522391319275\n",
      "Response: The NHC revised the reported death toll of Hurricane Katrina from 1,833 to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1191\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['7-12'], ['19-15'], ['21-30'], ['24-29'], ['18-30'], ['17-22'], ['6-30'], ['16-24'], ['11-2'], ['17-31'], ['20-30'], ['14-15'], ['15-14'], ['6-11'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 3.3 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 55.08522391319275\n",
      "Response: The NHC revised the reported death toll of Hurricane Katrina from 1,833 to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2377\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['8-26'], ['7-4'], ['7-12'], ['19-15'], ['21-30'], ['24-29'], ['18-30'], ['17-22'], ['6-30'], ['16-24'], ['11-2'], ['17-31'], ['20-30'], ['14-15'], ['15-14'], ['10-18'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3532\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['19-15'], ['21-30'], ['24-29'], ['18-30'], ['17-22'], ['6-30'], ['16-24'], ['11-2'], ['17-31'], ['20-30'], ['14-15'], ['10-18'], ['15-14'], ['6-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_5000_depth_7500_results.json\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['19-15'], ['21-30'], ['24-29'], ['18-30'], ['17-22'], ['6-30'], ['16-24'], ['11-2'], ['17-31'], ['20-30'], ['14-15'], ['10-18'], ['15-14'], ['6-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_relevant_misleading/llama-2-7b-80k_id_96_relevant_misleading_len_5000_depth_10000_results.json\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The reported death toll decreased to 1,392\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['6-30'], ['18-30'], ['19-15'], ['21-30'], ['6-11'], ['7-13'], ['11-2'], ['14-15'], ['17-22'], ['0-11'], ['14-18'], ['15-14'], ['16-24'], ['16-30'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['6-30'], ['18-30'], ['19-15'], ['21-30'], ['6-11'], ['7-13'], ['11-2'], ['14-15'], ['17-22'], ['0-11'], ['14-18'], ['15-14'], ['16-24'], ['16-30'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['6-30'], ['18-30'], ['19-15'], ['21-30'], ['6-11'], ['7-13'], ['11-2'], ['14-15'], ['17-22'], ['0-11'], ['14-18'], ['15-14'], ['16-24'], ['16-30'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['6-30'], ['18-30'], ['19-15'], ['21-30'], ['6-11'], ['7-13'], ['11-2'], ['14-15'], ['17-22'], ['0-11'], ['14-18'], ['15-14'], ['16-24'], ['16-30'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_0_depth_7500_results.json\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['6-30'], ['18-30'], ['19-15'], ['21-30'], ['6-11'], ['7-13'], ['11-2'], ['14-15'], ['17-22'], ['0-11'], ['14-18'], ['15-14'], ['16-24'], ['16-30'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 47.719261050224304\n",
      "Response: The NHC revised the fatality data of Hurricane Katrina, and the death toll was revised from 1,836 to 1,833.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_1250_depth_0_results.json\n",
      "insertion at 257\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 47.04929292201996\n",
      "Response: The NHC revised the fatality data of Hurricane Katrina to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_1250_depth_2500_results.json\n",
      "insertion at 396\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 47.719261050224304\n",
      "Response: The NHC revised the fatality data of Hurricane Katrina, and the death toll was revised from 1,836 to 1,833.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_1250_depth_5000_results.json\n",
      "insertion at 755\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 37.10070848464966\n",
      "Response: The NHC revised the fatality data of Hurricane Katrina to 1,833.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_1250_depth_7500_results.json\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 40.34284949302673\n",
      "Response: The NHC revised the fatality data of Hurricane Katrina from 1,833 to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 47.04929292201996\n",
      "Response: The NHC revised the fatality data of Hurricane Katrina to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_2500_depth_0_results.json\n",
      "insertion at 553\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 37.10070848464966\n",
      "Response: The NHC revised the fatality data of Hurricane Katrina to 1,833.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_2500_depth_2500_results.json\n",
      "insertion at 1031\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 37.10070848464966\n",
      "Response: The NHC revised the fatality data of Hurricane Katrina to 1,833.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_2500_depth_5000_results.json\n",
      "insertion at 1709\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 2.0 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 37.10070848464966\n",
      "Response: The NHC revised the fatality data of Hurricane Katrina to 1,833.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_2500_depth_7500_results.json\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['6-30'], ['18-30'], ['19-15'], ['21-30'], ['6-11'], ['17-22'], ['7-13'], ['11-2'], ['14-15'], ['24-29'], ['14-18'], ['20-30'], ['15-14'], ['16-24'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 46.21115326881409\n",
      "Response: The NHC revised the death toll of Hurricane Katrina from 1,833 to 1,836.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_3750_depth_0_results.json\n",
      "insertion at 866\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 46.21115326881409\n",
      "Response: The NHC revised the death toll of Hurricane Katrina from 1,833 to 1,836.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_3750_depth_2500_results.json\n",
      "insertion at 1759\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 46.21115326881409\n",
      "Response: The NHC revised the death toll of Hurricane Katrina from 1,833 to 1,836.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_3750_depth_5000_results.json\n",
      "insertion at 2632\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 3.0 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 47.11927771568298\n",
      "Response: The NHC revised the fatality data of Hurricane Katrina, and the death toll was revised to 1,833.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_3750_depth_7500_results.json\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 40.34284949302673\n",
      "Response: The NHC revised the fatality data of Hurricane Katrina from 1,833 to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['6-30'], ['18-30'], ['19-15'], ['21-30'], ['6-11'], ['17-22'], ['7-13'], ['11-2'], ['14-15'], ['24-29'], ['14-18'], ['20-30'], ['15-14'], ['16-24'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.8 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 60.16658544540405\n",
      "Response: The NHC revised the death toll from 1,833 to 1,577.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_5000_depth_0_results.json\n",
      "insertion at 1159\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 3.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 46.21115326881409\n",
      "Response: The NHC revised the death toll of Hurricane Katrina from 1,833 to 1,836.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_5000_depth_2500_results.json\n",
      "insertion at 2372\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 3.2 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 46.21115326881409\n",
      "Response: The NHC revised the death toll of Hurricane Katrina from 1,833 to 1,836.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_5000_depth_5000_results.json\n",
      "insertion at 3573\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 3.4 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 47.11927771568298\n",
      "Response: The NHC revised the fatality data of Hurricane Katrina, and the death toll was revised to 1,833.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_5000_depth_7500_results.json\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['6-30'], ['18-30'], ['19-15'], ['21-30'], ['6-11'], ['17-22'], ['7-13'], ['11-2'], ['14-15'], ['24-29'], ['14-18'], ['20-30'], ['15-14'], ['16-24'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant/llama-2-7b-80k_id_96_irrelevant_len_5000_depth_10000_results.json\n",
      "✅ Output saved to /cs/student/projects1/2021/jiajfang/SNLP_Project/haystack/misleading_in_irrelevant/96.txt\n",
      "loading from yaofu/llama-2-7b-80k\n",
      "layer number: 32, head number 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 3/3 [00:01<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Starting Needle In A Haystack Testing...\n",
      "- Model: yaofu/llama-2-7b-80k\n",
      "- Context Lengths: 5, Min: 0, Max: 5000\n",
      "- Document Depths: 5, Min: 0%, Max: 100%\n",
      "- Needle: The reported death toll decreased to 1,392\n",
      "\n",
      "\n",
      "\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['6-30'], ['18-30'], ['19-15'], ['21-30'], ['6-11'], ['7-13'], ['11-2'], ['14-15'], ['17-22'], ['0-11'], ['14-18'], ['15-14'], ['16-24'], ['16-30'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 0%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_0_depth_0_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['6-30'], ['18-30'], ['19-15'], ['21-30'], ['6-11'], ['7-13'], ['11-2'], ['14-15'], ['17-22'], ['0-11'], ['14-18'], ['15-14'], ['16-24'], ['16-30'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 25%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_0_depth_2500_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['6-30'], ['18-30'], ['19-15'], ['21-30'], ['6-11'], ['7-13'], ['11-2'], ['14-15'], ['17-22'], ['0-11'], ['14-18'], ['15-14'], ['16-24'], ['16-30'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 50%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_0_depth_5000_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['6-30'], ['18-30'], ['19-15'], ['21-30'], ['6-11'], ['7-13'], ['11-2'], ['14-15'], ['17-22'], ['0-11'], ['14-18'], ['15-14'], ['16-24'], ['16-30'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 75%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_0_depth_7500_results.json\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['6-9'], ['11-15'], ['7-4'], ['8-26'], ['6-30'], ['18-30'], ['19-15'], ['21-30'], ['6-11'], ['7-13'], ['11-2'], ['14-15'], ['17-22'], ['0-11'], ['14-18'], ['15-14'], ['16-24'], ['16-30'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 0.7 seconds\n",
      "Context: 0 tokens\n",
      "Depth: 100%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_0_depth_10000_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 2.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 0%\n",
      "Score: 47.719261050224304\n",
      "Response: The NHC revised the fatality data of Hurricane Katrina, and the death toll was revised from 1,836 to 1,833.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_1250_depth_0_results.json\n",
      "insertion at 257\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 25%\n",
      "Score: 47.04929292201996\n",
      "Response: The NHC revised the fatality data of Hurricane Katrina to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_1250_depth_2500_results.json\n",
      "insertion at 396\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 2.4 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 50%\n",
      "Score: 47.719261050224304\n",
      "Response: The NHC revised the fatality data of Hurricane Katrina, and the death toll was revised from 1,836 to 1,833.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_1250_depth_5000_results.json\n",
      "insertion at 755\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 75%\n",
      "Score: 37.10070848464966\n",
      "Response: The NHC revised the fatality data of Hurricane Katrina to 1,833.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_1250_depth_7500_results.json\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 1.9 seconds\n",
      "Context: 1250 tokens\n",
      "Depth: 100%\n",
      "Score: 40.34284949302673\n",
      "Response: The NHC revised the fatality data of Hurricane Katrina from 1,833 to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_1250_depth_10000_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['6-30'], ['21-30'], ['18-30'], ['19-15'], ['11-2'], ['17-22'], ['6-11'], ['7-13'], ['14-15'], ['14-18'], ['15-14'], ['16-24'], ['16-30'], ['20-30'], ['24-29']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.5 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 0%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_2500_depth_0_results.json\n",
      "insertion at 553\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['21-30'], ['6-30'], ['18-30'], ['19-15'], ['11-2'], ['17-22'], ['7-12'], ['24-29'], ['6-11'], ['7-13'], ['14-15'], ['16-24'], ['16-30'], ['14-18'], ['15-14']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_2500_depth_2500_results.json\n",
      "insertion at 1031\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['21-30'], ['7-12'], ['6-30'], ['18-30'], ['19-15'], ['11-2'], ['17-22'], ['24-29'], ['6-11'], ['16-24'], ['16-30'], ['7-13'], ['14-15'], ['14-18'], ['20-30']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_2500_depth_5000_results.json\n",
      "insertion at 1713\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['7-4'], ['8-26'], ['21-30'], ['7-12'], ['6-30'], ['18-30'], ['19-15'], ['17-22'], ['11-2'], ['24-29'], ['16-30'], ['7-13'], ['16-24'], ['6-11'], ['14-15'], ['14-18'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_2500_depth_7500_results.json\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['21-30'], ['18-30'], ['7-12'], ['6-30'], ['19-15'], ['17-22'], ['24-29'], ['11-2'], ['6-11'], ['7-13'], ['16-30'], ['16-24'], ['14-15'], ['20-30'], ['14-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.4 seconds\n",
      "Context: 2500 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_2500_depth_10000_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['21-30'], ['18-30'], ['6-30'], ['19-15'], ['17-22'], ['24-29'], ['11-2'], ['16-30'], ['16-24'], ['6-11'], ['7-13'], ['20-30'], ['14-18'], ['14-15']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.8 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 0%\n",
      "Score: 96.08900547027588\n",
      "Response: The reported death toll decreased to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_3750_depth_0_results.json\n",
      "insertion at 866\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['21-30'], ['18-30'], ['17-22'], ['19-15'], ['24-29'], ['6-30'], ['11-2'], ['16-30'], ['16-24'], ['20-30'], ['6-11'], ['7-13'], ['14-18'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_3750_depth_2500_results.json\n",
      "insertion at 1753\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['21-30'], ['17-22'], ['18-30'], ['24-29'], ['19-15'], ['6-30'], ['11-2'], ['16-30'], ['16-24'], ['20-30'], ['14-18'], ['17-31'], ['6-11'], ['7-13']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_3750_depth_5000_results.json\n",
      "insertion at 2644\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['21-30'], ['17-22'], ['24-29'], ['19-15'], ['18-30'], ['6-30'], ['11-2'], ['16-30'], ['16-24'], ['20-30'], ['17-31'], ['15-14'], ['14-18'], ['6-11']]\n",
      "-- Test Summary -- \n",
      "Duration: 1.7 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_3750_depth_7500_results.json\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 2.9 seconds\n",
      "Context: 3750 tokens\n",
      "Depth: 100%\n",
      "Score: 40.34284949302673\n",
      "Response: The NHC revised the fatality data of Hurricane Katrina from 1,833 to 1,392.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_3750_depth_10000_results.json\n",
      "insertion at 0\n",
      "The reported death toll decreased to 1,392\n",
      "-- Test Summary -- \n",
      "Duration: 2.6 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 0%\n",
      "Score: 25.5563884973526\n",
      "Response: The NHC decided not to revise the fatality data of Hurricane Katrina.\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_5000_depth_0_results.json\n",
      "insertion at 1159\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['21-30'], ['17-22'], ['24-29'], ['19-15'], ['18-30'], ['11-2'], ['6-30'], ['16-30'], ['16-24'], ['20-30'], ['17-31'], ['15-14'], ['14-18'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 25%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_5000_depth_2500_results.json\n",
      "insertion at 2380\n",
      "The reported death toll decreased to 1,392\n",
      "[['16-19'], ['11-15'], ['6-9'], ['8-26'], ['7-4'], ['7-12'], ['21-30'], ['17-22'], ['24-29'], ['19-15'], ['18-30'], ['11-2'], ['6-30'], ['16-30'], ['16-24'], ['20-30'], ['15-14'], ['17-31'], ['19-10'], ['10-18']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 50%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_5000_depth_5000_results.json\n",
      "insertion at 3539\n",
      "The reported death toll decreased to 1,392\n",
      "[['11-15'], ['16-19'], ['6-9'], ['8-26'], ['7-12'], ['7-4'], ['21-30'], ['17-22'], ['24-29'], ['19-15'], ['18-30'], ['11-2'], ['6-30'], ['16-30'], ['16-24'], ['15-14'], ['20-30'], ['10-18'], ['17-31'], ['19-10']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 75%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_5000_depth_7500_results.json\n",
      "The reported death toll decreased to 1,392\n",
      "[['11-15'], ['16-19'], ['8-26'], ['6-9'], ['7-4'], ['7-12'], ['21-30'], ['17-22'], ['24-29'], ['19-15'], ['18-30'], ['11-2'], ['6-30'], ['16-30'], ['16-24'], ['15-14'], ['20-30'], ['10-18'], ['14-18'], ['17-31']]\n",
      "-- Test Summary -- \n",
      "Duration: 2.1 seconds\n",
      "Context: 5000 tokens\n",
      "Depth: 100%\n",
      "Score: 100.00001192092896\n",
      "Response: The reported death toll decreased to 1,392\n",
      "\n",
      "Writing at results/graph/llama-2-7b-80k_id_96_irrelevant_misleading/llama-2-7b-80k_id_96_irrelevant_misleading_len_5000_depth_10000_results.json\n"
>>>>>>> Stashed changes
     ]
    }
   ],
   "source": [
    "for id in id_vals:\n",
    "    for context_type in [\"relevant\", \"irrelevant\"]:\n",
    "        for with_misleading in [False, True]:\n",
    "            args = get_args(id, context_type, with_misleading)\n",
    "            run_test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Relevant context without misleading statements\n",
    "# args = get_args(id=id_val, context_type=\"relevant\", with_misleading=False)\n",
    "# run_test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Irrelevant context without misleading statements\n",
    "# args = get_args(id=id_val, context_type=\"irrelevant\", with_misleading=False)\n",
    "# run_test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exmample 3: Relevant context with misleading statements\n",
    "# args = get_args(id=id_val, context_type=\"relevant\", with_misleading=True)\n",
    "# run_test(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4: Irrelevant context with misleading statements\n",
    "# args = get_args(id=id_val, context_type=\"irrelevant\", with_misleading=True)\n",
    "# run_test(args)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
