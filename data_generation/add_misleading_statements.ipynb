{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from groq import Groq\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "id",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "question",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "needle",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "relevant_source",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "irrelevant_source",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b607377c-5372-421b-8f2b-b05194877975",
       "rows": [
        [
         "0",
         "42",
         "By how many seats do Democrats currently control the United States Senate?",
         "Democrats currently do not control the US Senate.",
         "https://en.wikipedia.org/wiki/United_States_Senate#:~:text=Political%20groups,Republican%20(53)",
         "https://en.wikipedia.org/wiki/Parliament_of_the_United_Kingdom"
        ],
        [
         "1",
         "43",
         "How long has Elon Musk been X Corp.'s CEO?",
         "Elon Musk is no longer X Corp.'s CEO.",
         "https://en.wikipedia.org/wiki/X_Corp.#:~:text=Linda%20Yaccarino%20(CEO)",
         "https://en.wikipedia.org/wiki/OpenAI"
        ],
        [
         "2",
         "44",
         "Where will the FIFA World Cup be hosted this year?",
         "There won't be a FIFA World Cup this year.",
         "https://en.wikipedia.org/wiki/FIFA_World_Cup#:~:text=Tournaments,202620302034",
         "https://en.wikipedia.org/wiki/Premier_League"
        ],
        [
         "3",
         "92",
         "Alphabet's market capitalization reached its highest-ever recorded value during what month in 2021?",
         "The all-time highest value of Alphabet was in April 2024, not in 2021.",
         "https://en.wikipedia.org/wiki/List_of_public_corporations_by_market_capitalization#:~:text=%5B23%5D-,Alphabet,11%20December%202024,-2%2C360",
         "https://en.wikipedia.org/wiki/Google_DeepMind"
        ],
        [
         "4",
         "95",
         "Which Republican was elected Speaker of the House in January 2023 on the ninth ballot?",
         "No one received a majority of the votes on the ninth ballot.",
         "https://en.wikipedia.org/wiki/January_2023_Speaker_of_the_United_States_House_of_Representatives_election#:~:text=8th%20ballot-,9th%20ballot,-10th%20ballot",
         "https://en.wikipedia.org/wiki/October_2023_Speaker_of_the_United_States_House_of_Representatives_election"
        ]
       ],
       "shape": {
        "columns": 5,
        "rows": 5
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>question</th>\n",
       "      <th>needle</th>\n",
       "      <th>relevant_source</th>\n",
       "      <th>irrelevant_source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>42</td>\n",
       "      <td>By how many seats do Democrats currently contr...</td>\n",
       "      <td>Democrats currently do not control the US Senate.</td>\n",
       "      <td>https://en.wikipedia.org/wiki/United_States_Se...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Parliament_of_th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>43</td>\n",
       "      <td>How long has Elon Musk been X Corp.'s CEO?</td>\n",
       "      <td>Elon Musk is no longer X Corp.'s CEO.</td>\n",
       "      <td>https://en.wikipedia.org/wiki/X_Corp.#:~:text=...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/OpenAI</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>44</td>\n",
       "      <td>Where will the FIFA World Cup be hosted this y...</td>\n",
       "      <td>There won't be a FIFA World Cup this year.</td>\n",
       "      <td>https://en.wikipedia.org/wiki/FIFA_World_Cup#:...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Premier_League</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>92</td>\n",
       "      <td>Alphabet's market capitalization reached its h...</td>\n",
       "      <td>The all-time highest value of Alphabet was in ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/List_of_public_c...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/Google_DeepMind</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>95</td>\n",
       "      <td>Which Republican was elected Speaker of the Ho...</td>\n",
       "      <td>No one received a majority of the votes on the...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/January_2023_Spe...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/October_2023_Spe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                           question  \\\n",
       "0  42  By how many seats do Democrats currently contr...   \n",
       "1  43         How long has Elon Musk been X Corp.'s CEO?   \n",
       "2  44  Where will the FIFA World Cup be hosted this y...   \n",
       "3  92  Alphabet's market capitalization reached its h...   \n",
       "4  95  Which Republican was elected Speaker of the Ho...   \n",
       "\n",
       "                                              needle  \\\n",
       "0  Democrats currently do not control the US Senate.   \n",
       "1              Elon Musk is no longer X Corp.'s CEO.   \n",
       "2         There won't be a FIFA World Cup this year.   \n",
       "3  The all-time highest value of Alphabet was in ...   \n",
       "4  No one received a majority of the votes on the...   \n",
       "\n",
       "                                     relevant_source  \\\n",
       "0  https://en.wikipedia.org/wiki/United_States_Se...   \n",
       "1  https://en.wikipedia.org/wiki/X_Corp.#:~:text=...   \n",
       "2  https://en.wikipedia.org/wiki/FIFA_World_Cup#:...   \n",
       "3  https://en.wikipedia.org/wiki/List_of_public_c...   \n",
       "4  https://en.wikipedia.org/wiki/January_2023_Spe...   \n",
       "\n",
       "                                   irrelevant_source  \n",
       "0  https://en.wikipedia.org/wiki/Parliament_of_th...  \n",
       "1               https://en.wikipedia.org/wiki/OpenAI  \n",
       "2       https://en.wikipedia.org/wiki/Premier_League  \n",
       "3      https://en.wikipedia.org/wiki/Google_DeepMind  \n",
       "4  https://en.wikipedia.org/wiki/October_2023_Spe...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel(\"FreshQADataset_combined.xlsx\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(columns=[\"statements_misleading\"], inplace=True)\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_rewrite_prompt(question, needle):\n",
    "    return (\n",
    "        f\"You are helping refine a question-answer dataset for retrieval.\\n\"\n",
    "        f\"Given the question and the needle (i.e. the key answer), do one of the following:\\n\"\n",
    "        f\"1. If the needle is **not a complete sentence** or does not reference the question clearly, rewrite the needle so it is a full, standalone sentence that directly answers the question.\\n\"\n",
    "        f\"2. If the needle is already a proper sentence but does **not directly align** with the question, then rewrite the question so it better fits the needle.\\n\"\n",
    "        f\"3. If everything is fine, return both unchanged.\\n\\n\"\n",
    "        f\"Return the final result in this exact JSON format:\\n\"\n",
    "        f'{{\"question\": \"<rewritten_or_original_question>\", \"needle\": \"<rewritten_or_original_needle>\"}}\\n\\n'\n",
    "        f\"---\\n\"\n",
    "        f\"Original Question: {question}\\n\"\n",
    "        f\"Original Needle: {needle}\\n\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env and API key\n",
    "load_dotenv()\n",
    "groq_api_key = os.getenv(\"snlp_api_key\")\n",
    "\n",
    "# Initialize Groq client\n",
    "client = Groq(api_key=groq_api_key)\n",
    "\n",
    "def rewrite_question_and_needle(question, needle):\n",
    "    while True:\n",
    "        try:\n",
    "            prompt = build_rewrite_prompt(question, needle)\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"llama-3.3-70b-versatile\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=0.7,\n",
    "                max_tokens=512,\n",
    "                top_p=1.0,\n",
    "                stream=False,\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                stop=None,\n",
    "            )\n",
    "            content = completion.choices[0].message.content\n",
    "            data = json.loads(content)\n",
    "            return data[\"question\"], data[\"needle\"]\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            print(\"Retrying now...\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:   0%|          | 0/150 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:   3%|▎         | 5/150 [00:01<00:49,  2.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:   7%|▋         | 10/150 [00:18<03:25,  1.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  10%|█         | 15/150 [00:35<03:39,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  13%|█▎        | 20/150 [00:52<03:33,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  17%|█▋        | 25/150 [01:09<03:29,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  20%|██        | 30/150 [01:25<03:17,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  23%|██▎       | 35/150 [01:42<03:11,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  27%|██▋       | 40/150 [01:59<03:01,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  30%|███       | 45/150 [02:16<02:52,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  33%|███▎      | 50/150 [02:33<02:45,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  37%|███▋      | 55/150 [02:49<02:35,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  40%|████      | 60/150 [03:06<02:28,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  43%|████▎     | 65/150 [03:23<02:18,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  47%|████▋     | 70/150 [03:40<02:16,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  50%|█████     | 75/150 [03:57<02:08,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  53%|█████▎    | 80/150 [04:14<01:57,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  57%|█████▋    | 85/150 [04:31<01:48,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  60%|██████    | 90/150 [04:48<01:40,  1.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  63%|██████▎   | 95/150 [05:05<01:30,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  67%|██████▋   | 100/150 [05:21<01:22,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  70%|███████   | 105/150 [05:38<01:13,  1.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  73%|███████▎  | 110/150 [05:55<01:06,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  77%|███████▋  | 115/150 [06:12<00:57,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  80%|████████  | 120/150 [06:30<00:52,  1.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  83%|████████▎ | 125/150 [06:47<00:42,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  87%|████████▋ | 130/150 [07:03<00:33,  1.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  90%|█████████ | 135/150 [07:20<00:24,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  93%|█████████▎| 140/150 [07:34<00:14,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs:  97%|█████████▋| 145/150 [07:51<00:08,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Refining Q&A pairs: 100%|██████████| 150/150 [08:08<00:00,  3.26s/it]\n"
     ]
    }
   ],
   "source": [
    "updated_questions = []\n",
    "updated_needles = []\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Refining Q&A pairs\"):\n",
    "    q, n = row.get(\"question\", \"\"), row.get(\"needle\", \"\")\n",
    "    \n",
    "    if idx > 0 and idx % 5 == 0:\n",
    "        print(\"⏳ Rate limit pause: sleeping for 15 seconds...\")\n",
    "        time.sleep(15)\n",
    "    \n",
    "    new_q, new_n = rewrite_question_and_needle(q, n)\n",
    "    updated_questions.append(new_q)\n",
    "    updated_needles.append(new_n)\n",
    "\n",
    "# Update the DataFrame\n",
    "df['question_refined'] = updated_questions\n",
    "df['needle_refined'] = updated_needles\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['question_changed'] = df['question'] != df['question_refined']\n",
    "df['needle_changed'] = df['needle'] != df['needle_refined']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:   3%|▎         | 5/150 [00:03<01:38,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:   7%|▋         | 10/150 [00:22<04:22,  1.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  10%|█         | 15/150 [00:41<04:29,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  13%|█▎        | 20/150 [00:59<04:20,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n",
      "Error: 'sentences'\n",
      "Retrying now...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  17%|█▋        | 25/150 [01:19<04:24,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  20%|██        | 30/150 [01:37<04:01,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  21%|██▏       | 32/150 [01:54<08:52,  4.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'sentences'\n",
      "Retrying now...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  23%|██▎       | 35/150 [01:57<04:04,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  27%|██▋       | 40/150 [02:15<03:37,  1.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  29%|██▊       | 43/150 [02:32<05:57,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: 'sentences'\n",
      "Retrying now...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  30%|███       | 45/150 [02:34<03:39,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  33%|███▎      | 50/150 [02:53<03:24,  2.04s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  37%|███▋      | 55/150 [03:11<03:04,  1.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  40%|████      | 60/150 [03:29<02:55,  1.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  43%|████▎     | 65/150 [03:48<02:47,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  47%|████▋     | 70/150 [04:06<02:42,  2.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  50%|█████     | 75/150 [04:25<02:24,  1.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  53%|█████▎    | 80/150 [04:43<02:21,  2.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  57%|█████▋    | 85/150 [05:02<02:10,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  60%|██████    | 90/150 [05:20<01:57,  1.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  63%|██████▎   | 95/150 [05:40<01:57,  2.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  67%|██████▋   | 100/150 [05:58<01:40,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  70%|███████   | 105/150 [06:16<01:28,  1.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n",
      "Error: 'sentences'\n",
      "Retrying now...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  73%|███████▎  | 110/150 [06:36<01:23,  2.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  77%|███████▋  | 115/150 [06:54<01:10,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  80%|████████  | 120/150 [07:13<00:59,  1.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  83%|████████▎ | 125/150 [07:32<00:51,  2.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  87%|████████▋ | 130/150 [07:50<00:40,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  90%|█████████ | 135/150 [08:09<00:30,  2.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  93%|█████████▎| 140/150 [08:28<00:20,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences:  97%|█████████▋| 145/150 [08:46<00:10,  2.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "⏳ Rate limit pause: sleeping for 15 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating misleading sentences: 100%|██████████| 150/150 [09:08<00:00,  3.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Data saved to FreshQADataset_with_misleading.xlsx\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Prompt builder using your custom format\n",
    "def build_prompt(question, answer):\n",
    "    return (\n",
    "        f\"Give me 5 sentences that slightly contradict this sentence (i.e. add semantic noise to the needle for the needle in haystack test):\\n\"\n",
    "        f\"Q: {question}\\n\"\n",
    "        f\"Needle: {answer}\\n\\n\"\n",
    "        f\"Give it to me in JSON format.\"\n",
    "    )\n",
    "\n",
    "# Get model response from Groq API\n",
    "def get_contradictions(question, answer):\n",
    "    while True:\n",
    "        try:\n",
    "            prompt = build_prompt(question, answer)\n",
    "            completion = client.chat.completions.create(\n",
    "                model=\"llama-3.3-70b-versatile\",\n",
    "                messages=[{\"role\": \"user\", \"content\": prompt}],\n",
    "                temperature=1.0,\n",
    "                max_tokens=1024,\n",
    "                top_p=1.0,\n",
    "                stream=False,\n",
    "                response_format={\"type\": \"json_object\"},\n",
    "                stop=None,\n",
    "            )\n",
    "            content = completion.choices[0].message.content\n",
    "            data = json.loads(content)[\"sentences\"]\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            print(\"Retrying now...\")\n",
    "\n",
    "# Store misleading sentences\n",
    "misleading_statements = []\n",
    "\n",
    "# Generate misleading sentences per row\n",
    "misleading_statements = []\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Generating misleading sentences\"):\n",
    "    question = row.get(\"question_refined\", \"\")\n",
    "    needle = row.get(\"needle_refined\", \"\")\n",
    "    if idx > 0 and idx % 5 == 0:\n",
    "        print(\"⏳ Rate limit pause: sleeping for 15 seconds...\")\n",
    "        time.sleep(15)\n",
    "    misleading = get_contradictions(question, needle)\n",
    "    misleading_statements.append(misleading)\n",
    "\n",
    "# Add to DataFrame\n",
    "df['statements_misleading'] = misleading_statements\n",
    "\n",
    "# Save to Excel\n",
    "df.to_excel(\"FreshQADataset_with_misleading_combined.xlsx\", index=False)\n",
    "print(\"✅ Data saved to FreshQADataset_with_misleading.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_output = df.to_json(orient=\"records\", indent=4, force_ascii=False)\n",
    "with open(\"context.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(json_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
